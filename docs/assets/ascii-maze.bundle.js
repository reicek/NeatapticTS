"use strict";
(() => {
  var __defProp = Object.defineProperty;
  var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
  var __getOwnPropNames = Object.getOwnPropertyNames;
  var __hasOwnProp = Object.prototype.hasOwnProperty;
  var __require = /* @__PURE__ */ ((x) => typeof require !== "undefined" ? require : typeof Proxy !== "undefined" ? new Proxy(x, {
    get: (a, b) => (typeof require !== "undefined" ? require : a)[b]
  }) : x)(function(x) {
    if (typeof require !== "undefined") return require.apply(this, arguments);
    throw Error('Dynamic require of "' + x + '" is not supported');
  });
  var __esm = (fn, res) => function __init() {
    return fn && (res = (0, fn[__getOwnPropNames(fn)[0]])(fn = 0)), res;
  };
  var __commonJS = (cb, mod) => function __require2() {
    return mod || (0, cb[__getOwnPropNames(cb)[0]])((mod = { exports: {} }).exports, mod), mod.exports;
  };
  var __export = (target, all) => {
    for (var name in all)
      __defProp(target, name, { get: all[name], enumerable: true });
  };
  var __copyProps = (to, from, except, desc) => {
    if (from && typeof from === "object" || typeof from === "function") {
      for (let key of __getOwnPropNames(from))
        if (!__hasOwnProp.call(to, key) && key !== except)
          __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });
    }
    return to;
  };
  var __toCommonJS = (mod) => __copyProps(__defProp({}, "__esModule", { value: true }), mod);

  // src/architecture/connection.ts
  var kGain, kGater, kOpt, kPlasticRate, Connection;
  var init_connection = __esm({
    "src/architecture/connection.ts"() {
      "use strict";
      init_node();
      kGain = Symbol("connGain");
      kGater = Symbol("connGater");
      kOpt = Symbol("connOptMoments");
      kPlasticRate = Symbol("connPlasticRate");
      Connection = class _Connection {
        /** The source (pre-synaptic) node supplying activation. */
        from;
        /** The target (post-synaptic) node receiving activation. */
        to;
        /** Scalar multiplier applied to the source activation (prior to gain modulation). */
        weight;
        /** Standard eligibility trace (e.g., for RTRL / policy gradient credit assignment). */
        eligibility;
        /** Last applied delta weight (used by classic momentum). */
        previousDeltaWeight;
        /** Accumulated (batched) delta weight awaiting an apply step. */
        totalDeltaWeight;
        /** Extended trace structure for modulatory / eligibility propagation algorithms. Parallel arrays for cache-friendly iteration. */
        xtrace;
        /** Unique historical marking (auto-increment) for evolutionary alignment. */
        innovation;
        // enabled handled via bitfield (see _flags) exposed through accessor (enumerability removed for slimming)
        // --- Optimizer moment states (virtualized via symbol-backed bag + accessors) ---
        // NOTE: Accessor implementations below manage a lazily-created non-enumerable object containing:
        // { firstMoment, secondMoment, gradientAccumulator, maxSecondMoment, infinityNorm, secondMomentum, lookaheadShadowWeight }
        /**
         * Packed state flags (private for future-proofing hidden class):
         * bit0 => enabled gene expression (1 = active)
         * bit1 => DropConnect active mask (1 = not dropped this forward pass)
         * bit2 => hasGater (1 = symbol field present)
         * bit3 => plastic (plasticityRate > 0)
         * bits4+ reserved.
         */
        _flags;
        // bit0 enabled, bit1 dcActive, bit2 hasGater, bit3 plastic
        /**
         * Construct a new connection between two nodes.
         *
         * @param from Source node.
         * @param to Target node.
         * @param weight Optional initial weight (default: small random in [-0.1, 0.1]).
         *
         * @example
         * const link = new Connection(nodeA, nodeB, 0.42);
         * link.enabled = false;     // disable during mutation
         * link.enabled = true;      // re-enable later
         */
        constructor(from, to, weight) {
          this.from = from;
          this.to = to;
          this.weight = weight ?? Math.random() * 0.2 - 0.1;
          this.eligibility = 0;
          this.previousDeltaWeight = 0;
          this.totalDeltaWeight = 0;
          this.xtrace = {
            nodes: [],
            values: []
          };
          this._flags = 3;
          this.innovation = _Connection._nextInnovation++;
        }
        /**
         * Serialize to a minimal JSON-friendly shape (used for saving genomes / networks).
         * Undefined indices are preserved as `undefined` to allow later resolution / remapping.
         *
         * @returns Object with node indices, weight, gain, gater index (if any), innovation id & enabled flag.
         * @example
         * const json = connection.toJSON();
         * // => { from: 0, to: 3, weight: 0.12, gain: 1, innovation: 57, enabled: true }
         */
        toJSON() {
          const json = {
            from: this.from.index ?? void 0,
            to: this.to.index ?? void 0,
            weight: this.weight,
            gain: this.gain,
            innovation: this.innovation,
            enabled: this.enabled
          };
          if (this._flags & 4) {
            const g = this[kGater];
            if (g && typeof g.index !== "undefined") json.gater = g.index;
          }
          return json;
        }
        /**
         * Deterministic Cantor pairing function for a (sourceNodeId, targetNodeId) pair.
         * Useful when you want a stable innovation id without relying on global mutable counters
         * (e.g., for hashing or reproducible experiments).
         *
         * NOTE: For large indices this can overflow 53-bit safe integer space; keep node indices reasonable.
         *
         * @param sourceNodeId Source node integer id / index.
         * @param targetNodeId Target node integer id / index.
         * @returns Unique non-negative integer derived from the ordered pair.
         * @see https://en.wikipedia.org/wiki/Pairing_function
         * @example
         * const id = Connection.innovationID(2, 5); // deterministic
         */
        static innovationID(sourceNodeId, targetNodeId) {
          return 0.5 * (sourceNodeId + targetNodeId) * (sourceNodeId + targetNodeId + 1) + targetNodeId;
        }
        static _nextInnovation = 1;
        /**
         * Reset the monotonic auto-increment innovation counter (used for newly constructed / pooled instances).
         * You normally only call this at the start of an experiment or when deserializing a full population.
         *
         * @param value New starting value (default 1).
         * @example
         * Connection.resetInnovationCounter();     // back to 1
         * Connection.resetInnovationCounter(1000); // start counting from 1000
         */
        static resetInnovationCounter(value = 1) {
          _Connection._nextInnovation = value;
        }
        // --- Simple object pool to reduce GC churn when connections are frequently created/removed ---
        static _pool = [];
        /**
         * Acquire a `Connection` from the pool (or construct new). Fields are fully reset & given
         * a fresh sequential `innovation` id. Prefer this in evolutionary algorithms that mutate
         * topology frequently to reduce GC pressure.
         *
         * @param from Source node.
         * @param to Target node.
         * @param weight Optional initial weight.
         * @returns Reinitialized connection instance.
         * @example
         * const conn = Connection.acquire(a, b);
         * // ... use conn ...
         * Connection.release(conn); // when permanently removed
         */
        static acquire(from, to, weight) {
          let c;
          if (_Connection._pool.length) {
            c = _Connection._pool.pop();
            c.from = from;
            c.to = to;
            c.weight = weight ?? Math.random() * 0.2 - 0.1;
            if (c[kGain] !== void 0) delete c[kGain];
            if (c[kGater] !== void 0) delete c[kGater];
            c._flags = 3;
            c.eligibility = 0;
            c.previousDeltaWeight = 0;
            c.totalDeltaWeight = 0;
            c.xtrace.nodes.length = 0;
            c.xtrace.values.length = 0;
            if (c[kOpt]) delete c[kOpt];
            c.innovation = _Connection._nextInnovation++;
          } else c = new _Connection(from, to, weight);
          return c;
        }
        /**
         * Return a `Connection` to the internal pool for later reuse. Do NOT use the instance again
         * afterward unless re-acquired (treat as surrendered). Optimizer / trace fields are not
         * scrubbed here (they're overwritten during `acquire`).
         *
         * @param conn The connection instance to recycle.
         */
        static release(conn) {
          _Connection._pool.push(conn);
        }
        /** Whether the gene (connection) is currently expressed (participates in forward pass). */
        get enabled() {
          return (this._flags & 1) !== 0;
        }
        set enabled(v) {
          this._flags = v ? this._flags | 1 : this._flags & ~1;
        }
        /** DropConnect active mask: 1 = not dropped (active), 0 = dropped for this stochastic pass. */
        get dcMask() {
          return (this._flags & 2) !== 0 ? 1 : 0;
        }
        set dcMask(v) {
          this._flags = v ? this._flags | 2 : this._flags & ~2;
        }
        /** Whether a gater node is assigned (modulates gain); true if the gater symbol field is present. */
        get hasGater() {
          return (this._flags & 4) !== 0;
        }
        /** Whether this connection participates in plastic adaptation (rate > 0). */
        get plastic() {
          return (this._flags & 8) !== 0;
        }
        set plastic(v) {
          if (v) this._flags |= 8;
          else this._flags &= ~8;
          if (!v && this[kPlasticRate] !== void 0)
            delete this[kPlasticRate];
        }
        // --- Virtualized gain property ---
        /**
         * Multiplicative modulation applied *after* weight. Default is `1` (neutral). We only store an
         * internal symbol-keyed property when the gain is non-neutral, reducing memory usage across
         * large populations where most connections are ungated.
         */
        get gain() {
          return this[kGain] === void 0 ? 1 : this[kGain];
        }
        set gain(v) {
          if (v === 1) {
            if (this[kGain] !== void 0) delete this[kGain];
          } else {
            this[kGain] = v;
          }
        }
        // --- Optimizer field accessors (prototype-level to avoid per-instance enumerable keys) ---
        _ensureOptBag() {
          let bag = this[kOpt];
          if (!bag) {
            bag = {};
            this[kOpt] = bag;
          }
          return bag;
        }
        _getOpt(k) {
          const bag = this[kOpt];
          return bag ? bag[k] : void 0;
        }
        _setOpt(k, v) {
          if (v === void 0) {
            const bag = this[kOpt];
            if (bag) delete bag[k];
          } else {
            this._ensureOptBag()[k] = v;
          }
        }
        /** First moment estimate (Adam / AdamW) (was opt_m). */
        get firstMoment() {
          return this._getOpt("firstMoment");
        }
        set firstMoment(v) {
          this._setOpt("firstMoment", v);
        }
        /** Second raw moment estimate (Adam family) (was opt_v). */
        get secondMoment() {
          return this._getOpt("secondMoment");
        }
        set secondMoment(v) {
          this._setOpt("secondMoment", v);
        }
        /** Generic gradient accumulator (RMSProp / AdaGrad) (was opt_cache). */
        get gradientAccumulator() {
          return this._getOpt("gradientAccumulator");
        }
        set gradientAccumulator(v) {
          this._setOpt("gradientAccumulator", v);
        }
        /** AMSGrad: Maximum of past second moment (was opt_vhat). */
        get maxSecondMoment() {
          return this._getOpt("maxSecondMoment");
        }
        set maxSecondMoment(v) {
          this._setOpt("maxSecondMoment", v);
        }
        /** Adamax: Exponential moving infinity norm (was opt_u). */
        get infinityNorm() {
          return this._getOpt("infinityNorm");
        }
        set infinityNorm(v) {
          this._setOpt("infinityNorm", v);
        }
        /** Secondary momentum (Lion variant) (was opt_m2). */
        get secondMomentum() {
          return this._getOpt("secondMomentum");
        }
        set secondMomentum(v) {
          this._setOpt("secondMomentum", v);
        }
        /** Lookahead: shadow (slow) weight parameter (was _la_shadowWeight). */
        get lookaheadShadowWeight() {
          return this._getOpt("lookaheadShadowWeight");
        }
        set lookaheadShadowWeight(v) {
          this._setOpt("lookaheadShadowWeight", v);
        }
        // --- Virtualized gater property (non-enumerable) ---
        /** Optional gating node whose activation can modulate effective weight (symbol-backed). */
        get gater() {
          return (this._flags & 4) !== 0 ? this[kGater] : null;
        }
        set gater(node) {
          if (node === null) {
            if ((this._flags & 4) !== 0) {
              this._flags &= ~4;
              if (this[kGater] !== void 0) delete this[kGater];
            }
          } else {
            this[kGater] = node;
            this._flags |= 4;
          }
        }
        // --- Plasticity rate (virtualized) ---
        /** Per-connection plasticity / learning rate (0 means non-plastic). Setting >0 marks plastic flag. */
        get plasticityRate() {
          return this[kPlasticRate] === void 0 ? 0 : this[kPlasticRate];
        }
        set plasticityRate(v) {
          if (v === void 0 || v === 0) {
            if (this[kPlasticRate] !== void 0)
              delete this[kPlasticRate];
            this._flags &= ~8;
          } else {
            this[kPlasticRate] = v;
            this._flags |= 8;
          }
        }
        /** Convenience alias for DropConnect mask with clearer naming. */
        get dropConnectActiveMask() {
          return this.dcMask;
        }
        set dropConnectActiveMask(v) {
          this.dcMask = v;
        }
      };
    }
  });

  // src/config.ts
  var config;
  var init_config = __esm({
    "src/config.ts"() {
      "use strict";
      config = {
        warnings: false,
        // emit runtime guidance
        float32Mode: false,
        // numeric precision mode
        deterministicChainMode: false,
        // deep path test flag (ADD_NODE determinism)
        enableGatingTraces: true,
        // advanced gating trace infra
        enableNodePooling: false,
        // experimental node instance pooling
        enableSlabArrayPooling: false
        // experimental slab typed array pooling
        // slabPoolMaxPerKey: 4,        // optional override for per-key slab retention cap (default internal 4)
        // browserSlabChunkTargetMs: 3, // example: aim for ~3ms per async slab slice in Browser
        // poolMaxPerBucket: 256,     // example memory cap override
        // poolPrewarmCount: 2,       // example prewarm override
      };
    }
  });

  // src/neat/neat.constants.ts
  var neat_constants_exports = {};
  __export(neat_constants_exports, {
    EPSILON: () => EPSILON,
    EXTRA_CONNECTION_PROBABILITY: () => EXTRA_CONNECTION_PROBABILITY,
    NORM_EPSILON: () => NORM_EPSILON,
    PROB_EPSILON: () => PROB_EPSILON
  });
  var EPSILON, PROB_EPSILON, NORM_EPSILON, EXTRA_CONNECTION_PROBABILITY;
  var init_neat_constants = __esm({
    "src/neat/neat.constants.ts"() {
      "use strict";
      EPSILON = 1e-9;
      PROB_EPSILON = 1e-15;
      NORM_EPSILON = 1e-5;
      EXTRA_CONNECTION_PROBABILITY = 0.5;
    }
  });

  // src/methods/cost.ts
  var Cost;
  var init_cost = __esm({
    "src/methods/cost.ts"() {
      "use strict";
      init_neat_constants();
      Cost = class {
        /**
         * Calculates the Cross Entropy error, commonly used for classification tasks.
         *
         * This function measures the performance of a classification model whose output is
         * a probability value between 0 and 1. Cross-entropy loss increases as the
         * predicted probability diverges from the actual label.
         *
         * It uses a small epsilon (PROB_EPSILON = 1e-15) to prevent `log(0)` which would result in `NaN`.
         * Output values are clamped to the range `[epsilon, 1 - epsilon]` for numerical stability.
         *
         * @see {@link https://en.wikipedia.org/wiki/Cross_entropy}
         * @param {number[]} targets - An array of target values, typically 0 or 1 for binary classification, or probabilities for soft labels.
         * @param {number[]} outputs - An array of output values from the network, representing probabilities (expected to be between 0 and 1).
         * @returns {number} The mean cross-entropy error over all samples.
         * @throws {Error} If the target and output arrays have different lengths.
         */
        static crossEntropy(targets, outputs) {
          let error = 0;
          const epsilon = PROB_EPSILON;
          if (targets.length !== outputs.length) {
            throw new Error("Target and output arrays must have the same length.");
          }
          for (let i = 0; i < outputs.length; i++) {
            const target = targets[i];
            const output = outputs[i];
            const clampedOutput = Math.max(epsilon, Math.min(1 - epsilon, output));
            if (target === 1) {
              error -= Math.log(clampedOutput);
            } else if (target === 0) {
              error -= Math.log(1 - clampedOutput);
            } else {
              error -= target * Math.log(clampedOutput) + (1 - target) * Math.log(1 - clampedOutput);
            }
          }
          return error / outputs.length;
        }
        /**
         * Softmax Cross Entropy for mutually exclusive multi-class outputs given raw (pre-softmax or arbitrary) scores.
         * Applies a numerically stable softmax to the outputs internally then computes -sum(target * log(prob)).
         * Targets may be soft labels and are expected to sum to 1 (will be re-normalized if not).
         */
        static softmaxCrossEntropy(targets, outputs) {
          if (targets.length !== outputs.length) {
            throw new Error("Target and output arrays must have the same length.");
          }
          const n = outputs.length;
          let tSum = 0;
          for (const t of targets) tSum += t;
          const normTargets = tSum > 0 ? targets.map((t) => t / tSum) : targets.slice();
          const max = Math.max(...outputs);
          const exps = outputs.map((o) => Math.exp(o - max));
          const sum = exps.reduce((a, b) => a + b, 0) || 1;
          const probs = exps.map((e) => e / sum);
          let loss = 0;
          const eps = PROB_EPSILON;
          for (let i = 0; i < n; i++) {
            const p = Math.min(1 - eps, Math.max(eps, probs[i]));
            const t = normTargets[i];
            loss -= t * Math.log(p);
          }
          return loss;
        }
        /**
         * Calculates the Mean Squared Error (MSE), a common loss function for regression tasks.
         *
         * MSE measures the average of the squares of the errors—that is, the average
         * squared difference between the estimated values and the actual value.
         * It is sensitive to outliers due to the squaring of the error terms.
         *
         * @see {@link https://en.wikipedia.org/wiki/Mean_squared_error}
         * @param {number[]} targets - An array of target numerical values.
         * @param {number[]} outputs - An array of output values from the network.
         * @returns {number} The mean squared error.
         * @throws {Error} If the target and output arrays have different lengths (implicitly via forEach).
         */
        static mse(targets, outputs) {
          if (targets.length !== outputs.length) {
            throw new Error("Target and output arrays must have the same length.");
          }
          let error = 0;
          outputs.forEach((output, outputIndex) => {
            error += Math.pow(targets[outputIndex] - output, 2);
          });
          return error / outputs.length;
        }
        /**
         * Calculates the Binary Error rate, often used as a simple accuracy metric for classification.
         *
         * This function calculates the proportion of misclassifications by comparing the
         * rounded network outputs (thresholded at 0.5) against the target labels.
         * It assumes target values are 0 or 1, and outputs are probabilities between 0 and 1.
         * Note: This is equivalent to `1 - accuracy` for binary classification.
         *
         * @param {number[]} targets - An array of target values, expected to be 0 or 1.
         * @param {number[]} outputs - An array of output values from the network, typically probabilities between 0 and 1.
         * @returns {number} The proportion of misclassified samples (error rate, between 0 and 1).
         * @throws {Error} If the target and output arrays have different lengths (implicitly via forEach).
         */
        static binary(targets, outputs) {
          if (targets.length !== outputs.length) {
            throw new Error("Target and output arrays must have the same length.");
          }
          let misses = 0;
          outputs.forEach((output, outputIndex) => {
            misses += Math.round(targets[outputIndex]) !== Math.round(output) ? 1 : 0;
          });
          return misses / outputs.length;
        }
        /**
         * Calculates the Mean Absolute Error (MAE), another common loss function for regression tasks.
         *
         * MAE measures the average of the absolute differences between predictions and actual values.
         * Compared to MSE, it is less sensitive to outliers because errors are not squared.
         *
         * @see {@link https://en.wikipedia.org/wiki/Mean_absolute_error}
         * @param {number[]} targets - An array of target numerical values.
         * @param {number[]} outputs - An array of output values from the network.
         * @returns {number} The mean absolute error.
         * @throws {Error} If the target and output arrays have different lengths (implicitly via forEach).
         */
        static mae(targets, outputs) {
          if (targets.length !== outputs.length) {
            throw new Error("Target and output arrays must have the same length.");
          }
          let error = 0;
          outputs.forEach((output, outputIndex) => {
            error += Math.abs(targets[outputIndex] - output);
          });
          return error / outputs.length;
        }
        /**
         * Calculates the Mean Absolute Percentage Error (MAPE).
         *
         * MAPE expresses the error as a percentage of the actual value. It can be useful
         * for understanding the error relative to the magnitude of the target values.
         * However, it has limitations: it's undefined when the target value is zero and
         * can be skewed by target values close to zero.
         *
         * @see {@link https://en.wikipedia.org/wiki/Mean_absolute_percentage_error}
         * @param {number[]} targets - An array of target numerical values. Should not contain zeros for standard MAPE.
         * @param {number[]} outputs - An array of output values from the network.
         * @returns {number} The mean absolute percentage error, expressed as a proportion (e.g., 0.1 for 10%).
         * @throws {Error} If the target and output arrays have different lengths (implicitly via forEach).
         */
        static mape(targets, outputs) {
          if (targets.length !== outputs.length) {
            throw new Error("Target and output arrays must have the same length.");
          }
          let error = 0;
          const epsilon = PROB_EPSILON;
          outputs.forEach((output, outputIndex) => {
            const target = targets[outputIndex];
            error += Math.abs(
              (target - output) / Math.max(Math.abs(target), epsilon)
            );
          });
          return error / outputs.length;
        }
        /**
         * Calculates the Mean Squared Logarithmic Error (MSLE).
         *
         * MSLE is often used in regression tasks where the target values span a large range
         * or when penalizing under-predictions more than over-predictions is desired.
         * It measures the squared difference between the logarithms of the predicted and actual values.
         * Uses `log(1 + x)` instead of `log(x)` for numerical stability and to handle inputs of 0.
         * Assumes both targets and outputs are non-negative.
         *
         * @see {@link https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/loss-functions/mean-squared-logarithmic-error}
         * @param {number[]} targets - An array of target numerical values (assumed >= 0).
         * @param {number[]} outputs - An array of output values from the network (assumed >= 0).
         * @returns {number} The mean squared logarithmic error.
         * @throws {Error} If the target and output arrays have different lengths (implicitly via forEach).
         */
        static msle(targets, outputs) {
          if (targets.length !== outputs.length) {
            throw new Error("Target and output arrays must have the same length.");
          }
          let error = 0;
          outputs.forEach((output, outputIndex) => {
            const target = targets[outputIndex];
            const logTarget = Math.log(Math.max(target, 0) + 1);
            const logOutput = Math.log(Math.max(output, 0) + 1);
            error += Math.pow(logTarget - logOutput, 2);
          });
          return error / outputs.length;
        }
        /**
         * Calculates the Mean Hinge loss, primarily used for "maximum-margin" classification,
         * most notably for Support Vector Machines (SVMs).
         *
         * Hinge loss is used for training classifiers. It penalizes predictions that are
         * not only incorrect but also those that are correct but not confident (i.e., close to the decision boundary).
         * Assumes target values are encoded as -1 or 1.
         *
         * @see {@link https://en.wikipedia.org/wiki/Hinge_loss}
         * @param {number[]} targets - An array of target values, expected to be -1 or 1.
         * @param {number[]} outputs - An array of output values from the network (raw scores, not necessarily probabilities).
         * @returns {number} The mean hinge loss.
         * @throws {Error} If the target and output arrays have different lengths (implicitly via forEach).
         */
        static hinge(targets, outputs) {
          if (targets.length !== outputs.length) {
            throw new Error("Target and output arrays must have the same length.");
          }
          let error = 0;
          outputs.forEach((output, outputIndex) => {
            const target = targets[outputIndex];
            error += Math.max(0, 1 - target * output);
          });
          return error / outputs.length;
        }
        /**
         * Calculates the Focal Loss, which is useful for addressing class imbalance in classification tasks.
         * Focal loss down-weights easy examples and focuses training on hard negatives.
         *
         * @see https://arxiv.org/abs/1708.02002
         * @param {number[]} targets - Array of target values (0 or 1 for binary, or probabilities for soft labels).
         * @param {number[]} outputs - Array of predicted probabilities (between 0 and 1).
         * @param {number} gamma - Focusing parameter (default 2).
         * @param {number} alpha - Balancing parameter (default 0.25).
         * @returns {number} The mean focal loss.
         */
        static focalLoss(targets, outputs, gamma = 2, alpha = 0.25) {
          let error = 0;
          const epsilon = PROB_EPSILON;
          if (targets.length !== outputs.length) {
            throw new Error("Target and output arrays must have the same length.");
          }
          for (let i = 0; i < outputs.length; i++) {
            const t = targets[i];
            const p = Math.max(epsilon, Math.min(1 - epsilon, outputs[i]));
            const pt = t === 1 ? p : 1 - p;
            const a = t === 1 ? alpha : 1 - alpha;
            error += -a * Math.pow(1 - pt, gamma) * Math.log(pt);
          }
          return error / outputs.length;
        }
        /**
         * Calculates the Cross Entropy with Label Smoothing.
         * Label smoothing prevents the model from becoming overconfident by softening the targets.
         *
         * @see https://arxiv.org/abs/1512.00567
         * @param {number[]} targets - Array of target values (0 or 1 for binary, or probabilities for soft labels).
         * @param {number[]} outputs - Array of predicted probabilities (between 0 and 1).
         * @param {number} smoothing - Smoothing factor (between 0 and 1, e.g., 0.1).
         * @returns {number} The mean cross-entropy loss with label smoothing.
         */
        static labelSmoothing(targets, outputs, smoothing = 0.1) {
          let error = 0;
          const epsilon = PROB_EPSILON;
          if (targets.length !== outputs.length) {
            throw new Error("Target and output arrays must have the same length.");
          }
          for (let i = 0; i < outputs.length; i++) {
            const t = targets[i] * (1 - smoothing) + 0.5 * smoothing;
            const p = Math.max(epsilon, Math.min(1 - epsilon, outputs[i]));
            error -= t * Math.log(p) + (1 - t) * Math.log(1 - p);
          }
          return error / outputs.length;
        }
      };
    }
  });

  // src/methods/rate.ts
  var Rate;
  var init_rate = __esm({
    "src/methods/rate.ts"() {
      "use strict";
      Rate = class {
        /**
         * Implements a fixed learning rate schedule.
         *
         * The learning rate remains constant throughout the entire training process.
         * This is the simplest schedule and serves as a baseline, but may not be
         * optimal for complex problems.
         *
         * @returns A function that takes the base learning rate and the current iteration number, and always returns the base learning rate.
         * @param baseRate The initial learning rate, which will remain constant.
         * @param iteration The current training iteration (unused in this method, but included for consistency).
         */
        static fixed() {
          const func = (baseRate, iteration) => {
            return baseRate;
          };
          return func;
        }
        /**
         * Implements a step decay learning rate schedule.
         *
         * The learning rate is reduced by a multiplicative factor (`gamma`)
         * at predefined intervals (`stepSize` iterations). This allows for
         * faster initial learning, followed by finer adjustments as training progresses.
         *
         * Formula: `learning_rate = baseRate * gamma ^ floor(iteration / stepSize)`
         *
         * @param gamma The factor by which the learning rate is multiplied at each step. Should be less than 1. Defaults to 0.9.
         * @param stepSize The number of iterations after which the learning rate decays. Defaults to 100.
         * @returns A function that calculates the decayed learning rate for a given iteration.
         * @param baseRate The initial learning rate.
         * @param iteration The current training iteration.
         */
        static step(gamma = 0.9, stepSize = 100) {
          const func = (baseRate, iteration) => {
            return Math.max(
              0,
              baseRate * Math.pow(gamma, Math.floor(iteration / stepSize))
            );
          };
          return func;
        }
        /**
         * Implements an exponential decay learning rate schedule.
         *
         * The learning rate decreases exponentially after each iteration, multiplying
         * by the decay factor `gamma`. This provides a smooth, continuous reduction
         * in the learning rate over time.
         *
         * Formula: `learning_rate = baseRate * gamma ^ iteration`
         *
         * @param gamma The decay factor applied at each iteration. Should be less than 1. Defaults to 0.999.
         * @returns A function that calculates the exponentially decayed learning rate for a given iteration.
         * @param baseRate The initial learning rate.
         * @param iteration The current training iteration.
         */
        static exp(gamma = 0.999) {
          const func = (baseRate, iteration) => {
            return baseRate * Math.pow(gamma, iteration);
          };
          return func;
        }
        /**
         * Implements an inverse decay learning rate schedule.
         *
         * The learning rate decreases as the inverse of the iteration number,
         * controlled by the decay factor `gamma` and exponent `power`. The rate
         * decreases more slowly over time compared to exponential decay.
         *
         * Formula: `learning_rate = baseRate / (1 + gamma * Math.pow(iteration, power))`
         *
         * @param gamma Controls the rate of decay. Higher values lead to faster decay. Defaults to 0.001.
         * @param power The exponent controlling the shape of the decay curve. Defaults to 2.
         * @returns A function that calculates the inversely decayed learning rate for a given iteration.
         * @param baseRate The initial learning rate.
         * @param iteration The current training iteration.
         */
        static inv(gamma = 1e-3, power = 2) {
          const func = (baseRate, iteration) => {
            return baseRate / (1 + gamma * Math.pow(iteration, power));
          };
          return func;
        }
        /**
         * Implements a Cosine Annealing learning rate schedule.
         *
         * This schedule varies the learning rate cyclically according to a cosine function.
         * It starts at the `baseRate` and smoothly anneals down to `minRate` over a
         * specified `period` of iterations, then potentially repeats. This can help
         * the model escape local minima and explore the loss landscape more effectively.
         * Often used with "warm restarts" where the cycle repeats.
         *
         * Formula: `learning_rate = minRate + 0.5 * (baseRate - minRate) * (1 + cos(pi * current_cycle_iteration / period))`
         *
         * @param period The number of iterations over which the learning rate anneals from `baseRate` to `minRate` in one cycle. Defaults to 1000.
         * @param minRate The minimum learning rate value at the end of a cycle. Defaults to 0.
         * @returns A function that calculates the learning rate for a given iteration based on the cosine annealing schedule.
         * @param baseRate The initial (maximum) learning rate for the cycle.
         * @param iteration The current training iteration.
         * @see {@link https://arxiv.org/abs/1608.03983 SGDR: Stochastic Gradient Descent with Warm Restarts} - The paper introducing this technique.
         */
        static cosineAnnealing(period = 1e3, minRate = 0) {
          const func = (baseRate, iteration) => {
            const currentCycleIteration = iteration % period;
            const cosineDecay = 0.5 * (1 + Math.cos(currentCycleIteration / period * Math.PI));
            return minRate + (baseRate - minRate) * cosineDecay;
          };
          return func;
        }
        /**
         * Cosine Annealing with Warm Restarts (SGDR style) where the cycle length can grow by a multiplier (tMult) after each restart.
         *
         * @param initialPeriod Length of the first cycle in iterations.
         * @param minRate Minimum learning rate at valley.
         * @param tMult Factor to multiply the period after each restart (>=1).
         */
        static cosineAnnealingWarmRestarts(initialPeriod = 1e3, minRate = 0, tMult = 1) {
          let period = initialPeriod;
          let cycleStart = 0;
          let cycleEnd = period;
          return (baseRate, iteration) => {
            while (iteration >= cycleEnd) {
              cycleStart = cycleEnd;
              period = Math.max(1, Math.round(period * tMult));
              cycleEnd = cycleStart + period;
            }
            const cyclePos = iteration - cycleStart;
            const cosineDecay = 0.5 * (1 + Math.cos(cyclePos / period * Math.PI));
            return minRate + (baseRate - minRate) * cosineDecay;
          };
        }
        /**
         * Linear Warmup followed by Linear Decay to an end rate.
         * Warmup linearly increases LR from near 0 up to baseRate over warmupSteps, then linearly decays to endRate at totalSteps.
         * Iterations beyond totalSteps clamp to endRate.
         *
         * @param totalSteps Total steps for full schedule (must be > 0).
         * @param warmupSteps Steps for warmup (< totalSteps). Defaults to 10% of totalSteps.
         * @param endRate Final rate at totalSteps.
         */
        static linearWarmupDecay(totalSteps, warmupSteps, endRate = 0) {
          if (totalSteps <= 0) throw new Error("totalSteps must be > 0");
          const warm = Math.min(
            warmupSteps ?? Math.max(1, Math.floor(totalSteps * 0.1)),
            totalSteps - 1
          );
          return (baseRate, iteration) => {
            if (iteration <= warm) {
              return baseRate * (iteration / Math.max(1, warm));
            }
            if (iteration >= totalSteps) return endRate;
            const decaySteps = totalSteps - warm;
            const progress = (iteration - warm) / decaySteps;
            return endRate + (baseRate - endRate) * (1 - progress);
          };
        }
        /**
         * ReduceLROnPlateau style scheduler (stateful closure) that monitors error signal (third argument if provided)
         * and reduces rate by 'factor' if no improvement beyond 'minDelta' for 'patience' iterations.
         * Cooldown prevents immediate successive reductions.
         * NOTE: Requires the training loop to call with signature (baseRate, iteration, lastError).
         */
        static reduceOnPlateau(options) {
          const {
            factor = 0.5,
            patience = 10,
            minDelta = 1e-4,
            cooldown = 0,
            minRate = 0,
            verbose = false
          } = options || {};
          let currentRate;
          let bestError;
          let lastImprovementIter = 0;
          let cooldownUntil = -1;
          return (baseRate, iteration, lastError) => {
            if (currentRate === void 0) currentRate = baseRate;
            if (lastError !== void 0) {
              if (bestError === void 0 || lastError < bestError - minDelta) {
                bestError = lastError;
                lastImprovementIter = iteration;
              } else if (iteration - lastImprovementIter >= patience && iteration >= cooldownUntil) {
                const newRate = Math.max(minRate, currentRate * factor);
                if (newRate < currentRate) {
                  currentRate = newRate;
                  cooldownUntil = iteration + cooldown;
                  lastImprovementIter = iteration;
                }
              }
            }
            return currentRate;
          };
        }
      };
    }
  });

  // src/methods/activation.ts
  var Activation, activation_default;
  var init_activation = __esm({
    "src/methods/activation.ts"() {
      "use strict";
      Activation = {
        /**
         * Logistic (Sigmoid) activation function.
         * Outputs values between 0 and 1. Commonly used in older network architectures
         * and for output layers in binary classification tasks.
         * @param {number} x - The input value.
         * @param {boolean} [derivate=false] - Whether to compute the derivative.
         * @returns {number} The result of the logistic function or its derivative.
         */
        logistic: (x, derivate = false) => {
          const fx = 1 / (1 + Math.exp(-x));
          return !derivate ? fx : fx * (1 - fx);
        },
        /**
         * Alias for Logistic (Sigmoid) activation function.
         * Outputs values between 0 and 1. Commonly used in older network architectures
         * and for output layers in binary classification tasks.
         * @param {number} x - The input value.
         * @param {boolean} [derivate=false] - Whether to compute the derivative.
         * @returns {number} The result of the logistic function or its derivative.
         */
        sigmoid: (x, derivate = false) => {
          const fx = 1 / (1 + Math.exp(-x));
          return !derivate ? fx : fx * (1 - fx);
        },
        /**
         * Hyperbolic tangent (tanh) activation function.
         * Outputs values between -1 and 1. Often preferred over logistic sigmoid in hidden layers
         * due to its zero-centered output, which can help with training convergence.
         * @param {number} x - The input value.
         * @param {boolean} [derivate=false] - Whether to compute the derivative.
         * @returns {number} The result of the tanh function or its derivative.
         */
        tanh: (x, derivate = false) => {
          return derivate ? 1 - Math.pow(Math.tanh(x), 2) : Math.tanh(x);
        },
        /**
         * Identity activation function (Linear).
         * Outputs the input value directly: f(x) = x.
         * Used when no non-linearity is desired, e.g., in output layers for regression tasks.
         * @param {number} x - The input value.
         * @param {boolean} [derivate=false] - Whether to compute the derivative.
         * @returns {number} The result of the identity function (x) or its derivative (1).
         */
        identity: (x, derivate = false) => {
          return derivate ? 1 : x;
        },
        /**
         * Step activation function (Binary Step).
         * Outputs 0 if the input is negative or zero, and 1 if the input is positive.
         * Rarely used in modern deep learning due to its zero derivative almost everywhere,
         * hindering gradient-based learning.
         * @param {number} x - The input value.
         * @param {boolean} [derivate=false] - Whether to compute the derivative.
         * @returns {number} The result of the step function (0 or 1) or its derivative (0).
         */
        step: (x, derivate = false) => {
          return derivate ? 0 : x > 0 ? 1 : 0;
        },
        /**
         * Rectified Linear Unit (ReLU) activation function.
         * Outputs the input if it's positive, and 0 otherwise: f(x) = max(0, x).
         * Widely used in deep learning due to its simplicity, computational efficiency,
         * and ability to mitigate the vanishing gradient problem.
         *
         * Note: The derivative at x=0 is ambiguous (theoretically undefined). Here, we return 0,
         * which is a common practical choice. If you need a different behavior, consider using a custom activation.
         *
         * @param {number} x - The input value.
         * @param {boolean} [derivate=false] - Whether to compute the derivative.
         * @returns {number} The result of the ReLU function or its derivative (0 or 1).
         */
        relu: (x, derivate = false) => {
          return derivate ? x > 0 ? 1 : 0 : x > 0 ? x : 0;
        },
        /**
         * Softsign activation function.
         * A smooth approximation of the sign function: f(x) = x / (1 + |x|).
         * Outputs values between -1 and 1.
         * @param {number} x - The input value.
         * @param {boolean} [derivate=false] - Whether to compute the derivative.
         * @returns {number} The result of the softsign function or its derivative.
         */
        softsign: (x, derivate = false) => {
          const d = 1 + Math.abs(x);
          return derivate ? 1 / Math.pow(d, 2) : x / d;
        },
        /**
         * Sinusoid activation function.
         * Uses the standard sine function: f(x) = sin(x).
         * Can be useful for tasks involving periodic patterns.
         * @param {number} x - The input value.
         * @param {boolean} [derivate=false] - Whether to compute the derivative.
         * @returns {number} The result of the sinusoid function or its derivative (cos(x)).
         */
        sinusoid: (x, derivate = false) => {
          return derivate ? Math.cos(x) : Math.sin(x);
        },
        /**
         * Gaussian activation function.
         * Uses the Gaussian (bell curve) function: f(x) = exp(-x^2).
         * Outputs values between 0 and 1. Sometimes used in radial basis function (RBF) networks.
         * @param {number} x - The input value.
         * @param {boolean} [derivate=false] - Whether to compute the derivative.
         * @returns {number} The result of the Gaussian function or its derivative.
         */
        gaussian: (x, derivate = false) => {
          const d = Math.exp(-Math.pow(x, 2));
          return derivate ? -2 * x * d : d;
        },
        /**
         * Bent Identity activation function.
         * A function that behaves linearly for large positive inputs but non-linearly near zero:
         * f(x) = (sqrt(x^2 + 1) - 1) / 2 + x.
         * @param {number} x - The input value.
         * @param {boolean} [derivate=false] - Whether to compute the derivative.
         * @returns {number} The result of the bent identity function or its derivative.
         */
        bentIdentity: (x, derivate = false) => {
          const d = Math.sqrt(Math.pow(x, 2) + 1);
          return derivate ? x / (2 * d) + 1 : (d - 1) / 2 + x;
        },
        /**
         * Bipolar activation function (Sign function).
         * Outputs -1 if the input is negative or zero, and 1 if the input is positive.
         * Similar to the Step function but with outputs -1 and 1.
         * @param {number} x - The input value.
         * @param {boolean} [derivate=false] - Whether to compute the derivative.
         * @returns {number} The result of the bipolar function (-1 or 1) or its derivative (0).
         */
        bipolar: (x, derivate = false) => {
          return derivate ? 0 : x > 0 ? 1 : -1;
        },
        /**
         * Bipolar Sigmoid activation function.
         * A scaled and shifted version of the logistic sigmoid, outputting values between -1 and 1:
         * f(x) = 2 * logistic(x) - 1 = (1 - exp(-x)) / (1 + exp(-x)).
         * This is equivalent to the hyperbolic tangent (tanh) function.
         * @param {number} x - The input value.
         * @param {boolean} [derivate=false] - Whether to compute the derivative.
         * @returns {number} The result of the bipolar sigmoid function or its derivative.
         * @see {@link Activation.tanh}
         */
        bipolarSigmoid: (x, derivate = false) => {
          const d = 2 / (1 + Math.exp(-x)) - 1;
          return derivate ? 1 / 2 * (1 + d) * (1 - d) : d;
        },
        /**
         * Hard Tanh activation function.
         * A computationally cheaper, piecewise linear approximation of the tanh function:
         * f(x) = max(-1, min(1, x)). Outputs values clamped between -1 and 1.
         * @param {number} x - The input value.
         * @param {boolean} [derivate=false] - Whether to compute the derivative.
         * @returns {number} The result of the hard tanh function or its derivative (0 or 1).
         */
        hardTanh: (x, derivate = false) => {
          return derivate ? x > -1 && x < 1 ? 1 : 0 : Math.max(-1, Math.min(1, x));
        },
        /**
         * Absolute activation function.
         * Outputs the absolute value of the input: f(x) = |x|.
         *
         * Note: The derivative at x=0 is ambiguous (theoretically undefined). Here, we return 1.
         * If you need a different behavior, consider using a custom activation.
         *
         * @param {number} x - The input value.
         * @param {boolean} [derivate=false] - Whether to compute the derivative.
         * @returns {number} The result of the absolute function or its derivative (sign of x).
         */
        absolute: (x, derivate = false) => {
          return derivate ? x < 0 ? -1 : 1 : Math.abs(x);
        },
        /**
         * Inverse activation function.
         * Outputs 1 minus the input: f(x) = 1 - x.
         * @param {number} x - The input value.
         * @param {boolean} [derivate=false] - Whether to compute the derivative.
         * @returns {number} The result of the inverse function or its derivative (-1).
         */
        inverse: (x, derivate = false) => {
          return derivate ? -1 : 1 - x;
        },
        /**
         * Scaled Exponential Linear Unit (SELU) activation function.
         *
         * SELU aims to induce self-normalizing properties, meaning the outputs of SELU units
         * automatically converge towards zero mean and unit variance.
         * f(x) = scale * (max(0, x) + min(0, alpha * (exp(x) - 1)))
         * Recommended for deep networks composed primarily of SELU units.
         *
         * @param {number} x - The input value.
         * @param {boolean} [derivate=false] - Whether to compute the derivative.
         * @returns {number} The result of the SELU function or its derivative.
         * @see {@link https://arxiv.org/abs/1706.02515} - Self-Normalizing Neural Networks paper
         * @see {@link https://github.com/wagenaartje/neataptic/wiki/Activation#selu} - Neataptic context
         */
        selu: (x, derivate = false) => {
          const alpha = 1.6732632423543772;
          const scale = 1.0507009873554805;
          const fx = x > 0 ? x : alpha * Math.exp(x) - alpha;
          return derivate ? x > 0 ? scale : (fx + alpha) * scale : fx * scale;
        },
        /**
         * Softplus activation function.
         * A smooth approximation of the ReLU function: f(x) = log(1 + exp(x)).
         * Always positive. Its derivative is the logistic sigmoid function.
         * This implementation includes checks for numerical stability to avoid overflow/underflow.
         * @param {number} x - The input value.
         * @param {boolean} [derivate=false] - Whether to compute the derivative.
         * @returns {number} The result of the softplus function or its derivative (logistic sigmoid).
         * @see {@link https://en.wikipedia.org/wiki/Rectifier_(neural_networks)#Softplus}
         */
        softplus: (x, derivate = false) => {
          const fx = 1 / (1 + Math.exp(-x));
          if (derivate) {
            return fx;
          } else {
            if (x > 30) {
              return x;
            } else if (x < -30) {
              return Math.exp(x);
            }
            return Math.max(0, x) + Math.log(1 + Math.exp(-Math.abs(x)));
          }
        },
        /**
         * Swish activation function (SiLU - Sigmoid Linear Unit).
         * A self-gated activation function: f(x) = x * logistic(x).
         * Often performs better than ReLU in deeper models.
         * @param {number} x - The input value.
         * @param {boolean} [derivate=false] - Whether to compute the derivative.
         * @returns {number} The result of the swish function or its derivative.
         * @see {@link https://arxiv.org/abs/1710.05941} - Swish paper
         */
        swish: (x, derivate = false) => {
          const sigmoid_x = 1 / (1 + Math.exp(-x));
          if (derivate) {
            const swish_x = x * sigmoid_x;
            return swish_x + sigmoid_x * (1 - swish_x);
          } else {
            return x * sigmoid_x;
          }
        },
        /**
         * Gaussian Error Linear Unit (GELU) activation function.
         * Smooth approximation of ReLU, often used in Transformer models.
         * f(x) = x * Φ(x), where Φ(x) is the standard Gaussian cumulative distribution function (CDF).
         * This implementation uses a common fast approximation of GELU.
         * @param {number} x - The input value.
         * @param {boolean} [derivate=false] - Whether to compute the derivative.
         * @returns {number} The result of the GELU function or its derivative.
         * @see {@link https://arxiv.org/abs/1606.08415}
         */
        gelu: (x, derivate = false) => {
          const cdf = 0.5 * (1 + Math.tanh(Math.sqrt(2 / Math.PI) * (x + 0.044715 * Math.pow(x, 3))));
          if (derivate) {
            const intermediate = Math.sqrt(2 / Math.PI) * (1 + 0.134145 * x * x);
            const sech_arg = Math.sqrt(2 / Math.PI) * (x + 0.044715 * Math.pow(x, 3));
            const sech_val = 1 / Math.cosh(sech_arg);
            const sech_sq = sech_val * sech_val;
            return cdf + x * 0.5 * intermediate * sech_sq;
          } else {
            return x * cdf;
          }
        },
        /**
         * Mish activation function.
         * A self-gated activation function similar to Swish: f(x) = x * tanh(softplus(x)).
         * Aims to provide better performance than ReLU and Swish in some cases.
         * @param {number} x - The input value.
         * @param {boolean} [derivate=false] - Whether to compute the derivative.
         * @returns {number} The result of the Mish function or its derivative.
         * @see {@link https://arxiv.org/abs/1908.08681}
         */
        mish: (x, derivate = false) => {
          let sp_x;
          if (x > 30) {
            sp_x = x;
          } else if (x < -30) {
            sp_x = Math.exp(x);
          } else {
            sp_x = Math.max(0, x) + Math.log(1 + Math.exp(-Math.abs(x)));
          }
          const tanh_sp_x = Math.tanh(sp_x);
          if (derivate) {
            const sigmoid_x = 1 / (1 + Math.exp(-x));
            const sech_sp_x = 1 / Math.cosh(sp_x);
            const sech_sq_sp_x = sech_sp_x * sech_sp_x;
            return tanh_sp_x + x * sech_sq_sp_x * sigmoid_x;
          } else {
            return x * tanh_sp_x;
          }
        }
      };
      activation_default = Activation;
    }
  });

  // src/methods/gating.ts
  var gating;
  var init_gating = __esm({
    "src/methods/gating.ts"() {
      "use strict";
      gating = {
        /**
         * Output Gating: The gating neuron(s) control the activation flowing *out*
         * of the connection's target neuron(s). The connection's weight remains static,
         * but the output signal from the target neuron is modulated by the gater's state.
         * @property {string} name - Identifier for the output gating method.
         */
        OUTPUT: {
          name: "OUTPUT"
        },
        /**
         * Input Gating: The gating neuron(s) control the activation flowing *into*
         * the connection's target neuron(s). The connection effectively transmits
         * `connection_weight * source_activation * gater_activation` to the target neuron.
         * @property {string} name - Identifier for the input gating method.
         */
        INPUT: {
          name: "INPUT"
        },
        /**
         * Self Gating: The gating neuron(s) directly modulate the *weight* or strength
         * of the connection itself. The connection's effective weight becomes dynamic,
         * influenced by the gater's activation state (`effective_weight = connection_weight * gater_activation`).
         * @property {string} name - Identifier for the self-gating method.
         */
        SELF: {
          name: "SELF"
        }
      };
    }
  });

  // src/methods/mutation.ts
  var mutation, mutation_default;
  var init_mutation = __esm({
    "src/methods/mutation.ts"() {
      "use strict";
      init_activation();
      mutation = {
        /**
         * Adds a new node to the network by splitting an existing connection.
         * The original connection is disabled, and two new connections are created:
         * one from the original source to the new node, and one from the new node
         * to the original target. This increases network complexity, potentially
         * allowing for more sophisticated computations.
         */
        ADD_NODE: {
          name: "ADD_NODE"
          /**
           * @see Instinct Algorithm - Section 3.1 Add Node Mutation
           */
        },
        /**
         * Removes a hidden node from the network. Connections to and from the
         * removed node are also removed. This simplifies the network topology.
         */
        SUB_NODE: {
          name: "SUB_NODE",
          /** If true, attempts to preserve gating connections associated with the removed node. */
          keep_gates: true
          /**
           * @see Instinct Algorithm - Section 3.7 Remove Node Mutation
           */
        },
        /**
         * Adds a new connection between two previously unconnected nodes.
         * This increases network connectivity, potentially creating new pathways
         * for information flow.
         */
        ADD_CONN: {
          name: "ADD_CONN"
          /**
           * @see Instinct Algorithm - Section 3.2 Add Connection Mutation
           */
        },
        /**
         * Removes an existing connection between two nodes.
         * This prunes the network, potentially removing redundant or detrimental pathways.
         */
        SUB_CONN: {
          name: "SUB_CONN"
          /**
           * @see Instinct Algorithm - Section 3.8 Remove Connection Mutation
           */
        },
        /**
         * Modifies the weight of an existing connection by adding a random value
         * or multiplying by a random factor. This fine-tunes the strength of
         * the connection.
         */
        MOD_WEIGHT: {
          name: "MOD_WEIGHT",
          /** Minimum value for the random modification factor/offset. */
          min: -1,
          /** Maximum value for the random modification factor/offset. */
          max: 1
          /**
           * @see Instinct Algorithm - Section 3.4 Modify Weight Mutation
           */
        },
        /**
         * Modifies the bias of a node (excluding input nodes) by adding a random value.
         * This adjusts the node's activation threshold, influencing its firing behavior.
         */
        MOD_BIAS: {
          name: "MOD_BIAS",
          /** Minimum value for the random modification offset. */
          min: -1,
          /** Maximum value for the random modification offset. */
          max: 1
          /**
           * @see Instinct Algorithm - Section 3.5 Modify Bias Mutation
           */
        },
        /**
         * Randomly changes the activation function of a node (excluding input nodes).
         * This allows nodes to specialize their response characteristics during evolution.
         */
        MOD_ACTIVATION: {
          name: "MOD_ACTIVATION",
          /** If true, allows mutation of activation functions in output nodes. */
          mutateOutput: true,
          /** A list of allowed activation functions to choose from during mutation. */
          allowed: [
            activation_default.logistic,
            activation_default.tanh,
            activation_default.relu,
            activation_default.identity,
            activation_default.step,
            activation_default.softsign,
            activation_default.sinusoid,
            activation_default.gaussian,
            activation_default.bentIdentity,
            activation_default.bipolar,
            activation_default.bipolarSigmoid,
            activation_default.hardTanh,
            activation_default.absolute,
            activation_default.inverse,
            activation_default.selu,
            activation_default.softplus,
            activation_default.swish,
            activation_default.gelu,
            activation_default.mish
          ]
          /**
           * @see Instinct Algorithm - Section 3.6 Modify Squash Mutation
           */
        },
        /**
         * Adds a self-connection (recurrent connection from a node to itself).
         * This allows a node to retain information about its previous state,
         * introducing memory capabilities at the node level. Only applicable
         * to hidden and output nodes.
         */
        ADD_SELF_CONN: {
          name: "ADD_SELF_CONN"
        },
        /**
         * Removes a self-connection from a node.
         * This removes the node's direct recurrent loop.
         */
        SUB_SELF_CONN: {
          name: "SUB_SELF_CONN"
        },
        /**
         * Adds a gating mechanism to an existing connection. A new node (the gater)
         * is selected to control the flow of information through the gated connection.
         * This introduces multiplicative interactions, similar to LSTM or GRU units,
         * enabling more complex temporal processing or conditional logic.
         */
        ADD_GATE: {
          name: "ADD_GATE"
        },
        /**
         * Removes a gating mechanism from a connection.
         * This simplifies the network by removing the modulatory influence of the gater node.
         */
        SUB_GATE: {
          name: "SUB_GATE"
        },
        /**
         * Adds a recurrent connection between two nodes, potentially creating cycles
         * in the network graph (e.g., connecting a node to a node in a previous layer
         * or a non-adjacent node). This enables the network to maintain internal state
         * and process temporal dependencies.
         */
        ADD_BACK_CONN: {
          name: "ADD_BACK_CONN"
        },
        /**
         * Removes a recurrent connection (that is not a self-connection).
         * This simplifies the recurrent topology of the network.
         */
        SUB_BACK_CONN: {
          name: "SUB_BACK_CONN"
        },
        /**
         * Swaps the roles (bias and activation function) of two nodes (excluding input nodes).
         * Connections are generally preserved relative to the node indices.
         * This mutation alters the network's internal processing without changing
         * the overall node count or connection density.
         */
        SWAP_NODES: {
          name: "SWAP_NODES",
          /** If true, allows swapping involving output nodes. */
          mutateOutput: true
        },
        /**
         * Reinitializes the weights of all incoming, outgoing, and self connections for a node.
         * This can help escape local minima or inject diversity during evolution.
         */
        REINIT_WEIGHT: {
          name: "REINIT_WEIGHT",
          /** Range for random reinitialization. */
          min: -1,
          max: 1
        },
        /**
         * Marks a node for batch normalization. (Stub: actual normalization requires architectural support.)
         * This mutation can be used to toggle batch normalization on a node or layer.
         */
        BATCH_NORM: {
          name: "BATCH_NORM"
        },
        /**
         * Adds a new LSTM node (memory cell with gates) to the network.
         * This enables the evolution of memory-augmented architectures.
         */
        ADD_LSTM_NODE: {
          name: "ADD_LSTM_NODE"
          // Additional config can be added here if needed
        },
        /**
         * Adds a new GRU node (gated recurrent unit) to the network.
         * This enables the evolution of memory-augmented architectures.
         */
        ADD_GRU_NODE: {
          name: "ADD_GRU_NODE"
          // Additional config can be added here if needed
        },
        /** Placeholder for the list of all mutation methods. */
        ALL: [],
        /** Placeholder for the list of mutation methods suitable for feedforward networks. */
        FFW: []
      };
      mutation.ALL = [
        mutation.ADD_NODE,
        mutation.SUB_NODE,
        mutation.ADD_CONN,
        mutation.SUB_CONN,
        mutation.MOD_WEIGHT,
        mutation.MOD_BIAS,
        mutation.MOD_ACTIVATION,
        mutation.ADD_GATE,
        mutation.SUB_GATE,
        mutation.ADD_SELF_CONN,
        mutation.SUB_SELF_CONN,
        mutation.ADD_BACK_CONN,
        mutation.SUB_BACK_CONN,
        mutation.SWAP_NODES,
        mutation.REINIT_WEIGHT,
        mutation.BATCH_NORM,
        mutation.ADD_LSTM_NODE,
        // Added
        mutation.ADD_GRU_NODE
        // Added
      ];
      mutation.FFW = [
        mutation.ADD_NODE,
        mutation.SUB_NODE,
        mutation.ADD_CONN,
        mutation.SUB_CONN,
        mutation.MOD_WEIGHT,
        mutation.MOD_BIAS,
        mutation.MOD_ACTIVATION,
        mutation.SWAP_NODES,
        mutation.REINIT_WEIGHT,
        mutation.BATCH_NORM
      ];
      mutation_default = mutation;
    }
  });

  // src/methods/selection.ts
  var selection;
  var init_selection = __esm({
    "src/methods/selection.ts"() {
      "use strict";
      selection = {
        /**
         * Fitness Proportionate Selection (also known as Roulette Wheel Selection).
         *
         * Individuals are selected based on their fitness relative to the total fitness
         * of the population. An individual's chance of being selected is directly
         * proportional to its fitness score. Higher fitness means a higher probability
         * of selection. This method can struggle if fitness values are very close or
         * if there are large disparities.
         */
        FITNESS_PROPORTIONATE: {
          name: "FITNESS_PROPORTIONATE"
        },
        /**
         * Power Selection.
         *
         * Similar to Fitness Proportionate Selection, but fitness scores are raised
         * to a specified power before calculating selection probabilities. This increases
         * the selection pressure towards individuals with higher fitness scores, making
         * them disproportionately more likely to be selected compared to FITNESS_PROPORTIONATE.
         *
         * @property {number} power - The exponent applied to each individual's fitness score. Higher values increase selection pressure. Must be a positive number. Defaults to 4.
         */
        POWER: {
          name: "POWER",
          power: 4
        },
        /**
         * Tournament Selection.
         *
         * Selects individuals by holding competitions ('tournaments') among randomly
         * chosen subsets of the population. In each tournament, a fixed number (`size`)
         * of individuals are compared, and the fittest individual is chosen with a
         * certain `probability`. If not chosen (with probability 1 - `probability`),
         * the next fittest individual in the tournament might be selected (implementation dependent),
         * or another tournament might be run. This method is less sensitive to the scale
         * of fitness values compared to fitness proportionate methods.
         *
         * @property {number} size - The number of individuals participating in each tournament. Must be a positive integer. Defaults to 5.
         * @property {number} probability - The probability (between 0 and 1) of selecting the absolute fittest individual from the tournament participants. Defaults to 0.5.
         */
        TOURNAMENT: {
          name: "TOURNAMENT",
          size: 5,
          probability: 0.5
        }
      };
    }
  });

  // src/methods/crossover.ts
  var crossover;
  var init_crossover = __esm({
    "src/methods/crossover.ts"() {
      "use strict";
      crossover = {
        /**
         * Single-point crossover.
         * A single crossover point is selected, and genes are exchanged between parents up to this point.
         * This method is particularly useful for binary-encoded genomes.
         *
         * @property {string} name - The name of the crossover method.
         * @property {number[]} config - Configuration for the crossover point.
         * @see {@link https://en.wikipedia.org/wiki/Crossover_(genetic_algorithm)#One-point_crossover}
         */
        SINGLE_POINT: {
          name: "SINGLE_POINT",
          config: [0.4]
        },
        /**
         * Two-point crossover.
         * Two crossover points are selected, and genes are exchanged between parents between these points.
         * This method is an extension of single-point crossover and is often used for more complex genomes.
         *
         * @property {string} name - The name of the crossover method.
         * @property {number[]} config - Configuration for the two crossover points.
         * @see {@link https://en.wikipedia.org/wiki/Crossover_(genetic_algorithm)#Two-point_and_k-point_crossover}
         */
        TWO_POINT: {
          name: "TWO_POINT",
          config: [0.4, 0.9]
        },
        /**
         * Uniform crossover.
         * Each gene is selected randomly from one of the parents with equal probability.
         * This method provides a high level of genetic diversity in the offspring.
         *
         * @property {string} name - The name of the crossover method.
         * @see {@link https://en.wikipedia.org/wiki/Crossover_(genetic_algorithm)#Uniform_crossover}
         */
        UNIFORM: {
          name: "UNIFORM"
        },
        /**
         * Average crossover.
         * The offspring's genes are the average of the parents' genes.
         * This method is particularly useful for real-valued genomes.
         *
         * @property {string} name - The name of the crossover method.
         * @see {@link https://en.wikipedia.org/wiki/Crossover_(genetic_algorithm)#Arithmetic_recombination}
         */
        AVERAGE: {
          name: "AVERAGE"
        }
      };
    }
  });

  // src/methods/connection.ts
  var groupConnection, connection_default;
  var init_connection2 = __esm({
    "src/methods/connection.ts"() {
      "use strict";
      groupConnection = Object.freeze({
        // Renamed export
        /**
         * Connects all nodes in the source group to all nodes in the target group.
         */
        ALL_TO_ALL: Object.freeze({
          name: "ALL_TO_ALL"
          // Renamed name
        }),
        /**
         * Connects all nodes in the source group to all nodes in the target group, excluding self-connections (if groups are identical).
         */
        ALL_TO_ELSE: Object.freeze({
          name: "ALL_TO_ELSE"
          // Renamed name
        }),
        /**
         * Connects each node in the source group to the node at the same index in the target group. Requires groups to be the same size.
         */
        ONE_TO_ONE: Object.freeze({
          name: "ONE_TO_ONE"
          // Renamed name
        })
      });
      connection_default = groupConnection;
    }
  });

  // src/methods/methods.ts
  var methods_exports = {};
  __export(methods_exports, {
    Activation: () => activation_default,
    Cost: () => Cost,
    Rate: () => Rate,
    crossover: () => crossover,
    gating: () => gating,
    groupConnection: () => connection_default,
    mutation: () => mutation,
    selection: () => selection
  });
  var init_methods = __esm({
    "src/methods/methods.ts"() {
      "use strict";
      init_cost();
      init_rate();
      init_activation();
      init_gating();
      init_mutation();
      init_selection();
      init_crossover();
      init_connection2();
    }
  });

  // src/architecture/node.ts
  var node_exports = {};
  __export(node_exports, {
    default: () => Node2
  });
  var Node2;
  var init_node = __esm({
    "src/architecture/node.ts"() {
      "use strict";
      init_connection();
      init_config();
      init_methods();
      Node2 = class _Node {
        /**
         * The bias value of the node. Added to the weighted sum of inputs before activation.
         * Input nodes typically have a bias of 0.
         */
        bias;
        /**
         * The activation function (squashing function) applied to the node's state.
         * Maps the internal state to the node's output (activation).
         * @param x The node's internal state (sum of weighted inputs + bias).
         * @param derivate If true, returns the derivative of the function instead of the function value.
         * @returns The activation value or its derivative.
         */
        squash;
        /**
         * The type of the node: 'input', 'hidden', or 'output'.
         * Determines behavior (e.g., input nodes don't have biases modified typically, output nodes calculate error differently).
         */
        type;
        /**
         * The output value of the node after applying the activation function. This is the value transmitted to connected nodes.
         */
        activation;
        /**
         * The internal state of the node (sum of weighted inputs + bias) before the activation function is applied.
         */
        state;
        /**
         * The node's state from the previous activation cycle. Used for recurrent self-connections.
         */
        old;
        /**
         * A mask factor (typically 0 or 1) used for implementing dropout. If 0, the node's output is effectively silenced.
         */
        mask;
        /**
         * The change in bias applied in the previous training iteration. Used for calculating momentum.
         */
        previousDeltaBias;
        /**
         * Accumulates changes in bias over a mini-batch during batch training. Reset after each weight update.
         */
        totalDeltaBias;
        /**
         * Stores incoming, outgoing, gated, and self-connections for this node.
         */
        connections;
        /**
         * Stores error values calculated during backpropagation.
         */
        error;
        /**
         * The derivative of the activation function evaluated at the node's current state. Used in backpropagation.
         */
        derivative;
        /**
         * Optional index, potentially used to identify the node's position within a layer or network structure. Not used internally by the Node class itself.
         */
        index;
        /**
         * Internal flag to detect cycles during activation
         */
        isActivating;
        /** Stable per-node gene identifier for NEAT innovation reuse */
        geneId;
        /**
         * Global index counter for assigning unique indices to nodes.
         */
        static _globalNodeIndex = 0;
        static _nextGeneId = 1;
        /**
         * Creates a new node.
         * @param type The type of the node ('input', 'hidden', or 'output'). Defaults to 'hidden'.
         * @param customActivation Optional custom activation function (should handle derivative if needed).
         */
        constructor(type = "hidden", customActivation, rng = Math.random) {
          this.bias = type === "input" ? 0 : rng() * 0.2 - 0.1;
          this.squash = customActivation || activation_default.logistic || ((x) => x);
          this.type = type;
          this.activation = 0;
          this.state = 0;
          this.old = 0;
          this.mask = 1;
          this.previousDeltaBias = 0;
          this.totalDeltaBias = 0;
          this.connections = {
            in: [],
            out: [],
            gated: [],
            // Self-connection initialized as an empty array.
            self: []
          };
          this.error = {
            responsibility: 0,
            projected: 0,
            gated: 0
          };
          if (typeof this.index === "undefined") {
            this.index = _Node._globalNodeIndex++;
          }
          this.geneId = _Node._nextGeneId++;
        }
        /**
         * Sets a custom activation function for this node at runtime.
         * @param fn The activation function (should handle derivative if needed).
         */
        setActivation(fn) {
          this.squash = fn;
        }
        /**
         * Activates the node, calculating its output value based on inputs and state.
         * This method also calculates eligibility traces (`xtrace`) used for training recurrent connections.
         *
         * The activation process involves:
         * 1. Calculating the node's internal state (`this.state`) based on:
         *    - Incoming connections' weighted activations.
         *    - The recurrent self-connection's weighted state from the previous timestep (`this.old`).
         *    - The node's bias.
         * 2. Applying the activation function (`this.squash`) to the state to get the activation (`this.activation`).
         * 3. Applying the dropout mask (`this.mask`).
         * 4. Calculating the derivative of the activation function.
         * 5. Updating the gain of connections gated by this node.
         * 6. Calculating and updating eligibility traces for incoming connections.
         *
         * @param input Optional input value. If provided, sets the node's activation directly (used for input nodes).
         * @returns The calculated activation value of the node.
         * @see {@link https://medium.com/data-science/neuro-evolution-on-steroids-82bd14ddc2f6#1-3-activation Instinct Algorithm - Section 1.3 Activation}
         */
        activate(input) {
          return this._activateCore(true, input);
        }
        /**
         * Activates the node without calculating eligibility traces (`xtrace`).
         * This is a performance optimization used during inference (when the network
         * is just making predictions, not learning) as trace calculations are only needed for training.
         *
         * @param input Optional input value. If provided, sets the node's activation directly (used for input nodes).
         * @returns The calculated activation value of the node.
         * @see {@link https://medium.com/data-science/neuro-evolution-on-steroids-82bd14ddc2f6#1-3-activation Instinct Algorithm - Section 1.3 Activation}
         */
        noTraceActivate(input) {
          return this._activateCore(false, input);
        }
        /**
         * Internal shared implementation for activate/noTraceActivate.
         * @param withTrace Whether to update eligibility traces.
         * @param input Optional externally supplied activation (bypasses weighted sum if provided).
         */
        _activateCore(withTrace, input) {
          if (this.mask === 0) {
            this.activation = 0;
            return 0;
          }
          if (typeof input !== "undefined") {
            if (this.type === "input") {
              this.activation = input;
              return this.activation;
            }
            this.state = input;
            this.activation = this.squash(this.state) * this.mask;
            this.derivative = this.squash(this.state, true);
            for (const connection of this.connections.gated)
              connection.gain = this.activation;
            if (withTrace)
              for (const connection of this.connections.in)
                connection.eligibility = connection.from.activation;
            return this.activation;
          }
          this.old = this.state;
          let newState = this.bias;
          if (this.connections.self.length) {
            for (const conn of this.connections.self) {
              if (conn.dcMask === 0) continue;
              newState += conn.gain * conn.weight * this.old;
            }
          }
          if (this.connections.in.length) {
            for (const conn of this.connections.in) {
              if (conn.dcMask === 0 || conn.enabled === false) continue;
              newState += conn.from.activation * conn.weight * conn.gain;
            }
          }
          this.state = newState;
          if (typeof this.squash !== "function") {
            if (config.warnings)
              console.warn("Invalid activation function; using identity.");
            this.squash = activation_default.identity;
          }
          if (typeof this.mask !== "number") this.mask = 1;
          this.activation = this.squash(this.state) * this.mask;
          this.derivative = this.squash(this.state, true);
          if (this.connections.gated.length) {
            for (const conn of this.connections.gated) conn.gain = this.activation;
          }
          if (withTrace) {
            for (const conn of this.connections.in)
              conn.eligibility = conn.from.activation;
          }
          return this.activation;
        }
        /**
         * Back-propagates the error signal through the node and calculates weight/bias updates.
         *
         * This method implements the backpropagation algorithm, including:
         * 1. Calculating the node's error responsibility based on errors from subsequent nodes (`projected` error)
         *    and errors from connections it gates (`gated` error).
         * 2. Calculating the gradient for each incoming connection's weight using eligibility traces (`xtrace`).
         * 3. Calculating the change (delta) for weights and bias, incorporating:
         *    - Learning rate.
         *    - L1/L2/custom regularization.
         *    - Momentum (using Nesterov Accelerated Gradient - NAG).
         * 4. Optionally applying the calculated updates immediately or accumulating them for batch training.
         *
         * @param rate The learning rate (controls the step size of updates).
         * @param momentum The momentum factor (helps accelerate learning and overcome local minima). Uses NAG.
         * @param update If true, apply the calculated weight/bias updates immediately. If false, accumulate them in `totalDelta*` properties for batch updates.
         * @param regularization The regularization setting. Can be:
         *   - number (L2 lambda)
         *   - { type: 'L1'|'L2', lambda: number }
         *   - (weight: number) => number (custom function)
         * @param target The target output value for this node. Only used if the node is of type 'output'.
         */
        propagate(rate, momentum, update, regularization = 0, target) {
          if (update && momentum > 0) {
            for (const connection of this.connections.in) {
              connection.weight += momentum * connection.previousDeltaWeight;
              connection.eligibility += 1e-12;
            }
            this.bias += momentum * this.previousDeltaBias;
          }
          let error = 0;
          if (this.type === "output") {
            this.error.responsibility = this.error.projected = target - this.activation;
          } else {
            for (const connection of this.connections.out) {
              error += connection.to.error.responsibility * // Error responsibility of the node this connection points to.
              connection.weight * // Weight of the connection.
              connection.gain;
            }
            this.error.projected = this.derivative * error;
            error = 0;
            for (const connection of this.connections.gated) {
              const node = connection.to;
              let influence = node.connections.self.reduce(
                (sum, selfConn) => sum + (selfConn.gater === this ? node.old : 0),
                0
              );
              influence += connection.weight * connection.from.activation;
              error += node.error.responsibility * influence;
            }
            this.error.gated = this.derivative * error;
            this.error.responsibility = this.error.projected + this.error.gated;
          }
          if (this.type === "constant") return;
          for (const connection of this.connections.in) {
            if (connection.dcMask === 0) {
              connection.totalDeltaWeight += 0;
              continue;
            }
            let gradient = this.error.projected * connection.eligibility;
            for (let j = 0; j < connection.xtrace.nodes.length; j++) {
              const node = connection.xtrace.nodes[j];
              const value = connection.xtrace.values[j];
              gradient += node.error.responsibility * value;
            }
            let regTerm = 0;
            if (typeof regularization === "function") {
              regTerm = regularization(connection.weight);
            } else if (typeof regularization === "object" && regularization !== null) {
              if (regularization.type === "L1") {
                regTerm = regularization.lambda * Math.sign(connection.weight);
              } else if (regularization.type === "L2") {
                regTerm = regularization.lambda * connection.weight;
              }
            } else {
              regTerm = regularization * connection.weight;
            }
            let deltaWeight = rate * (gradient * this.mask - regTerm);
            if (!Number.isFinite(deltaWeight)) {
              console.warn("deltaWeight is not finite, clamping to 0", {
                node: this.index,
                connection,
                deltaWeight
              });
              deltaWeight = 0;
            } else if (Math.abs(deltaWeight) > 1e3) {
              deltaWeight = Math.sign(deltaWeight) * 1e3;
            }
            connection.totalDeltaWeight += deltaWeight;
            if (!Number.isFinite(connection.totalDeltaWeight)) {
              console.warn("totalDeltaWeight became NaN/Infinity, resetting to 0", {
                node: this.index,
                connection
              });
              connection.totalDeltaWeight = 0;
            }
            if (update) {
              let currentDeltaWeight = connection.totalDeltaWeight + momentum * connection.previousDeltaWeight;
              if (!Number.isFinite(currentDeltaWeight)) {
                console.warn("currentDeltaWeight is not finite, clamping to 0", {
                  node: this.index,
                  connection,
                  currentDeltaWeight
                });
                currentDeltaWeight = 0;
              } else if (Math.abs(currentDeltaWeight) > 1e3) {
                currentDeltaWeight = Math.sign(currentDeltaWeight) * 1e3;
              }
              if (momentum > 0) {
                connection.weight -= momentum * connection.previousDeltaWeight;
              }
              connection.weight += currentDeltaWeight;
              if (!Number.isFinite(connection.weight)) {
                console.warn(
                  `Weight update produced invalid value: ${connection.weight}. Resetting to 0.`,
                  { node: this.index, connection }
                );
                connection.weight = 0;
              } else if (Math.abs(connection.weight) > 1e6) {
                connection.weight = Math.sign(connection.weight) * 1e6;
              }
              connection.previousDeltaWeight = currentDeltaWeight;
              connection.totalDeltaWeight = 0;
            }
          }
          for (const connection of this.connections.self) {
            if (connection.dcMask === 0) {
              connection.totalDeltaWeight += 0;
              continue;
            }
            let gradient = this.error.projected * connection.eligibility;
            for (let j = 0; j < connection.xtrace.nodes.length; j++) {
              const node = connection.xtrace.nodes[j];
              const value = connection.xtrace.values[j];
              gradient += node.error.responsibility * value;
            }
            let regTerm = 0;
            if (typeof regularization === "function") {
              regTerm = regularization(connection.weight);
            } else if (typeof regularization === "object" && regularization !== null) {
              if (regularization.type === "L1") {
                regTerm = regularization.lambda * Math.sign(connection.weight);
              } else if (regularization.type === "L2") {
                regTerm = regularization.lambda * connection.weight;
              }
            } else {
              regTerm = regularization * connection.weight;
            }
            let deltaWeight = rate * (gradient * this.mask - regTerm);
            if (!Number.isFinite(deltaWeight)) {
              console.warn("self deltaWeight is not finite, clamping to 0", {
                node: this.index,
                connection,
                deltaWeight
              });
              deltaWeight = 0;
            } else if (Math.abs(deltaWeight) > 1e3) {
              deltaWeight = Math.sign(deltaWeight) * 1e3;
            }
            connection.totalDeltaWeight += deltaWeight;
            if (!Number.isFinite(connection.totalDeltaWeight)) {
              console.warn(
                "self totalDeltaWeight became NaN/Infinity, resetting to 0",
                { node: this.index, connection }
              );
              connection.totalDeltaWeight = 0;
            }
            if (update) {
              let currentDeltaWeight = connection.totalDeltaWeight + momentum * connection.previousDeltaWeight;
              if (!Number.isFinite(currentDeltaWeight)) {
                console.warn("self currentDeltaWeight is not finite, clamping to 0", {
                  node: this.index,
                  connection,
                  currentDeltaWeight
                });
                currentDeltaWeight = 0;
              } else if (Math.abs(currentDeltaWeight) > 1e3) {
                currentDeltaWeight = Math.sign(currentDeltaWeight) * 1e3;
              }
              if (momentum > 0) {
                connection.weight -= momentum * connection.previousDeltaWeight;
              }
              connection.weight += currentDeltaWeight;
              if (!Number.isFinite(connection.weight)) {
                console.warn(
                  "self weight update produced invalid value, resetting to 0",
                  { node: this.index, connection }
                );
                connection.weight = 0;
              } else if (Math.abs(connection.weight) > 1e6) {
                connection.weight = Math.sign(connection.weight) * 1e6;
              }
              connection.previousDeltaWeight = currentDeltaWeight;
              connection.totalDeltaWeight = 0;
            }
          }
          let deltaBias = rate * this.error.responsibility;
          if (!Number.isFinite(deltaBias)) {
            console.warn("deltaBias is not finite, clamping to 0", {
              node: this.index,
              deltaBias
            });
            deltaBias = 0;
          } else if (Math.abs(deltaBias) > 1e3) {
            deltaBias = Math.sign(deltaBias) * 1e3;
          }
          this.totalDeltaBias += deltaBias;
          if (!Number.isFinite(this.totalDeltaBias)) {
            console.warn("totalDeltaBias became NaN/Infinity, resetting to 0", {
              node: this.index
            });
            this.totalDeltaBias = 0;
          }
          if (update) {
            let currentDeltaBias = this.totalDeltaBias + momentum * this.previousDeltaBias;
            if (!Number.isFinite(currentDeltaBias)) {
              console.warn("currentDeltaBias is not finite, clamping to 0", {
                node: this.index,
                currentDeltaBias
              });
              currentDeltaBias = 0;
            } else if (Math.abs(currentDeltaBias) > 1e3) {
              currentDeltaBias = Math.sign(currentDeltaBias) * 1e3;
            }
            if (momentum > 0) {
              this.bias -= momentum * this.previousDeltaBias;
            }
            this.bias += currentDeltaBias;
            if (!Number.isFinite(this.bias)) {
              console.warn("bias update produced invalid value, resetting to 0", {
                node: this.index
              });
              this.bias = 0;
            } else if (Math.abs(this.bias) > 1e6) {
              this.bias = Math.sign(this.bias) * 1e6;
            }
            this.previousDeltaBias = currentDeltaBias;
            this.totalDeltaBias = 0;
          }
        }
        /**
         * Converts the node's essential properties to a JSON object for serialization.
         * Does not include state, activation, error, or connection information, as these
         * are typically transient or reconstructed separately.
         * @returns A JSON representation of the node's configuration.
         */
        toJSON() {
          return {
            index: this.index,
            bias: this.bias,
            type: this.type,
            squash: this.squash ? this.squash.name : null,
            mask: this.mask
          };
        }
        /**
         * Creates a Node instance from a JSON object.
         * @param json The JSON object containing node configuration.
         * @returns A new Node instance configured according to the JSON object.
         */
        static fromJSON(json) {
          const node = new _Node(json.type);
          node.bias = json.bias;
          node.mask = json.mask;
          if (json.squash) {
            const squashFn = activation_default[json.squash];
            if (typeof squashFn === "function") {
              node.squash = squashFn;
            } else {
              console.warn(
                `fromJSON: Unknown or invalid squash function '${json.squash}' for node. Using identity.`
              );
              node.squash = activation_default.identity;
            }
          }
          return node;
        }
        /**
         * Checks if this node is connected to another node.
         * @param target The target node to check the connection with.
         * @returns True if connected, otherwise false.
         */
        isConnectedTo(target) {
          return this.connections.out.some((conn) => conn.to === target);
        }
        /**
         * Applies a mutation method to the node. Used in neuro-evolution.
         *
         * This allows modifying the node's properties, such as its activation function or bias,
         * based on predefined mutation methods.
         *
         * @param method A mutation method object, typically from `methods.mutation`. It should define the type of mutation and its parameters (e.g., allowed functions, modification range).
         * @throws {Error} If the mutation method is invalid, not provided, or not found in `methods.mutation`.
         * @see {@link https://medium.com/data-science/neuro-evolution-on-steroids-82bd14ddc2f6#3-mutation Instinct Algorithm - Section 3 Mutation}
         */
        mutate(method) {
          if (!method) {
            throw new Error("Mutation method cannot be null or undefined.");
          }
          if (!(method.name in mutation)) {
            throw new Error(`Unknown mutation method: ${method.name}`);
          }
          switch (method) {
            case mutation.MOD_ACTIVATION:
              if (!method.allowed || method.allowed.length === 0) {
                console.warn(
                  "MOD_ACTIVATION mutation called without allowed functions specified."
                );
                return;
              }
              const allowed = method.allowed;
              const currentIndex = allowed.indexOf(this.squash);
              let newIndex = currentIndex;
              if (allowed.length > 1) {
                newIndex = (currentIndex + Math.floor(Math.random() * (allowed.length - 1)) + 1) % allowed.length;
              }
              this.squash = allowed[newIndex];
              break;
            case mutation.MOD_BIAS:
              const min = method.min ?? -1;
              const max = method.max ?? 1;
              const modification = Math.random() * (max - min) + min;
              this.bias += modification;
              break;
            case mutation.REINIT_WEIGHT:
              const reinitMin = method.min ?? -1;
              const reinitMax = method.max ?? 1;
              for (const conn of this.connections.in) {
                conn.weight = Math.random() * (reinitMax - reinitMin) + reinitMin;
              }
              for (const conn of this.connections.out) {
                conn.weight = Math.random() * (reinitMax - reinitMin) + reinitMin;
              }
              for (const conn of this.connections.self) {
                conn.weight = Math.random() * (reinitMax - reinitMin) + reinitMin;
              }
              break;
            case mutation.BATCH_NORM:
              this.batchNorm = true;
              break;
            // Add cases for other mutation types if needed.
            default:
              throw new Error(`Unsupported mutation method: ${method.name}`);
          }
        }
        /**
         * Creates a connection from this node to a target node or all nodes in a group.
         *
         * @param target The target Node or a group object containing a `nodes` array.
         * @param weight The weight for the new connection(s). If undefined, a default or random weight might be assigned by the Connection constructor (currently defaults to 0, consider changing).
         * @returns An array containing the newly created Connection object(s).
         * @throws {Error} If the target is undefined.
         * @throws {Error} If trying to create a self-connection when one already exists (weight is not 0).
         */
        connect(target, weight) {
          const connections = [];
          if (!target) {
            throw new Error("Cannot connect to an undefined target.");
          }
          if ("bias" in target) {
            const targetNode = target;
            if (targetNode === this) {
              if (this.connections.self.length === 0) {
                const selfConnection = Connection.acquire(this, this, weight ?? 1);
                this.connections.self.push(selfConnection);
                connections.push(selfConnection);
              }
            } else {
              const connection = Connection.acquire(this, targetNode, weight);
              targetNode.connections.in.push(connection);
              this.connections.out.push(connection);
              connections.push(connection);
            }
          } else if ("nodes" in target && Array.isArray(target.nodes)) {
            for (const node of target.nodes) {
              const connection = Connection.acquire(this, node, weight);
              node.connections.in.push(connection);
              this.connections.out.push(connection);
              connections.push(connection);
            }
          } else {
            throw new Error(
              "Invalid target type for connection. Must be a Node or a group { nodes: Node[] }."
            );
          }
          return connections;
        }
        /**
         * Removes the connection from this node to the target node.
         *
         * @param target The target node to disconnect from.
         * @param twosided If true, also removes the connection from the target node back to this node (if it exists). Defaults to false.
         */
        disconnect(target, twosided = false) {
          if (this === target) {
            this.connections.self = [];
            return;
          }
          this.connections.out = this.connections.out.filter((conn) => {
            if (conn.to === target) {
              target.connections.in = target.connections.in.filter(
                (inConn) => inConn !== conn
                // Filter by reference.
              );
              if (conn.gater) {
                conn.gater.ungate(conn);
              }
              return false;
            }
            return true;
          });
          if (twosided) {
            target.disconnect(this, false);
          }
        }
        /**
         * Makes this node gate the provided connection(s).
         * The connection's gain will be controlled by this node's activation value.
         *
         * @param connections A single Connection object or an array of Connection objects to be gated.
         */
        gate(connections) {
          if (!Array.isArray(connections)) {
            connections = [connections];
          }
          for (const connection of connections) {
            if (!connection || !connection.from || !connection.to) {
              console.warn("Attempted to gate an invalid or incomplete connection.");
              continue;
            }
            if (connection.gater === this) {
              console.warn("Node is already gating this connection.");
              continue;
            }
            if (connection.gater !== null) {
              console.warn(
                "Connection is already gated by another node. Ungate first."
              );
              continue;
            }
            this.connections.gated.push(connection);
            connection.gater = this;
          }
        }
        /**
         * Removes this node's gating control over the specified connection(s).
         * Resets the connection's gain to 1 and removes it from the `connections.gated` list.
         *
         * @param connections A single Connection object or an array of Connection objects to ungate.
         */
        ungate(connections) {
          if (!Array.isArray(connections)) {
            connections = [connections];
          }
          for (const connection of connections) {
            if (!connection) continue;
            const index = this.connections.gated.indexOf(connection);
            if (index !== -1) {
              this.connections.gated.splice(index, 1);
              connection.gater = null;
              connection.gain = 1;
            } else {
            }
          }
        }
        /**
         * Clears the node's dynamic state information.
         * Resets activation, state, previous state, error signals, and eligibility traces.
         * Useful for starting a new activation sequence (e.g., for a new input pattern).
         */
        clear() {
          for (const connection of this.connections.in) {
            connection.eligibility = 0;
            connection.xtrace = { nodes: [], values: [] };
          }
          for (const connection of this.connections.self) {
            connection.eligibility = 0;
            connection.xtrace = { nodes: [], values: [] };
          }
          for (const connection of this.connections.gated) {
            connection.gain = 0;
          }
          this.error = { responsibility: 0, projected: 0, gated: 0 };
          this.old = this.state = this.activation = 0;
        }
        /**
         * Checks if this node has a direct outgoing connection to the given node.
         * Considers both regular outgoing connections and the self-connection.
         *
         * @param node The potential target node.
         * @returns True if this node projects to the target node, false otherwise.
         */
        isProjectingTo(node) {
          if (node === this && this.connections.self.length > 0) return true;
          return this.connections.out.some((conn) => conn.to === node);
        }
        /**
         * Checks if the given node has a direct outgoing connection to this node.
         * Considers both regular incoming connections and the self-connection.
         *
         * @param node The potential source node.
         * @returns True if the given node projects to this node, false otherwise.
         */
        isProjectedBy(node) {
          if (node === this && this.connections.self.length > 0) return true;
          return this.connections.in.some((conn) => conn.from === node);
        }
        /**
         * Applies accumulated batch updates to incoming and self connections and this node's bias.
         * Uses momentum in a Nesterov-compatible way: currentDelta = accumulated + momentum * previousDelta.
         * Resets accumulators after applying. Safe to call on any node type.
         * @param momentum Momentum factor (0 to disable)
         */
        applyBatchUpdates(momentum) {
          return this.applyBatchUpdatesWithOptimizer({ type: "sgd", momentum });
        }
        /**
         * Extended batch update supporting multiple optimizers.
         *
         * Applies accumulated (batch) gradients stored in `totalDeltaWeight` / `totalDeltaBias` to the
         * underlying weights and bias using the selected optimization algorithm. Supports both classic
         * SGD (with Nesterov-style momentum via preceding propagate logic) and a collection of adaptive
         * optimizers. After applying an update, gradient accumulators are reset to 0.
         *
         * Supported optimizers (type):
         *  - 'sgd'      : Standard gradient descent with optional momentum.
         *  - 'rmsprop'  : Exponential moving average of squared gradients (cache) to normalize step.
         *  - 'adagrad'  : Accumulate squared gradients; learning rate effectively decays per weight.
         *  - 'adam'     : Bias‑corrected first (m) & second (v) moment estimates.
         *  - 'adamw'    : Adam with decoupled weight decay (applied after adaptive step).
         *  - 'amsgrad'  : Adam variant maintaining a maximum of past v (vhat) to enforce non‑increasing step size.
         *  - 'adamax'   : Adam variant using the infinity norm (u) instead of second moment.
         *  - 'nadam'    : Adam + Nesterov momentum style update (lookahead on first moment).
         *  - 'radam'    : Rectified Adam – warms up variance by adaptively rectifying denominator when sample size small.
         *  - 'lion'     : Uses sign of combination of two momentum buffers (beta1 & beta2) for update direction only.
         *  - 'adabelief': Adam-like but second moment on (g - m) (gradient surprise) for variance reduction.
         *  - 'lookahead': Wrapper; performs k fast optimizer steps then interpolates (alpha) towards a slow (shadow) weight.
         *
         * Options:
         *  - momentum     : (SGD) momentum factor (Nesterov handled in propagate when update=true).
         *  - beta1/beta2  : Exponential decay rates for first/second moments (Adam family, Lion, AdaBelief, etc.).
         *  - eps          : Numerical stability epsilon added to denominator terms.
         *  - weightDecay  : Decoupled weight decay (AdamW) or additionally applied after main step when adamw selected.
         *  - lrScale      : Learning rate scalar already scheduled externally (passed as currentRate).
         *  - t            : Global step (1-indexed) for bias correction / rectification.
         *  - baseType     : Underlying optimizer for lookahead (not itself lookahead).
         *  - la_k         : Lookahead synchronization interval (number of fast steps).
         *  - la_alpha     : Interpolation factor towards slow (shadow) weights/bias at sync points.
         *
         * Internal per-connection temp fields (created lazily):
         *  - firstMoment / secondMoment / maxSecondMoment / infinityNorm : Moment / variance / max variance / infinity norm caches.
         *  - gradientAccumulator : Single accumulator (RMSProp / AdaGrad).
         *  - previousDeltaWeight : For classic SGD momentum.
         *  - lookaheadShadowWeight / _la_shadowBias : Lookahead shadow copies.
         *
         * Safety: We clip extreme weight / bias magnitudes and guard against NaN/Infinity.
         *
         * @param opts Optimizer configuration (see above).
         */
        applyBatchUpdatesWithOptimizer(opts) {
          const type = opts.type || "sgd";
          const effectiveType = type === "lookahead" ? opts.baseType || "sgd" : type;
          const momentum = opts.momentum ?? 0;
          const beta1 = opts.beta1 ?? 0.9;
          const beta2 = opts.beta2 ?? 0.999;
          const eps = opts.eps ?? 1e-8;
          const wd = opts.weightDecay ?? 0;
          const lrScale = opts.lrScale ?? 1;
          const t = Math.max(1, Math.floor(opts.t ?? 1));
          if (type === "lookahead") {
            this._la_k = this._la_k || opts.la_k || 5;
            this._la_alpha = this._la_alpha || opts.la_alpha || 0.5;
            this._la_step = (this._la_step || 0) + 1;
            if (!this._la_shadowBias)
              this._la_shadowBias = this.bias;
          }
          const applyConn = (conn) => {
            let g = conn.totalDeltaWeight || 0;
            if (!Number.isFinite(g)) g = 0;
            switch (effectiveType) {
              case "rmsprop": {
                conn.gradientAccumulator = (conn.gradientAccumulator ?? 0) * 0.9 + 0.1 * (g * g);
                const adj = g / (Math.sqrt(conn.gradientAccumulator) + eps);
                this._safeUpdateWeight(conn, adj * lrScale);
                break;
              }
              case "adagrad": {
                conn.gradientAccumulator = (conn.gradientAccumulator ?? 0) + g * g;
                const adj = g / (Math.sqrt(conn.gradientAccumulator) + eps);
                this._safeUpdateWeight(conn, adj * lrScale);
                break;
              }
              case "adam":
              case "adamw":
              case "amsgrad": {
                conn.firstMoment = (conn.firstMoment ?? 0) * beta1 + (1 - beta1) * g;
                conn.secondMoment = (conn.secondMoment ?? 0) * beta2 + (1 - beta2) * (g * g);
                if (effectiveType === "amsgrad") {
                  conn.maxSecondMoment = Math.max(
                    conn.maxSecondMoment ?? 0,
                    conn.secondMoment ?? 0
                  );
                }
                const vEff = effectiveType === "amsgrad" ? conn.maxSecondMoment : conn.secondMoment;
                const mHat = conn.firstMoment / (1 - Math.pow(beta1, t));
                const vHat = vEff / (1 - Math.pow(beta2, t));
                let step = mHat / (Math.sqrt(vHat) + eps) * lrScale;
                if (effectiveType === "adamw" && wd !== 0)
                  step -= wd * (conn.weight || 0);
                this._safeUpdateWeight(conn, step);
                break;
              }
              case "adamax": {
                conn.firstMoment = (conn.firstMoment ?? 0) * beta1 + (1 - beta1) * g;
                conn.infinityNorm = Math.max(
                  (conn.infinityNorm ?? 0) * beta2,
                  Math.abs(g)
                );
                const mHat = conn.firstMoment / (1 - Math.pow(beta1, t));
                const stepVal = mHat / (conn.infinityNorm || 1e-12) * lrScale;
                this._safeUpdateWeight(conn, stepVal);
                break;
              }
              case "nadam": {
                conn.firstMoment = (conn.firstMoment ?? 0) * beta1 + (1 - beta1) * g;
                conn.secondMoment = (conn.secondMoment ?? 0) * beta2 + (1 - beta2) * (g * g);
                const mHat = conn.firstMoment / (1 - Math.pow(beta1, t));
                const vHat = conn.secondMoment / (1 - Math.pow(beta2, t));
                const mNesterov = mHat * beta1 + (1 - beta1) * g / (1 - Math.pow(beta1, t));
                this._safeUpdateWeight(
                  conn,
                  mNesterov / (Math.sqrt(vHat) + eps) * lrScale
                );
                break;
              }
              case "radam": {
                conn.firstMoment = (conn.firstMoment ?? 0) * beta1 + (1 - beta1) * g;
                conn.secondMoment = (conn.secondMoment ?? 0) * beta2 + (1 - beta2) * (g * g);
                const mHat = conn.firstMoment / (1 - Math.pow(beta1, t));
                const vHat = conn.secondMoment / (1 - Math.pow(beta2, t));
                const rhoInf = 2 / (1 - beta2) - 1;
                const rhoT = rhoInf - 2 * t * Math.pow(beta2, t) / (1 - Math.pow(beta2, t));
                if (rhoT > 4) {
                  const rt = Math.sqrt(
                    (rhoT - 4) * (rhoT - 2) * rhoInf / ((rhoInf - 4) * (rhoInf - 2) * rhoT)
                  );
                  this._safeUpdateWeight(
                    conn,
                    rt * mHat / (Math.sqrt(vHat) + eps) * lrScale
                  );
                } else {
                  this._safeUpdateWeight(conn, mHat * lrScale);
                }
                break;
              }
              case "lion": {
                conn.firstMoment = (conn.firstMoment ?? 0) * beta1 + (1 - beta1) * g;
                conn.secondMomentum = (conn.secondMomentum ?? 0) * beta2 + (1 - beta2) * g;
                const update = Math.sign(
                  (conn.firstMoment || 0) + (conn.secondMomentum || 0)
                );
                this._safeUpdateWeight(conn, -update * lrScale);
                break;
              }
              case "adabelief": {
                conn.firstMoment = (conn.firstMoment ?? 0) * beta1 + (1 - beta1) * g;
                const g_m = g - conn.firstMoment;
                conn.secondMoment = (conn.secondMoment ?? 0) * beta2 + (1 - beta2) * (g_m * g_m);
                const mHat = conn.firstMoment / (1 - Math.pow(beta1, t));
                const vHat = conn.secondMoment / (1 - Math.pow(beta2, t));
                this._safeUpdateWeight(
                  conn,
                  mHat / (Math.sqrt(vHat) + eps + 1e-12) * lrScale
                );
                break;
              }
              default: {
                let currentDeltaWeight = g + momentum * (conn.previousDeltaWeight || 0);
                if (!Number.isFinite(currentDeltaWeight)) currentDeltaWeight = 0;
                if (Math.abs(currentDeltaWeight) > 1e3)
                  currentDeltaWeight = Math.sign(currentDeltaWeight) * 1e3;
                this._safeUpdateWeight(conn, currentDeltaWeight * lrScale);
                conn.previousDeltaWeight = currentDeltaWeight;
              }
            }
            if (effectiveType === "adamw" && wd !== 0) {
              this._safeUpdateWeight(conn, -wd * (conn.weight || 0) * lrScale);
            }
            conn.totalDeltaWeight = 0;
          };
          for (const connection of this.connections.in) applyConn(connection);
          for (const connection of this.connections.self) applyConn(connection);
          if (this.type !== "input" && this.type !== "constant") {
            let gB = this.totalDeltaBias || 0;
            if (!Number.isFinite(gB)) gB = 0;
            if ([
              "adam",
              "adamw",
              "amsgrad",
              "adamax",
              "nadam",
              "radam",
              "lion",
              "adabelief"
            ].includes(effectiveType)) {
              this.opt_mB = (this.opt_mB ?? 0) * beta1 + (1 - beta1) * gB;
              if (effectiveType === "lion") {
                this.opt_mB2 = (this.opt_mB2 ?? 0) * beta2 + (1 - beta2) * gB;
              }
              this.opt_vB = (this.opt_vB ?? 0) * beta2 + (1 - beta2) * (effectiveType === "adabelief" ? Math.pow(gB - this.opt_mB, 2) : gB * gB);
              if (effectiveType === "amsgrad") {
                this.opt_vhatB = Math.max(
                  this.opt_vhatB ?? 0,
                  this.opt_vB ?? 0
                );
              }
              const vEffB = effectiveType === "amsgrad" ? this.opt_vhatB : this.opt_vB;
              const mHatB = this.opt_mB / (1 - Math.pow(beta1, t));
              const vHatB = vEffB / (1 - Math.pow(beta2, t));
              let stepB;
              if (effectiveType === "adamax") {
                this.opt_uB = Math.max(
                  (this.opt_uB ?? 0) * beta2,
                  Math.abs(gB)
                );
                stepB = mHatB / (this.opt_uB || 1e-12) * lrScale;
              } else if (effectiveType === "nadam") {
                const mNesterovB = mHatB * beta1 + (1 - beta1) * gB / (1 - Math.pow(beta1, t));
                stepB = mNesterovB / (Math.sqrt(vHatB) + eps) * lrScale;
              } else if (effectiveType === "radam") {
                const rhoInf = 2 / (1 - beta2) - 1;
                const rhoT = rhoInf - 2 * t * Math.pow(beta2, t) / (1 - Math.pow(beta2, t));
                if (rhoT > 4) {
                  const rt = Math.sqrt(
                    (rhoT - 4) * (rhoT - 2) * rhoInf / ((rhoInf - 4) * (rhoInf - 2) * rhoT)
                  );
                  stepB = rt * mHatB / (Math.sqrt(vHatB) + eps) * lrScale;
                } else {
                  stepB = mHatB * lrScale;
                }
              } else if (effectiveType === "lion") {
                const updateB = Math.sign(
                  this.opt_mB + this.opt_mB2
                );
                stepB = -updateB * lrScale;
              } else if (effectiveType === "adabelief") {
                stepB = mHatB / (Math.sqrt(vHatB) + eps + 1e-12) * lrScale;
              } else {
                stepB = mHatB / (Math.sqrt(vHatB) + eps) * lrScale;
              }
              if (effectiveType === "adamw" && wd !== 0)
                stepB -= wd * (this.bias || 0) * lrScale;
              let nextBias = this.bias + stepB;
              if (!Number.isFinite(nextBias)) nextBias = 0;
              if (Math.abs(nextBias) > 1e6) nextBias = Math.sign(nextBias) * 1e6;
              this.bias = nextBias;
            } else {
              let currentDeltaBias = gB + momentum * (this.previousDeltaBias || 0);
              if (!Number.isFinite(currentDeltaBias)) currentDeltaBias = 0;
              if (Math.abs(currentDeltaBias) > 1e3)
                currentDeltaBias = Math.sign(currentDeltaBias) * 1e3;
              let nextBias = this.bias + currentDeltaBias * lrScale;
              if (!Number.isFinite(nextBias)) nextBias = 0;
              if (Math.abs(nextBias) > 1e6) nextBias = Math.sign(nextBias) * 1e6;
              this.bias = nextBias;
              this.previousDeltaBias = currentDeltaBias;
            }
            this.totalDeltaBias = 0;
          } else {
            this.previousDeltaBias = 0;
            this.totalDeltaBias = 0;
          }
          if (type === "lookahead") {
            const k = this._la_k || 5;
            const alpha = this._la_alpha || 0.5;
            if (this._la_step % k === 0) {
              this._la_shadowBias = (1 - alpha) * this._la_shadowBias + alpha * this.bias;
              this.bias = this._la_shadowBias;
              const blendConn = (conn) => {
                if (!conn.lookaheadShadowWeight)
                  conn.lookaheadShadowWeight = conn.weight;
                conn.lookaheadShadowWeight = (1 - alpha) * conn.lookaheadShadowWeight + alpha * conn.weight;
                conn.weight = conn.lookaheadShadowWeight;
              };
              for (const c of this.connections.in) blendConn(c);
              for (const c of this.connections.self) blendConn(c);
            }
          }
        }
        /**
         * Internal helper to safely update a connection weight with clipping and NaN checks.
         */
        _safeUpdateWeight(connection, delta) {
          let next = connection.weight + delta;
          if (!Number.isFinite(next)) next = 0;
          if (Math.abs(next) > 1e6) next = Math.sign(next) * 1e6;
          connection.weight = next;
        }
      };
    }
  });

  // src/architecture/nodePool.ts
  function resetNode(node, type, rng = Math.random) {
    if (type) node.type = type;
    const t = node.type;
    node.bias = t === "input" ? 0 : rng() * 0.2 - 0.1;
    node.activation = 0;
    node.state = 0;
    node.old = 0;
    node.mask = 1;
    node.previousDeltaBias = 0;
    node.totalDeltaBias = 0;
    node.derivative = void 0;
    node.connections.in.length = 0;
    node.connections.out.length = 0;
    node.connections.gated.length = 0;
    node.connections.self.length = 0;
    node.error = { responsibility: 0, projected: 0, gated: 0 };
    node.geneId = nextGeneId++;
  }
  function acquireNode(opts = {}) {
    const { type = "hidden", activationFn, rng } = opts;
    let node;
    if (pool.length) {
      node = pool.pop();
      reusedCount++;
      resetNode(node, type, rng);
      if (activationFn) node.squash = activationFn;
    } else {
      node = new Node2(type, activationFn, rng);
      node.geneId = nextGeneId++;
      freshCount++;
    }
    return node;
  }
  function releaseNode(node) {
    node.connections.in.length = 0;
    node.connections.out.length = 0;
    node.connections.gated.length = 0;
    node.connections.self.length = 0;
    node.error = { responsibility: 0, projected: 0, gated: 0 };
    pool.push(node);
    if (pool.length > highWaterMark) highWaterMark = pool.length;
  }
  var pool, highWaterMark, nextGeneId, reusedCount, freshCount;
  var init_nodePool = __esm({
    "src/architecture/nodePool.ts"() {
      "use strict";
      init_node();
      pool = [];
      highWaterMark = 0;
      nextGeneId = 1;
      reusedCount = 0;
      freshCount = 0;
    }
  });

  // src/multithreading/workers/node/testworker.ts
  var testworker_exports = {};
  __export(testworker_exports, {
    TestWorker: () => TestWorker,
    default: () => testworker_default
  });
  var import_child_process, TestWorker, testworker_default;
  var init_testworker = __esm({
    "src/multithreading/workers/node/testworker.ts"() {
      "use strict";
      import_child_process = __require("child_process");
      TestWorker = class {
        worker;
        /**
         * Creates a new TestWorker instance.
         *
         * This initializes a new worker process and sends the dataset and cost function
         * to the worker for further processing.
         *
         * @param {number[]} dataSet - The serialized dataset to be used by the worker.
         * @param {{ name: string }} cost - The cost function to evaluate the network.
         */
        constructor(dataSet, cost) {
          let pathModule = null;
          try {
            pathModule = __require("path");
          } catch {
          }
          const workerPath = pathModule ? pathModule.join(__dirname, "/worker") : "./worker";
          this.worker = (0, import_child_process.fork)(workerPath);
          this.worker.send({ set: dataSet, cost: cost.name });
        }
        /**
         * Evaluates a neural network using the worker process.
         *
         * The network is serialized and sent to the worker for evaluation. The worker
         * sends back the evaluation result, which is returned as a promise.
         *
         * @param {any} network - The neural network to evaluate. It must implement a `serialize` method.
         * @returns {Promise<number>} A promise that resolves to the evaluation result.
         *
         * @example
         * // Example: evaluate a mock network (assumes `worker` is an instance of TestWorker)
         * // Note: `evaluate` returns a Promise — use `await` inside an async function.
         * const mockNetwork = { serialize: () => [[0], [0], [0]] };
         * const score = await worker.evaluate(mockNetwork);
         * console.log('score', score);
         */
        async evaluate(network) {
          const serialized = network.serialize();
          const data = {
            activations: serialized[0],
            states: serialized[1],
            conns: serialized[2]
          };
          return new Promise((resolve, reject) => {
            const onMessage = (e) => {
              cleanup();
              resolve(e);
            };
            const onError = (err) => {
              cleanup();
              reject(err);
            };
            const onExit = (code, signal) => {
              cleanup();
              reject(
                new Error(
                  `worker exited${code != null ? ` with code ${code}` : signal ? ` with signal ${signal}` : ""}`
                )
              );
            };
            const cleanup = () => {
              this.worker.off("message", onMessage);
              this.worker.off("error", onError);
              this.worker.off("exit", onExit);
            };
            this.worker.once("message", onMessage);
            this.worker.once("error", onError);
            this.worker.once("exit", onExit);
            this.worker.send(data);
          });
        }
        /**
         * Terminates the worker process.
         *
         * This method ensures that the worker process is properly terminated to free up system resources.
         *
         * @example
         * // Create and terminate a worker when it's no longer needed
         * const worker = new TestWorker([0, 1, 2], { name: 'mse' });
         * // ...use worker.evaluate(...) as needed
         * worker.terminate();
         */
        terminate() {
          this.worker.kill();
        }
      };
      testworker_default = TestWorker;
    }
  });

  // src/multithreading/workers/browser/testworker.ts
  var testworker_exports2 = {};
  __export(testworker_exports2, {
    TestWorker: () => TestWorker2
  });
  var TestWorker2;
  var init_testworker2 = __esm({
    "src/multithreading/workers/browser/testworker.ts"() {
      "use strict";
      init_multi();
      TestWorker2 = class _TestWorker {
        worker;
        url;
        /**
         * Creates a new TestWorker instance.
         * @param {number[]} dataSet - The serialized dataset to be used by the worker.
         * @param {any} cost - The cost function to evaluate the network.
         */
        constructor(dataSet, cost) {
          const blob = new Blob([_TestWorker._createBlobString(cost)]);
          this.url = window.URL.createObjectURL(blob);
          this.worker = new Worker(this.url);
          const data = { set: new Float64Array(dataSet).buffer };
          this.worker.postMessage(data, [data.set]);
        }
        /**
         * Evaluates a network using the worker process.
         * @param {any} network - The network to evaluate.
         * @returns {Promise<number>} A promise that resolves to the evaluation result.
         */
        evaluate(network) {
          return new Promise((resolve, reject) => {
            const serialized = network.serialize();
            const data = {
              activations: new Float64Array(serialized[0]).buffer,
              states: new Float64Array(serialized[1]).buffer,
              conns: new Float64Array(serialized[2]).buffer
            };
            this.worker.onmessage = function(e) {
              const error = new Float64Array(e.data.buffer)[0];
              resolve(error);
            };
            this.worker.postMessage(data, [
              data.activations,
              data.states,
              data.conns
            ]);
          });
        }
        /**
         * Terminates the worker process and revokes the object URL.
         */
        terminate() {
          this.worker.terminate();
          window.URL.revokeObjectURL(this.url);
        }
        /**
         * Creates a string representation of the worker's blob.
         * @param {any} cost - The cost function to be used by the worker.
         * @returns {string} The blob string.
         */
        static _createBlobString(cost) {
          return `
      const F = [${Multi.activations.toString()}];
      const cost = ${cost.toString()};
      const multi = {
        deserializeDataSet: ${Multi.deserializeDataSet.toString()},
        testSerializedSet: ${Multi.testSerializedSet.toString()},
        activateSerializedNetwork: ${Multi.activateSerializedNetwork.toString()}
      };

      let set;

      this.onmessage = function (e) {
        if (typeof e.data.set === 'undefined') {
          const A = new Float64Array(e.data.activations);
          const S = new Float64Array(e.data.states);
          const data = new Float64Array(e.data.conns);

          const error = multi.testSerializedSet(set, cost, A, S, data, F);

          const answer = { buffer: new Float64Array([error]).buffer };
          postMessage(answer, [answer.buffer]);
        } else {
          set = multi.deserializeDataSet(new Float64Array(e.data.set));
        }
      };`;
        }
      };
    }
  });

  // src/multithreading/workers/workers.ts
  var Workers;
  var init_workers = __esm({
    "src/multithreading/workers/workers.ts"() {
      "use strict";
      Workers = class {
        /**
         * Loads the Node.js test worker dynamically.
         * @returns {Promise<any>} A promise that resolves to the Node.js TestWorker class.
         */
        static async getNodeTestWorker() {
          const module = await Promise.resolve().then(() => (init_testworker(), testworker_exports));
          return module.TestWorker;
        }
        /**
         * Loads the browser test worker dynamically.
         * @returns {Promise<any>} A promise that resolves to the browser TestWorker class.
         */
        static async getBrowserTestWorker() {
          const module = await Promise.resolve().then(() => (init_testworker2(), testworker_exports2));
          return module.TestWorker;
        }
      };
    }
  });

  // src/multithreading/multi.ts
  var Multi;
  var init_multi = __esm({
    "src/multithreading/multi.ts"() {
      "use strict";
      init_workers();
      init_network();
      Multi = class _Multi {
        /** Workers for multi-threading */
        static workers = Workers;
        /**
         * A list of compiled activation functions in a specific order.
         */
        static activations = [
          (x) => 1 / (1 + Math.exp(-x)),
          // Logistic (0)
          (x) => Math.tanh(x),
          // Tanh (1)
          (x) => x,
          // Identity (2)
          (x) => x > 0 ? 1 : 0,
          // Step (3)
          (x) => x > 0 ? x : 0,
          // ReLU (4)
          (x) => x / (1 + Math.abs(x)),
          // Softsign (5)
          (x) => Math.sin(x),
          // Sinusoid (6)
          (x) => Math.exp(-Math.pow(x, 2)),
          // Gaussian (7)
          (x) => (Math.sqrt(Math.pow(x, 2) + 1) - 1) / 2 + x,
          // Bent Identity (8)
          (x) => x > 0 ? 1 : -1,
          // Bipolar (9)
          (x) => 2 / (1 + Math.exp(-x)) - 1,
          // Bipolar Sigmoid (10)
          (x) => Math.max(-1, Math.min(1, x)),
          // Hard Tanh (11)
          (x) => Math.abs(x),
          // Absolute (12)
          (x) => 1 - x,
          // Inverse (13)
          (x) => {
            const alpha = 1.6732632423543772;
            const scale = 1.0507009873554805;
            const fx = x > 0 ? x : alpha * Math.exp(x) - alpha;
            return fx * scale;
          },
          (x) => Math.log(1 + Math.exp(x))
          // Softplus (15) - Added
        ];
        /**
         * Serializes a dataset into a flat array.
         * @param {Array<{ input: number[]; output: number[] }>} dataSet - The dataset to serialize.
         * @returns {number[]} The serialized dataset.
         */
        static serializeDataSet(dataSet) {
          const serialized = [dataSet[0].input.length, dataSet[0].output.length];
          for (let i = 0; i < dataSet.length; i++) {
            for (let j = 0; j < serialized[0]; j++) {
              serialized.push(dataSet[i].input[j]);
            }
            for (let j = 0; j < serialized[1]; j++) {
              serialized.push(dataSet[i].output[j]);
            }
          }
          return serialized;
        }
        /**
         * Activates a serialized network.
         * @param {number[]} input - The input values.
         * @param {number[]} A - The activations array.
         * @param {number[]} S - The states array.
         * @param {number[]} data - The serialized network data.
         * @param {Function[]} F - The activation functions.
         * @returns {number[]} The output values.
         */
        static activateSerializedNetwork(input, A, S, data, F) {
          for (let i = 0; i < data[0]; i++) A[i] = input[i];
          for (let i = 2; i < data.length; i++) {
            const index = data[i++];
            const bias = data[i++];
            const squash = data[i++];
            const selfweight = data[i++];
            const selfgater = data[i++];
            S[index] = (selfgater === -1 ? 1 : A[selfgater]) * selfweight * S[index] + bias;
            while (data[i] !== -2) {
              S[index] += A[data[i++]] * data[i++] * (data[i++] === -1 ? 1 : A[data[i - 1]]);
            }
            A[index] = F[squash](S[index]);
          }
          const output = [];
          for (let i = A.length - data[1]; i < A.length; i++) output.push(A[i]);
          return output;
        }
        /**
         * Deserializes a dataset from a flat array.
         * @param {number[]} serializedSet - The serialized dataset.
         * @returns {Array<{ input: number[]; output: number[] }>} The deserialized dataset as an array of input-output pairs.
         */
        static deserializeDataSet(serializedSet) {
          const set = [];
          const sampleSize = serializedSet[0] + serializedSet[1];
          for (let i = 0; i < (serializedSet.length - 2) / sampleSize; i++) {
            const input = [];
            for (let j = 2 + i * sampleSize; j < 2 + i * sampleSize + serializedSet[0]; j++) {
              input.push(serializedSet[j]);
            }
            const output = [];
            for (let j = 2 + i * sampleSize + serializedSet[0]; j < 2 + i * sampleSize + sampleSize; j++) {
              output.push(serializedSet[j]);
            }
            set.push({ input, output });
          }
          return set;
        }
        /**
         * Logistic activation function.
         * @param {number} x - The input value.
         * @returns {number} The activated value.
         */
        static logistic(x) {
          return 1 / (1 + Math.exp(-x));
        }
        /**
         * Hyperbolic tangent activation function.
         * @param {number} x - The input value.
         * @returns {number} The activated value.
         */
        static tanh(x) {
          return Math.tanh(x);
        }
        /**
         * Identity activation function.
         * @param {number} x - The input value.
         * @returns {number} The activated value.
         */
        static identity(x) {
          return x;
        }
        /**
         * Step activation function.
         * @param {number} x - The input value.
         * @returns {number} The activated value.
         */
        static step(x) {
          return x > 0 ? 1 : 0;
        }
        /**
         * Rectified Linear Unit (ReLU) activation function.
         * @param {number} x - The input value.
         * @returns {number} The activated value.
         */
        static relu(x) {
          return x > 0 ? x : 0;
        }
        /**
         * Softsign activation function.
         * @param {number} x - The input value.
         * @returns {number} The activated value.
         */
        static softsign(x) {
          return x / (1 + Math.abs(x));
        }
        /**
         * Sinusoid activation function.
         * @param {number} x - The input value.
         * @returns {number} The activated value.
         */
        static sinusoid(x) {
          return Math.sin(x);
        }
        /**
         * Gaussian activation function.
         * @param {number} x - The input value.
         * @returns {number} The activated value.
         */
        static gaussian(x) {
          return Math.exp(-Math.pow(x, 2));
        }
        /**
         * Bent Identity activation function.
         * @param {number} x - The input value.
         * @returns {number} The activated value.
         */
        static bentIdentity(x) {
          return (Math.sqrt(Math.pow(x, 2) + 1) - 1) / 2 + x;
        }
        /**
         * Bipolar activation function.
         * @param {number} x - The input value.
         * @returns {number} The activated value.
         */
        static bipolar(x) {
          return x > 0 ? 1 : -1;
        }
        /**
         * Bipolar Sigmoid activation function.
         * @param {number} x - The input value.
         * @returns {number} The activated value.
         */
        static bipolarSigmoid(x) {
          return 2 / (1 + Math.exp(-x)) - 1;
        }
        /**
         * Hard Tanh activation function.
         * @param {number} x - The input value.
         * @returns {number} The activated value.
         */
        static hardTanh(x) {
          return Math.max(-1, Math.min(1, x));
        }
        /**
         * Absolute activation function.
         * @param {number} x - The input value.
         * @returns {number} The activated value.
         */
        static absolute(x) {
          return Math.abs(x);
        }
        /**
         * Inverse activation function.
         * @param {number} x - The input value.
         * @returns {number} The activated value.
         */
        static inverse(x) {
          return 1 - x;
        }
        /**
         * Scaled Exponential Linear Unit (SELU) activation function.
         * @param {number} x - The input value.
         * @returns {number} The activated value.
         */
        static selu(x) {
          const alpha = 1.6732632423543772;
          const scale = 1.0507009873554805;
          const fx = x > 0 ? x : alpha * Math.exp(x) - alpha;
          return fx * scale;
        }
        /**
         * Softplus activation function. - Added
         * @param {number} x - The input value.
         * @returns {number} The activated value.
         */
        static softplus(x) {
          return Math.log(1 + Math.exp(x));
        }
        /**
         * Tests a serialized dataset using a cost function.
         * @param {Array<{ input: number[]; output: number[] }>} set - The serialized dataset as an array of input-output pairs.
         * @param {Function} cost - The cost function.
         * @param {number[]} A - The activations array.
         * @param {number[]} S - The states array.
         * @param {number[]} data - The serialized network data.
         * @param {Function[]} F - The activation functions.
         * @returns {number} The average error.
         */
        static testSerializedSet(set, cost, A, S, data, F) {
          let error = 0;
          for (let i = 0; i < set.length; i++) {
            const output = _Multi.activateSerializedNetwork(
              set[i].input,
              A,
              S,
              data,
              F
            );
            error += cost(set[i].output, output);
          }
          return error / set.length;
        }
        /**
         * Gets the browser test worker.
         * @returns {Promise<any>} The browser test worker.
         */
        static async getBrowserTestWorker() {
          const { TestWorker: TestWorker3 } = await Promise.resolve().then(() => (init_testworker2(), testworker_exports2));
          return TestWorker3;
        }
        /**
         * Gets the node test worker.
         * @returns {Promise<any>} The node test worker.
         */
        static async getNodeTestWorker() {
          const { TestWorker: TestWorker3 } = await Promise.resolve().then(() => (init_testworker(), testworker_exports));
          return TestWorker3;
        }
      };
    }
  });

  // src/architecture/activationArrayPool.ts
  var ActivationArrayPool, activationArrayPool;
  var init_activationArrayPool = __esm({
    "src/architecture/activationArrayPool.ts"() {
      "use strict";
      init_config();
      ActivationArrayPool = class {
        /** Buckets keyed by length, storing reusable arrays. */
        buckets = /* @__PURE__ */ new Map();
        /** Count of arrays created since last clear(), for diagnostics. */
        created = 0;
        /** Count of successful reuses since last clear(), for diagnostics. */
        reused = 0;
        /** Max arrays retained per size bucket; Infinity by default. */
        maxPerBucket = Number.POSITIVE_INFINITY;
        /**
         * Acquire an activation array of fixed length.
         * Zero-fills reused arrays to guarantee clean state.
         *
         * @param size Required array length.
         * @returns Zeroed activation array of the requested size.
         */
        acquire(size) {
          const bucket = this.buckets.get(size);
          if (bucket && bucket.length > 0) {
            this.reused++;
            const arr = bucket.pop();
            arr.fill(0);
            return arr;
          }
          this.created++;
          return config.float32Mode ? new Float32Array(size) : new Array(size).fill(0);
        }
        /**
         * Return an activation array to the pool. If the bucket is full per
         * `maxPerBucket`, the array is dropped and left to GC.
         *
         * @param array Array to release back to the pool.
         */
        release(array) {
          const size = array.length >>> 0;
          if (!this.buckets.has(size)) this.buckets.set(size, []);
          const bucket = this.buckets.get(size);
          if (bucket.length < this.maxPerBucket) bucket.push(array);
        }
        /**
         * Clear all buckets and reset counters. Frees references to pooled arrays.
         */
        clear() {
          this.buckets.clear();
          this.created = 0;
          this.reused = 0;
        }
        /**
         * Snapshot of diagnostics: creations, reuses, and number of active buckets.
         */
        stats() {
          return {
            created: this.created,
            reused: this.reused,
            bucketCount: this.buckets.size
          };
        }
        /**
         * Configure a capacity cap per size bucket to avoid unbounded memory growth.
         *
         * @param cap Non-negative capacity per bucket (Infinity allowed).
         */
        setMaxPerBucket(cap) {
          if (typeof cap === "number" && cap >= 0) this.maxPerBucket = cap;
        }
        /**
         * Pre-allocate and retain arrays for a given size bucket up to `count` items.
         *
         * @param size Array length (bucket key).
         * @param count Number of arrays to prepare (rounded down, min 0).
         */
        prewarm(size, count) {
          const n = Math.max(0, Math.floor(count));
          if (!this.buckets.has(size)) this.buckets.set(size, []);
          const bucket = this.buckets.get(size);
          for (let i = 0; i < n && bucket.length < this.maxPerBucket; i++) {
            const arr = config.float32Mode ? new Float32Array(size) : new Array(size).fill(0);
            bucket.push(arr);
            this.created++;
          }
        }
        /**
         * Current retained count for a size bucket.
         *
         * @param size Array length (bucket key).
         * @returns Number of arrays available to reuse for that length.
         */
        bucketSize(size) {
          return this.buckets.get(size)?.length ?? 0;
        }
      };
      activationArrayPool = new ActivationArrayPool();
    }
  });

  // package.json
  var require_package = __commonJS({
    "package.json"(exports, module) {
      module.exports = {
        name: "@reicek/neataptic-ts",
        version: "0.1.11",
        description: "Architecture-free neural network library with genetic algorithm implementations",
        main: "./dist/neataptic.js",
        module: "./dist/neataptic.js",
        types: "./dist/neataptic.d.ts",
        type: "module",
        scripts: {
          test: "jest --config=jest.config.mjs --no-cache --coverage --collect-coverage --runInBand --testPathIgnorePatterns=.e2e.test.ts --verbose",
          pretest: "npm run build",
          "test:bench": "jest --no-cache --runInBand --verbose --testPathPattern=benchmark",
          "bench:asciiMaze": "node -r ts-node/register test/benchmarks/asciiMaze.micro.bench.ts",
          "test:silent": "jest --no-cache --coverage --collect-coverage --runInBand --testPathIgnorePatterns=.e2e.test.ts --silent",
          deploy: "npm run build && npm run test:dist && npm publish",
          build: "npm run build:webpack && npm run build:ts",
          "build:ts": "tsc",
          "build:webpack": "webpack --config webpack.config.js",
          "start:ts": "ts-node src/neataptic.ts",
          "test:e2e": "cross-env FORCE_COLOR=true jest e2e.test.ts --no-cache --runInBand",
          "test:e2e:logs": "npx jest e2e.test.ts --verbose --runInBand --no-cache",
          "test:dist": "npm run build:ts && jest --no-cache --coverage --collect-coverage --runInBand --testPathIgnorePatterns=.e2e.test.ts",
          "docs:build-scripts": "tsc -p tsconfig.docs.json && node scripts/write-dist-docs-pkg.mjs",
          "docs:folders": "npm run docs:build-scripts && node ./dist-docs/scripts/generate-docs.js",
          "docs:html": "npm run docs:build-scripts && node ./dist-docs/scripts/render-docs-html.js",
          "build:ascii-maze": "npx esbuild test/examples/asciiMaze/browser-entry.ts --bundle --outfile=docs/assets/ascii-maze.bundle.js --platform=browser --format=iife --sourcemap --external:fs --external:child_process --external:path",
          "docs:examples": "node scripts/copy-examples.mjs",
          prettier: "npm run prettier:tests && npm run prettier:src",
          "prettier:tests": "npx prettier --write test/**/*.ts",
          "prettier:src": "npx prettier --write src/**/*.ts",
          docs: "npm run build:ascii-maze && npm run docs:examples && npm run docs:build-scripts && node ./dist-docs/scripts/generate-docs.js && node ./dist-docs/scripts/render-docs-html.js",
          "onnx:export": "node scripts/export-onnx.mjs"
        },
        exports: {
          ".": {
            types: "./dist/neataptic.d.ts",
            import: "./dist/neataptic.js"
          }
        },
        devDependencies: {
          "@types/chai": "^5.2.2",
          "@types/fs-extra": "^11.0.4",
          "@types/jest": "^30.0.0",
          "@types/node": "^24.3.0",
          "@types/seedrandom": "^3.0.8",
          "@types/webpack": "^5.28.5",
          "@types/webpack-dev-server": "^4.7.2",
          chai: "^6.0.1",
          "copy-webpack-plugin": "^13.0.1",
          "cross-env": "^10.0.0",
          esbuild: "^0.25.9",
          "fast-glob": "^3.3.3",
          "fs-extra": "^11.3.1",
          husky: "^9.1.7",
          jest: "^30.0.5",
          "jest-environment-jsdom": "^30.0.5",
          "jsdoc-to-markdown": "^9.1.2",
          marked: "^16.2.0",
          mkdocs: "^0.0.1",
          puppeteer: "^24.17.0",
          "ts-jest": "^29.4.1",
          "ts-loader": "^9.5.2",
          "ts-morph": "^26.0.0",
          "ts-node": "^10.9.2",
          typescript: "^5.9.2",
          "undici-types": "^7.15.0",
          webpack: "^5.101.3",
          "webpack-cli": "^6.0.1"
        },
        repository: {
          type: "git",
          url: "https://github.com/reicek/NeatapticTS.git"
        },
        keywords: [
          "neural network",
          "machine learning",
          "genetic algorithm",
          "mutation",
          "neat"
        ],
        author: {
          name: "Cesar Anton",
          email: "reicek@gmail.com"
        },
        license: "MIT",
        publishConfig: {
          access: "public",
          registry: "https://registry.npmjs.org/"
        },
        bugs: {
          url: "https://github.com/reicek/NeatapticTS/issues",
          email: "reicek@gmail.com"
        },
        homepage: "https://reicek.github.io/NeatapticTS/",
        engines: {
          node: ">=22.0.0"
        },
        prettier: {
          singleQuote: true
        },
        dependencies: {
          seedrandom: "^3.0.5",
          undici: "^7.15.0"
        }
      };
    }
  });

  // src/architecture/network/network.onnx.ts
  function rebuildConnectionsLocal(networkLike) {
    const uniqueConnections = /* @__PURE__ */ new Set();
    networkLike.nodes.forEach(
      (node) => node.connections?.out.forEach((conn) => uniqueConnections.add(conn))
    );
    networkLike.connections = Array.from(uniqueConnections);
  }
  function mapActivationToOnnx(squash) {
    const upperName = (squash?.name || "").toUpperCase();
    if (upperName.includes("TANH")) return "Tanh";
    if (upperName.includes("LOGISTIC") || upperName.includes("SIGMOID"))
      return "Sigmoid";
    if (upperName.includes("RELU")) return "Relu";
    if (squash)
      console.warn(
        `Unsupported activation function ${squash.name} for ONNX export, defaulting to Identity.`
      );
    return "Identity";
  }
  function inferLayerOrdering(network) {
    const inputNodes = network.nodes.filter((n) => n.type === "input");
    const outputNodes = network.nodes.filter((n) => n.type === "output");
    const hiddenNodes = network.nodes.filter((n) => n.type === "hidden");
    if (hiddenNodes.length === 0) return [inputNodes, outputNodes];
    let remainingHidden = [...hiddenNodes];
    let previousLayer = inputNodes;
    const layerAccumulator = [];
    while (remainingHidden.length) {
      const currentLayer = remainingHidden.filter(
        (hidden) => hidden.connections.in.every(
          (conn) => previousLayer.includes(conn.from)
        )
      );
      if (!currentLayer.length)
        throw new Error(
          "Invalid network structure for ONNX export: cannot resolve layered ordering."
        );
      layerAccumulator.push(previousLayer);
      previousLayer = currentLayer;
      remainingHidden = remainingHidden.filter((h) => !currentLayer.includes(h));
    }
    layerAccumulator.push(previousLayer);
    layerAccumulator.push(outputNodes);
    return layerAccumulator;
  }
  function validateLayerHomogeneityAndConnectivity(layers, network, options) {
    for (let layerIndex = 1; layerIndex < layers.length; layerIndex++) {
      const previousLayerNodes = layers[layerIndex - 1];
      const currentLayerNodes = layers[layerIndex];
      const activationNameSet = new Set(
        currentLayerNodes.map((n) => n.squash && n.squash.name)
      );
      if (activationNameSet.size > 1 && !options.allowMixedActivations)
        throw new Error(
          `ONNX export error: Mixed activation functions detected in layer ${layerIndex}. (enable allowMixedActivations to decompose layer)`
        );
      if (activationNameSet.size > 1 && options.allowMixedActivations)
        console.warn(
          `Warning: Mixed activations in layer ${layerIndex}; exporting per-neuron Gemm + Activation (+Concat) baseline.`
        );
      for (const targetNode of currentLayerNodes) {
        for (const sourceNode of previousLayerNodes) {
          const isConnected = targetNode.connections.in.some(
            (conn) => conn.from === sourceNode
          );
          if (!isConnected && !options.allowPartialConnectivity)
            throw new Error(
              `ONNX export error: Missing connection from node ${sourceNode.index} to node ${targetNode.index} in layer ${layerIndex}. (enable allowPartialConnectivity)`
            );
        }
      }
    }
  }
  function buildOnnxModel(network, layers, options = {}) {
    const {
      includeMetadata = false,
      opset = 18,
      batchDimension = false,
      legacyNodeOrdering = false,
      producerName = "neataptic-ts",
      producerVersion,
      docString
    } = options;
    const inputLayerNodes = layers[0];
    const outputLayerNodes = layers[layers.length - 1];
    const batchDims = batchDimension ? [{ dim_param: "N" }, { dim_value: inputLayerNodes.length }] : [{ dim_value: inputLayerNodes.length }];
    const outBatchDims = batchDimension ? [{ dim_param: "N" }, { dim_value: outputLayerNodes.length }] : [{ dim_value: outputLayerNodes.length }];
    const model = {
      graph: {
        inputs: [
          {
            name: "input",
            type: {
              tensor_type: {
                elem_type: 1,
                shape: { dim: batchDims }
              }
            }
          }
        ],
        outputs: [
          {
            name: "output",
            type: {
              tensor_type: {
                elem_type: 1,
                shape: { dim: outBatchDims }
              }
            }
          }
        ],
        initializer: [],
        node: []
      }
    };
    if (includeMetadata) {
      const pkgVersion = (() => {
        try {
          return require_package().version;
        } catch {
          return "0.0.0";
        }
      })();
      model.ir_version = 9;
      model.opset_import = [{ version: opset, domain: "" }];
      model.producer_name = producerName;
      model.producer_version = producerVersion || pkgVersion;
      model.doc_string = docString || "Exported from NeatapticTS ONNX exporter (phases 1-2 baseline)";
    }
    let previousOutputName = "input";
    const recurrentLayerIndices = [];
    if (options.allowRecurrent && options.recurrentSingleStep) {
      for (let layerIndex = 1; layerIndex < layers.length - 1; layerIndex++) {
        const hiddenLayerNodes = layers[layerIndex];
        if (hiddenLayerNodes.some((n) => n.connections.self.length > 0)) {
          recurrentLayerIndices.push(layerIndex);
          const prevName = layerIndex === 1 ? "hidden_prev" : `hidden_prev_l${layerIndex}`;
          model.graph.inputs.push({
            name: prevName,
            type: {
              tensor_type: {
                elem_type: 1,
                shape: {
                  dim: batchDimension ? [{ dim_param: "N" }, { dim_value: hiddenLayerNodes.length }] : [{ dim_value: hiddenLayerNodes.length }]
                }
              }
            }
          });
        }
      }
    }
    const hiddenSizesMetadata = [];
    for (let layerIndex = 1; layerIndex < layers.length; layerIndex++) {
      const previousLayerNodes = layers[layerIndex - 1];
      const currentLayerNodes = layers[layerIndex];
      const isOutputLayer = layerIndex === layers.length - 1;
      if (!isOutputLayer) hiddenSizesMetadata.push(currentLayerNodes.length);
      const convSpec = options.conv2dMappings?.find(
        (m) => m.layerIndex === layerIndex
      );
      if (convSpec) {
        const prevWidthExpected = convSpec.inHeight * convSpec.inWidth * convSpec.inChannels;
        const prevWidthActual = previousLayerNodes.length;
        const thisWidthExpected = convSpec.outChannels * convSpec.outHeight * convSpec.outWidth;
        const thisWidthActual = currentLayerNodes.length;
        const pads = [
          convSpec.padTop || 0,
          convSpec.padLeft || 0,
          convSpec.padBottom || 0,
          convSpec.padRight || 0
        ];
        const shapeValid = prevWidthExpected === prevWidthActual && thisWidthExpected === thisWidthActual;
        if (!shapeValid) {
          console.warn(
            `Conv2D mapping for layer ${layerIndex} skipped: dimension mismatch (expected prev=${prevWidthExpected} got ${prevWidthActual}; expected this=${thisWidthExpected} got ${thisWidthActual}).`
          );
        } else {
          const W = [];
          const B = [];
          for (let oc = 0; oc < convSpec.outChannels; oc++) {
            const repIndex = oc * convSpec.outHeight * convSpec.outWidth;
            const repNeuron = currentLayerNodes[repIndex];
            B.push(repNeuron.bias);
            for (let ic = 0; ic < convSpec.inChannels; ic++) {
              for (let kh = 0; kh < convSpec.kernelHeight; kh++) {
                for (let kw = 0; kw < convSpec.kernelWidth; kw++) {
                  const inputFeatureIndex = ic * (convSpec.inHeight * convSpec.inWidth) + kh * convSpec.inWidth + kw;
                  const sourceNode = previousLayerNodes[inputFeatureIndex];
                  const conn = repNeuron.connections.in.find(
                    (cc) => cc.from === sourceNode
                  );
                  W.push(conn ? conn.weight : 0);
                }
              }
            }
          }
          const convWName = `ConvW${layerIndex - 1}`;
          const convBName = `ConvB${layerIndex - 1}`;
          model.graph.initializer.push({
            name: convWName,
            data_type: 1,
            dims: [
              convSpec.outChannels,
              convSpec.inChannels,
              convSpec.kernelHeight,
              convSpec.kernelWidth
            ],
            float_data: W
          });
          model.graph.initializer.push({
            name: convBName,
            data_type: 1,
            dims: [convSpec.outChannels],
            float_data: B
          });
          const convOut = `Conv_${layerIndex}`;
          model.graph.node.push({
            op_type: "Conv",
            input: [previousOutputName, convWName, convBName],
            output: [convOut],
            name: `conv_l${layerIndex}`,
            attributes: [
              {
                name: "kernel_shape",
                type: "INTS",
                ints: [convSpec.kernelHeight, convSpec.kernelWidth]
              },
              {
                name: "strides",
                type: "INTS",
                ints: [convSpec.strideHeight, convSpec.strideWidth]
              },
              { name: "pads", type: "INTS", ints: pads }
            ]
          });
          const actOp = convSpec.activation || mapActivationToOnnx(currentLayerNodes[0].squash);
          const activationOutputName = `Layer_${layerIndex}`;
          model.graph.node.push({
            op_type: actOp,
            input: [convOut],
            output: [activationOutputName],
            name: `act_conv_l${layerIndex}`
          });
          previousOutputName = activationOutputName;
          const poolSpecPostConv = options.pool2dMappings?.find(
            (p) => p.afterLayerIndex === layerIndex
          );
          if (poolSpecPostConv) {
            const kernel = [
              poolSpecPostConv.kernelHeight,
              poolSpecPostConv.kernelWidth
            ];
            const strides = [
              poolSpecPostConv.strideHeight,
              poolSpecPostConv.strideWidth
            ];
            const pads2 = [
              poolSpecPostConv.padTop || 0,
              poolSpecPostConv.padLeft || 0,
              poolSpecPostConv.padBottom || 0,
              poolSpecPostConv.padRight || 0
            ];
            const poolOut = `Pool_${layerIndex}`;
            model.graph.node.push({
              op_type: poolSpecPostConv.type,
              input: [previousOutputName],
              output: [poolOut],
              name: `pool_after_l${layerIndex}`,
              attributes: [
                { name: "kernel_shape", type: "INTS", ints: kernel },
                { name: "strides", type: "INTS", ints: strides },
                { name: "pads", type: "INTS", ints: pads2 }
              ]
            });
            previousOutputName = poolOut;
            if (options.flattenAfterPooling) {
              const flatOut = `PoolFlat_${layerIndex}`;
              model.graph.node.push({
                op_type: "Flatten",
                input: [previousOutputName],
                output: [flatOut],
                name: `flatten_after_l${layerIndex}`,
                attributes: [{ name: "axis", type: "INT", i: 1 }]
              });
              previousOutputName = flatOut;
              model.metadata_props = model.metadata_props || [];
              const flMeta = model.metadata_props.find(
                (m) => m.key === "flatten_layers"
              );
              if (flMeta) {
                try {
                  const arr = JSON.parse(flMeta.value);
                  if (Array.isArray(arr) && !arr.includes(layerIndex)) {
                    arr.push(layerIndex);
                    flMeta.value = JSON.stringify(arr);
                  }
                } catch {
                  flMeta.value = JSON.stringify([layerIndex]);
                }
              } else {
                model.metadata_props.push({
                  key: "flatten_layers",
                  value: JSON.stringify([layerIndex])
                });
              }
            }
            model.metadata_props = model.metadata_props || [];
            const poolLayersMeta = model.metadata_props.find(
              (m) => m.key === "pool2d_layers"
            );
            if (poolLayersMeta) {
              try {
                const arr = JSON.parse(poolLayersMeta.value);
                if (Array.isArray(arr) && !arr.includes(layerIndex)) {
                  arr.push(layerIndex);
                  poolLayersMeta.value = JSON.stringify(arr);
                }
              } catch {
                poolLayersMeta.value = JSON.stringify([layerIndex]);
              }
            } else {
              model.metadata_props.push({
                key: "pool2d_layers",
                value: JSON.stringify([layerIndex])
              });
            }
            const poolSpecsMeta = model.metadata_props.find(
              (m) => m.key === "pool2d_specs"
            );
            if (poolSpecsMeta) {
              try {
                const arr = JSON.parse(poolSpecsMeta.value);
                if (Array.isArray(arr)) {
                  arr.push({ ...poolSpecPostConv });
                  poolSpecsMeta.value = JSON.stringify(arr);
                }
              } catch {
                poolSpecsMeta.value = JSON.stringify([poolSpecPostConv]);
              }
            } else {
              model.metadata_props.push({
                key: "pool2d_specs",
                value: JSON.stringify([poolSpecPostConv])
              });
            }
          }
          model.metadata_props = model.metadata_props || [];
          const convLayersMeta = model.metadata_props.find(
            (m) => m.key === "conv2d_layers"
          );
          if (convLayersMeta) {
            try {
              const arr = JSON.parse(convLayersMeta.value);
              if (Array.isArray(arr) && !arr.includes(layerIndex)) {
                arr.push(layerIndex);
                convLayersMeta.value = JSON.stringify(arr);
              }
            } catch {
              convLayersMeta.value = JSON.stringify([layerIndex]);
            }
          } else {
            model.metadata_props.push({
              key: "conv2d_layers",
              value: JSON.stringify([layerIndex])
            });
          }
          const convSpecsMeta = model.metadata_props.find(
            (m) => m.key === "conv2d_specs"
          );
          if (convSpecsMeta) {
            try {
              const arr = JSON.parse(convSpecsMeta.value);
              if (Array.isArray(arr)) {
                arr.push({ ...convSpec });
                convSpecsMeta.value = JSON.stringify(arr);
              }
            } catch {
              convSpecsMeta.value = JSON.stringify([convSpec]);
            }
          } else {
            model.metadata_props.push({
              key: "conv2d_specs",
              value: JSON.stringify([convSpec])
            });
          }
          continue;
        }
      }
      const mixed = options.allowMixedActivations && new Set(currentLayerNodes.map((n) => n.squash && n.squash.name)).size > 1;
      if (recurrentLayerIndices.includes(layerIndex) && !isOutputLayer) {
        if (mixed)
          throw new Error(
            `Recurrent export does not yet support mixed activations in hidden layer ${layerIndex}.`
          );
        const weightMatrixValues = [];
        const biasVector = new Array(currentLayerNodes.length).fill(0);
        for (let r = 0; r < currentLayerNodes.length; r++) {
          const targetNode = currentLayerNodes[r];
          biasVector[r] = targetNode.bias;
          for (let c = 0; c < previousLayerNodes.length; c++) {
            const sourceNode = previousLayerNodes[c];
            const inboundConn = targetNode.connections.in.find(
              (conn) => conn.from === sourceNode
            );
            weightMatrixValues.push(inboundConn ? inboundConn.weight : 0);
          }
        }
        const weightTensorName = `W${layerIndex - 1}`;
        const biasTensorName = `B${layerIndex - 1}`;
        model.graph.initializer.push({
          name: weightTensorName,
          data_type: 1,
          dims: [currentLayerNodes.length, previousLayerNodes.length],
          float_data: weightMatrixValues
        });
        model.graph.initializer.push({
          name: biasTensorName,
          data_type: 1,
          dims: [currentLayerNodes.length],
          float_data: biasVector
        });
        const recurrentWeights = [];
        for (let r = 0; r < currentLayerNodes.length; r++) {
          for (let c = 0; c < currentLayerNodes.length; c++) {
            if (r === c) {
              const selfConn = currentLayerNodes[r].connections.self[0];
              recurrentWeights.push(selfConn ? selfConn.weight : 0);
            } else {
              recurrentWeights.push(0);
            }
          }
        }
        const rName = `R${layerIndex - 1}`;
        model.graph.initializer.push({
          name: rName,
          data_type: 1,
          dims: [currentLayerNodes.length, currentLayerNodes.length],
          float_data: recurrentWeights
        });
        model.graph.node.push({
          op_type: "Gemm",
          input: [previousOutputName, weightTensorName, biasTensorName],
          output: [`Gemm_in_${layerIndex}`],
          name: `gemm_in_l${layerIndex}`,
          attributes: [
            { name: "alpha", type: "FLOAT", f: 1 },
            { name: "beta", type: "FLOAT", f: 1 },
            { name: "transB", type: "INT", i: 1 }
          ]
        });
        const prevHiddenInputName = layerIndex === 1 ? "hidden_prev" : `hidden_prev_l${layerIndex}`;
        model.graph.node.push({
          op_type: "Gemm",
          input: [prevHiddenInputName, rName],
          output: [`Gemm_rec_${layerIndex}`],
          name: `gemm_rec_l${layerIndex}`,
          attributes: [
            { name: "alpha", type: "FLOAT", f: 1 },
            { name: "beta", type: "FLOAT", f: 1 },
            { name: "transB", type: "INT", i: 1 }
          ]
        });
        model.graph.node.push({
          op_type: "Add",
          input: [`Gemm_in_${layerIndex}`, `Gemm_rec_${layerIndex}`],
          output: [`RecurrentSum_${layerIndex}`],
          name: `add_recurrent_l${layerIndex}`
        });
        model.graph.node.push({
          op_type: mapActivationToOnnx(currentLayerNodes[0].squash),
          input: [`RecurrentSum_${layerIndex}`],
          output: [`Layer_${layerIndex}`],
          name: `act_l${layerIndex}`
        });
        previousOutputName = `Layer_${layerIndex}`;
      } else if (!mixed) {
        const weightMatrixValues = [];
        const biasVector = new Array(currentLayerNodes.length).fill(0);
        for (let r = 0; r < currentLayerNodes.length; r++) {
          const targetNode = currentLayerNodes[r];
          biasVector[r] = targetNode.bias;
          for (let c = 0; c < previousLayerNodes.length; c++) {
            const sourceNode = previousLayerNodes[c];
            const inboundConn = targetNode.connections.in.find(
              (conn) => conn.from === sourceNode
            );
            weightMatrixValues.push(inboundConn ? inboundConn.weight : 0);
          }
        }
        const weightTensorName = `W${layerIndex - 1}`;
        const biasTensorName = `B${layerIndex - 1}`;
        const gemmOutputName = `Gemm_${layerIndex}`;
        const activationOutputName = `Layer_${layerIndex}`;
        model.graph.initializer.push({
          name: weightTensorName,
          data_type: 1,
          dims: [currentLayerNodes.length, previousLayerNodes.length],
          float_data: weightMatrixValues
        });
        model.graph.initializer.push({
          name: biasTensorName,
          data_type: 1,
          dims: [currentLayerNodes.length],
          float_data: biasVector
        });
        if (!legacyNodeOrdering) {
          model.graph.node.push({
            op_type: "Gemm",
            input: [previousOutputName, weightTensorName, biasTensorName],
            output: [gemmOutputName],
            name: `gemm_l${layerIndex}`,
            attributes: [
              { name: "alpha", type: "FLOAT", f: 1 },
              { name: "beta", type: "FLOAT", f: 1 },
              { name: "transB", type: "INT", i: 1 }
            ]
          });
          model.graph.node.push({
            op_type: mapActivationToOnnx(currentLayerNodes[0].squash),
            input: [gemmOutputName],
            output: [activationOutputName],
            name: `act_l${layerIndex}`
          });
        } else {
          model.graph.node.push({
            op_type: mapActivationToOnnx(currentLayerNodes[0].squash),
            input: [gemmOutputName],
            output: [activationOutputName],
            name: `act_l${layerIndex}`
          });
          model.graph.node.push({
            op_type: "Gemm",
            input: [previousOutputName, weightTensorName, biasTensorName],
            output: [gemmOutputName],
            name: `gemm_l${layerIndex}`,
            attributes: [
              { name: "alpha", type: "FLOAT", f: 1 },
              { name: "beta", type: "FLOAT", f: 1 },
              { name: "transB", type: "INT", i: 1 }
            ]
          });
        }
        previousOutputName = activationOutputName;
        const poolSpecDense = options.pool2dMappings?.find(
          (p) => p.afterLayerIndex === layerIndex
        );
        if (poolSpecDense) {
          const kernel = [poolSpecDense.kernelHeight, poolSpecDense.kernelWidth];
          const strides = [poolSpecDense.strideHeight, poolSpecDense.strideWidth];
          const pads = [
            poolSpecDense.padTop || 0,
            poolSpecDense.padLeft || 0,
            poolSpecDense.padBottom || 0,
            poolSpecDense.padRight || 0
          ];
          const poolOut = `Pool_${layerIndex}`;
          model.graph.node.push({
            op_type: poolSpecDense.type,
            input: [previousOutputName],
            output: [poolOut],
            name: `pool_after_l${layerIndex}`,
            attributes: [
              { name: "kernel_shape", type: "INTS", ints: kernel },
              { name: "strides", type: "INTS", ints: strides },
              { name: "pads", type: "INTS", ints: pads }
            ]
          });
          previousOutputName = poolOut;
          if (options.flattenAfterPooling) {
            const flatOut = `PoolFlat_${layerIndex}`;
            model.graph.node.push({
              op_type: "Flatten",
              input: [previousOutputName],
              output: [flatOut],
              name: `flatten_after_l${layerIndex}`,
              attributes: [{ name: "axis", type: "INT", i: 1 }]
            });
            previousOutputName = flatOut;
            model.metadata_props = model.metadata_props || [];
            const flMeta = model.metadata_props.find(
              (m) => m.key === "flatten_layers"
            );
            if (flMeta) {
              try {
                const arr = JSON.parse(flMeta.value);
                if (Array.isArray(arr) && !arr.includes(layerIndex)) {
                  arr.push(layerIndex);
                  flMeta.value = JSON.stringify(arr);
                }
              } catch {
                flMeta.value = JSON.stringify([layerIndex]);
              }
            } else {
              model.metadata_props.push({
                key: "flatten_layers",
                value: JSON.stringify([layerIndex])
              });
            }
          }
          model.metadata_props = model.metadata_props || [];
          const poolLayersMeta = model.metadata_props.find(
            (m) => m.key === "pool2d_layers"
          );
          if (poolLayersMeta) {
            try {
              const arr = JSON.parse(poolLayersMeta.value);
              if (Array.isArray(arr) && !arr.includes(layerIndex)) {
                arr.push(layerIndex);
                poolLayersMeta.value = JSON.stringify(arr);
              }
            } catch {
              poolLayersMeta.value = JSON.stringify([layerIndex]);
            }
          } else {
            model.metadata_props.push({
              key: "pool2d_layers",
              value: JSON.stringify([layerIndex])
            });
          }
          const poolSpecsMeta = model.metadata_props.find(
            (m) => m.key === "pool2d_specs"
          );
          if (poolSpecsMeta) {
            try {
              const arr = JSON.parse(poolSpecsMeta.value);
              if (Array.isArray(arr)) {
                arr.push({ ...poolSpecDense });
                poolSpecsMeta.value = JSON.stringify(arr);
              }
            } catch {
              poolSpecsMeta.value = JSON.stringify([poolSpecDense]);
            }
          } else {
            model.metadata_props.push({
              key: "pool2d_specs",
              value: JSON.stringify([poolSpecDense])
            });
          }
        }
      } else {
        const perNeuronActivationOutputs = [];
        currentLayerNodes.forEach((targetNode, idx) => {
          const weightRow = [];
          for (let c = 0; c < previousLayerNodes.length; c++) {
            const sourceNode = previousLayerNodes[c];
            const inboundConn = targetNode.connections.in.find(
              (conn) => conn.from === sourceNode
            );
            weightRow.push(inboundConn ? inboundConn.weight : 0);
          }
          const weightTensorName = `W${layerIndex - 1}_n${idx}`;
          const biasTensorName = `B${layerIndex - 1}_n${idx}`;
          const gemmOutputName = `Gemm_${layerIndex}_n${idx}`;
          const actOutputName = `Layer_${layerIndex}_n${idx}`;
          model.graph.initializer.push({
            name: weightTensorName,
            data_type: 1,
            dims: [1, previousLayerNodes.length],
            float_data: weightRow
          });
          model.graph.initializer.push({
            name: biasTensorName,
            data_type: 1,
            dims: [1],
            float_data: [targetNode.bias]
          });
          model.graph.node.push({
            op_type: "Gemm",
            input: [previousOutputName, weightTensorName, biasTensorName],
            output: [gemmOutputName],
            name: `gemm_l${layerIndex}_n${idx}`,
            attributes: [
              { name: "alpha", type: "FLOAT", f: 1 },
              { name: "beta", type: "FLOAT", f: 1 },
              { name: "transB", type: "INT", i: 1 }
            ]
          });
          model.graph.node.push({
            op_type: mapActivationToOnnx(targetNode.squash),
            input: [gemmOutputName],
            output: [actOutputName],
            name: `act_l${layerIndex}_n${idx}`
          });
          perNeuronActivationOutputs.push(actOutputName);
        });
        const activationOutputName = `Layer_${layerIndex}`;
        model.graph.node.push({
          op_type: "Concat",
          input: perNeuronActivationOutputs,
          output: [activationOutputName],
          name: `concat_l${layerIndex}`,
          attributes: [{ name: "axis", type: "INT", i: batchDimension ? 1 : 0 }]
        });
        previousOutputName = activationOutputName;
        const poolSpecPerNeuron = options.pool2dMappings?.find(
          (p) => p.afterLayerIndex === layerIndex
        );
        if (poolSpecPerNeuron) {
          const kernel = [
            poolSpecPerNeuron.kernelHeight,
            poolSpecPerNeuron.kernelWidth
          ];
          const strides = [
            poolSpecPerNeuron.strideHeight,
            poolSpecPerNeuron.strideWidth
          ];
          const pads = [
            poolSpecPerNeuron.padTop || 0,
            poolSpecPerNeuron.padLeft || 0,
            poolSpecPerNeuron.padBottom || 0,
            poolSpecPerNeuron.padRight || 0
          ];
          const poolOut = `Pool_${layerIndex}`;
          model.graph.node.push({
            op_type: poolSpecPerNeuron.type,
            input: [previousOutputName],
            output: [poolOut],
            name: `pool_after_l${layerIndex}`,
            attributes: [
              { name: "kernel_shape", type: "INTS", ints: kernel },
              { name: "strides", type: "INTS", ints: strides },
              { name: "pads", type: "INTS", ints: pads }
            ]
          });
          previousOutputName = poolOut;
          if (options.flattenAfterPooling) {
            const flatOut = `PoolFlat_${layerIndex}`;
            model.graph.node.push({
              op_type: "Flatten",
              input: [previousOutputName],
              output: [flatOut],
              name: `flatten_after_l${layerIndex}`,
              attributes: [{ name: "axis", type: "INT", i: 1 }]
            });
            previousOutputName = flatOut;
            model.metadata_props = model.metadata_props || [];
            const flMeta = model.metadata_props.find(
              (m) => m.key === "flatten_layers"
            );
            if (flMeta) {
              try {
                const arr = JSON.parse(flMeta.value);
                if (Array.isArray(arr) && !arr.includes(layerIndex)) {
                  arr.push(layerIndex);
                  flMeta.value = JSON.stringify(arr);
                }
              } catch {
                flMeta.value = JSON.stringify([layerIndex]);
              }
            } else {
              model.metadata_props.push({
                key: "flatten_layers",
                value: JSON.stringify([layerIndex])
              });
            }
          }
          model.metadata_props = model.metadata_props || [];
          const poolLayersMeta = model.metadata_props.find(
            (m) => m.key === "pool2d_layers"
          );
          if (poolLayersMeta) {
            try {
              const arr = JSON.parse(poolLayersMeta.value);
              if (Array.isArray(arr) && !arr.includes(layerIndex)) {
                arr.push(layerIndex);
                poolLayersMeta.value = JSON.stringify(arr);
              }
            } catch {
              poolLayersMeta.value = JSON.stringify([layerIndex]);
            }
          } else {
            model.metadata_props.push({
              key: "pool2d_layers",
              value: JSON.stringify([layerIndex])
            });
          }
          const poolSpecsMeta = model.metadata_props.find(
            (m) => m.key === "pool2d_specs"
          );
          if (poolSpecsMeta) {
            try {
              const arr = JSON.parse(poolSpecsMeta.value);
              if (Array.isArray(arr)) {
                arr.push({ ...poolSpecPerNeuron });
                poolSpecsMeta.value = JSON.stringify(arr);
              }
            } catch {
              poolSpecsMeta.value = JSON.stringify([poolSpecPerNeuron]);
            }
          } else {
            model.metadata_props.push({
              key: "pool2d_specs",
              value: JSON.stringify([poolSpecPerNeuron])
            });
          }
        }
      }
    }
    if (options.allowRecurrent) {
      for (let layerIndex = 1; layerIndex < layers.length - 1; layerIndex++) {
        const current = layers[layerIndex];
        const size = current.length;
        if (!model.metadata_props) model.metadata_props = [];
        if (size >= 8 && size < 10) {
          model.metadata_props.push({
            key: "rnn_pattern_fallback",
            value: JSON.stringify({
              layer: layerIndex,
              reason: "size_between_gru_lstm_thresholds"
            })
          });
        }
        if (size >= 10 && size % 5 === 0) {
          const unit = size / 5;
          const prevLayerNodes = layers[layerIndex - 1];
          const inputGate = current.slice(0, unit);
          const forgetGate = current.slice(unit, unit * 2);
          const cell = current.slice(unit * 2, unit * 3);
          const outputGate = current.slice(unit * 3, unit * 4);
          const outputBlock = current.slice(unit * 4, unit * 5);
          const gateOrder = [inputGate, forgetGate, cell, outputGate];
          const numGates = gateOrder.length;
          const prevSize = prevLayerNodes.length;
          const W = [];
          const R = [];
          const B = [];
          for (let g = 0; g < numGates; g++) {
            const gate2 = gateOrder[g];
            for (let r = 0; r < unit; r++) {
              const neuron = gate2[r];
              for (let c = 0; c < prevSize; c++) {
                const source = prevLayerNodes[c];
                const conn = neuron.connections.in.find(
                  (cc) => cc.from === source
                );
                W.push(conn ? conn.weight : 0);
              }
              for (let c = 0; c < unit; c++) {
                if (gate2 === cell && c === r) {
                  const selfConn = neuron.connections.self[0];
                  R.push(selfConn ? selfConn.weight : 0);
                } else R.push(0);
              }
              B.push(neuron.bias);
            }
          }
          model.graph.initializer.push({
            name: `LSTM_W${layerIndex - 1}`,
            data_type: 1,
            dims: [numGates * unit, prevSize],
            float_data: W
          });
          model.graph.initializer.push({
            name: `LSTM_R${layerIndex - 1}`,
            data_type: 1,
            dims: [numGates * unit, unit],
            float_data: R
          });
          model.graph.initializer.push({
            name: `LSTM_B${layerIndex - 1}`,
            data_type: 1,
            dims: [numGates * unit],
            float_data: B
          });
          model.graph.node.push({
            op_type: "LSTM",
            input: [
              previousOutputName,
              `LSTM_W${layerIndex - 1}`,
              `LSTM_R${layerIndex - 1}`,
              `LSTM_B${layerIndex - 1}`
            ],
            output: [`Layer_${layerIndex}_lstm_hidden`],
            name: `lstm_l${layerIndex}`,
            attributes: [
              { name: "hidden_size", type: "INT", i: unit },
              { name: "layout", type: "INT", i: 0 }
            ]
          });
          model.metadata_props = model.metadata_props || [];
          const lstmMetaIdx = model.metadata_props.findIndex(
            (m) => m.key === "lstm_emitted_layers"
          );
          if (lstmMetaIdx >= 0) {
            try {
              const arr = JSON.parse(model.metadata_props[lstmMetaIdx].value);
              if (Array.isArray(arr) && !arr.includes(layerIndex)) {
                arr.push(layerIndex);
                model.metadata_props[lstmMetaIdx].value = JSON.stringify(arr);
              }
            } catch {
              model.metadata_props[lstmMetaIdx].value = JSON.stringify([
                layerIndex
              ]);
            }
          } else {
            model.metadata_props.push({
              key: "lstm_emitted_layers",
              value: JSON.stringify([layerIndex])
            });
          }
        }
        if (size >= 8 && size % 4 === 0) {
          const unitG = size / 4;
          const prevLayerNodes = layers[layerIndex - 1];
          const updateGate = current.slice(0, unitG);
          const resetGate = current.slice(unitG, unitG * 2);
          const candidate = current.slice(unitG * 2, unitG * 3);
          const outputBlock = current.slice(unitG * 3, unitG * 4);
          const gateOrderGRU = [updateGate, resetGate, candidate];
          const numGatesGRU = gateOrderGRU.length;
          const prevSizeGRU = prevLayerNodes.length;
          const Wg = [];
          const Rg = [];
          const Bg = [];
          for (let g = 0; g < numGatesGRU; g++) {
            const gate2 = gateOrderGRU[g];
            for (let r = 0; r < unitG; r++) {
              const neuron = gate2[r];
              for (let c = 0; c < prevSizeGRU; c++) {
                const src = prevLayerNodes[c];
                const conn = neuron.connections.in.find(
                  (cc) => cc.from === src
                );
                Wg.push(conn ? conn.weight : 0);
              }
              for (let c = 0; c < unitG; c++) {
                if (gate2 === candidate && c === r) {
                  const selfConn = neuron.connections.self[0];
                  Rg.push(selfConn ? selfConn.weight : 0);
                } else Rg.push(0);
              }
              Bg.push(neuron.bias);
            }
          }
          model.graph.initializer.push({
            name: `GRU_W${layerIndex - 1}`,
            data_type: 1,
            dims: [numGatesGRU * unitG, prevSizeGRU],
            float_data: Wg
          });
          model.graph.initializer.push({
            name: `GRU_R${layerIndex - 1}`,
            data_type: 1,
            dims: [numGatesGRU * unitG, unitG],
            float_data: Rg
          });
          model.graph.initializer.push({
            name: `GRU_B${layerIndex - 1}`,
            data_type: 1,
            dims: [numGatesGRU * unitG],
            float_data: Bg
          });
          const prevOutName = layerIndex === 1 ? "input" : `Layer_${layerIndex - 1}`;
          model.graph.node.push({
            op_type: "GRU",
            input: [
              prevOutName,
              `GRU_W${layerIndex - 1}`,
              `GRU_R${layerIndex - 1}`,
              `GRU_B${layerIndex - 1}`
            ],
            output: [`Layer_${layerIndex}_gru_hidden`],
            name: `gru_l${layerIndex}`,
            attributes: [
              { name: "hidden_size", type: "INT", i: unitG },
              { name: "layout", type: "INT", i: 0 }
            ]
          });
          model.metadata_props = model.metadata_props || [];
          const gruMetaIdx = model.metadata_props.findIndex(
            (m) => m.key === "gru_emitted_layers"
          );
          if (gruMetaIdx >= 0) {
            try {
              const arr = JSON.parse(model.metadata_props[gruMetaIdx].value);
              if (Array.isArray(arr) && !arr.includes(layerIndex)) {
                arr.push(layerIndex);
                model.metadata_props[gruMetaIdx].value = JSON.stringify(arr);
              }
            } catch {
              model.metadata_props[gruMetaIdx].value = JSON.stringify([
                layerIndex
              ]);
            }
          } else {
            model.metadata_props.push({
              key: "gru_emitted_layers",
              value: JSON.stringify([layerIndex])
            });
          }
        }
      }
    }
    if (includeMetadata) {
      model.metadata_props = model.metadata_props || [];
      model.metadata_props.push({
        key: "layer_sizes",
        value: JSON.stringify(hiddenSizesMetadata)
      });
      if (recurrentLayerIndices.length) {
        model.metadata_props.push({
          key: "recurrent_single_step",
          value: JSON.stringify(recurrentLayerIndices)
        });
      }
      if (options.validateConvSharing && options.conv2dMappings && options.conv2dMappings.length) {
        const verified = [];
        const mismatched = [];
        for (const spec of options.conv2dMappings) {
          const layerIdx = spec.layerIndex;
          const prevLayerNodes = layers[layerIdx - 1];
          const layerNodes = layers[layerIdx];
          if (!layerNodes || !prevLayerNodes) continue;
          const repPerChannel = [];
          let allOk = true;
          for (let oc = 0; oc < spec.outChannels; oc++) {
            const repIndex = oc * (spec.outHeight * spec.outWidth);
            const repNeuron = layerNodes[repIndex];
            const kernel = [];
            for (let ic = 0; ic < spec.inChannels; ic++) {
              for (let kh = 0; kh < spec.kernelHeight; kh++) {
                for (let kw = 0; kw < spec.kernelWidth; kw++) {
                  const inputFeatureIndex = ic * (spec.inHeight * spec.inWidth) + kh * spec.inWidth + kw;
                  const sourceNode = prevLayerNodes[inputFeatureIndex];
                  const conn = repNeuron.connections.in.find(
                    (cc) => cc.from === sourceNode
                  );
                  kernel.push(conn ? conn.weight : 0);
                }
              }
            }
            repPerChannel.push(kernel);
          }
          const tol = 1e-9;
          for (let oc = 0; oc < spec.outChannels && allOk; oc++) {
            for (let oh = 0; oh < spec.outHeight && allOk; oh++) {
              for (let ow = 0; ow < spec.outWidth && allOk; ow++) {
                const idx = oc * (spec.outHeight * spec.outWidth) + oh * spec.outWidth + ow;
                const neuron = layerNodes[idx];
                if (!neuron) continue;
                let kPtr = 0;
                for (let ic = 0; ic < spec.inChannels && allOk; ic++) {
                  const hBase = oh * spec.strideHeight - (spec.padTop || 0);
                  const wBase = ow * spec.strideWidth - (spec.padLeft || 0);
                  for (let kh = 0; kh < spec.kernelHeight && allOk; kh++) {
                    for (let kw = 0; kw < spec.kernelWidth && allOk; kw++) {
                      const ih = hBase + kh;
                      const iw = wBase + kw;
                      if (ih < 0 || ih >= spec.inHeight || iw < 0 || iw >= spec.inWidth) {
                        kPtr++;
                        continue;
                      }
                      const inputFeatureIndex = ic * (spec.inHeight * spec.inWidth) + ih * spec.inWidth + iw;
                      const srcNode = prevLayerNodes[inputFeatureIndex];
                      const conn = neuron.connections.in.find(
                        (cc) => cc.from === srcNode
                      );
                      const wVal = conn ? conn.weight : 0;
                      if (Math.abs(wVal - repPerChannel[oc][kPtr]) > tol) {
                        allOk = false;
                      }
                      kPtr++;
                    }
                  }
                }
                if (!allOk) break;
              }
            }
          }
          if (allOk) verified.push(layerIdx);
          else {
            mismatched.push(layerIdx);
            console.warn(
              `Conv2D weight sharing mismatch detected in layer ${layerIdx}`
            );
          }
        }
        if (verified.length)
          model.metadata_props.push({
            key: "conv2d_sharing_verified",
            value: JSON.stringify(verified)
          });
        if (mismatched.length)
          model.metadata_props.push({
            key: "conv2d_sharing_mismatch",
            value: JSON.stringify(mismatched)
          });
      }
    }
    return model;
  }
  function exportToONNX(network, options = {}) {
    rebuildConnectionsLocal(network);
    network.nodes.forEach((node, idx) => node.index = idx);
    if (!network.connections || network.connections.length === 0)
      throw new Error("ONNX export currently only supports simple MLPs");
    const layers = inferLayerOrdering(network);
    const lstmPatternStubs = [];
    if (options.allowRecurrent) {
      try {
        for (let li = 1; li < layers.length - 1; li++) {
          const hiddenLayer = layers[li];
          const total = hiddenLayer.length;
          if (total >= 10 && total % 5 === 0) {
            const seg = total / 5;
            const memorySlice = hiddenLayer.slice(seg * 2, seg * 3);
            const allSelf = memorySlice.every(
              (n) => n.connections.self.length === 1
            );
            if (allSelf) {
              lstmPatternStubs.push({ layerIndex: li, unitSize: seg });
            }
          }
        }
      } catch {
      }
    }
    validateLayerHomogeneityAndConnectivity(layers, network, options);
    const model = buildOnnxModel(network, layers, options);
    if (options.includeMetadata) {
      const inferredSpecs = [];
      const inferredLayers = [];
      for (let li = 1; li < layers.length - 1; li++) {
        const prevWidth = layers[li - 1].length;
        const currWidth = layers[li].length;
        const s = Math.sqrt(prevWidth);
        if (Math.abs(s - Math.round(s)) > 1e-9) continue;
        const sInt = Math.round(s);
        for (const k of [3, 2]) {
          if (k >= sInt) continue;
          const outSpatial = sInt - k + 1;
          if (outSpatial * outSpatial === currWidth) {
            const alreadyDeclared = options.conv2dMappings?.some(
              (m) => m.layerIndex === li
            );
            if (alreadyDeclared) break;
            inferredLayers.push(li);
            inferredSpecs.push({
              layerIndex: li,
              inHeight: sInt,
              inWidth: sInt,
              inChannels: 1,
              kernelHeight: k,
              kernelWidth: k,
              strideHeight: 1,
              strideWidth: 1,
              outHeight: outSpatial,
              outWidth: outSpatial,
              outChannels: 1,
              note: "heuristic_inferred_no_export_applied"
            });
            break;
          }
        }
      }
      if (inferredLayers.length) {
        model.metadata_props = model.metadata_props || [];
        model.metadata_props.push({
          key: "conv2d_inferred_layers",
          value: JSON.stringify(inferredLayers)
        });
        model.metadata_props.push({
          key: "conv2d_inferred_specs",
          value: JSON.stringify(inferredSpecs)
        });
      }
    }
    if (lstmPatternStubs.length) {
      model.metadata_props = model.metadata_props || [];
      model.metadata_props.push({
        key: "lstm_groups_stub",
        value: JSON.stringify(lstmPatternStubs)
      });
    }
    return model;
  }
  var init_network_onnx = __esm({
    "src/architecture/network/network.onnx.ts"() {
      "use strict";
      init_methods();
      init_connection();
    }
  });

  // src/architecture/onnx.ts
  var init_onnx = __esm({
    "src/architecture/onnx.ts"() {
      "use strict";
      init_network_onnx();
      init_network_onnx();
    }
  });

  // src/architecture/network/network.standalone.ts
  function generateStandalone(net) {
    if (!net.nodes.some((nodeRef) => nodeRef.type === "output")) {
      throw new Error(
        "Cannot create standalone function: network has no output nodes."
      );
    }
    const emittedActivationSource = {};
    const activationFunctionSources = [];
    const activationFunctionIndexMap = {};
    let nextActivationFunctionIndex = 0;
    const initialActivations = [];
    const initialStates = [];
    const bodyLines = [];
    const builtinActivationSnippets = {
      logistic: "function logistic(x){ return 1 / (1 + Math.exp(-x)); }",
      tanh: "function tanh(x){ return Math.tanh(x); }",
      relu: "function relu(x){ return x > 0 ? x : 0; }",
      identity: "function identity(x){ return x; }",
      step: "function step(x){ return x > 0 ? 1 : 0; }",
      softsign: "function softsign(x){ return x / (1 + Math.abs(x)); }",
      sinusoid: "function sinusoid(x){ return Math.sin(x); }",
      gaussian: "function gaussian(x){ return Math.exp(-Math.pow(x, 2)); }",
      bentIdentity: "function bentIdentity(x){ return (Math.sqrt(Math.pow(x, 2) + 1) - 1) / 2 + x; }",
      bipolar: "function bipolar(x){ return x > 0 ? 1 : -1; }",
      bipolarSigmoid: "function bipolarSigmoid(x){ return 2 / (1 + Math.exp(-x)) - 1; }",
      hardTanh: "function hardTanh(x){ return Math.max(-1, Math.min(1, x)); }",
      absolute: "function absolute(x){ return Math.abs(x); }",
      inverse: "function inverse(x){ return 1 - x; }",
      selu: "function selu(x){ var a=1.6732632423543772,s=1.0507009873554805; var fx=x>0?x:a*Math.exp(x)-a; return fx*s; }",
      softplus: "function softplus(x){ if(x>30)return x; if(x<-30)return Math.exp(x); return Math.max(0,x)+Math.log(1+Math.exp(-Math.abs(x))); }",
      swish: "function swish(x){ var s=1/(1+Math.exp(-x)); return x*s; }",
      gelu: "function gelu(x){ var cdf=0.5*(1.0+Math.tanh(Math.sqrt(2.0/Math.PI)*(x+0.044715*Math.pow(x,3)))); return x*cdf; }",
      mish: "function mish(x){ var sp_x; if(x>30){sp_x=x;}else if(x<-30){sp_x=Math.exp(x);}else{sp_x=Math.log(1+Math.exp(x));} var tanh_sp_x=Math.tanh(sp_x); return x*tanh_sp_x; }"
    };
    net.nodes.forEach((node, nodeIndex) => {
      node.index = nodeIndex;
      initialActivations.push(node.activation);
      initialStates.push(node.state);
    });
    bodyLines.push("for(var i = 0; i < input.length; i++) A[i] = input[i];");
    for (let nodeIndex = net.input; nodeIndex < net.nodes.length; nodeIndex++) {
      const node = net.nodes[nodeIndex];
      const squashFn = node.squash;
      const squashName = squashFn.name || `anonymous_squash_${nodeIndex}`;
      if (!(squashName in emittedActivationSource)) {
        let functionSource;
        if (builtinActivationSnippets[squashName]) {
          functionSource = builtinActivationSnippets[squashName];
          if (!functionSource.startsWith(`function ${squashName}`)) {
            functionSource = `function ${squashName}${functionSource.substring(
              functionSource.indexOf("(")
            )}`;
          }
          functionSource = stripCoverage(functionSource);
        } else {
          functionSource = squashFn.toString();
          functionSource = stripCoverage(functionSource);
          if (functionSource.startsWith("function")) {
            functionSource = `function ${squashName}${functionSource.substring(
              functionSource.indexOf("(")
            )}`;
          } else if (functionSource.includes("=>")) {
            functionSource = `function ${squashName}${functionSource.substring(
              functionSource.indexOf("(")
            )}`;
          } else {
            functionSource = `function ${squashName}(x){ return x; }`;
          }
        }
        emittedActivationSource[squashName] = functionSource;
        activationFunctionSources.push(functionSource);
        activationFunctionIndexMap[squashName] = nextActivationFunctionIndex++;
      }
      const activationFunctionIndex = activationFunctionIndexMap[squashName];
      const incomingTerms = [];
      for (const connection of node.connections.in) {
        if (typeof connection.from.index === "undefined") continue;
        let term = `A[${connection.from.index}] * ${connection.weight}`;
        if (connection.gater && typeof connection.gater.index !== "undefined") {
          term += ` * A[${connection.gater.index}]`;
        }
        incomingTerms.push(term);
      }
      if (node.connections.self.length > 0) {
        const selfConn = node.connections.self[0];
        let term = `S[${nodeIndex}] * ${selfConn.weight}`;
        if (selfConn.gater && typeof selfConn.gater.index !== "undefined") {
          term += ` * A[${selfConn.gater.index}]`;
        }
        incomingTerms.push(term);
      }
      const sumExpression = incomingTerms.length > 0 ? incomingTerms.join(" + ") : "0";
      bodyLines.push(`S[${nodeIndex}] = ${sumExpression} + ${node.bias};`);
      const maskValue = typeof node.mask === "number" && node.mask !== 1 ? node.mask : 1;
      bodyLines.push(
        `A[${nodeIndex}] = F[${activationFunctionIndex}](S[${nodeIndex}])${maskValue !== 1 ? ` * ${maskValue}` : ""};`
      );
    }
    const outputIndices = [];
    for (let nodeIndex = net.nodes.length - net.output; nodeIndex < net.nodes.length; nodeIndex++) {
      if (typeof net.nodes[nodeIndex]?.index !== "undefined") {
        outputIndices.push(net.nodes[nodeIndex].index);
      }
    }
    bodyLines.push(
      `return [${outputIndices.map((idx) => `A[${idx}]`).join(",")}];`
    );
    const activationArrayLiteral = Object.entries(activationFunctionIndexMap).sort(([, a], [, b]) => a - b).map(([name]) => name).join(",");
    const activationArrayType = net._activationPrecision === "f32" ? "Float32Array" : "Float64Array";
    let generatedSource = "";
    generatedSource += `(function(){
`;
    generatedSource += `${activationFunctionSources.join("\n")}
`;
    generatedSource += `var F = [${activationArrayLiteral}];
`;
    generatedSource += `var A = new ${activationArrayType}([${initialActivations.join(
      ","
    )}]);
`;
    generatedSource += `var S = new ${activationArrayType}([${initialStates.join(
      ","
    )}]);
`;
    generatedSource += `function activate(input){
`;
    generatedSource += `if (!input || input.length !== ${net.input}) { throw new Error('Invalid input size. Expected ${net.input}, got ' + (input ? input.length : 'undefined')); }
`;
    generatedSource += bodyLines.join("\n");
    generatedSource += `}
`;
    generatedSource += `return activate;
})();`;
    return generatedSource;
  }
  var stripCoverage;
  var init_network_standalone = __esm({
    "src/architecture/network/network.standalone.ts"() {
      "use strict";
      stripCoverage = (code) => {
        code = code.replace(/\/\*\s*istanbul\s+ignore\s+[\s\S]*?\*\//g, "");
        code = code.replace(/cov_[\w$]+\(\)\.(s|f|b)\[\d+\](\[\d+\])?\+\+/g, "");
        code = code.replace(/cov_[\w$]+\(\)/g, "");
        code = code.replace(/^\s*\/\/ # sourceMappingURL=.*\s*$/gm, "");
        code = code.replace(/\(\s*,\s*/g, "( ");
        code = code.replace(/\s*,\s*\)/g, " )");
        code = code.trim();
        code = code.replace(/^\s*;\s*$/gm, "");
        code = code.replace(/;{2,}/g, ";");
        code = code.replace(/^\s*[,;]?\s*$/gm, "");
        return code;
      };
    }
  });

  // src/architecture/network/network.topology.ts
  function computeTopoOrder() {
    const internalNet = this;
    if (!internalNet._enforceAcyclic) {
      internalNet._topoOrder = null;
      internalNet._topoDirty = false;
      return;
    }
    const inDegree = /* @__PURE__ */ new Map();
    this.nodes.forEach((node) => inDegree.set(node, 0));
    for (const connection of this.connections) {
      if (connection.from !== connection.to) {
        inDegree.set(connection.to, (inDegree.get(connection.to) || 0) + 1);
      }
    }
    const processingQueue = [];
    this.nodes.forEach((node) => {
      if (node.type === "input" || (inDegree.get(node) || 0) === 0) {
        processingQueue.push(node);
      }
    });
    const topoOrder = [];
    while (processingQueue.length) {
      const node = processingQueue.shift();
      topoOrder.push(node);
      for (const outgoing of node.connections.out) {
        if (outgoing.to === node) continue;
        const remaining = (inDegree.get(outgoing.to) || 0) - 1;
        inDegree.set(outgoing.to, remaining);
        if (remaining === 0) processingQueue.push(outgoing.to);
      }
    }
    internalNet._topoOrder = topoOrder.length === this.nodes.length ? topoOrder : this.nodes.slice();
    internalNet._topoDirty = false;
  }
  function hasPath(from, to) {
    if (from === to) return true;
    const visited = /* @__PURE__ */ new Set();
    const dfsStack = [from];
    while (dfsStack.length) {
      const current = dfsStack.pop();
      if (current === to) return true;
      if (visited.has(current)) continue;
      visited.add(current);
      for (const edge of current.connections.out) {
        if (edge.to !== current) dfsStack.push(edge.to);
      }
    }
    return false;
  }
  var init_network_topology = __esm({
    "src/architecture/network/network.topology.ts"() {
      "use strict";
    }
  });

  // src/architecture/network/network.slab.ts
  function _slabPoolCap() {
    const configuredCap = config.slabPoolMaxPerKey;
    if (configuredCap === void 0) return 4;
    return configuredCap < 0 ? 0 : configuredCap | 0;
  }
  function _poolKey(kind, bytes, length) {
    return kind + ":" + bytes + ":" + length;
  }
  function _acquireTA(kind, ctor, length, bytesPerElement) {
    if (!config.enableSlabArrayPooling) {
      _slabAllocStats.fresh++;
      return new ctor(length);
    }
    const key = _poolKey(kind, bytesPerElement, length);
    const list = _slabArrayPool[key];
    if (list && list.length) {
      _slabAllocStats.pooled++;
      (_slabPoolMetrics[key] ||= { created: 0, reused: 0, maxRetained: 0 }).reused++;
      return list.pop();
    }
    _slabAllocStats.fresh++;
    (_slabPoolMetrics[key] ||= { created: 0, reused: 0, maxRetained: 0 }).created++;
    return new ctor(length);
  }
  function _releaseTA(kind, bytesPerElement, arr) {
    if (!config.enableSlabArrayPooling) return;
    const key = _poolKey(kind, bytesPerElement, arr.length);
    const list = _slabArrayPool[key] ||= [];
    if (list.length < _slabPoolCap()) list.push(arr);
    const m = _slabPoolMetrics[key] ||= {
      created: 0,
      reused: 0,
      maxRetained: 0
    };
    if (list.length > m.maxRetained) m.maxRetained = list.length;
  }
  function rebuildConnectionSlab(force = false) {
    const internalNet = this;
    if (!force && !internalNet._slabDirty) return;
    if (internalNet._nodeIndexDirty) _reindexNodes.call(this);
    const connectionCount = this.connections.length;
    let capacity = internalNet._connCapacity || 0;
    const growthFactor = typeof window === "undefined" ? 1.75 : 1.25;
    const needAllocate = capacity < connectionCount;
    if (needAllocate) {
      capacity = capacity === 0 ? Math.ceil(connectionCount * growthFactor) : capacity;
      while (capacity < connectionCount)
        capacity = Math.ceil(capacity * growthFactor);
      if (internalNet._connWeights)
        _releaseTA(
          "w",
          internalNet._useFloat32Weights ? 4 : 8,
          internalNet._connWeights
        );
      if (internalNet._connFrom)
        _releaseTA("f", 4, internalNet._connFrom);
      if (internalNet._connTo)
        _releaseTA("t", 4, internalNet._connTo);
      if (internalNet._connFlags)
        _releaseTA("fl", 1, internalNet._connFlags);
      if (internalNet._connGain)
        _releaseTA(
          "g",
          internalNet._useFloat32Weights ? 4 : 8,
          internalNet._connGain
        );
      if (internalNet._connPlastic)
        _releaseTA(
          "p",
          internalNet._useFloat32Weights ? 4 : 8,
          internalNet._connPlastic
        );
      internalNet._connWeights = _acquireTA(
        "w",
        internalNet._useFloat32Weights ? Float32Array : Float64Array,
        capacity,
        internalNet._useFloat32Weights ? 4 : 8
      );
      internalNet._connFrom = _acquireTA("f", Uint32Array, capacity, 4);
      internalNet._connTo = _acquireTA("t", Uint32Array, capacity, 4);
      internalNet._connFlags = _acquireTA("fl", Uint8Array, capacity, 1);
      internalNet._connGain = null;
      internalNet._connPlastic = null;
      internalNet._connCapacity = capacity;
    } else {
      capacity = internalNet._connCapacity;
    }
    const weightArray = internalNet._connWeights;
    const fromIndexArray = internalNet._connFrom;
    const toIndexArray = internalNet._connTo;
    const flagArray = internalNet._connFlags;
    let gainArray = internalNet._connGain;
    let anyNonNeutralGain = false;
    let plasticArray = internalNet._connPlastic;
    let anyPlastic = false;
    for (let connectionIndex = 0; connectionIndex < connectionCount; connectionIndex++) {
      const connection = this.connections[connectionIndex];
      weightArray[connectionIndex] = connection.weight;
      fromIndexArray[connectionIndex] = connection.from.index >>> 0;
      toIndexArray[connectionIndex] = connection.to.index >>> 0;
      flagArray[connectionIndex] = connection._flags & 255;
      const gainValue = connection.gain;
      if (gainValue !== 1) {
        if (!gainArray) {
          gainArray = _acquireTA(
            "g",
            internalNet._useFloat32Weights ? Float32Array : Float64Array,
            capacity,
            internalNet._useFloat32Weights ? 4 : 8
          );
          internalNet._connGain = gainArray;
          for (let j = 0; j < connectionIndex; j++) gainArray[j] = 1;
        }
        gainArray[connectionIndex] = gainValue;
        anyNonNeutralGain = true;
      } else if (gainArray) {
        gainArray[connectionIndex] = 1;
      }
      if (connection._flags & 8) anyPlastic = true;
    }
    if (!anyNonNeutralGain && gainArray) {
      _releaseTA(
        "g",
        internalNet._useFloat32Weights ? 4 : 8,
        gainArray
      );
      internalNet._connGain = null;
    }
    if (anyPlastic && !plasticArray) {
      plasticArray = _acquireTA(
        "p",
        internalNet._useFloat32Weights ? Float32Array : Float64Array,
        capacity,
        internalNet._useFloat32Weights ? 4 : 8
      );
      internalNet._connPlastic = plasticArray;
      for (let i = 0; i < connectionCount; i++) {
        const c = this.connections[i];
        plasticArray[i] = c.plasticityRate || 0;
      }
    } else if (!anyPlastic && plasticArray) {
      _releaseTA(
        "p",
        internalNet._useFloat32Weights ? 4 : 8,
        plasticArray
      );
      internalNet._connPlastic = null;
    }
    internalNet._connCount = connectionCount;
    internalNet._slabDirty = false;
    internalNet._adjDirty = true;
    internalNet._slabVersion = (internalNet._slabVersion || 0) + 1;
  }
  function getConnectionSlab() {
    rebuildConnectionSlab.call(this);
    const internalNet = this;
    let gain = internalNet._connGain || null;
    if (!gain) {
      const cap = internalNet._connCapacity || internalNet._connWeights && internalNet._connWeights.length || 0;
      gain = internalNet._useFloat32Weights ? new Float32Array(cap) : new Float64Array(cap);
      for (let i = 0; i < (internalNet._connCount || 0); i++) gain[i] = 1;
    }
    return {
      weights: internalNet._connWeights,
      from: internalNet._connFrom,
      to: internalNet._connTo,
      flags: internalNet._connFlags,
      gain,
      plastic: internalNet._connPlastic || null,
      version: internalNet._slabVersion || 0,
      used: internalNet._connCount || 0,
      capacity: internalNet._connCapacity || internalNet._connWeights && internalNet._connWeights.length || 0
    };
  }
  function _reindexNodes() {
    const internalNet = this;
    for (let nodeIndex = 0; nodeIndex < this.nodes.length; nodeIndex++)
      this.nodes[nodeIndex].index = nodeIndex;
    internalNet._nodeIndexDirty = false;
  }
  function _buildAdjacency() {
    const internalNet = this;
    if (!internalNet._connFrom || !internalNet._connTo) return;
    const nodeCount = this.nodes.length;
    const connectionCount = internalNet._connCount ?? internalNet._connFrom.length;
    const fanOutCounts = new Uint32Array(nodeCount);
    for (let connectionIndex = 0; connectionIndex < connectionCount; connectionIndex++) {
      fanOutCounts[internalNet._connFrom[connectionIndex]]++;
    }
    const outgoingStartIndices = new Uint32Array(nodeCount + 1);
    let runningOffset = 0;
    for (let nodeIndex = 0; nodeIndex < nodeCount; nodeIndex++) {
      outgoingStartIndices[nodeIndex] = runningOffset;
      runningOffset += fanOutCounts[nodeIndex];
    }
    outgoingStartIndices[nodeCount] = runningOffset;
    const outgoingOrder = new Uint32Array(connectionCount);
    const insertionCursor = outgoingStartIndices.slice();
    for (let connectionIndex = 0; connectionIndex < connectionCount; connectionIndex++) {
      const fromNodeIndex = internalNet._connFrom[connectionIndex];
      outgoingOrder[insertionCursor[fromNodeIndex]++] = connectionIndex;
    }
    internalNet._outStart = outgoingStartIndices;
    internalNet._outOrder = outgoingOrder;
    internalNet._adjDirty = false;
  }
  function _canUseFastSlab(training) {
    const internalNet = this;
    return !training && // Training may require gradients / noise injection.
    internalNet._enforceAcyclic && // Must have acyclic guarantee for single forward sweep.
    !internalNet._topoDirty && // Topological order must be current.
    this.gates.length === 0 && // Gating implies dynamic per-edge behavior.
    this.selfconns.length === 0 && // Self connections require recurrent handling.
    this.dropout === 0 && // Dropout introduces stochastic masking.
    internalNet._weightNoiseStd === 0 && // Global weight noise disables deterministic slab pass.
    internalNet._weightNoisePerHidden.length === 0 && // Per hidden noise variants.
    internalNet._stochasticDepth.length === 0;
  }
  function fastSlabActivate(input) {
    const internalNet = this;
    rebuildConnectionSlab.call(this);
    if (internalNet._adjDirty) _buildAdjacency.call(this);
    if (this.gates && this.gates.length > 0)
      return this.activate(input, false);
    if (!internalNet._connWeights || !internalNet._connFrom || !internalNet._connTo || !internalNet._outStart || !internalNet._outOrder) {
      return this.activate(input, false);
    }
    if (internalNet._topoDirty) this._computeTopoOrder();
    if (internalNet._nodeIndexDirty) _reindexNodes.call(this);
    const topoOrder = internalNet._topoOrder || this.nodes;
    const nodeCount = this.nodes.length;
    const useFloat32Activation = internalNet._activationPrecision === "f32";
    if (!internalNet._fastA || internalNet._fastA.length !== nodeCount || useFloat32Activation && !(internalNet._fastA instanceof Float32Array) || !useFloat32Activation && !(internalNet._fastA instanceof Float64Array)) {
      internalNet._fastA = useFloat32Activation ? new Float32Array(nodeCount) : new Float64Array(nodeCount);
    }
    if (!internalNet._fastS || internalNet._fastS.length !== nodeCount || useFloat32Activation && !(internalNet._fastS instanceof Float32Array) || !useFloat32Activation && !(internalNet._fastS instanceof Float64Array)) {
      internalNet._fastS = useFloat32Activation ? new Float32Array(nodeCount) : new Float64Array(nodeCount);
    }
    const activationBuffer = internalNet._fastA;
    const stateBuffer = internalNet._fastS;
    stateBuffer.fill(0);
    for (let inputIndex = 0; inputIndex < this.input; inputIndex++) {
      activationBuffer[inputIndex] = input[inputIndex];
      this.nodes[inputIndex].activation = input[inputIndex];
      this.nodes[inputIndex].state = 0;
    }
    const weightArray = internalNet._connWeights;
    const toIndexArray = internalNet._connTo;
    const outgoingOrder = internalNet._outOrder;
    const outgoingStartIndices = internalNet._outStart;
    for (let topoIdx = 0; topoIdx < topoOrder.length; topoIdx++) {
      const node = topoOrder[topoIdx];
      const nodeIndex = node.index >>> 0;
      if (nodeIndex >= this.input) {
        const weightedSum = stateBuffer[nodeIndex] + node.bias;
        const activated = node.squash(weightedSum);
        node.state = stateBuffer[nodeIndex];
        node.activation = activated;
        activationBuffer[nodeIndex] = activated;
      }
      const edgeStart = outgoingStartIndices[nodeIndex];
      const edgeEnd = outgoingStartIndices[nodeIndex + 1];
      const sourceActivation = activationBuffer[nodeIndex];
      for (let cursorIdx = edgeStart; cursorIdx < edgeEnd; cursorIdx++) {
        const connectionIndex = outgoingOrder[cursorIdx];
        let w = weightArray[connectionIndex];
        const gainArr = internalNet._connGain;
        if (gainArr) w *= gainArr[connectionIndex];
        stateBuffer[toIndexArray[connectionIndex]] += sourceActivation * w;
      }
    }
    const outputBaseIndex = nodeCount - this.output;
    const pooledOutputArray = activationArrayPool.acquire(this.output);
    for (let outputOffset = 0; outputOffset < this.output; outputOffset++) {
      pooledOutputArray[outputOffset] = activationBuffer[outputBaseIndex + outputOffset];
    }
    const result = Array.from(pooledOutputArray);
    activationArrayPool.release(pooledOutputArray);
    return result;
  }
  function canUseFastSlab(training) {
    return _canUseFastSlab.call(this, training);
  }
  var _slabArrayPool, _slabPoolMetrics, _slabAllocStats;
  var init_network_slab = __esm({
    "src/architecture/network/network.slab.ts"() {
      "use strict";
      init_activationArrayPool();
      init_config();
      _slabArrayPool = /* @__PURE__ */ Object.create(null);
      _slabPoolMetrics = /* @__PURE__ */ Object.create(null);
      _slabAllocStats = { fresh: 0, pooled: 0 };
    }
  });

  // src/architecture/network/network.prune.ts
  function rankConnections(conns, method) {
    const ranked = [...conns];
    if (method === "snip") {
      ranked.sort((a, b) => {
        const gradMagA = Math.abs(a.totalDeltaWeight) || Math.abs(a.previousDeltaWeight) || 0;
        const gradMagB = Math.abs(b.totalDeltaWeight) || Math.abs(b.previousDeltaWeight) || 0;
        const saliencyA = gradMagA ? Math.abs(a.weight) * gradMagA : Math.abs(a.weight);
        const saliencyB = gradMagB ? Math.abs(b.weight) * gradMagB : Math.abs(b.weight);
        return saliencyA - saliencyB;
      });
    } else {
      ranked.sort((a, b) => Math.abs(a.weight) - Math.abs(b.weight));
    }
    return ranked;
  }
  function regrowConnections(network, desiredRemaining, maxAttempts) {
    const netAny = network;
    let attempts = 0;
    while (network.connections.length < desiredRemaining && attempts < maxAttempts) {
      attempts++;
      const fromNode = network.nodes[Math.floor(netAny._rand() * network.nodes.length)];
      const toNode = network.nodes[Math.floor(netAny._rand() * network.nodes.length)];
      if (!fromNode || !toNode || fromNode === toNode) continue;
      if (network.connections.some((c) => c.from === fromNode && c.to === toNode))
        continue;
      if (netAny._enforceAcyclic && network.nodes.indexOf(fromNode) > network.nodes.indexOf(toNode))
        continue;
      network.connect(fromNode, toNode);
    }
  }
  function maybePrune(iteration) {
    const cfg = this._pruningConfig;
    if (!cfg) return;
    if (iteration < cfg.start || iteration > cfg.end) return;
    if (cfg.lastPruneIter != null && iteration === cfg.lastPruneIter) return;
    if ((iteration - cfg.start) % (cfg.frequency || 1) !== 0) return;
    const initialConnectionBaseline = this._initialConnectionCount;
    if (!initialConnectionBaseline) return;
    const progressFraction = (iteration - cfg.start) / Math.max(1, cfg.end - cfg.start);
    const targetSparsityNow = cfg.targetSparsity * Math.min(1, Math.max(0, progressFraction));
    const desiredRemainingConnections = Math.max(
      1,
      Math.floor(initialConnectionBaseline * (1 - targetSparsityNow))
    );
    const excessConnectionCount = this.connections.length - desiredRemainingConnections;
    if (excessConnectionCount <= 0) {
      cfg.lastPruneIter = iteration;
      return;
    }
    const rankedConnections = rankConnections(
      this.connections,
      cfg.method || "magnitude"
    );
    const connectionsToPrune = rankedConnections.slice(0, excessConnectionCount);
    connectionsToPrune.forEach((conn) => this.disconnect(conn.from, conn.to));
    if (cfg.regrowFraction && cfg.regrowFraction > 0) {
      const intendedRegrowCount = Math.floor(
        connectionsToPrune.length * cfg.regrowFraction
      );
      regrowConnections(
        this,
        desiredRemainingConnections,
        intendedRegrowCount * 10
      );
    }
    cfg.lastPruneIter = iteration;
    this._topoDirty = true;
  }
  function pruneToSparsity(targetSparsity, method = "magnitude") {
    if (targetSparsity <= 0) return;
    if (targetSparsity >= 1) targetSparsity = 0.999;
    const netAny = this;
    if (!netAny._evoInitialConnCount)
      netAny._evoInitialConnCount = this.connections.length;
    const evolutionaryBaseline = netAny._evoInitialConnCount;
    const desiredRemainingConnections = Math.max(
      1,
      Math.floor(evolutionaryBaseline * (1 - targetSparsity))
    );
    const excessConnectionCount = this.connections.length - desiredRemainingConnections;
    if (excessConnectionCount <= 0) return;
    const rankedConnections = rankConnections(this.connections, method);
    const connectionsToRemove = rankedConnections.slice(0, excessConnectionCount);
    connectionsToRemove.forEach((c) => this.disconnect(c.from, c.to));
    netAny._topoDirty = true;
  }
  function getCurrentSparsity() {
    const initialBaseline = this._initialConnectionCount;
    if (!initialBaseline) return 0;
    return 1 - this.connections.length / initialBaseline;
  }
  var init_network_prune = __esm({
    "src/architecture/network/network.prune.ts"() {
      "use strict";
      init_node();
      init_connection();
    }
  });

  // src/architecture/network/network.gating.ts
  function gate(node, connection) {
    if (!this.nodes.includes(node))
      throw new Error(
        "Gating node must be part of the network to gate a connection!"
      );
    if (connection.gater) {
      if (config.warnings) console.warn("Connection is already gated. Skipping.");
      return;
    }
    node.gate(connection);
    this.gates.push(connection);
  }
  function ungate(connection) {
    const index = this.gates.indexOf(connection);
    if (index === -1) {
      if (config.warnings)
        console.warn("Attempted to ungate a connection not in the gates list.");
      return;
    }
    this.gates.splice(index, 1);
    connection.gater?.ungate(connection);
  }
  var init_network_gating = __esm({
    "src/architecture/network/network.gating.ts"() {
      "use strict";
      init_node();
      init_connection();
      init_mutation();
      init_config();
    }
  });

  // src/architecture/network/network.deterministic.ts
  function setSeed(seed) {
    this._rngState = seed >>> 0;
    this._rand = () => {
      this._rngState = this._rngState + 1831565813 >>> 0;
      let r = Math.imul(
        this._rngState ^ this._rngState >>> 15,
        1 | this._rngState
      );
      r ^= r + Math.imul(r ^ r >>> 7, 61 | r);
      return ((r ^ r >>> 14) >>> 0) / 4294967296;
    };
  }
  function snapshotRNG() {
    return { step: this._trainingStep, state: this._rngState };
  }
  function restoreRNG(fn) {
    this._rand = fn;
    this._rngState = void 0;
  }
  function getRNGState() {
    return this._rngState;
  }
  function setRNGState(state) {
    if (typeof state === "number") this._rngState = state >>> 0;
  }
  var init_network_deterministic = __esm({
    "src/architecture/network/network.deterministic.ts"() {
      "use strict";
    }
  });

  // src/architecture/network/network.stats.ts
  function deepCloneValue(value) {
    try {
      return globalThis.structuredClone ? globalThis.structuredClone(value) : JSON.parse(JSON.stringify(value));
    } catch {
      return JSON.parse(JSON.stringify(value));
    }
  }
  function getRegularizationStats() {
    const lastStatsSnapshot = this._lastStats;
    return lastStatsSnapshot ? deepCloneValue(lastStatsSnapshot) : null;
  }
  var init_network_stats = __esm({
    "src/architecture/network/network.stats.ts"() {
      "use strict";
    }
  });

  // src/architecture/network/network.remove.ts
  function removeNode(node) {
    const internalNet = this;
    const idx = this.nodes.indexOf(node);
    if (idx === -1) throw new Error("Node not in network");
    if (node.type === "input" || node.type === "output") {
      throw new Error("Cannot remove input or output node from the network.");
    }
    this.gates = this.gates.filter((c) => {
      if (c.gater === node) {
        c.gater = null;
        return false;
      }
      return true;
    });
    const inbound = node.connections.in.slice();
    const outbound = node.connections.out.slice();
    inbound.forEach((c) => this.disconnect(c.from, c.to));
    outbound.forEach((c) => this.disconnect(c.from, c.to));
    node.connections.self.slice().forEach(() => this.disconnect(node, node));
    const removed = this.nodes.splice(idx, 1)[0];
    if (config.enableNodePooling && removed) {
      releaseNode(removed);
    }
    inbound.forEach((ic) => {
      outbound.forEach((oc) => {
        if (!ic.from || !oc.to || ic.from === oc.to) return;
        const exists = this.connections.some(
          (c) => c.from === ic.from && c.to === oc.to
        );
        if (!exists) this.connect(ic.from, oc.to);
      });
    });
    internalNet._topoDirty = true;
    internalNet._nodeIndexDirty = true;
    internalNet._slabDirty = true;
    internalNet._adjDirty = true;
  }
  var init_network_remove = __esm({
    "src/architecture/network/network.remove.ts"() {
      "use strict";
      init_nodePool();
      init_config();
    }
  });

  // src/architecture/network/network.connect.ts
  function connect(from, to, weight) {
    if (this._enforceAcyclic && this.nodes.indexOf(from) > this.nodes.indexOf(to))
      return [];
    const connections = from.connect(to, weight);
    for (const c of connections) {
      if (from !== to) {
        this.connections.push(c);
      } else {
        if (this._enforceAcyclic) continue;
        this.selfconns.push(c);
      }
    }
    if (connections.length) {
      this._topoDirty = true;
      this._slabDirty = true;
    }
    return connections;
  }
  function disconnect(from, to) {
    const list = from === to ? this.selfconns : this.connections;
    for (let i = 0; i < list.length; i++) {
      const c = list[i];
      if (c.from === from && c.to === to) {
        if (c.gater) this.ungate(c);
        list.splice(i, 1);
        break;
      }
    }
    from.disconnect(to);
    this._topoDirty = true;
    this._slabDirty = true;
  }
  var init_network_connect = __esm({
    "src/architecture/network/network.connect.ts"() {
      "use strict";
      init_node();
      init_connection();
    }
  });

  // src/architecture/network/network.serialize.ts
  function serialize() {
    this.nodes.forEach(
      (nodeRef, nodeIndex) => nodeRef.index = nodeIndex
    );
    const activations = this.nodes.map(
      (nodeRef) => nodeRef.activation
    );
    const states = this.nodes.map((nodeRef) => nodeRef.state);
    const squashes = this.nodes.map(
      (nodeRef) => nodeRef.squash.name
    );
    const serializedConnections = this.connections.concat(this.selfconns).map((connInstance) => ({
      from: connInstance.from.index,
      to: connInstance.to.index,
      weight: connInstance.weight,
      gater: connInstance.gater ? connInstance.gater.index : null
    }));
    const inputSize = this.input;
    const outputSize = this.output;
    return [
      activations,
      states,
      squashes,
      serializedConnections,
      inputSize,
      outputSize
    ];
  }
  function deserialize(data, inputSize, outputSize) {
    const [
      activations,
      states,
      squashes,
      connections,
      serializedInput,
      serializedOutput
    ] = data;
    const input = typeof inputSize === "number" ? inputSize : serializedInput || 0;
    const output = typeof outputSize === "number" ? outputSize : serializedOutput || 0;
    const net = new (init_network(), __toCommonJS(network_exports)).default(input, output);
    net.nodes = [];
    net.connections = [];
    net.selfconns = [];
    net.gates = [];
    activations.forEach((activation, nodeIndex) => {
      let type;
      if (nodeIndex < input) type = "input";
      else if (nodeIndex >= activations.length - output) type = "output";
      else type = "hidden";
      const node = new Node2(type);
      node.activation = activation;
      node.state = states[nodeIndex];
      const squashName = squashes[nodeIndex];
      if (!activation_default[squashName]) {
        console.warn(
          `Unknown squash function '${String(
            squashName
          )}' encountered during deserialize. Falling back to identity.`
        );
      }
      node.squash = activation_default[squashName] || activation_default.identity;
      node.index = nodeIndex;
      net.nodes.push(node);
    });
    connections.forEach((serializedConn) => {
      if (serializedConn.from < net.nodes.length && serializedConn.to < net.nodes.length) {
        const sourceNode = net.nodes[serializedConn.from];
        const targetNode = net.nodes[serializedConn.to];
        const createdConnection = net.connect(
          sourceNode,
          targetNode,
          serializedConn.weight
        )[0];
        if (createdConnection && serializedConn.gater != null) {
          if (serializedConn.gater < net.nodes.length) {
            net.gate(
              net.nodes[serializedConn.gater],
              createdConnection
            );
          } else {
            console.warn(
              "Invalid gater index encountered during deserialize; skipping gater assignment."
            );
          }
        }
      } else {
        console.warn(
          "Invalid connection indices encountered during deserialize; skipping connection."
        );
      }
    });
    return net;
  }
  function toJSONImpl() {
    const json = {
      formatVersion: 2,
      input: this.input,
      output: this.output,
      dropout: this.dropout,
      nodes: [],
      connections: []
    };
    this.nodes.forEach((node, nodeIndex) => {
      node.index = nodeIndex;
      json.nodes.push({
        type: node.type,
        bias: node.bias,
        squash: node.squash.name,
        index: nodeIndex,
        geneId: node.geneId
      });
      if (node.connections.self.length > 0) {
        const selfConn = node.connections.self[0];
        json.connections.push({
          from: nodeIndex,
          to: nodeIndex,
          weight: selfConn.weight,
          gater: selfConn.gater ? selfConn.gater.index : null,
          enabled: selfConn.enabled !== false
        });
      }
    });
    this.connections.forEach((connInstance) => {
      if (typeof connInstance.from.index !== "number" || typeof connInstance.to.index !== "number")
        return;
      json.connections.push({
        from: connInstance.from.index,
        to: connInstance.to.index,
        weight: connInstance.weight,
        gater: connInstance.gater ? connInstance.gater.index : null,
        enabled: connInstance.enabled !== false
      });
    });
    return json;
  }
  function fromJSONImpl(json) {
    if (!json || typeof json !== "object")
      throw new Error("Invalid JSON for network.");
    if (json.formatVersion !== 2)
      console.warn("fromJSONImpl: Unknown formatVersion, attempting import.");
    const net = new (init_network(), __toCommonJS(network_exports)).default(
      json.input,
      json.output
    );
    net.dropout = json.dropout || 0;
    net.nodes = [];
    net.connections = [];
    net.selfconns = [];
    net.gates = [];
    json.nodes.forEach((nodeJson, nodeIndex) => {
      const node = new Node2(nodeJson.type);
      node.bias = nodeJson.bias;
      node.squash = activation_default[nodeJson.squash] || activation_default.identity;
      node.index = nodeIndex;
      if (typeof nodeJson.geneId === "number")
        node.geneId = nodeJson.geneId;
      net.nodes.push(node);
    });
    json.connections.forEach((connJson) => {
      if (typeof connJson.from !== "number" || typeof connJson.to !== "number")
        return;
      const sourceNode = net.nodes[connJson.from];
      const targetNode = net.nodes[connJson.to];
      const createdConnection = net.connect(
        sourceNode,
        targetNode,
        connJson.weight
      )[0];
      if (createdConnection && connJson.gater != null && typeof connJson.gater === "number" && net.nodes[connJson.gater]) {
        net.gate(net.nodes[connJson.gater], createdConnection);
      }
      if (createdConnection && typeof connJson.enabled !== "undefined")
        createdConnection.enabled = connJson.enabled;
    });
    return net;
  }
  var init_network_serialize = __esm({
    "src/architecture/network/network.serialize.ts"() {
      "use strict";
      init_node();
      init_connection();
      init_methods();
    }
  });

  // src/architecture/network/network.genetic.ts
  function crossOver(network1, network2, equal = false) {
    if (network1.input !== network2.input || network1.output !== network2.output)
      throw new Error(
        "Parent networks must have the same input and output sizes for crossover."
      );
    const offspring = new (init_network(), __toCommonJS(network_exports)).default(
      network1.input,
      network1.output
    );
    offspring.connections = [];
    offspring.nodes = [];
    offspring.selfconns = [];
    offspring.gates = [];
    const score1 = network1.score || 0;
    const score2 = network2.score || 0;
    const n1Size = network1.nodes.length;
    const n2Size = network2.nodes.length;
    let size;
    if (equal || score1 === score2) {
      const max = Math.max(n1Size, n2Size);
      const min = Math.min(n1Size, n2Size);
      size = Math.floor(Math.random() * (max - min + 1) + min);
    } else size = score1 > score2 ? n1Size : n2Size;
    const outputSize = network1.output;
    network1.nodes.forEach((n, i) => n.index = i);
    network2.nodes.forEach((n, i) => n.index = i);
    for (let i = 0; i < size; i++) {
      let chosen;
      const node1 = i < n1Size ? network1.nodes[i] : void 0;
      const node2 = i < n2Size ? network2.nodes[i] : void 0;
      if (i < network1.input) chosen = node1;
      else if (i >= size - outputSize) {
        const o1 = n1Size - (size - i);
        const o2 = n2Size - (size - i);
        const n1o = o1 >= network1.input && o1 < n1Size ? network1.nodes[o1] : void 0;
        const n2o = o2 >= network2.input && o2 < n2Size ? network2.nodes[o2] : void 0;
        if (n1o && n2o)
          chosen = (network1._rand || Math.random)() >= 0.5 ? n1o : n2o;
        else chosen = n1o || n2o;
      } else {
        if (node1 && node2)
          chosen = (network1._rand || Math.random)() >= 0.5 ? node1 : node2;
        else if (node1 && (score1 >= score2 || equal)) chosen = node1;
        else if (node2 && (score2 >= score1 || equal)) chosen = node2;
      }
      if (chosen) {
        const nn = new Node2(chosen.type);
        nn.bias = chosen.bias;
        nn.squash = chosen.squash;
        offspring.nodes.push(nn);
      }
    }
    offspring.nodes.forEach((n, i) => n.index = i);
    const n1conns = {};
    const n2conns = {};
    network1.connections.concat(network1.selfconns).forEach((c) => {
      if (typeof c.from.index === "number" && typeof c.to.index === "number")
        n1conns[Connection.innovationID(c.from.index, c.to.index)] = {
          weight: c.weight,
          from: c.from.index,
          to: c.to.index,
          gater: c.gater ? c.gater.index : -1,
          enabled: c.enabled !== false
        };
    });
    network2.connections.concat(network2.selfconns).forEach((c) => {
      if (typeof c.from.index === "number" && typeof c.to.index === "number")
        n2conns[Connection.innovationID(c.from.index, c.to.index)] = {
          weight: c.weight,
          from: c.from.index,
          to: c.to.index,
          gater: c.gater ? c.gater.index : -1,
          enabled: c.enabled !== false
        };
    });
    const chosenConns = [];
    const keys1 = Object.keys(n1conns);
    keys1.forEach((k) => {
      const c1 = n1conns[k];
      if (n2conns[k]) {
        const c2 = n2conns[k];
        const pick = (network1._rand || Math.random)() >= 0.5 ? c1 : c2;
        if (c1.enabled === false || c2.enabled === false) {
          const rp = network1._reenableProb ?? network2._reenableProb ?? 0.25;
          pick.enabled = Math.random() < rp;
        }
        chosenConns.push(pick);
        delete n2conns[k];
      } else if (score1 >= score2 || equal) {
        if (c1.enabled === false) {
          const rp = network1._reenableProb ?? 0.25;
          c1.enabled = Math.random() < rp;
        }
        chosenConns.push(c1);
      }
    });
    if (score2 >= score1 || equal)
      Object.keys(n2conns).forEach((k) => {
        const d = n2conns[k];
        if (d.enabled === false) {
          const rp = network2._reenableProb ?? 0.25;
          d.enabled = Math.random() < rp;
        }
        chosenConns.push(d);
      });
    const nodeCount = offspring.nodes.length;
    chosenConns.forEach((cd) => {
      if (cd.from < nodeCount && cd.to < nodeCount) {
        const from = offspring.nodes[cd.from];
        const to = offspring.nodes[cd.to];
        if (cd.from >= cd.to) return;
        if (!from.isProjectingTo(to)) {
          const conn = offspring.connect(
            from,
            to
          )[0];
          if (conn) {
            conn.weight = cd.weight;
            conn.enabled = cd.enabled !== false;
            if (cd.gater !== -1 && cd.gater < nodeCount)
              offspring.gate(offspring.nodes[cd.gater], conn);
          }
        }
      }
    });
    return offspring;
  }
  var init_network_genetic = __esm({
    "src/architecture/network/network.genetic.ts"() {
      "use strict";
      init_node();
      init_connection();
    }
  });

  // src/architecture/network/network.activate.ts
  var network_activate_exports = {};
  __export(network_activate_exports, {
    activateBatch: () => activateBatch,
    activateRaw: () => activateRaw,
    noTraceActivate: () => noTraceActivate
  });
  function noTraceActivate(input) {
    const self = this;
    if (self._enforceAcyclic && self._topoDirty)
      this._computeTopoOrder();
    if (!Array.isArray(input) || input.length !== this.input) {
      throw new Error(
        `Input size mismatch: expected ${this.input}, got ${input ? input.length : "undefined"}`
      );
    }
    if (this._canUseFastSlab(false)) {
      try {
        return this._fastSlabActivate(input);
      } catch {
      }
    }
    const output = activationArrayPool.acquire(this.output);
    let outIndex = 0;
    this.nodes.forEach((node, index) => {
      if (node.type === "input") node.noTraceActivate(input[index]);
      else if (node.type === "output")
        output[outIndex++] = node.noTraceActivate();
      else node.noTraceActivate();
    });
    const result = Array.from(output);
    activationArrayPool.release(output);
    return result;
  }
  function activateRaw(input, training = false, maxActivationDepth = 1e3) {
    const self = this;
    if (!self._reuseActivationArrays)
      return this.activate(input, training, maxActivationDepth);
    return this.activate(input, training, maxActivationDepth);
  }
  function activateBatch(inputs, training = false) {
    if (!Array.isArray(inputs))
      throw new Error("inputs must be an array of input arrays");
    const out = new Array(inputs.length);
    for (let i = 0; i < inputs.length; i++) {
      const x = inputs[i];
      if (!Array.isArray(x) || x.length !== this.input) {
        throw new Error(
          `Input[${i}] size mismatch: expected ${this.input}, got ${x ? x.length : "undefined"}`
        );
      }
      out[i] = this.activate(x, training);
    }
    return out;
  }
  var init_network_activate = __esm({
    "src/architecture/network/network.activate.ts"() {
      "use strict";
      init_activationArrayPool();
    }
  });

  // src/architecture/group.ts
  var Group;
  var init_group = __esm({
    "src/architecture/group.ts"() {
      "use strict";
      init_node();
      init_layer();
      init_config();
      init_methods();
      Group = class _Group {
        /**
         * An array holding all the nodes within this group.
         */
        nodes;
        /**
         * Stores connection information related to this group.
         * `in`: Connections coming into any node in this group from outside.
         * `out`: Connections going out from any node in this group to outside.
         * `self`: Connections between nodes within this same group (e.g., in ONE_TO_ONE connections).
         */
        connections;
        /**
         * Creates a new group comprised of a specified number of nodes.
         * @param {number} size - The quantity of nodes to initialize within this group.
         */
        constructor(size) {
          this.nodes = [];
          this.connections = {
            in: [],
            out: [],
            self: []
          };
          for (let i = 0; i < size; i++) {
            this.nodes.push(new Node2());
          }
        }
        /**
         * Activates all nodes in the group. If input values are provided, they are assigned
         * sequentially to the nodes before activation. Otherwise, nodes activate based on their
         * existing states and incoming connections.
         *
         * @param {number[]} [value] - An optional array of input values. If provided, its length must match the number of nodes in the group.
         * @returns {number[]} An array containing the activation value of each node in the group, in order.
         * @throws {Error} If the `value` array is provided and its length does not match the number of nodes in the group.
         */
        activate(value) {
          const values = [];
          if (value !== void 0 && value.length !== this.nodes.length) {
            throw new Error(
              "Array with values should be same as the amount of nodes!"
            );
          }
          for (let i = 0; i < this.nodes.length; i++) {
            const activation = value === void 0 ? this.nodes[i].activate() : this.nodes[i].activate(value[i]);
            values.push(activation);
          }
          return values;
        }
        /**
         * Propagates the error backward through all nodes in the group. If target values are provided,
         * the error is calculated against these targets (typically for output layers). Otherwise,
         * the error is calculated based on the error propagated from subsequent layers/nodes.
         *
         * @param {number} rate - The learning rate to apply during weight updates.
         * @param {number} momentum - The momentum factor to apply during weight updates.
         * @param {number[]} [target] - Optional target values for error calculation. If provided, its length must match the number of nodes.
         * @throws {Error} If the `target` array is provided and its length does not match the number of nodes in the group.
         */
        propagate(rate, momentum, target) {
          if (target !== void 0 && target.length !== this.nodes.length) {
            throw new Error(
              "Array with values should be same as the amount of nodes!"
            );
          }
          for (let i = this.nodes.length - 1; i >= 0; i--) {
            if (target === void 0) {
              this.nodes[i].propagate(rate, momentum, true, 0);
            } else {
              this.nodes[i].propagate(rate, momentum, true, 0, target[i]);
            }
          }
        }
        /**
         * Establishes connections from all nodes in this group to a target Group, Layer, or Node.
         * The connection pattern (e.g., all-to-all, one-to-one) can be specified.
         *
         * @param {Group | Layer | Node} target - The destination entity (Group, Layer, or Node) to connect to.
         * @param {methods.groupConnection | methods.connection} [method] - The connection method/type (e.g., `methods.groupConnection.ALL_TO_ALL`, `methods.groupConnection.ONE_TO_ONE`). Defaults depend on the target type and whether it's the same group.
         * @param {number} [weight] - An optional fixed weight to assign to all created connections. If not provided, weights might be initialized randomly or based on node defaults.
         * @returns {any[]} An array containing all the connection objects created. Consider using a more specific type like `Connection[]`.
         * @throws {Error} If `methods.groupConnection.ONE_TO_ONE` is used and the source and target groups have different sizes.
         */
        connect(target, method, weight) {
          let connections = [];
          let i, j;
          if (target instanceof _Group) {
            if (method === void 0) {
              if (this !== target) {
                if (config.warnings)
                  console.warn(
                    "No group connection specified, using ALL_TO_ALL by default."
                  );
                method = connection_default.ALL_TO_ALL;
              } else {
                if (config.warnings)
                  console.warn(
                    "Connecting group to itself, using ONE_TO_ONE by default."
                  );
                method = connection_default.ONE_TO_ONE;
              }
            }
            if (method === connection_default.ALL_TO_ALL || method === connection_default.ALL_TO_ELSE) {
              for (i = 0; i < this.nodes.length; i++) {
                for (j = 0; j < target.nodes.length; j++) {
                  if (method === connection_default.ALL_TO_ELSE && this.nodes[i] === target.nodes[j])
                    continue;
                  let connection = this.nodes[i].connect(target.nodes[j], weight);
                  this.connections.out.push(connection[0]);
                  target.connections.in.push(connection[0]);
                  connections.push(connection[0]);
                }
              }
            } else if (method === connection_default.ONE_TO_ONE) {
              if (this.nodes.length !== target.nodes.length) {
                throw new Error(
                  "Cannot create ONE_TO_ONE connection: source and target groups must have the same size."
                );
              }
              for (i = 0; i < this.nodes.length; i++) {
                let connection = this.nodes[i].connect(target.nodes[i], weight);
                if (this === target) {
                  this.connections.self.push(connection[0]);
                } else {
                  this.connections.out.push(connection[0]);
                  target.connections.in.push(connection[0]);
                }
                connections.push(connection[0]);
              }
            }
          } else if (target instanceof Layer) {
            connections = target.input(this, method, weight);
          } else if (target instanceof Node2) {
            for (i = 0; i < this.nodes.length; i++) {
              let connection = this.nodes[i].connect(target, weight);
              this.connections.out.push(connection[0]);
              connections.push(connection[0]);
            }
          }
          return connections;
        }
        /**
         * Configures nodes within this group to act as gates for the specified connection(s).
         * Gating allows the output of a node in this group to modulate the flow of signal through the gated connection.
         *
         * @param {any | any[]} connections - A single connection object or an array of connection objects to be gated. Consider using a more specific type like `Connection | Connection[]`.
         * @param {methods.gating} method - The gating mechanism to use (e.g., `methods.gating.INPUT`, `methods.gating.OUTPUT`, `methods.gating.SELF`). Specifies which part of the connection is influenced by the gater node.
         * @throws {Error} If no gating `method` is specified.
         */
        gate(connections, method) {
          if (method === void 0) {
            throw new Error(
              "Please specify a gating method: Gating.INPUT, Gating.OUTPUT, or Gating.SELF"
            );
          }
          if (!Array.isArray(connections)) {
            connections = [connections];
          }
          const nodes1 = [];
          const nodes2 = [];
          let i, j;
          for (i = 0; i < connections.length; i++) {
            const connection = connections[i];
            if (!nodes1.includes(connection.from)) nodes1.push(connection.from);
            if (!nodes2.includes(connection.to)) nodes2.push(connection.to);
          }
          switch (method) {
            // Gate the input to the target node(s) of the connection(s)
            case gating.INPUT:
              for (let i2 = 0; i2 < connections.length; i2++) {
                const conn = connections[i2];
                const gater = this.nodes[i2 % this.nodes.length];
                gater.gate(conn);
              }
              break;
            // Gate the output from the source node(s) of the connection(s)
            case gating.OUTPUT:
              for (i = 0; i < nodes1.length; i++) {
                let node = nodes1[i];
                let gater = this.nodes[i % this.nodes.length];
                for (j = 0; j < node.connections.out.length; j++) {
                  let conn = node.connections.out[j];
                  if (connections.includes(conn)) {
                    gater.gate(conn);
                  }
                }
              }
              break;
            // Gate the self-connection of the node(s) involved
            case gating.SELF:
              for (i = 0; i < nodes1.length; i++) {
                let node = nodes1[i];
                let gater = this.nodes[i % this.nodes.length];
                const selfConn = Array.isArray(node.connections.self) ? node.connections.self[0] : node.connections.self;
                if (connections.includes(selfConn)) {
                  gater.gate(selfConn);
                }
              }
              break;
          }
        }
        /**
         * Sets specific properties (like bias, squash function, or type) for all nodes within the group.
         *
         * @param {{ bias?: number; squash?: any; type?: string }} values - An object containing the properties and their new values. Only provided properties are updated.
         *        `bias`: Sets the bias term for all nodes.
         *        `squash`: Sets the activation function (squashing function) for all nodes.
         *        `type`: Sets the node type (e.g., 'input', 'hidden', 'output') for all nodes.
         */
        set(values) {
          for (let i = 0; i < this.nodes.length; i++) {
            if (values.bias !== void 0) {
              this.nodes[i].bias = values.bias;
            }
            this.nodes[i].squash = values.squash || this.nodes[i].squash;
            this.nodes[i].type = values.type || this.nodes[i].type;
          }
        }
        /**
         * Removes connections between nodes in this group and a target Group or Node.
         *
         * @param {Group | Node} target - The Group or Node to disconnect from.
         * @param {boolean} [twosided=false] - If true, also removes connections originating from the `target` and ending in this group. Defaults to false (only removes connections from this group to the target).
         */
        disconnect(target, twosided = false) {
          let i, j, k;
          if (target instanceof _Group) {
            for (i = 0; i < this.nodes.length; i++) {
              for (j = 0; j < target.nodes.length; j++) {
                this.nodes[i].disconnect(target.nodes[j], twosided);
                for (k = this.connections.out.length - 1; k >= 0; k--) {
                  let conn = this.connections.out[k];
                  if (conn.from === this.nodes[i] && conn.to === target.nodes[j]) {
                    this.connections.out.splice(k, 1);
                    break;
                  }
                }
                if (twosided) {
                  for (k = this.connections.in.length - 1; k >= 0; k--) {
                    let conn = this.connections.in[k];
                    if (conn.from === target.nodes[j] && conn.to === this.nodes[i]) {
                      this.connections.in.splice(k, 1);
                      break;
                    }
                  }
                  for (k = target.connections.out.length - 1; k >= 0; k--) {
                    let conn = target.connections.out[k];
                    if (conn.from === target.nodes[j] && conn.to === this.nodes[i]) {
                      target.connections.out.splice(k, 1);
                      break;
                    }
                  }
                  for (k = target.connections.in.length - 1; k >= 0; k--) {
                    let conn = target.connections.in[k];
                    if (conn.from === this.nodes[i] && conn.to === target.nodes[j]) {
                      target.connections.in.splice(k, 1);
                      break;
                    }
                  }
                }
              }
            }
          } else if (target instanceof Node2) {
            for (i = 0; i < this.nodes.length; i++) {
              this.nodes[i].disconnect(target, twosided);
              for (j = this.connections.out.length - 1; j >= 0; j--) {
                let conn = this.connections.out[j];
                if (conn.from === this.nodes[i] && conn.to === target) {
                  this.connections.out.splice(j, 1);
                  break;
                }
              }
              if (twosided) {
                for (j = this.connections.in.length - 1; j >= 0; j--) {
                  const conn = this.connections.in[j];
                  if (conn.from === target && conn.to === this.nodes[i]) {
                    this.connections.in.splice(j, 1);
                    break;
                  }
                }
              }
            }
          }
        }
        /**
         * Resets the state of all nodes in the group. This typically involves clearing
         * activation values, state, and propagated errors, preparing the group for a new input pattern,
         * especially relevant in recurrent networks or sequence processing.
         */
        clear() {
          for (let i = 0; i < this.nodes.length; i++) {
            this.nodes[i].clear();
          }
        }
        /**
         * Serializes the group into a JSON-compatible format, avoiding circular references.
         * Only includes node indices and connection counts.
         *
         * @returns {object} A JSON-compatible representation of the group.
         */
        toJSON() {
          return {
            size: this.nodes.length,
            nodeIndices: this.nodes.map((n) => n.index),
            connections: {
              in: this.connections.in.length,
              out: this.connections.out.length,
              self: this.connections.self.length
            }
          };
        }
      };
    }
  });

  // src/architecture/layer.ts
  var layer_exports = {};
  __export(layer_exports, {
    default: () => Layer
  });
  var Layer;
  var init_layer = __esm({
    "src/architecture/layer.ts"() {
      "use strict";
      init_node();
      init_group();
      init_methods();
      init_activationArrayPool();
      Layer = class _Layer {
        /**
         * An array containing all the nodes (neurons or groups) that constitute this layer.
         * The order of nodes might be relevant depending on the layer type and its connections.
         */
        nodes;
        // Note: While typed as Node[], can contain Group instances in practice for memory layers.
        /**
         * Stores connection information related to this layer. This is often managed
         * by the network or higher-level structures rather than directly by the layer itself.
         * `in`: Incoming connections to the layer's nodes.
         * `out`: Outgoing connections from the layer's nodes.
         * `self`: Self-connections within the layer's nodes.
         */
        connections;
        /**
         * Represents the primary output group of nodes for this layer.
         * This group is typically used when connecting this layer *to* another layer or group.
         * It might be null if the layer is not yet fully constructed or is an input layer.
         */
        output;
        /**
         * Dropout rate for this layer (0 to 1). If > 0, all nodes in the layer are masked together during training.
         * Layer-level dropout takes precedence over node-level dropout for nodes in this layer.
         */
        dropout = 0;
        /**
         * Initializes a new Layer instance.
         */
        constructor() {
          this.output = null;
          this.nodes = [];
          this.connections = { in: [], out: [], self: [] };
        }
        /**
         * Activates all nodes within the layer, computing their output values.
         *
         * If an input `value` array is provided, it's used as the initial activation
         * for the corresponding nodes in the layer. Otherwise, nodes compute their
         * activation based on their incoming connections.
         *
         * During training, layer-level dropout is applied, masking all nodes in the layer together.
         * During inference, all masks are set to 1.
         *
         * @param value - An optional array of activation values to set for the layer's nodes. The length must match the number of nodes.
         * @param training - A boolean indicating whether the layer is in training mode. Defaults to false.
         * @returns An array containing the activation value of each node in the layer after activation.
         * @throws {Error} If the provided `value` array's length does not match the number of nodes in the layer.
         */
        activate(value, training = false) {
          const out = activationArrayPool.acquire(this.nodes.length);
          if (value !== void 0 && value.length !== this.nodes.length) {
            throw new Error(
              "Array with values should be same as the amount of nodes!"
            );
          }
          let layerMask = 1;
          if (training && this.dropout > 0) {
            layerMask = Math.random() >= this.dropout ? 1 : 0;
            this.nodes.forEach((node) => {
              node.mask = layerMask;
            });
          } else {
            this.nodes.forEach((node) => {
              node.mask = 1;
            });
          }
          for (let i = 0; i < this.nodes.length; i++) {
            let activation;
            if (value === void 0) {
              activation = this.nodes[i].activate();
            } else {
              activation = this.nodes[i].activate(value[i]);
            }
            out[i] = activation;
          }
          const cloned = Array.from(out);
          activationArrayPool.release(out);
          return cloned;
        }
        /**
         * Propagates the error backward through all nodes in the layer.
         *
         * This is a core step in the backpropagation algorithm used for training.
         * If a `target` array is provided (typically for the output layer), it's used
         * to calculate the initial error for each node. Otherwise, nodes calculate
         * their error based on the error propagated from subsequent layers.
         *
         * @param rate - The learning rate, controlling the step size of weight adjustments.
         * @param momentum - The momentum factor, used to smooth weight updates and escape local minima.
         * @param target - An optional array of target values (expected outputs) for the layer's nodes. The length must match the number of nodes.
         * @throws {Error} If the provided `target` array's length does not match the number of nodes in the layer.
         */
        propagate(rate, momentum, target) {
          if (target !== void 0 && target.length !== this.nodes.length) {
            throw new Error(
              "Array with values should be same as the amount of nodes!"
            );
          }
          for (let i = this.nodes.length - 1; i >= 0; i--) {
            if (target === void 0) {
              this.nodes[i].propagate(rate, momentum, true, 0);
            } else {
              this.nodes[i].propagate(rate, momentum, true, 0, target[i]);
            }
          }
        }
        /**
         * Connects this layer's output to a target component (Layer, Group, or Node).
         *
         * This method delegates the connection logic primarily to the layer's `output` group
         * or the target layer's `input` method. It establishes the forward connections
         * necessary for signal propagation.
         *
         * @param target - The destination Layer, Group, or Node to connect to.
         * @param method - The connection method (e.g., `ALL_TO_ALL`, `ONE_TO_ONE`) defining the connection pattern. See `methods.groupConnection`.
         * @param weight - An optional fixed weight to assign to all created connections.
         * @returns An array containing the newly created connection objects.
         * @throws {Error} If the layer's `output` group is not defined.
         */
        connect(target, method, weight) {
          if (!this.output) {
            throw new Error(
              "Layer output is not defined. Cannot connect from this layer."
            );
          }
          let connections = [];
          if (target instanceof _Layer) {
            connections = target.input(this, method, weight);
          } else if (target instanceof Group || target instanceof Node2) {
            connections = this.output.connect(target, method, weight);
          }
          return connections;
        }
        /**
         * Applies gating to a set of connections originating from this layer's output group.
         *
         * Gating allows the activity of nodes in this layer (specifically, the output group)
         * to modulate the flow of information through the specified `connections`.
         *
         * @param connections - An array of connection objects to be gated.
         * @param method - The gating method (e.g., `INPUT`, `OUTPUT`, `SELF`) specifying how the gate influences the connection. See `methods.gating`.
         * @throws {Error} If the layer's `output` group is not defined.
         */
        gate(connections, method) {
          if (!this.output) {
            throw new Error(
              "Layer output is not defined. Cannot gate from this layer."
            );
          }
          this.output.gate(connections, method);
        }
        /**
         * Configures properties for all nodes within the layer.
         *
         * Allows batch setting of common node properties like bias, activation function (`squash`),
         * or node type. If a node within the `nodes` array is actually a `Group` (e.g., in memory layers),
         * the configuration is applied recursively to the nodes within that group.
         *
         * @param values - An object containing the properties and their values to set.
         *                 Example: `{ bias: 0.5, squash: methods.Activation.ReLU }`
         */
        set(values) {
          for (let i = 0; i < this.nodes.length; i++) {
            let node = this.nodes[i];
            if (node instanceof Node2) {
              if (values.bias !== void 0) {
                node.bias = values.bias;
              }
              node.squash = values.squash || node.squash;
              node.type = values.type || node.type;
            } else if (this.isGroup(node)) {
              node.set(values);
            }
          }
        }
        /**
         * Removes connections between this layer's nodes and a target Group or Node.
         *
         * @param target - The Group or Node to disconnect from.
         * @param twosided - If true, removes connections in both directions (from this layer to target, and from target to this layer). Defaults to false.
         */
        disconnect(target, twosided) {
          twosided = twosided || false;
          let i, j, k;
          if (target instanceof Group) {
            for (i = 0; i < this.nodes.length; i++) {
              for (j = 0; j < target.nodes.length; j++) {
                this.nodes[i].disconnect(target.nodes[j], twosided);
                for (k = this.connections.out.length - 1; k >= 0; k--) {
                  let conn = this.connections.out[k];
                  if (conn.from === this.nodes[i] && conn.to === target.nodes[j]) {
                    this.connections.out.splice(k, 1);
                    break;
                  }
                }
                if (twosided) {
                  for (k = this.connections.in.length - 1; k >= 0; k--) {
                    let conn = this.connections.in[k];
                    if (conn.from === target.nodes[j] && conn.to === this.nodes[i]) {
                      this.connections.in.splice(k, 1);
                      break;
                    }
                  }
                }
              }
            }
          } else if (target instanceof Node2) {
            for (i = 0; i < this.nodes.length; i++) {
              this.nodes[i].disconnect(target, twosided);
              for (j = this.connections.out.length - 1; j >= 0; j--) {
                let conn = this.connections.out[j];
                if (conn.from === this.nodes[i] && conn.to === target) {
                  this.connections.out.splice(j, 1);
                  break;
                }
              }
              if (twosided) {
                for (k = this.connections.in.length - 1; k >= 0; k--) {
                  let conn = this.connections.in[k];
                  if (conn.from === target && conn.to === this.nodes[i]) {
                    this.connections.in.splice(k, 1);
                    break;
                  }
                }
              }
            }
          }
        }
        /**
         * Resets the activation state of all nodes within the layer.
         * This is typically done before processing a new input sequence or sample.
         */
        clear() {
          for (let i = 0; i < this.nodes.length; i++) {
            this.nodes[i].clear();
          }
        }
        /**
         * Handles the connection logic when this layer is the *target* of a connection.
         *
         * It connects the output of the `from` layer or group to this layer's primary
         * input mechanism (which is often the `output` group itself, but depends on the layer type).
         * This method is usually called by the `connect` method of the source layer/group.
         *
         * @param from - The source Layer or Group connecting *to* this layer.
         * @param method - The connection method (e.g., `ALL_TO_ALL`). Defaults to `ALL_TO_ALL`.
         * @param weight - An optional fixed weight for the connections.
         * @returns An array containing the newly created connection objects.
         * @throws {Error} If the layer's `output` group (acting as input target here) is not defined.
         */
        input(from, method, weight) {
          if (from instanceof _Layer) from = from.output;
          method = method || connection_default.ALL_TO_ALL;
          if (!this.output) {
            throw new Error("Layer output (acting as input target) is not defined.");
          }
          return from.connect(this.output, method, weight);
        }
        // Static Layer Factory Methods
        /**
         * Creates a standard fully connected (dense) layer.
         *
         * All nodes in the source layer/group will connect to all nodes in this layer
         * when using the default `ALL_TO_ALL` connection method via `layer.input()`.
         *
         * @param size - The number of nodes (neurons) in this layer.
         * @returns A new Layer instance configured as a dense layer.
         */
        static dense(size) {
          const layer = new _Layer();
          const block = new Group(size);
          layer.nodes.push(...block.nodes);
          layer.output = block;
          layer.input = (from, method, weight) => {
            if (from instanceof _Layer) from = from.output;
            method = method || connection_default.ALL_TO_ALL;
            return from.connect(block, method, weight);
          };
          return layer;
        }
        /**
         * Creates a Long Short-Term Memory (LSTM) layer.
         *
         * LSTMs are a type of recurrent neural network (RNN) cell capable of learning
         * long-range dependencies. This implementation uses standard LSTM architecture
         * with input, forget, and output gates, and a memory cell.
         *
         * @param size - The number of LSTM units (and nodes in each gate/cell group).
         * @returns A new Layer instance configured as an LSTM layer.
         */
        static lstm(size) {
          const layer = new _Layer();
          const inputGate = new Group(size);
          const forgetGate = new Group(size);
          const memoryCell = new Group(size);
          const outputGate = new Group(size);
          const outputBlock = new Group(size);
          inputGate.set({ bias: 1 });
          forgetGate.set({ bias: 1 });
          outputGate.set({ bias: 1 });
          memoryCell.set({ bias: 0 });
          outputBlock.set({ bias: 0 });
          memoryCell.connect(inputGate, connection_default.ALL_TO_ALL);
          memoryCell.connect(forgetGate, connection_default.ALL_TO_ALL);
          memoryCell.connect(outputGate, connection_default.ALL_TO_ALL);
          memoryCell.connect(memoryCell, connection_default.ONE_TO_ONE);
          const output = memoryCell.connect(
            outputBlock,
            connection_default.ALL_TO_ALL
          );
          outputGate.gate(output, gating.OUTPUT);
          memoryCell.nodes.forEach((node, i) => {
            const selfConnection = node.connections.self.find(
              (conn) => conn.to === node && conn.from === node
            );
            if (selfConnection) {
              selfConnection.gater = forgetGate.nodes[i];
              if (!forgetGate.nodes[i].connections.gated.includes(selfConnection)) {
                forgetGate.nodes[i].connections.gated.push(selfConnection);
              }
            } else {
              console.warn(
                `LSTM Warning: No self-connection found for memory cell node ${i}`
              );
            }
          });
          layer.nodes = [
            ...inputGate.nodes,
            ...forgetGate.nodes,
            ...memoryCell.nodes,
            ...outputGate.nodes,
            ...outputBlock.nodes
          ];
          layer.output = outputBlock;
          layer.input = (from, method, weight) => {
            if (from instanceof _Layer) from = from.output;
            method = method || connection_default.ALL_TO_ALL;
            let connections = [];
            const input = from.connect(memoryCell, method, weight);
            connections = connections.concat(input);
            connections = connections.concat(from.connect(inputGate, method, weight));
            connections = connections.concat(
              from.connect(outputGate, method, weight)
            );
            connections = connections.concat(
              from.connect(forgetGate, method, weight)
            );
            inputGate.gate(input, gating.INPUT);
            return connections;
          };
          return layer;
        }
        /**
         * Creates a Gated Recurrent Unit (GRU) layer.
         *
         * GRUs are another type of recurrent neural network cell, often considered
         * simpler than LSTMs but achieving similar performance on many tasks.
         * They use an update gate and a reset gate to manage information flow.
         *
         * @param size - The number of GRU units (and nodes in each gate/cell group).
         * @returns A new Layer instance configured as a GRU layer.
         */
        static gru(size) {
          const layer = new _Layer();
          const updateGate = new Group(size);
          const inverseUpdateGate = new Group(size);
          const resetGate = new Group(size);
          const memoryCell = new Group(size);
          const output = new Group(size);
          const previousOutput = new Group(size);
          previousOutput.set({
            bias: 0,
            squash: activation_default.identity,
            // Pass through previous output directly
            type: "variant"
            // Custom type identifier
          });
          memoryCell.set({
            squash: activation_default.tanh
            // Tanh activation for candidate state
          });
          inverseUpdateGate.set({
            bias: 0,
            squash: activation_default.inverse,
            // Activation computes 1 - input
            type: "variant"
            // Custom type identifier
          });
          updateGate.set({ bias: 1 });
          resetGate.set({ bias: 0 });
          previousOutput.connect(updateGate, connection_default.ALL_TO_ALL);
          previousOutput.connect(resetGate, connection_default.ALL_TO_ALL);
          updateGate.connect(
            inverseUpdateGate,
            connection_default.ONE_TO_ONE,
            1
          );
          const reset = previousOutput.connect(
            memoryCell,
            connection_default.ALL_TO_ALL
          );
          resetGate.gate(reset, gating.OUTPUT);
          const update1 = previousOutput.connect(
            output,
            connection_default.ALL_TO_ALL
          );
          const update2 = memoryCell.connect(
            output,
            connection_default.ALL_TO_ALL
          );
          updateGate.gate(update1, gating.OUTPUT);
          inverseUpdateGate.gate(update2, gating.OUTPUT);
          output.connect(previousOutput, connection_default.ONE_TO_ONE, 1);
          layer.nodes = [
            ...updateGate.nodes,
            ...inverseUpdateGate.nodes,
            ...resetGate.nodes,
            ...memoryCell.nodes,
            ...output.nodes,
            ...previousOutput.nodes
          ];
          layer.output = output;
          layer.input = (from, method, weight) => {
            if (from instanceof _Layer) from = from.output;
            method = method || connection_default.ALL_TO_ALL;
            let connections = [];
            connections = connections.concat(
              from.connect(updateGate, method, weight)
            );
            connections = connections.concat(from.connect(resetGate, method, weight));
            connections = connections.concat(
              from.connect(memoryCell, method, weight)
            );
            return connections;
          };
          return layer;
        }
        /**
         * Creates a Memory layer, designed to hold state over a fixed number of time steps.
         *
         * This layer consists of multiple groups (memory blocks), each holding the state
         * from a previous time step. The input connects to the most recent block, and
         * information propagates backward through the blocks. The layer's output
         * concatenates the states of all memory blocks.
         *
         * @param size - The number of nodes in each memory block (must match the input size).
         * @param memory - The number of time steps to remember (number of memory blocks).
         * @returns A new Layer instance configured as a Memory layer.
         * @throws {Error} If the connecting layer's size doesn't match the memory block `size`.
         */
        static memory(size, memory) {
          const layer = new _Layer();
          let previous = null;
          for (let i = 0; i < memory; i++) {
            const block = new Group(size);
            block.set({
              squash: activation_default.identity,
              bias: 0,
              type: "variant"
              // Custom type identifier
            });
            if (previous != null) {
              previous.connect(block, connection_default.ONE_TO_ONE, 1);
            }
            layer.nodes.push(block);
            previous = block;
          }
          layer.nodes.reverse();
          const outputGroup = new Group(0);
          for (const group of layer.nodes) {
            if (this.prototype.isGroup(group)) {
              outputGroup.nodes = outputGroup.nodes.concat(group.nodes);
            } else {
              console.warn(
                "Unexpected Node type found directly in Memory layer nodes list during output group creation."
              );
            }
          }
          layer.output = outputGroup;
          layer.input = (from, method, weight) => {
            if (from instanceof _Layer) from = from.output;
            method = method || connection_default.ALL_TO_ALL;
            const inputBlock = layer.nodes[layer.nodes.length - 1];
            if (!this.prototype.isGroup(inputBlock)) {
              throw new Error("Memory layer input block is not a Group.");
            }
            if (from.nodes.length !== inputBlock.nodes.length) {
              throw new Error(
                `Previous layer size (${from.nodes.length}) must be same as memory size (${inputBlock.nodes.length})`
              );
            }
            return from.connect(inputBlock, connection_default.ONE_TO_ONE, 1);
          };
          return layer;
        }
        /**
         * Creates a batch normalization layer.
         * Applies batch normalization to the activations of the nodes in this layer during activation.
         * @param size - The number of nodes in this layer.
         * @returns A new Layer instance configured as a batch normalization layer.
         */
        static batchNorm(size) {
          const layer = _Layer.dense(size);
          layer.batchNorm = true;
          const baseActivate = layer.activate.bind(layer);
          layer.activate = function(value, training = false) {
            const activations = baseActivate(value, training);
            const mean = activations.reduce((a, b) => a + b, 0) / activations.length;
            const variance = activations.reduce((a, b) => a + (b - mean) ** 2, 0) / activations.length;
            const epsilon = (init_neat_constants(), __toCommonJS(neat_constants_exports)).NORM_EPSILON;
            return activations.map((a) => (a - mean) / Math.sqrt(variance + epsilon));
          };
          return layer;
        }
        /**
         * Creates a layer normalization layer.
         * Applies layer normalization to the activations of the nodes in this layer during activation.
         * @param size - The number of nodes in this layer.
         * @returns A new Layer instance configured as a layer normalization layer.
         */
        static layerNorm(size) {
          const layer = _Layer.dense(size);
          layer.layerNorm = true;
          const baseActivate = layer.activate.bind(layer);
          layer.activate = function(value, training = false) {
            const activations = baseActivate(value, training);
            const mean = activations.reduce((a, b) => a + b, 0) / activations.length;
            const variance = activations.reduce((a, b) => a + (b - mean) ** 2, 0) / activations.length;
            const epsilon = (init_neat_constants(), __toCommonJS(neat_constants_exports)).NORM_EPSILON;
            return activations.map((a) => (a - mean) / Math.sqrt(variance + epsilon));
          };
          return layer;
        }
        /**
         * Creates a 1D convolutional layer (stub implementation).
         * @param size - Number of output nodes (filters).
         * @param kernelSize - Size of the convolution kernel.
         * @param stride - Stride of the convolution (default 1).
         * @param padding - Padding (default 0).
         * @returns A new Layer instance representing a 1D convolutional layer.
         */
        static conv1d(size, kernelSize, stride = 1, padding = 0) {
          const layer = new _Layer();
          layer.nodes = Array.from({ length: size }, () => new Node2());
          layer.output = new Group(size);
          layer.conv1d = { kernelSize, stride, padding };
          layer.activate = function(value) {
            if (!value) return this.nodes.map((n) => n.activate());
            return value.slice(0, size);
          };
          return layer;
        }
        /**
         * Creates a multi-head self-attention layer (stub implementation).
         * @param size - Number of output nodes.
         * @param heads - Number of attention heads (default 1).
         * @returns A new Layer instance representing an attention layer.
         */
        static attention(size, heads = 1) {
          const layer = new _Layer();
          layer.nodes = Array.from({ length: size }, () => new Node2());
          layer.output = new Group(size);
          layer.attention = { heads };
          layer.activate = function(value) {
            if (!value) return this.nodes.map((n) => n.activate());
            const avg = value.reduce((a, b) => a + b, 0) / value.length;
            return Array(size).fill(avg);
          };
          return layer;
        }
        /**
         * Type guard to check if an object is likely a `Group`.
         *
         * This is a duck-typing check based on the presence of expected properties
         * (`set` method and `nodes` array). Used internally where `layer.nodes`
         * might contain `Group` instances (e.g., in `Memory` layers).
         *
         * @param obj - The object to inspect.
         * @returns `true` if the object has `set` and `nodes` properties matching a Group, `false` otherwise.
         */
        isGroup(obj) {
          return !!obj && typeof obj.set === "function" && Array.isArray(obj.nodes);
        }
      };
    }
  });

  // src/architecture/network/network.mutate.ts
  var network_mutate_exports = {};
  __export(network_mutate_exports, {
    mutateImpl: () => mutateImpl
  });
  function mutateImpl(method) {
    if (method == null) throw new Error("No (correct) mutate method given!");
    let key;
    if (typeof method === "string") key = method;
    else key = method?.name ?? method?.type ?? method?.identity;
    if (!key) {
      for (const k in mutation_default) {
        if (method === mutation_default[k]) {
          key = k;
          break;
        }
      }
    }
    const fn = key ? MUTATION_DISPATCH[key] : void 0;
    if (!fn) {
      if (config.warnings) {
        console.warn("[mutate] Unknown mutation method ignored:", key);
      }
      return;
    }
    fn.call(this, method);
    this._topoDirty = true;
  }
  function _addNode() {
    const internal = this;
    if (internal._enforceAcyclic) internal._topoDirty = true;
    if (config.deterministicChainMode) {
      const inputNode = this.nodes.find((n) => n.type === "input");
      const outputNode = this.nodes.find((n) => n.type === "output");
      if (!inputNode || !outputNode) return;
      if (!internal._detChain) {
        if (!this.connections.some(
          (c) => c.from === inputNode && c.to === outputNode
        )) {
          this.connect(inputNode, outputNode);
        }
        internal._detChain = [inputNode];
      }
      const chain = internal._detChain;
      const tail = chain[chain.length - 1];
      let terminal = this.connections.find(
        (c) => c.from === tail && c.to === outputNode
      );
      if (!terminal) terminal = this.connect(tail, outputNode)[0];
      const prevGater2 = terminal.gater;
      this.disconnect(terminal.from, terminal.to);
      const hidden2 = new Node2("hidden", void 0, internal._rand);
      hidden2.mutate(mutation_default.MOD_ACTIVATION);
      const outIndex = this.nodes.indexOf(outputNode);
      const insertIndex2 = Math.min(outIndex, this.nodes.length - this.output);
      this.nodes.splice(insertIndex2, 0, hidden2);
      internal._nodeIndexDirty = true;
      const c12 = this.connect(tail, hidden2)[0];
      const c22 = this.connect(hidden2, outputNode)[0];
      chain.push(hidden2);
      internal._preferredChainEdge = c22;
      if (prevGater2) this.gate(prevGater2, internal._rand() >= 0.5 ? c12 : c22);
      for (let i = 0; i < chain.length; i++) {
        const node = chain[i];
        const target = i + 1 < chain.length ? chain[i + 1] : outputNode;
        const keep = node.connections.out.find((e) => e.to === target);
        if (keep) {
          for (const extra of node.connections.out.slice()) {
            if (extra !== keep) {
              try {
                this.disconnect(extra.from, extra.to);
              } catch {
              }
            }
          }
        }
      }
      return;
    }
    if (this.connections.length === 0) {
      const input = this.nodes.find((n) => n.type === "input");
      const output = this.nodes.find((n) => n.type === "output");
      if (input && output) this.connect(input, output);
      else return;
    }
    const connection = this.connections[Math.floor(internal._rand() * this.connections.length)];
    if (!connection) return;
    const prevGater = connection.gater;
    this.disconnect(connection.from, connection.to);
    const hidden = new Node2("hidden", void 0, internal._rand);
    hidden.mutate(mutation_default.MOD_ACTIVATION);
    const targetIndex = this.nodes.indexOf(connection.to);
    const insertIndex = Math.min(targetIndex, this.nodes.length - this.output);
    this.nodes.splice(insertIndex, 0, hidden);
    internal._nodeIndexDirty = true;
    const c1 = this.connect(connection.from, hidden)[0];
    const c2 = this.connect(hidden, connection.to)[0];
    internal._preferredChainEdge = c2;
    if (prevGater) this.gate(prevGater, internal._rand() >= 0.5 ? c1 : c2);
  }
  function _subNode() {
    const hidden = this.nodes.filter((n) => n.type === "hidden");
    if (hidden.length === 0) {
      if (config.warnings) console.warn("No hidden nodes left to remove!");
      return;
    }
    const internal = this;
    const victim = hidden[Math.floor(internal._rand() * hidden.length)];
    this.remove(victim);
    const anyConn = this.connections[0];
    if (anyConn) anyConn.weight += 1e-4;
  }
  function _addConn() {
    const netInternal = this;
    if (netInternal._enforceAcyclic) netInternal._topoDirty = true;
    const forwardConnectionCandidates = [];
    for (let sourceIndex = 0; sourceIndex < this.nodes.length - this.output; sourceIndex++) {
      const sourceNode = this.nodes[sourceIndex];
      for (let targetIndex = Math.max(sourceIndex + 1, this.input); targetIndex < this.nodes.length; targetIndex++) {
        const targetNode = this.nodes[targetIndex];
        if (!sourceNode.isProjectingTo(targetNode))
          forwardConnectionCandidates.push([sourceNode, targetNode]);
      }
    }
    if (forwardConnectionCandidates.length === 0) return;
    const selectedPair = forwardConnectionCandidates[Math.floor(netInternal._rand() * forwardConnectionCandidates.length)];
    this.connect(selectedPair[0], selectedPair[1]);
  }
  function _subConn() {
    const netInternal = this;
    const removableForwardConnections = this.connections.filter(
      (candidateConn) => {
        const sourceHasMultipleOutgoing = candidateConn.from.connections.out.length > 1;
        const targetHasMultipleIncoming = candidateConn.to.connections.in.length > 1;
        const targetLayerPeers = this.nodes.filter(
          (n) => n.type === candidateConn.to.type && Math.abs(
            this.nodes.indexOf(n) - this.nodes.indexOf(candidateConn.to)
          ) < Math.max(this.input, this.output)
        );
        let wouldDisconnectLayerPeerGroup = false;
        if (targetLayerPeers.length > 0) {
          const peerConnectionsFromSource = this.connections.filter(
            (c) => c.from === candidateConn.from && targetLayerPeers.includes(c.to)
          );
          if (peerConnectionsFromSource.length <= 1)
            wouldDisconnectLayerPeerGroup = true;
        }
        return sourceHasMultipleOutgoing && targetHasMultipleIncoming && this.nodes.indexOf(candidateConn.to) > this.nodes.indexOf(candidateConn.from) && !wouldDisconnectLayerPeerGroup;
      }
    );
    if (removableForwardConnections.length === 0) return;
    const connectionToRemove = removableForwardConnections[Math.floor(netInternal._rand() * removableForwardConnections.length)];
    this.disconnect(connectionToRemove.from, connectionToRemove.to);
  }
  function _modWeight(method) {
    const allConnections = this.connections.concat(this.selfconns);
    if (allConnections.length === 0) return;
    const connectionToPerturb = allConnections[Math.floor(this._rand() * allConnections.length)];
    const modification = this._rand() * (method.max - method.min) + method.min;
    connectionToPerturb.weight += modification;
  }
  function _modBias(method) {
    if (this.nodes.length <= this.input) return;
    const targetNodeIndex = Math.floor(
      this._rand() * (this.nodes.length - this.input) + this.input
    );
    const nodeForBiasMutation = this.nodes[targetNodeIndex];
    nodeForBiasMutation.mutate(method);
  }
  function _modActivation(method) {
    const canMutateOutput = method.mutateOutput ?? true;
    const numMutableNodes = this.nodes.length - this.input - (canMutateOutput ? 0 : this.output);
    if (numMutableNodes <= 0) {
      if (config.warnings)
        console.warn(
          "No nodes available for activation function mutation based on config."
        );
      return;
    }
    const targetNodeIndex = Math.floor(
      this._rand() * numMutableNodes + this.input
    );
    const targetNode = this.nodes[targetNodeIndex];
    targetNode.mutate(method);
  }
  function _addSelfConn() {
    const netInternal = this;
    if (netInternal._enforceAcyclic) return;
    const nodesWithoutSelfLoop = this.nodes.filter(
      (n, idx) => idx >= this.input && n.connections.self.length === 0
    );
    if (nodesWithoutSelfLoop.length === 0) {
      if (config.warnings)
        console.warn("All eligible nodes already have self-connections.");
      return;
    }
    const nodeReceivingSelfLoop = nodesWithoutSelfLoop[Math.floor(netInternal._rand() * nodesWithoutSelfLoop.length)];
    this.connect(nodeReceivingSelfLoop, nodeReceivingSelfLoop);
  }
  function _subSelfConn() {
    if (this.selfconns.length === 0) {
      if (config.warnings) console.warn("No self-connections exist to remove.");
      return;
    }
    const selfConnectionToRemove = this.selfconns[Math.floor(this._rand() * this.selfconns.length)];
    this.disconnect(selfConnectionToRemove.from, selfConnectionToRemove.to);
  }
  function _addGate() {
    const netInternal = this;
    const allConnectionsIncludingSelf = this.connections.concat(this.selfconns);
    const ungatedConnectionCandidates = allConnectionsIncludingSelf.filter(
      (c) => c.gater === null
    );
    if (ungatedConnectionCandidates.length === 0 || this.nodes.length <= this.input) {
      if (config.warnings) console.warn("All connections are already gated.");
      return;
    }
    const gatingNodeIndex = Math.floor(
      netInternal._rand() * (this.nodes.length - this.input) + this.input
    );
    const gatingNode = this.nodes[gatingNodeIndex];
    const connectionToGate = ungatedConnectionCandidates[Math.floor(netInternal._rand() * ungatedConnectionCandidates.length)];
    this.gate(gatingNode, connectionToGate);
  }
  function _subGate() {
    if (this.gates.length === 0) {
      if (config.warnings) console.warn("No gated connections to ungate.");
      return;
    }
    const gatedConnectionIndex = Math.floor(
      this._rand() * this.gates.length
    );
    const gatedConnection = this.gates[gatedConnectionIndex];
    this.ungate(gatedConnection);
  }
  function _addBackConn() {
    const netInternal = this;
    if (netInternal._enforceAcyclic) return;
    const backwardConnectionCandidates = [];
    for (let laterIndex = this.input; laterIndex < this.nodes.length; laterIndex++) {
      const laterNode = this.nodes[laterIndex];
      for (let earlierIndex = this.input; earlierIndex < laterIndex; earlierIndex++) {
        const earlierNode = this.nodes[earlierIndex];
        if (!laterNode.isProjectingTo(earlierNode))
          backwardConnectionCandidates.push([laterNode, earlierNode]);
      }
    }
    if (backwardConnectionCandidates.length === 0) return;
    const selectedBackwardPair = backwardConnectionCandidates[Math.floor(netInternal._rand() * backwardConnectionCandidates.length)];
    this.connect(selectedBackwardPair[0], selectedBackwardPair[1]);
  }
  function _subBackConn() {
    const removableBackwardConnections = this.connections.filter(
      (candidateConn) => candidateConn.from.connections.out.length > 1 && candidateConn.to.connections.in.length > 1 && this.nodes.indexOf(candidateConn.from) > this.nodes.indexOf(candidateConn.to)
    );
    if (removableBackwardConnections.length === 0) return;
    const backwardConnectionToRemove = removableBackwardConnections[Math.floor(this._rand() * removableBackwardConnections.length)];
    this.disconnect(
      backwardConnectionToRemove.from,
      backwardConnectionToRemove.to
    );
  }
  function _swapNodes(method) {
    const netInternal = this;
    const canSwapOutput = method.mutateOutput ?? true;
    const numSwappableNodes = this.nodes.length - this.input - (canSwapOutput ? 0 : this.output);
    if (numSwappableNodes < 2) return;
    let firstNodeIndex = Math.floor(
      netInternal._rand() * numSwappableNodes + this.input
    );
    let secondNodeIndex = Math.floor(
      netInternal._rand() * numSwappableNodes + this.input
    );
    while (firstNodeIndex === secondNodeIndex)
      secondNodeIndex = Math.floor(
        netInternal._rand() * numSwappableNodes + this.input
      );
    const firstNode = this.nodes[firstNodeIndex];
    const secondNode = this.nodes[secondNodeIndex];
    const tempBias = firstNode.bias;
    const tempSquash = firstNode.squash;
    firstNode.bias = secondNode.bias;
    firstNode.squash = secondNode.squash;
    secondNode.bias = tempBias;
    secondNode.squash = tempSquash;
  }
  function _addLSTMNode() {
    const netInternal = this;
    if (netInternal._enforceAcyclic) return;
    if (this.connections.length === 0) return;
    const connectionToExpand = this.connections[Math.floor(Math.random() * this.connections.length)];
    const gaterLSTM = connectionToExpand.gater;
    this.disconnect(connectionToExpand.from, connectionToExpand.to);
    const Layer2 = (init_layer(), __toCommonJS(layer_exports)).default;
    const lstmLayer = Layer2.lstm(1);
    lstmLayer.nodes.forEach((n) => {
      n.type = "hidden";
      this.nodes.push(n);
    });
    this.connect(connectionToExpand.from, lstmLayer.nodes[0]);
    this.connect(lstmLayer.output.nodes[0], connectionToExpand.to);
    if (gaterLSTM)
      this.gate(gaterLSTM, this.connections[this.connections.length - 1]);
  }
  function _addGRUNode() {
    const netInternal = this;
    if (netInternal._enforceAcyclic) return;
    if (this.connections.length === 0) return;
    const connectionToExpand = this.connections[Math.floor(Math.random() * this.connections.length)];
    const gaterGRU = connectionToExpand.gater;
    this.disconnect(connectionToExpand.from, connectionToExpand.to);
    const Layer2 = (init_layer(), __toCommonJS(layer_exports)).default;
    const gruLayer = Layer2.gru(1);
    gruLayer.nodes.forEach((n) => {
      n.type = "hidden";
      this.nodes.push(n);
    });
    this.connect(connectionToExpand.from, gruLayer.nodes[0]);
    this.connect(gruLayer.output.nodes[0], connectionToExpand.to);
    if (gaterGRU)
      this.gate(gaterGRU, this.connections[this.connections.length - 1]);
  }
  function _reinitWeight(method) {
    if (this.nodes.length <= this.input) return;
    const internal = this;
    const idx = Math.floor(
      internal._rand() * (this.nodes.length - this.input) + this.input
    );
    const node = this.nodes[idx];
    const min = method?.min ?? -1;
    const max = method?.max ?? 1;
    const sample = () => internal._rand() * (max - min) + min;
    for (const c of node.connections.in) c.weight = sample();
    for (const c of node.connections.out) c.weight = sample();
    for (const c of node.connections.self) c.weight = sample();
  }
  function _batchNorm() {
    const hidden = this.nodes.filter((n) => n.type === "hidden");
    if (!hidden.length) return;
    const internal = this;
    const node = hidden[Math.floor(internal._rand() * hidden.length)];
    node._batchNorm = true;
  }
  var MUTATION_DISPATCH;
  var init_network_mutate = __esm({
    "src/architecture/network/network.mutate.ts"() {
      "use strict";
      init_node();
      init_mutation();
      init_config();
      MUTATION_DISPATCH = {
        ADD_NODE: _addNode,
        SUB_NODE: _subNode,
        ADD_CONN: _addConn,
        SUB_CONN: _subConn,
        MOD_WEIGHT: _modWeight,
        MOD_BIAS: _modBias,
        MOD_ACTIVATION: _modActivation,
        ADD_SELF_CONN: _addSelfConn,
        SUB_SELF_CONN: _subSelfConn,
        ADD_GATE: _addGate,
        SUB_GATE: _subGate,
        ADD_BACK_CONN: _addBackConn,
        SUB_BACK_CONN: _subBackConn,
        SWAP_NODES: _swapNodes,
        ADD_LSTM_NODE: _addLSTMNode,
        ADD_GRU_NODE: _addGRUNode,
        REINIT_WEIGHT: _reinitWeight,
        BATCH_NORM: _batchNorm
      };
    }
  });

  // src/architecture/network/network.training.ts
  var network_training_exports = {};
  __export(network_training_exports, {
    __trainingInternals: () => __trainingInternals,
    applyGradientClippingImpl: () => applyGradientClippingImpl,
    trainImpl: () => trainImpl,
    trainSetImpl: () => trainSetImpl
  });
  function computeMonitoredError(trainError, recentErrors, cfg, state) {
    if (cfg.window <= 1 && cfg.type !== "ema" && cfg.type !== "adaptive-ema") {
      return trainError;
    }
    const type = cfg.type;
    if (type === "median") {
      const sorted = [...recentErrors].sort((a, b) => a - b);
      const midIndex = Math.floor(sorted.length / 2);
      return sorted.length % 2 ? sorted[midIndex] : (sorted[midIndex - 1] + sorted[midIndex]) / 2;
    }
    if (type === "ema") {
      if (state.emaValue == null) state.emaValue = trainError;
      else
        state.emaValue = state.emaValue + cfg.emaAlpha * (trainError - state.emaValue);
      return state.emaValue;
    }
    if (type === "adaptive-ema") {
      const mean = recentErrors.reduce((a, b) => a + b, 0) / recentErrors.length;
      const variance = recentErrors.reduce((a, b) => a + (b - mean) * (b - mean), 0) / recentErrors.length;
      const baseAlpha = cfg.emaAlpha || 2 / (cfg.window + 1);
      const varianceScaled = variance / Math.max(mean * mean, 1e-8);
      const adaptiveAlpha = Math.min(
        0.95,
        Math.max(baseAlpha, baseAlpha * (1 + 2 * varianceScaled))
      );
      if (state.adaptiveBaseEmaValue == null) {
        state.adaptiveBaseEmaValue = trainError;
        state.adaptiveEmaValue = trainError;
      } else {
        state.adaptiveBaseEmaValue = state.adaptiveBaseEmaValue + baseAlpha * (trainError - state.adaptiveBaseEmaValue);
        state.adaptiveEmaValue = state.adaptiveEmaValue + adaptiveAlpha * (trainError - state.adaptiveEmaValue);
      }
      return Math.min(state.adaptiveEmaValue, state.adaptiveBaseEmaValue);
    }
    if (type === "gaussian") {
      const sigma = cfg.window / 3 || 1;
      let weightSum = 0;
      let weightedAccumulator = 0;
      const length = recentErrors.length;
      for (let i = 0; i < length; i++) {
        const weight = Math.exp(-0.5 * Math.pow((i - (length - 1)) / sigma, 2));
        weightSum += weight;
        weightedAccumulator += weight * recentErrors[i];
      }
      return weightedAccumulator / (weightSum || 1);
    }
    if (type === "trimmed") {
      const ratio = Math.min(0.49, Math.max(0, cfg.trimmedRatio || 0.1));
      const sorted = [...recentErrors].sort((a, b) => a - b);
      const drop = Math.floor(sorted.length * ratio);
      const trimmed = sorted.slice(drop, sorted.length - drop);
      return trimmed.reduce((a, b) => a + b, 0) / (trimmed.length || 1);
    }
    if (type === "wma") {
      let weightSum = 0;
      let weightedAccumulator = 0;
      for (let i = 0; i < recentErrors.length; i++) {
        const weight = i + 1;
        weightSum += weight;
        weightedAccumulator += weight * recentErrors[i];
      }
      return weightedAccumulator / (weightSum || 1);
    }
    return recentErrors.reduce((a, b) => a + b, 0) / recentErrors.length;
  }
  function computePlateauMetric(trainError, plateauErrors, cfg, state) {
    if (cfg.window <= 1 && cfg.type !== "ema") return trainError;
    if (cfg.type === "median") {
      const sorted = [...plateauErrors].sort((a, b) => a - b);
      const mid = Math.floor(sorted.length / 2);
      return sorted.length % 2 ? sorted[mid] : (sorted[mid - 1] + sorted[mid]) / 2;
    }
    if (cfg.type === "ema") {
      if (state.plateauEmaValue == null) state.plateauEmaValue = trainError;
      else
        state.plateauEmaValue = state.plateauEmaValue + cfg.emaAlpha * (trainError - state.plateauEmaValue);
      return state.plateauEmaValue;
    }
    return plateauErrors.reduce((a, b) => a + b, 0) / plateauErrors.length;
  }
  function detectMixedPrecisionOverflow(net, internalNet) {
    if (!internalNet._mixedPrecision.enabled) return false;
    if (internalNet._forceNextOverflow) {
      internalNet._forceNextOverflow = false;
      return true;
    }
    let overflow = false;
    net.nodes.forEach((node) => {
      if (node._fp32Bias !== void 0) {
        if (!Number.isFinite(node.bias)) overflow = true;
      }
    });
    return overflow;
  }
  function zeroAccumulatedGradients(net) {
    net.nodes.forEach((node) => {
      node.connections.in.forEach((c) => {
        c.totalDeltaWeight = 0;
      });
      node.connections.self.forEach((c) => {
        c.totalDeltaWeight = 0;
      });
      if (typeof node.totalDeltaBias === "number")
        node.totalDeltaBias = 0;
      node.previousDeltaBias = 0;
    });
  }
  function averageAccumulatedGradients(net, accumulationSteps) {
    if (accumulationSteps <= 1) return;
    net.nodes.forEach((node) => {
      node.connections.in.forEach((c) => {
        if (typeof c.totalDeltaWeight === "number")
          c.totalDeltaWeight /= accumulationSteps;
      });
      node.connections.self.forEach((c) => {
        if (typeof c.totalDeltaWeight === "number")
          c.totalDeltaWeight /= accumulationSteps;
      });
      if (typeof node.totalDeltaBias === "number")
        node.totalDeltaBias /= accumulationSteps;
    });
  }
  function applyOptimizerStep(net, optimizer, currentRate, momentum, internalNet) {
    let sumSq = 0;
    net.nodes.forEach((node) => {
      if (node.type === "input") return;
      node.applyBatchUpdatesWithOptimizer({
        type: optimizer.type,
        baseType: optimizer.baseType,
        beta1: optimizer.beta1,
        beta2: optimizer.beta2,
        eps: optimizer.eps,
        weightDecay: optimizer.weightDecay,
        momentum: optimizer.momentum ?? momentum,
        lrScale: currentRate,
        t: internalNet._optimizerStep,
        la_k: optimizer.la_k,
        la_alpha: optimizer.la_alpha
      });
      node.connections.in.forEach((c) => {
        if (typeof c.previousDeltaWeight === "number")
          sumSq += c.previousDeltaWeight * c.previousDeltaWeight;
      });
      node.connections.self.forEach((c) => {
        if (typeof c.previousDeltaWeight === "number")
          sumSq += c.previousDeltaWeight * c.previousDeltaWeight;
      });
    });
    return Math.sqrt(sumSq);
  }
  function maybeIncreaseLossScale(internalNet) {
    internalNet._mixedPrecisionState.goodSteps++;
    const incEvery = internalNet._mpIncreaseEvery || 200;
    if (internalNet._mixedPrecisionState.goodSteps >= incEvery && internalNet._mixedPrecision.lossScale < internalNet._mixedPrecisionState.maxLossScale) {
      internalNet._mixedPrecision.lossScale *= 2;
      internalNet._mixedPrecisionState.goodSteps = 0;
      internalNet._mixedPrecisionState.scaleUpEvents = (internalNet._mixedPrecisionState.scaleUpEvents || 0) + 1;
    }
  }
  function handleOverflow(internalNet) {
    internalNet._mixedPrecisionState.badSteps++;
    internalNet._mixedPrecisionState.goodSteps = 0;
    internalNet._mixedPrecision.lossScale = Math.max(
      internalNet._mixedPrecisionState.minLossScale,
      Math.floor(internalNet._mixedPrecision.lossScale / 2) || 1
    );
    internalNet._mixedPrecisionState.overflowCount = (internalNet._mixedPrecisionState.overflowCount || 0) + 1;
    internalNet._mixedPrecisionState.scaleDownEvents = (internalNet._mixedPrecisionState.scaleDownEvents || 0) + 1;
    internalNet._lastOverflowStep = internalNet._optimizerStep;
  }
  function applyGradientClippingImpl(net, cfg) {
    const internalNet = net;
    const collectGroups = () => {
      const collected = [];
      if (cfg.mode.startsWith("layerwise")) {
        if (net.layers && net.layers.length > 0) {
          for (let li = 0; li < net.layers.length; li++) {
            const layer = net.layers[li];
            if (!layer || !layer.nodes) continue;
            const groupVals = [];
            layer.nodes.forEach((node) => {
              if (!node || node.type === "input") return;
              node.connections.in.forEach((c) => {
                if (typeof c.totalDeltaWeight === "number")
                  groupVals.push(c.totalDeltaWeight);
              });
              node.connections.self.forEach((c) => {
                if (typeof c.totalDeltaWeight === "number")
                  groupVals.push(c.totalDeltaWeight);
              });
              if (typeof node.totalDeltaBias === "number")
                groupVals.push(node.totalDeltaBias);
            });
            if (groupVals.length) collected.push(groupVals);
          }
        } else {
          net.nodes.forEach((node) => {
            if (node.type === "input") return;
            const groupVals = [];
            node.connections.in.forEach((c) => {
              if (typeof c.totalDeltaWeight === "number")
                groupVals.push(c.totalDeltaWeight);
            });
            node.connections.self.forEach((c) => {
              if (typeof c.totalDeltaWeight === "number")
                groupVals.push(c.totalDeltaWeight);
            });
            if (typeof node.totalDeltaBias === "number")
              groupVals.push(node.totalDeltaBias);
            if (groupVals.length) collected.push(groupVals);
          });
        }
      } else {
        const globalVals = [];
        net.nodes.forEach((node) => {
          node.connections.in.forEach((c) => {
            if (typeof c.totalDeltaWeight === "number")
              globalVals.push(c.totalDeltaWeight);
          });
          node.connections.self.forEach((c) => {
            if (typeof c.totalDeltaWeight === "number")
              globalVals.push(c.totalDeltaWeight);
          });
          if (typeof node.totalDeltaBias === "number")
            globalVals.push(node.totalDeltaBias);
        });
        if (globalVals.length) collected.push(globalVals);
      }
      return collected;
    };
    const groups = collectGroups();
    internalNet._lastGradClipGroupCount = groups.length;
    const computeAbsolutePercentileThreshold = (values, percentile) => {
      if (!values.length) return 0;
      const sortedByAbs = [...values].sort((a, b) => Math.abs(a) - Math.abs(b));
      const rank = Math.min(
        sortedByAbs.length - 1,
        Math.max(0, Math.floor(percentile / 100 * sortedByAbs.length - 1))
      );
      return Math.abs(sortedByAbs[rank]);
    };
    const applyScale = (scaleFn) => {
      let groupIndex = 0;
      net.nodes.forEach((node) => {
        if (cfg.mode.startsWith("layerwise") && node.type === "input") return;
        const activeGroup = cfg.mode.startsWith("layerwise") ? groups[groupIndex++] : groups[0];
        node.connections.in.forEach((c) => {
          if (typeof c.totalDeltaWeight === "number")
            c.totalDeltaWeight = scaleFn(c.totalDeltaWeight, activeGroup);
        });
        node.connections.self.forEach((c) => {
          if (typeof c.totalDeltaWeight === "number")
            c.totalDeltaWeight = scaleFn(c.totalDeltaWeight, activeGroup);
        });
        if (typeof node.totalDeltaBias === "number")
          node.totalDeltaBias = scaleFn(
            node.totalDeltaBias,
            activeGroup
          );
      });
    };
    if (cfg.mode === "norm" || cfg.mode === "layerwiseNorm") {
      const maxAllowedNorm = cfg.maxNorm || 1;
      groups.forEach((groupValues) => {
        const groupL2Norm = Math.sqrt(
          groupValues.reduce((sum, v) => sum + v * v, 0)
        );
        if (groupL2Norm > maxAllowedNorm && groupL2Norm > 0) {
          const normScaleFactor = maxAllowedNorm / groupL2Norm;
          applyScale(
            (currentValue, owningGroup) => owningGroup === groupValues ? currentValue * normScaleFactor : currentValue
          );
        }
      });
    } else if (cfg.mode === "percentile" || cfg.mode === "layerwisePercentile") {
      const percentileSetting = cfg.percentile || 99;
      groups.forEach((groupValues) => {
        const percentileThreshold = computeAbsolutePercentileThreshold(
          groupValues,
          percentileSetting
        );
        if (percentileThreshold <= 0) return;
        applyScale(
          (currentValue, owningGroup) => owningGroup === groupValues && Math.abs(currentValue) > percentileThreshold ? percentileThreshold * Math.sign(currentValue) : currentValue
        );
      });
    }
  }
  function trainSetImpl(net, set, batchSize, accumulationSteps, currentRate, momentum, regularization, costFunction, optimizer) {
    const internalNet = net;
    let cumulativeError = 0;
    let batchSampleCount = 0;
    internalNet._gradAccumMicroBatches = 0;
    let totalProcessedSamples = 0;
    const outputNodes = net.nodes.filter((n) => n.type === "output");
    let computeError;
    if (typeof costFunction === "function") computeError = costFunction;
    else if (costFunction && typeof costFunction.fn === "function")
      computeError = costFunction.fn;
    else if (costFunction && typeof costFunction.calculate === "function")
      computeError = costFunction.calculate;
    else computeError = () => 0;
    for (let sampleIndex = 0; sampleIndex < set.length; sampleIndex++) {
      const dataPoint = set[sampleIndex];
      const input = dataPoint.input;
      const target = dataPoint.output;
      if (input.length !== net.input || target.length !== net.output) {
        if (config.warnings)
          console.warn(
            `Data point ${sampleIndex} has incorrect dimensions (input: ${input.length}/${net.input}, output: ${target.length}/${net.output}), skipping.`
          );
        continue;
      }
      try {
        const output = net.activate(input, true);
        if (optimizer && optimizer.type && optimizer.type !== "sgd") {
          for (let outIndex = 0; outIndex < outputNodes.length; outIndex++)
            outputNodes[outIndex].propagate(
              currentRate,
              momentum,
              false,
              regularization,
              target[outIndex]
            );
          for (let reverseIndex = net.nodes.length - 1; reverseIndex >= 0; reverseIndex--) {
            const node = net.nodes[reverseIndex];
            if (node.type === "output" || node.type === "input") continue;
            node.propagate(currentRate, momentum, false, regularization);
          }
        } else {
          for (let outIndex = 0; outIndex < outputNodes.length; outIndex++)
            outputNodes[outIndex].propagate(
              currentRate,
              momentum,
              true,
              regularization,
              target[outIndex]
            );
          for (let reverseIndex = net.nodes.length - 1; reverseIndex >= 0; reverseIndex--) {
            const node = net.nodes[reverseIndex];
            if (node.type === "output" || node.type === "input") continue;
            node.propagate(currentRate, momentum, true, regularization);
          }
        }
        cumulativeError += computeError(target, output);
        batchSampleCount++;
        totalProcessedSamples++;
      } catch (e) {
        if (config.warnings)
          console.warn(
            `Error processing data point ${sampleIndex} (input: ${JSON.stringify(
              input
            )}): ${e.message}. Skipping.`
          );
      }
      if (batchSampleCount > 0 && ((sampleIndex + 1) % batchSize === 0 || sampleIndex === set.length - 1)) {
        if (optimizer && optimizer.type && optimizer.type !== "sgd") {
          internalNet._gradAccumMicroBatches++;
          const readyForStep = internalNet._gradAccumMicroBatches % accumulationSteps === 0 || sampleIndex === set.length - 1;
          if (readyForStep) {
            internalNet._optimizerStep = (internalNet._optimizerStep || 0) + 1;
            const overflowDetected = detectMixedPrecisionOverflow(
              net,
              internalNet
            );
            if (overflowDetected) {
              zeroAccumulatedGradients(net);
              if (internalNet._mixedPrecision.enabled)
                handleOverflow(internalNet);
              internalNet._lastGradNorm = 0;
            } else {
              if (internalNet._currentGradClip)
                applyGradientClippingImpl(net, internalNet._currentGradClip);
              if (accumulationSteps > 1 && internalNet._accumulationReduction === "average") {
                averageAccumulatedGradients(net, accumulationSteps);
              }
              internalNet._lastGradNorm = applyOptimizerStep(
                net,
                optimizer,
                currentRate,
                momentum,
                internalNet
              );
              if (internalNet._mixedPrecision.enabled)
                maybeIncreaseLossScale(internalNet);
            }
          }
          batchSampleCount = 0;
        }
      }
    }
    if (internalNet._lastGradNorm == null) internalNet._lastGradNorm = 0;
    return totalProcessedSamples > 0 ? cumulativeError / totalProcessedSamples : 0;
  }
  function trainImpl(net, set, options) {
    const internalNet = net;
    if (!set || set.length === 0 || set[0].input.length !== net.input || set[0].output.length !== net.output) {
      throw new Error(
        "Dataset is invalid or dimensions do not match network input/output size!"
      );
    }
    options = options || {};
    if (typeof options.iterations === "undefined" && typeof options.error === "undefined") {
      if (config.warnings)
        console.warn("Missing `iterations` or `error` option.");
      throw new Error(
        "Missing `iterations` or `error` option. Training requires a stopping condition."
      );
    }
    if (config.warnings) {
      if (typeof options.rate === "undefined") {
        console.warn("Missing `rate` option");
        console.warn("Missing `rate` option, using default learning rate 0.3.");
      }
      if (typeof options.iterations === "undefined")
        console.warn(
          "Missing `iterations` option. Training will run potentially indefinitely until `error` threshold is met."
        );
    }
    let targetError = options.error ?? -Infinity;
    const cost = options.cost || Cost.mse;
    if (typeof cost !== "function" && !(typeof cost === "object" && (typeof cost.fn === "function" || typeof cost.calculate === "function"))) {
      throw new Error("Invalid cost function provided to Network.train.");
    }
    const baseRate = options.rate ?? 0.3;
    const dropout = options.dropout || 0;
    if (dropout < 0 || dropout >= 1) throw new Error("dropout must be in [0,1)");
    const momentum = options.momentum || 0;
    const batchSize = options.batchSize || 1;
    if (batchSize > set.length)
      throw new Error("Batch size cannot be larger than the dataset length.");
    const accumulationSteps = options.accumulationSteps || 1;
    internalNet._accumulationReduction = options.accumulationReduction === "sum" ? "sum" : "average";
    if (accumulationSteps < 1 || !Number.isFinite(accumulationSteps))
      throw new Error("accumulationSteps must be >=1");
    if (options.gradientClip) {
      const gc = options.gradientClip;
      if (gc.mode)
        internalNet._currentGradClip = {
          mode: gc.mode,
          maxNorm: gc.maxNorm,
          percentile: gc.percentile
        };
      else if (typeof gc.maxNorm === "number")
        internalNet._currentGradClip = { mode: "norm", maxNorm: gc.maxNorm };
      else if (typeof gc.percentile === "number")
        internalNet._currentGradClip = {
          mode: "percentile",
          percentile: gc.percentile
        };
      internalNet._gradClipSeparateBias = !!gc.separateBias;
    } else {
      internalNet._currentGradClip = void 0;
      internalNet._gradClipSeparateBias = false;
    }
    if (options.mixedPrecision) {
      const mp = options.mixedPrecision === true ? { lossScale: 1024 } : options.mixedPrecision;
      internalNet._mixedPrecision.enabled = true;
      internalNet._mixedPrecision.lossScale = mp.lossScale || 1024;
      const dyn = mp.dynamic || {};
      internalNet._mixedPrecisionState.minLossScale = dyn.minScale || 1;
      internalNet._mixedPrecisionState.maxLossScale = dyn.maxScale || 65536;
      internalNet._mpIncreaseEvery = dyn.increaseEvery || dyn.stableStepsForIncrease || 200;
      net.connections.forEach((c) => {
        c._fp32Weight = c.weight;
      });
      net.nodes.forEach((n) => {
        if (n.type !== "input") n._fp32Bias = n.bias;
      });
    } else {
      internalNet._mixedPrecision.enabled = false;
      internalNet._mixedPrecision.lossScale = 1;
      internalNet._mpIncreaseEvery = 200;
    }
    const allowedOptimizers = /* @__PURE__ */ new Set([
      "sgd",
      "rmsprop",
      "adagrad",
      "adam",
      "adamw",
      "amsgrad",
      "adamax",
      "nadam",
      "radam",
      "lion",
      "adabelief",
      "lookahead"
    ]);
    let optimizerConfig = void 0;
    if (typeof options.optimizer !== "undefined") {
      if (typeof options.optimizer === "string")
        optimizerConfig = { type: options.optimizer.toLowerCase() };
      else if (typeof options.optimizer === "object" && options.optimizer !== null) {
        optimizerConfig = { ...options.optimizer };
        if (typeof optimizerConfig.type === "string")
          optimizerConfig.type = optimizerConfig.type.toLowerCase();
      } else
        throw new Error("Invalid optimizer option; must be string or object");
      if (!allowedOptimizers.has(optimizerConfig.type))
        throw new Error(`Unknown optimizer type: ${optimizerConfig.type}`);
      if (optimizerConfig.type === "lookahead") {
        if (!optimizerConfig.baseType) optimizerConfig.baseType = "adam";
        if (optimizerConfig.baseType === "lookahead")
          throw new Error(
            "Nested lookahead (baseType lookahead) is not supported"
          );
        if (!allowedOptimizers.has(optimizerConfig.baseType))
          throw new Error(
            `Unknown baseType for lookahead: ${optimizerConfig.baseType}`
          );
        optimizerConfig.la_k = optimizerConfig.la_k || 5;
        optimizerConfig.la_alpha = optimizerConfig.la_alpha ?? 0.5;
      }
    }
    const iterations = options.iterations ?? Number.MAX_SAFE_INTEGER;
    const start2 = Date.now();
    let finalError = Infinity;
    const movingAverageWindow = Math.max(1, options.movingAverageWindow || 1);
    const movingAverageType = options.movingAverageType || "sma";
    const emaAlpha = (() => {
      if (movingAverageType !== "ema") return void 0;
      if (options.emaAlpha && options.emaAlpha > 0 && options.emaAlpha <= 1)
        return options.emaAlpha;
      return 2 / (movingAverageWindow + 1);
    })();
    const plateauWindow = Math.max(
      1,
      options.plateauMovingAverageWindow || movingAverageWindow
    );
    const plateauType = options.plateauMovingAverageType || movingAverageType;
    const plateauEmaAlpha = (() => {
      if (plateauType !== "ema") return void 0;
      if (options.plateauEmaAlpha && options.plateauEmaAlpha > 0 && options.plateauEmaAlpha <= 1)
        return options.plateauEmaAlpha;
      return 2 / (plateauWindow + 1);
    })();
    const earlyStopPatience = options.earlyStopPatience;
    const earlyStopMinDelta = options.earlyStopMinDelta || 0;
    let bestError = Infinity;
    let noImproveCount = 0;
    const recentErrorsCapacity = movingAverageWindow;
    const recentErrorsBuf = new Array(recentErrorsCapacity);
    let recentErrorsCount = 0;
    let recentErrorsWriteIdx = 0;
    const recentErrorsPush = (value) => {
      if (recentErrorsCapacity === 1) {
        recentErrorsBuf[0] = value;
        recentErrorsCount = 1;
        recentErrorsWriteIdx = 0;
        return;
      }
      recentErrorsBuf[recentErrorsWriteIdx] = value;
      recentErrorsWriteIdx = (recentErrorsWriteIdx + 1) % recentErrorsCapacity;
      if (recentErrorsCount < recentErrorsCapacity) recentErrorsCount++;
    };
    const recentErrorsChrono = () => {
      if (recentErrorsCount === 0) return [];
      if (recentErrorsCount < recentErrorsCapacity)
        return recentErrorsBuf.slice(0, recentErrorsCount);
      const out = new Array(recentErrorsCount);
      const start3 = recentErrorsWriteIdx;
      for (let i = 0; i < recentErrorsCount; i++)
        out[i] = recentErrorsBuf[(start3 + i) % recentErrorsCapacity];
      return out;
    };
    let emaValue = void 0;
    let adaptiveBaseEmaValue = void 0;
    let adaptiveEmaValue = void 0;
    const plateauCapacity = plateauWindow;
    const plateauBuf = new Array(plateauCapacity);
    let plateauCount = 0;
    let plateauWriteIdx = 0;
    const plateauPush = (value) => {
      if (plateauCapacity === 1) {
        plateauBuf[0] = value;
        plateauCount = 1;
        plateauWriteIdx = 0;
        return;
      }
      plateauBuf[plateauWriteIdx] = value;
      plateauWriteIdx = (plateauWriteIdx + 1) % plateauCapacity;
      if (plateauCount < plateauCapacity) plateauCount++;
    };
    const plateauChrono = () => {
      if (plateauCount === 0) return [];
      if (plateauCount < plateauCapacity)
        return plateauBuf.slice(0, plateauCount);
      const out = new Array(plateauCount);
      const start3 = plateauWriteIdx;
      for (let i = 0; i < plateauCount; i++)
        out[i] = plateauBuf[(start3 + i) % plateauCapacity];
      return out;
    };
    let plateauEmaValue = void 0;
    net.dropout = dropout;
    let performedIterations = 0;
    for (let iter = 1; iter <= iterations; iter++) {
      if (net._maybePrune) {
        net._maybePrune((internalNet._globalEpoch || 0) + iter);
      }
      const trainError = trainSetImpl(
        net,
        set,
        batchSize,
        accumulationSteps,
        baseRate,
        momentum,
        {},
        cost,
        optimizerConfig
      );
      performedIterations = iter;
      recentErrorsPush(trainError);
      let monitored = trainError;
      if (movingAverageWindow > 1 || movingAverageType === "ema" || movingAverageType === "adaptive-ema") {
        const recentArr = recentErrorsChrono();
        if (movingAverageType === "median") {
          const sorted = [...recentArr].sort((a, b) => a - b);
          const mid = Math.floor(sorted.length / 2);
          monitored = sorted.length % 2 ? sorted[mid] : (sorted[mid - 1] + sorted[mid]) / 2;
        } else if (movingAverageType === "ema") {
          if (emaValue == null) emaValue = trainError;
          else emaValue = emaValue + emaAlpha * (trainError - emaValue);
          monitored = emaValue;
        } else if (movingAverageType === "adaptive-ema") {
          const mean = recentArr.reduce((a, b) => a + b, 0) / recentArr.length;
          const variance = recentArr.reduce((a, b) => a + (b - mean) * (b - mean), 0) / recentArr.length;
          const baseAlpha = emaAlpha || 2 / (movingAverageWindow + 1);
          const varScaled = variance / Math.max(mean * mean, 1e-8);
          const adaptAlpha = Math.min(
            0.95,
            Math.max(baseAlpha, baseAlpha * (1 + 2 * varScaled))
          );
          if (adaptiveBaseEmaValue == null) {
            adaptiveBaseEmaValue = trainError;
            adaptiveEmaValue = trainError;
          } else {
            adaptiveBaseEmaValue = adaptiveBaseEmaValue + baseAlpha * (trainError - adaptiveBaseEmaValue);
            adaptiveEmaValue = adaptiveEmaValue + adaptAlpha * (trainError - adaptiveEmaValue);
          }
          monitored = Math.min(adaptiveEmaValue, adaptiveBaseEmaValue);
        } else if (movingAverageType === "gaussian") {
          const gaussianWindow = recentArr;
          const windowLength = gaussianWindow.length;
          const sigma = movingAverageWindow / 3 || 1;
          let gaussianWeightSum = 0;
          let gaussianWeightedAccumulator = 0;
          for (let gi = 0; gi < windowLength; gi++) {
            const weight = Math.exp(
              -0.5 * Math.pow((gi - (windowLength - 1)) / sigma, 2)
            );
            gaussianWeightSum += weight;
            gaussianWeightedAccumulator += weight * gaussianWindow[gi];
          }
          monitored = gaussianWeightedAccumulator / (gaussianWeightSum || 1);
        } else if (movingAverageType === "trimmed") {
          const tailTrimRatio = Math.min(
            0.49,
            Math.max(0, options.trimmedRatio || 0.1)
          );
          const sorted = [...recentArr].sort((a, b) => a - b);
          const elementsToDropEachSide = Math.floor(
            sorted.length * tailTrimRatio
          );
          const trimmedSegment = sorted.slice(
            elementsToDropEachSide,
            sorted.length - elementsToDropEachSide
          );
          monitored = trimmedSegment.reduce((a, b) => a + b, 0) / (trimmedSegment.length || 1);
        } else if (movingAverageType === "wma") {
          let linearWeightSum = 0;
          let linearWeightedAccumulator = 0;
          for (let li = 0; li < recentArr.length; li++) {
            const weight = li + 1;
            linearWeightSum += weight;
            linearWeightedAccumulator += weight * recentArr[li];
          }
          monitored = linearWeightedAccumulator / (linearWeightSum || 1);
        } else {
          monitored = recentArr.reduce((a, b) => a + b, 0) / recentArr.length;
        }
      }
      finalError = monitored;
      plateauPush(trainError);
      let plateauError = trainError;
      if (plateauWindow > 1 || plateauType === "ema") {
        if (plateauType === "median") {
          const sorted = [...plateauChrono()].sort((a, b) => a - b);
          const mid = Math.floor(sorted.length / 2);
          plateauError = sorted.length % 2 ? sorted[mid] : (sorted[mid - 1] + sorted[mid]) / 2;
        } else if (plateauType === "ema") {
          if (plateauEmaValue == null) plateauEmaValue = trainError;
          else
            plateauEmaValue = plateauEmaValue + plateauEmaAlpha * (trainError - plateauEmaValue);
          plateauError = plateauEmaValue;
        } else {
          const arr = plateauChrono();
          plateauError = arr.reduce((a, b) => a + b, 0) / arr.length;
        }
      }
      if (typeof options.metricsHook === "function") {
        try {
          options.metricsHook({
            iteration: iter,
            error: finalError,
            plateauError,
            gradNorm: internalNet._lastGradNorm ?? 0
          });
        } catch {
        }
      }
      if (options.checkpoint && typeof options.checkpoint.save === "function") {
        if (options.checkpoint.last) {
          try {
            options.checkpoint.save({
              type: "last",
              iteration: iter,
              error: finalError,
              network: net.toJSON()
            });
          } catch {
          }
        }
        if (options.checkpoint.best) {
          if (finalError < net._checkpointBestError || net._checkpointBestError == null) {
            net._checkpointBestError = finalError;
            try {
              options.checkpoint.save({
                type: "best",
                iteration: iter,
                error: finalError,
                network: net.toJSON()
              });
            } catch {
            }
          }
        }
      }
      if (options.schedule && options.schedule.iterations && iter % options.schedule.iterations === 0) {
        try {
          options.schedule.function({ error: finalError, iteration: iter });
        } catch {
        }
      }
      if (finalError < bestError - earlyStopMinDelta) {
        bestError = finalError;
        noImproveCount = 0;
      } else if (earlyStopPatience) {
        noImproveCount++;
      }
      if (earlyStopPatience && noImproveCount >= earlyStopPatience) break;
      if (finalError <= targetError) break;
    }
    net.nodes.forEach((n) => {
      if (n.type === "hidden") n.mask = 1;
    });
    net.dropout = 0;
    internalNet._globalEpoch = (internalNet._globalEpoch || 0) + performedIterations;
    return {
      /** Final monitored (possibly smoothed) error achieved at termination. */
      error: finalError,
      /** Number of iterations actually executed (could be < requested iterations due to early stop). */
      iterations: performedIterations,
      /** Wall-clock training duration in milliseconds. */
      time: Date.now() - start2
    };
  }
  var __trainingInternals;
  var init_network_training = __esm({
    "src/architecture/network/network.training.ts"() {
      "use strict";
      init_methods();
      init_config();
      __trainingInternals = {
        computeMonitoredError,
        computePlateauMetric
      };
    }
  });

  // src/architecture/network/network.evolve.ts
  var network_evolve_exports = {};
  __export(network_evolve_exports, {
    evolveNetwork: () => evolveNetwork
  });
  function computeComplexityPenalty(genome, growth) {
    const n = genome.nodes.length;
    const c = genome.connections.length;
    const g = genome.gates.length;
    const cached = _complexityCache.get(genome);
    if (cached && cached.nodes === n && cached.conns === c && cached.gates === g)
      return cached.value * growth;
    const base = n - genome.input - genome.output + c + g;
    _complexityCache.set(genome, { nodes: n, conns: c, gates: g, value: base });
    return base * growth;
  }
  function buildSingleThreadFitness(set, cost, amount, growth) {
    return (genome) => {
      let score = 0;
      for (let i = 0; i < amount; i++) {
        try {
          score -= genome.test(set, cost).error;
        } catch (e) {
          if (config.warnings)
            console.warn(
              `Genome evaluation failed: ${e && e.message || e}. Penalizing with -Infinity fitness.`
            );
          return -Infinity;
        }
      }
      score -= computeComplexityPenalty(genome, growth);
      score = isNaN(score) ? -Infinity : score;
      return score / amount;
    };
  }
  async function buildMultiThreadFitness(set, cost, amount, growth, threads, options) {
    const serializedSet = Multi.serializeDataSet(set);
    const workers = [];
    let WorkerCtor = null;
    try {
      const isNode = typeof process !== "undefined" && !!process.versions?.node;
      if (isNode && Multi.workers?.getNodeTestWorker)
        WorkerCtor = await Multi.workers.getNodeTestWorker();
      else if (!isNode && Multi.workers?.getBrowserTestWorker)
        WorkerCtor = await Multi.workers.getBrowserTestWorker();
    } catch (e) {
      if (config.warnings)
        console.warn(
          "Failed to load worker class; falling back to single-thread path:",
          e?.message || e
        );
    }
    if (!WorkerCtor)
      return {
        fitnessFunction: buildSingleThreadFitness(set, cost, amount, growth),
        threads: 1
      };
    for (let i = 0; i < threads; i++) {
      try {
        workers.push(
          new WorkerCtor(serializedSet, {
            name: cost.name || cost.toString?.() || "cost"
          })
        );
      } catch (e) {
        if (config.warnings) console.warn("Worker spawn failed", e);
      }
    }
    const fitnessFunction = (population) => new Promise((resolve) => {
      if (!workers.length) {
        resolve();
        return;
      }
      const queue = population.slice();
      let active = workers.length;
      const startNext = (worker) => {
        if (!queue.length) {
          if (--active === 0) resolve();
          return;
        }
        const genome = queue.shift();
        worker.evaluate(genome).then((result) => {
          if (typeof genome !== "undefined" && typeof result === "number") {
            genome.score = -result - computeComplexityPenalty(genome, growth);
            genome.score = isNaN(result) ? -Infinity : genome.score;
          }
          startNext(worker);
        }).catch(() => startNext(worker));
      };
      workers.forEach((w) => startNext(w));
    });
    options.fitnessPopulation = true;
    options._workerTerminators = () => {
      workers.forEach((w) => {
        try {
          w.terminate && w.terminate();
        } catch {
        }
      });
    };
    return { fitnessFunction, threads };
  }
  async function evolveNetwork(set, options) {
    if (!set || set.length === 0 || set[0].input.length !== this.input || set[0].output.length !== this.output) {
      throw new Error(
        "Dataset is invalid or dimensions do not match network input/output size!"
      );
    }
    options = options || {};
    let targetError = options.error ?? 0.05;
    const growth = options.growth ?? 1e-4;
    const cost = options.cost || Cost.mse;
    const amount = options.amount || 1;
    const log = options.log || 0;
    const schedule = options.schedule;
    const clear = options.clear || false;
    let threads = typeof options.threads === "undefined" ? 1 : options.threads;
    const start2 = Date.now();
    const evoConfig = {
      targetError,
      growth,
      cost,
      amount,
      log,
      schedule,
      clear,
      threads
    };
    if (typeof options.iterations === "undefined" && typeof options.error === "undefined") {
      throw new Error(
        "At least one stopping condition (`iterations` or `error`) must be specified for evolution."
      );
    } else if (typeof options.error === "undefined") targetError = -1;
    else if (typeof options.iterations === "undefined") options.iterations = 0;
    let fitnessFunction;
    if (threads === 1)
      fitnessFunction = buildSingleThreadFitness(set, cost, amount, growth);
    else {
      const multi = await buildMultiThreadFitness(
        set,
        cost,
        amount,
        growth,
        threads,
        options
      );
      fitnessFunction = multi.fitnessFunction;
      threads = multi.threads;
    }
    options.network = this;
    if (options.populationSize != null && options.popsize == null)
      options.popsize = options.populationSize;
    if (typeof options.speciation === "undefined") options.speciation = false;
    const { default: Neat2 } = await Promise.resolve().then(() => (init_neat(), neat_exports));
    const neat = new Neat2(this.input, this.output, fitnessFunction, options);
    if (typeof options.iterations === "number" && options.iterations === 0) {
      if (neat._warnIfNoBestGenome) {
        try {
          neat._warnIfNoBestGenome();
        } catch {
        }
      }
    }
    if (options.popsize && options.popsize <= 10) {
      neat.options.mutationRate = neat.options.mutationRate ?? 0.5;
      neat.options.mutationAmount = neat.options.mutationAmount ?? 1;
    }
    let error = Infinity;
    let bestFitness = -Infinity;
    let bestGenome;
    let infiniteErrorCount = 0;
    const MAX_INF = 5;
    const iterationsSpecified = typeof options.iterations === "number";
    while ((targetError === -1 || error > targetError) && (!iterationsSpecified || neat.generation < options.iterations)) {
      const fittest = await neat.evolve();
      const fitness = fittest.score ?? -Infinity;
      error = -(fitness - computeComplexityPenalty(fittest, growth)) || Infinity;
      if (fitness > bestFitness) {
        bestFitness = fitness;
        bestGenome = fittest;
      }
      if (!isFinite(error) || isNaN(error)) {
        if (++infiniteErrorCount >= MAX_INF) break;
      } else infiniteErrorCount = 0;
      if (schedule && neat.generation % schedule.iterations === 0) {
        try {
          schedule.function({
            fitness: bestFitness,
            error,
            iteration: neat.generation
          });
        } catch {
        }
      }
    }
    if (typeof bestGenome !== "undefined") {
      this.nodes = bestGenome.nodes;
      this.connections = bestGenome.connections;
      this.selfconns = bestGenome.selfconns;
      this.gates = bestGenome.gates;
      if (clear) this.clear();
    } else if (neat._warnIfNoBestGenome) {
      try {
        neat._warnIfNoBestGenome();
      } catch {
      }
    }
    try {
      options._workerTerminators && options._workerTerminators();
    } catch {
    }
    return { error, iterations: neat.generation, time: Date.now() - start2 };
  }
  var _complexityCache;
  var init_network_evolve = __esm({
    "src/architecture/network/network.evolve.ts"() {
      "use strict";
      init_network();
      init_methods();
      init_config();
      init_multi();
      _complexityCache = /* @__PURE__ */ new WeakMap();
    }
  });

  // src/architecture/network.ts
  var network_exports = {};
  __export(network_exports, {
    default: () => Network3
  });
  var Network3;
  var init_network = __esm({
    "src/architecture/network.ts"() {
      "use strict";
      init_node();
      init_nodePool();
      init_connection();
      init_multi();
      init_methods();
      init_mutation();
      init_config();
      init_activationArrayPool();
      init_onnx();
      init_network_standalone();
      init_network_topology();
      init_network_slab();
      init_network_prune();
      init_network_gating();
      init_network_deterministic();
      init_network_stats();
      init_network_remove();
      init_network_connect();
      init_network_serialize();
      init_network_genetic();
      Network3 = class _Network {
        input;
        output;
        score;
        nodes;
        connections;
        gates;
        selfconns;
        dropout = 0;
        _dropConnectProb = 0;
        _lastGradNorm;
        _optimizerStep = 0;
        _weightNoiseStd = 0;
        _weightNoisePerHidden = [];
        _weightNoiseSchedule;
        _stochasticDepth = [];
        _wnOrig;
        _trainingStep = 0;
        _rand = Math.random;
        _rngState;
        _lastStats = null;
        _stochasticDepthSchedule;
        _mixedPrecision = {
          enabled: false,
          lossScale: 1
        };
        _mixedPrecisionState = {
          goodSteps: 0,
          badSteps: 0,
          minLossScale: 1,
          maxLossScale: 65536,
          overflowCount: 0,
          scaleUpEvents: 0,
          scaleDownEvents: 0
        };
        _gradAccumMicroBatches = 0;
        _currentGradClip;
        _lastRawGradNorm = 0;
        _accumulationReduction = "average";
        _gradClipSeparateBias = false;
        _lastGradClipGroupCount = 0;
        _lastOverflowStep = -1;
        _forceNextOverflow = false;
        _pruningConfig;
        _initialConnectionCount;
        _enforceAcyclic = false;
        _topoOrder = null;
        _topoDirty = true;
        _globalEpoch = 0;
        layers;
        _evoInitialConnCount;
        // baseline for evolution-time pruning
        _activationPrecision = "f64";
        // typed array precision for compiled path
        _reuseActivationArrays = false;
        // reuse pooled output arrays
        _returnTypedActivations = false;
        // if true and reuse enabled, return typed array directly
        _activationPool;
        // pooled output array
        // Packed connection slab fields (for memory + cache efficiency when iterating connections)
        _connWeights;
        _connFrom;
        _connTo;
        _slabDirty = true;
        _useFloat32Weights = true;
        // Cached node.index maintenance (avoids repeated this.nodes.indexOf in hot paths like slab rebuild)
        _nodeIndexDirty = true;
        // when true, node.index values must be reassigned sequentially
        // Fast slab forward path structures
        _outStart;
        _outOrder;
        _adjDirty = true;
        // Cached typed arrays for fast slab forward pass
        _fastA;
        _fastS;
        // Internal hint: track a preferred linear chain edge to split on subsequent ADD_NODE mutations
        // to encourage deep path formation even in stochastic modes. Updated each time we split it.
        _preferredChainEdge;
        // Slab helpers delegated to network.slab.ts
        _canUseFastSlab(training) {
          return canUseFastSlab.call(this, training);
        }
        _fastSlabActivate(input) {
          return fastSlabActivate.call(this, input);
        }
        rebuildConnectionSlab(force = false) {
          return rebuildConnectionSlab.call(this, force);
        }
        getConnectionSlab() {
          return getConnectionSlab.call(this);
        }
        /**
         * Public wrapper for fast slab forward pass (primarily for tests / benchmarking).
         * Prefer using standard activate(); it will auto dispatch when eligible.
         * Falls back internally if prerequisites not met.
         */
        fastSlabActivate(input) {
          return this._fastSlabActivate(input);
        }
        constructor(input, output, options) {
          if (typeof input === "undefined" || typeof output === "undefined") {
            throw new Error("No input or output size given");
          }
          this.input = input;
          this.output = output;
          this.nodes = [];
          this.connections = [];
          this.gates = [];
          this.selfconns = [];
          this.dropout = 0;
          this._enforceAcyclic = options?.enforceAcyclic || false;
          if (options?.activationPrecision) {
            this._activationPrecision = options.activationPrecision;
          } else if (config.float32Mode) {
            this._activationPrecision = "f32";
          }
          if (options?.reuseActivationArrays) this._reuseActivationArrays = true;
          if (options?.returnTypedActivations) this._returnTypedActivations = true;
          try {
            if (typeof config.poolMaxPerBucket === "number")
              activationArrayPool.setMaxPerBucket(config.poolMaxPerBucket);
            const prewarm = typeof config.poolPrewarmCount === "number" ? config.poolPrewarmCount : 2;
            activationArrayPool.prewarm(this.output, prewarm);
          } catch {
          }
          if (options?.seed !== void 0) {
            this.setSeed(options.seed);
          }
          for (let i = 0; i < this.input + this.output; i++) {
            const type = i < this.input ? "input" : "output";
            if (config.enableNodePooling)
              this.nodes.push(acquireNode({ type, rng: this._rand }));
            else this.nodes.push(new Node2(type, void 0, this._rand));
          }
          for (let i = 0; i < this.input; i++) {
            for (let j = this.input; j < this.input + this.output; j++) {
              const weight = this._rand() * this.input * Math.sqrt(2 / this.input);
              this.connect(this.nodes[i], this.nodes[j], weight);
            }
          }
          const minHidden = options?.minHidden || 0;
          if (minHidden > 0) {
            while (this.nodes.length < this.input + this.output + minHidden) {
              this.addNodeBetween();
            }
          }
        }
        // --- Changed: made public (was private) for deterministic pooling stress harness ---
        addNodeBetween() {
          if (this.connections.length === 0) return;
          const idx = Math.floor(this._rand() * this.connections.length);
          const conn = this.connections[idx];
          if (!conn) return;
          this.disconnect(conn.from, conn.to);
          const newNode = config.enableNodePooling ? acquireNode({ type: "hidden", rng: this._rand }) : new Node2("hidden", void 0, this._rand);
          this.nodes.push(newNode);
          this.connect(conn.from, newNode, conn.weight);
          this.connect(newNode, conn.to, 1);
          this._topoDirty = true;
          this._nodeIndexDirty = true;
        }
        // --- DropConnect API (re-added for tests) ---
        enableDropConnect(p) {
          if (p < 0 || p >= 1)
            throw new Error("DropConnect probability must be in [0,1)");
          this._dropConnectProb = p;
        }
        disableDropConnect() {
          this._dropConnectProb = 0;
        }
        // --- Acyclic enforcement toggle (used by tests) ---
        setEnforceAcyclic(flag) {
          this._enforceAcyclic = !!flag;
        }
        _computeTopoOrder() {
          return computeTopoOrder.call(this);
        }
        _hasPath(from, to) {
          return hasPath.call(this, from, to);
        }
        // --- Pruning configuration & helpers ---
        configurePruning(cfg) {
          const { start: start2, end, targetSparsity } = cfg;
          if (start2 < 0 || end < start2)
            throw new Error("Invalid pruning schedule window");
          if (targetSparsity <= 0 || targetSparsity >= 1)
            throw new Error("targetSparsity must be in (0,1)");
          this._pruningConfig = {
            start: start2,
            end,
            targetSparsity,
            regrowFraction: cfg.regrowFraction ?? 0,
            frequency: cfg.frequency ?? 1,
            method: cfg.method || "magnitude",
            lastPruneIter: void 0
          };
          this._initialConnectionCount = this.connections.length;
        }
        getCurrentSparsity() {
          return getCurrentSparsity.call(this);
        }
        _maybePrune(iteration) {
          return maybePrune.call(this, iteration);
        }
        /**
         * Immediately prune connections to reach (or approach) a target sparsity fraction.
         * Used by evolutionary pruning (generation-based) independent of training iteration schedule.
         * @param targetSparsity fraction in (0,1). 0.8 means keep 20% of original (if first call sets baseline)
         * @param method 'magnitude' | 'snip'
         */
        pruneToSparsity(targetSparsity, method = "magnitude") {
          return pruneToSparsity.call(this, targetSparsity, method);
        }
        /** Enable weight noise. Provide a single std dev number or { perHiddenLayer: number[] }. */
        enableWeightNoise(stdDev) {
          if (typeof stdDev === "number") {
            if (stdDev < 0) throw new Error("Weight noise stdDev must be >= 0");
            this._weightNoiseStd = stdDev;
            this._weightNoisePerHidden = [];
          } else if (stdDev && Array.isArray(stdDev.perHiddenLayer)) {
            if (!this.layers || this.layers.length < 3)
              throw new Error(
                "Per-hidden-layer weight noise requires a layered network with at least one hidden layer"
              );
            const hiddenLayerCount = this.layers.length - 2;
            if (stdDev.perHiddenLayer.length !== hiddenLayerCount)
              throw new Error(
                `Expected ${hiddenLayerCount} std dev entries (one per hidden layer), got ${stdDev.perHiddenLayer.length}`
              );
            if (stdDev.perHiddenLayer.some((s) => s < 0))
              throw new Error("Weight noise std devs must be >= 0");
            this._weightNoiseStd = 0;
            this._weightNoisePerHidden = stdDev.perHiddenLayer.slice();
          } else {
            throw new Error("Invalid weight noise configuration");
          }
        }
        disableWeightNoise() {
          this._weightNoiseStd = 0;
          this._weightNoisePerHidden = [];
        }
        setWeightNoiseSchedule(fn) {
          this._weightNoiseSchedule = fn;
        }
        clearWeightNoiseSchedule() {
          this._weightNoiseSchedule = void 0;
        }
        setRandom(fn) {
          this._rand = fn;
        }
        setSeed(seed) {
          setSeed.call(this, seed);
        }
        testForceOverflow() {
          this._forceNextOverflow = true;
        }
        get trainingStep() {
          return this._trainingStep;
        }
        get lastSkippedLayers() {
          return this._lastSkippedLayers || [];
        }
        snapshotRNG() {
          return snapshotRNG.call(this);
        }
        restoreRNG(fn) {
          restoreRNG.call(this, fn);
        }
        getRNGState() {
          return getRNGState.call(this);
        }
        setRNGState(state) {
          setRNGState.call(this, state);
        }
        setStochasticDepthSchedule(fn) {
          this._stochasticDepthSchedule = fn;
        }
        clearStochasticDepthSchedule() {
          this._stochasticDepthSchedule = void 0;
        }
        getRegularizationStats() {
          return getRegularizationStats.call(this);
        }
        /** Configure stochastic depth with survival probabilities per hidden layer (length must match hidden layer count when using layered network). */
        setStochasticDepth(survival) {
          if (!Array.isArray(survival)) throw new Error("survival must be an array");
          if (survival.some((p) => p <= 0 || p > 1))
            throw new Error("Stochastic depth survival probs must be in (0,1]");
          if (!this.layers || this.layers.length === 0)
            throw new Error("Stochastic depth requires layer-based network");
          const hiddenLayerCount = Math.max(0, this.layers.length - 2);
          if (survival.length !== hiddenLayerCount)
            throw new Error(
              `Expected ${hiddenLayerCount} survival probabilities for hidden layers, got ${survival.length}`
            );
          this._stochasticDepth = survival.slice();
        }
        disableStochasticDepth() {
          this._stochasticDepth = [];
        }
        /**
         * Creates a deep copy of the network.
         * @returns {Network} A new Network instance that is a clone of the current network.
         */
        clone() {
          return _Network.fromJSON(this.toJSON());
        }
        /**
         * Resets all masks in the network to 1 (no dropout). Applies to both node-level and layer-level dropout.
         * Should be called after training to ensure inference is unaffected by previous dropout.
         */
        resetDropoutMasks() {
          if (this.layers && this.layers.length > 0) {
            for (const layer of this.layers) {
              if (typeof layer.nodes !== "undefined") {
                for (const node of layer.nodes) {
                  if (typeof node.mask !== "undefined") node.mask = 1;
                }
              }
            }
          } else {
            for (const node of this.nodes) {
              if (typeof node.mask !== "undefined") node.mask = 1;
            }
          }
        }
        // Delegated standalone generator
        standalone() {
          return generateStandalone(this);
        }
        /**
         * Activates the network using the given input array.
         * Performs a forward pass through the network, calculating the activation of each node.
         *
         * @param {number[]} input - An array of numerical values corresponding to the network's input nodes.
         * @param {boolean} [training=false] - Flag indicating if the activation is part of a training process.
         * @param {number} [maxActivationDepth=1000] - Maximum allowed activation depth to prevent infinite loops/cycles.
         * @returns {number[]} An array of numerical values representing the activations of the network's output nodes.
         */
        /**
         * Standard activation API returning a plain number[] for backward compatibility.
         * Internally may use pooled typed arrays; if so they are cloned before returning.
         */
        activate(input, training = false, maxActivationDepth = 1e3) {
          if (this._enforceAcyclic && this._topoDirty) this._computeTopoOrder();
          if (!Array.isArray(input) || input.length !== this.input) {
            throw new Error(
              `Input size mismatch: expected ${this.input}, got ${input ? input.length : "undefined"}`
            );
          }
          if (this._canUseFastSlab(training)) {
            try {
              return this._fastSlabActivate(input);
            } catch {
            }
          }
          const outputArr = activationArrayPool.acquire(this.output);
          if (!this.nodes || this.nodes.length === 0) {
            throw new Error(
              "Network structure is corrupted or empty. No nodes found."
            );
          }
          let output = outputArr;
          this._lastSkippedLayers = [];
          const stats = {
            droppedHiddenNodes: 0,
            totalHiddenNodes: 0,
            droppedConnections: 0,
            totalConnections: this.connections.length,
            skippedLayers: [],
            weightNoise: { count: 0, sumAbs: 0, maxAbs: 0, meanAbs: 0 }
          };
          let appliedWeightNoise = false;
          let dynamicStd = this._weightNoiseStd;
          if (training) {
            if (this._weightNoiseSchedule)
              dynamicStd = this._weightNoiseSchedule(this._trainingStep);
            if (dynamicStd > 0 || this._weightNoisePerHidden.length > 0) {
              for (const c of this.connections) {
                if (c._origWeightNoise != null) continue;
                c._origWeightNoise = c.weight;
                let std = dynamicStd;
                if (this._weightNoisePerHidden.length > 0 && this.layers) {
                  let fromLayerIndex = -1;
                  for (let li = 0; li < this.layers.length; li++) {
                    if (this.layers[li].nodes.includes(c.from)) {
                      fromLayerIndex = li;
                      break;
                    }
                  }
                  if (fromLayerIndex > 0 && fromLayerIndex < this.layers.length) {
                    const hiddenIdx = fromLayerIndex - 1;
                    if (hiddenIdx >= 0 && hiddenIdx < this._weightNoisePerHidden.length)
                      std = this._weightNoisePerHidden[hiddenIdx];
                  }
                }
                if (std > 0) {
                  const noise = std * _Network._gaussianRand(this._rand);
                  c.weight += noise;
                  c._wnLast = noise;
                  appliedWeightNoise = true;
                } else {
                  c._wnLast = 0;
                }
              }
            }
          }
          if (training && this._stochasticDepthSchedule && this._stochasticDepth.length > 0) {
            const updated = this._stochasticDepthSchedule(
              this._trainingStep,
              this._stochasticDepth.slice()
            );
            if (Array.isArray(updated) && updated.length === this._stochasticDepth.length && !updated.some((p) => p <= 0 || p > 1)) {
              this._stochasticDepth = updated.slice();
            }
          }
          if (this.layers && this.layers.length > 0 && this._stochasticDepth.length > 0) {
            let acts;
            for (let li = 0; li < this.layers.length; li++) {
              const layer = this.layers[li];
              const isHidden = li > 0 && li < this.layers.length - 1;
              let skip = false;
              if (training && isHidden) {
                const hiddenIndex = li - 1;
                if (hiddenIndex < this._stochasticDepth.length) {
                  const surviveProb = this._stochasticDepth[hiddenIndex];
                  skip = this._rand() >= surviveProb;
                  if (skip) {
                    if (!acts || acts.length !== layer.nodes.length) skip = false;
                  }
                  if (!skip) {
                    const raw2 = li === 0 ? layer.activate(input, training) : layer.activate(void 0, training);
                    acts = surviveProb < 1 ? raw2.map((a) => a * (1 / surviveProb)) : raw2;
                    continue;
                  }
                }
              }
              if (skip) {
                this._lastSkippedLayers.push(li);
                stats.skippedLayers.push(li);
                continue;
              }
              const raw = li === 0 ? layer.activate(input, training) : layer.activate(void 0, training);
              acts = raw;
            }
            if (acts) {
              for (let i = 0; i < acts.length && i < this.output; i++)
                output[i] = acts[i];
            }
          } else if (this.layers && this.layers.length > 0) {
            let lastActs;
            for (let li = 0; li < this.layers.length; li++) {
              const layer = this.layers[li];
              const isHidden = li > 0 && li < this.layers.length - 1;
              const raw = li === 0 ? layer.activate(input, false) : layer.activate(void 0, false);
              if (isHidden && training && this.dropout > 0) {
                let dropped = 0;
                for (const node of layer.nodes) {
                  node.mask = this._rand() < this.dropout ? 0 : 1;
                  stats.totalHiddenNodes++;
                  if (node.mask === 0) stats.droppedHiddenNodes++;
                  if (node.mask === 0) {
                    node.activation = 0;
                    dropped++;
                  }
                }
                if (dropped === layer.nodes.length && layer.nodes.length > 0) {
                  const idx = Math.floor(this._rand() * layer.nodes.length);
                  layer.nodes[idx].mask = 1;
                  layer.nodes[idx].activation = raw[idx];
                }
              } else if (isHidden) {
                for (const node of layer.nodes) node.mask = 1;
              }
              lastActs = raw;
            }
            if (lastActs) {
              if (this._reuseActivationArrays) {
                for (let i = 0; i < lastActs.length && i < this.output; i++)
                  output[i] = lastActs[i];
              } else {
                for (let i = 0; i < lastActs.length && i < this.output; i++)
                  output[i] = lastActs[i];
              }
            }
          } else {
            let hiddenNodes = this.nodes.filter((node) => node.type === "hidden");
            let droppedCount = 0;
            if (training && this.dropout > 0) {
              for (const node of hiddenNodes) {
                node.mask = this._rand() < this.dropout ? 0 : 1;
                stats.totalHiddenNodes++;
                if (node.mask === 0) {
                  droppedCount++;
                  stats.droppedHiddenNodes++;
                }
              }
              if (droppedCount === hiddenNodes.length && hiddenNodes.length > 0) {
                const idx = Math.floor(this._rand() * hiddenNodes.length);
                hiddenNodes[idx].mask = 1;
              }
            } else {
              for (const node of hiddenNodes) node.mask = 1;
            }
            if (training && this._weightNoiseStd > 0) {
              if (!this._wnOrig) this._wnOrig = new Array(this.connections.length);
              for (let ci = 0; ci < this.connections.length; ci++) {
                const c = this.connections[ci];
                if (c._origWeightNoise != null) continue;
                c._origWeightNoise = c.weight;
                const noise = this._weightNoiseStd * _Network._gaussianRand(this._rand);
                c.weight += noise;
              }
            }
            let outIndex = 0;
            this.nodes.forEach((node, index) => {
              if (node.type === "input") {
                node.activate(input[index]);
              } else if (node.type === "output") {
                const activation = node.activate();
                output[outIndex++] = activation;
              } else {
                node.activate();
              }
            });
            if (training && this._dropConnectProb > 0) {
              for (const conn of this.connections) {
                const mask = this._rand() < this._dropConnectProb ? 0 : 1;
                if (mask === 0) stats.droppedConnections++;
                conn.dcMask = mask;
                if (mask === 0) {
                  if (conn._origWeight == null)
                    conn._origWeight = conn.weight;
                  conn.weight = 0;
                } else if (conn._origWeight != null) {
                  conn.weight = conn._origWeight;
                  delete conn._origWeight;
                }
              }
            } else {
              for (const conn of this.connections) {
                if (conn._origWeight != null) {
                  conn.weight = conn._origWeight;
                  delete conn._origWeight;
                }
                conn.dcMask = 1;
              }
            }
            if (training && appliedWeightNoise) {
              for (const c of this.connections) {
                if (c._origWeightNoise != null) {
                  c.weight = c._origWeightNoise;
                  delete c._origWeightNoise;
                }
              }
            }
          }
          if (training) this._trainingStep++;
          if (stats.weightNoise.count > 0)
            stats.weightNoise.meanAbs = stats.weightNoise.sumAbs / stats.weightNoise.count;
          this._lastStats = stats;
          const result = Array.from(output);
          activationArrayPool.release(output);
          return result;
        }
        static _gaussianRand(rng = Math.random) {
          let u = 0, v = 0;
          while (u === 0) u = rng();
          while (v === 0) v = rng();
          return Math.sqrt(-2 * Math.log(u)) * Math.cos(2 * Math.PI * v);
        }
        /**
         * Activates the network without calculating eligibility traces.
         * This is a performance optimization for scenarios where backpropagation is not needed,
         * such as during testing, evaluation, or deployment (inference).
         *
         * @param {number[]} input - An array of numerical values corresponding to the network's input nodes.
         *                           The length must match the network's `input` size.
         * @returns {number[]} An array of numerical values representing the activations of the network's output nodes.
         *
         * @see {@link Node.noTraceActivate}
         */
        // Delegated activation helpers
        noTraceActivate(input) {
          const { noTraceActivate: noTraceActivate2 } = (init_network_activate(), __toCommonJS(network_activate_exports));
          return noTraceActivate2.call(this, input);
        }
        /**
         * Raw activation that can return a typed array when pooling is enabled (zero-copy).
         * If reuseActivationArrays=false falls back to standard activate().
         */
        activateRaw(input, training = false, maxActivationDepth = 1e3) {
          const { activateRaw: activateRaw2 } = (init_network_activate(), __toCommonJS(network_activate_exports));
          return activateRaw2.call(this, input, training, maxActivationDepth);
        }
        /**
         * Activate the network over a batch of input vectors (micro-batching).
         *
         * Currently iterates sample-by-sample while reusing the network's internal
         * fast-path allocations. Outputs are cloned number[] arrays for API
         * compatibility. Future optimizations can vectorize this path.
         *
         * @param inputs Array of input vectors, each length must equal this.input
         * @param training Whether to run with training-time stochastic features
         * @returns Array of output vectors, each length equals this.output
         */
        activateBatch(inputs, training = false) {
          const { activateBatch: activateBatch2 } = (init_network_activate(), __toCommonJS(network_activate_exports));
          return activateBatch2.call(this, inputs, training);
        }
        /**
         * Propagates the error backward through the network (backpropagation).
         * Calculates the error gradient for each node and connection.
         * If `update` is true, it adjusts the weights and biases based on the calculated gradients,
         * learning rate, momentum, and optional L2 regularization.
         *
         * The process starts from the output nodes and moves backward layer by layer (or topologically for recurrent nets).
         *
         * @param {number} rate - The learning rate (controls the step size of weight adjustments).
         * @param {number} momentum - The momentum factor (helps overcome local minima and speeds up convergence). Typically between 0 and 1.
         * @param {boolean} update - If true, apply the calculated weight and bias updates. If false, only calculate gradients (e.g., for batch accumulation).
         * @param {number[]} target - An array of target values corresponding to the network's output nodes.
         *                            The length must match the network's `output` size.
         * @param {number} [regularization=0] - The L2 regularization factor (lambda). Helps prevent overfitting by penalizing large weights.
         * @param {(target: number, output: number) => number} [costDerivative] - Optional derivative of the cost function for output nodes.
         * @throws {Error} If the `target` array length does not match the network's `output` size.
         *
         * @see {@link Node.propagate} for the node-level backpropagation logic.
         */
        propagate(rate, momentum, update, target, regularization = 0, costDerivative) {
          if (!target || target.length !== this.output) {
            throw new Error(
              "Output target length should match network output length"
            );
          }
          let targetIndex = target.length;
          for (let i = this.nodes.length - 1; i >= this.nodes.length - this.output; i--) {
            if (costDerivative) {
              this.nodes[i].propagate(
                rate,
                momentum,
                update,
                regularization,
                target[--targetIndex],
                costDerivative
              );
            } else {
              this.nodes[i].propagate(
                rate,
                momentum,
                update,
                regularization,
                target[--targetIndex]
              );
            }
          }
          for (let i = this.nodes.length - this.output - 1; i >= this.input; i--) {
            this.nodes[i].propagate(rate, momentum, update, regularization);
          }
        }
        /**
         * Clears the internal state of all nodes in the network.
         * Resets node activation, state, eligibility traces, and extended traces to their initial values (usually 0).
         * This is typically done before processing a new input sequence in recurrent networks or between training epochs if desired.
         *
         * @see {@link Node.clear}
         */
        clear() {
          this.nodes.forEach((node) => node.clear());
        }
        /**
         * Mutates the network's structure or parameters according to the specified method.
         * This is a core operation for neuro-evolutionary algorithms (like NEAT).
         * The method argument should be one of the mutation types defined in `methods.mutation`.
         *
         * @param {any} method - The mutation method to apply (e.g., `mutation.ADD_NODE`, `mutation.MOD_WEIGHT`).
         *                       Some methods might have associated parameters (e.g., `MOD_WEIGHT` uses `min`, `max`).
         * @throws {Error} If no valid mutation `method` is provided.
         *
         * @see {@link methods.mutation} for available mutation types.
         */
        mutate(method) {
          const { mutateImpl: mutateImpl2 } = (init_network_mutate(), __toCommonJS(network_mutate_exports));
          return mutateImpl2.call(this, method);
        }
        /**
         * Creates a connection between two nodes in the network.
         * Handles both regular connections and self-connections.
         * Adds the new connection object(s) to the appropriate network list (`connections` or `selfconns`).
         *
         * @param {Node} from - The source node of the connection.
         * @param {Node} to - The target node of the connection.
         * @param {number} [weight] - Optional weight for the connection. If not provided, a random weight is usually assigned by the underlying `Node.connect` method.
         * @returns {Connection[]} An array containing the newly created connection object(s). Typically contains one connection, but might be empty or contain more in specialized node types.
         *
         * @see {@link Node.connect}
         */
        connect(from, to, weight) {
          return connect.call(this, from, to, weight);
        }
        /**
         * Gates a connection with a specified node.
         * The activation of the `node` (gater) will modulate the weight of the `connection`.
         * Adds the connection to the network's `gates` list.
         *
         * @param {Node} node - The node that will act as the gater. Must be part of this network.
         * @param {Connection} connection - The connection to be gated.
         * @throws {Error} If the provided `node` is not part of this network.
         * @throws {Error} If the `connection` is already gated (though currently handled with a warning).
         *
         * @see {@link Node.gate}
         */
        gate(node, connection) {
          return gate.call(this, node, connection);
        }
        /**
         * Removes a node from the network.
         * This involves:
         * 1. Disconnecting all incoming and outgoing connections associated with the node.
         * 2. Removing any self-connections.
         * 3. Removing the node from the `nodes` array.
         * 4. Attempting to reconnect the node's direct predecessors to its direct successors
         *    to maintain network flow, if possible and configured.
         * 5. Handling gates involving the removed node (ungating connections gated *by* this node,
         *    and potentially re-gating connections that were gated *by other nodes* onto the removed node's connections).
         *
         * @param {Node} node - The node instance to remove. Must exist within the network's `nodes` list.
         * @throws {Error} If the specified `node` is not found in the network's `nodes` list.
         */
        remove(node) {
          const result = removeNode.call(this, node);
          if (config.enableNodePooling) {
            try {
              releaseNode(node);
            } catch {
            }
          }
          return result;
        }
        /**
         * Disconnects two nodes, removing the connection between them.
         * Handles both regular connections and self-connections.
         * If the connection being removed was gated, it is also ungated.
         *
         * @param {Node} from - The source node of the connection to remove.
         * @param {Node} to - The target node of the connection to remove.
         *
         * @see {@link Node.disconnect}
         */
        disconnect(from, to) {
          return disconnect.call(this, from, to);
        }
        // slab rebuild + accessor moved to network.slab.ts
        /**
         * Removes the gate from a specified connection.
         * The connection will no longer be modulated by its gater node.
         * Removes the connection from the network's `gates` list.
         *
         * @param {Connection} connection - The connection object to ungate.
         * @throws {Error} If the provided `connection` is not found in the network's `gates` list (i.e., it wasn't gated).
         *
         * @see {@link Node.ungate}
         */
        ungate(connection) {
          return ungate.call(this, connection);
        }
        /**
         * Trains the network on a given dataset subset for one pass (epoch or batch).
         * Performs activation and backpropagation for each item in the set.
         * Updates weights based on batch size configuration.
         *
         * @param {{ input: number[]; output: number[] }[]} set - The training dataset subset (e.g., a batch or the full set for one epoch).
         * @param {number} batchSize - The number of samples to process before updating weights.
         * @param {number} currentRate - The learning rate to use for this training pass.
         * @param {number} momentum - The momentum factor to use.
         * @param {any} regularization - The regularization configuration (L1, L2, or custom function).
         * @param {(target: number[], output: number[]) => number} costFunction - The function used to calculate the error between target and output.
         * @returns {number} The average error calculated over the provided dataset subset.
         * @private Internal method used by `train`.
         */
        _applyGradientClipping(cfg) {
          const { applyGradientClippingImpl: applyGradientClippingImpl2 } = (init_network_training(), __toCommonJS(network_training_exports));
          applyGradientClippingImpl2(this, cfg);
        }
        // Training is implemented in network.training.ts; this wrapper keeps public API stable.
        train(set, options) {
          const { trainImpl: trainImpl2 } = (init_network_training(), __toCommonJS(network_training_exports));
          return trainImpl2(this, set, options);
        }
        /** Returns last recorded raw (pre-update) gradient L2 norm. */
        getRawGradientNorm() {
          return this._lastRawGradNorm;
        }
        /** Returns current mixed precision loss scale (1 if disabled). */
        getLossScale() {
          return this._mixedPrecision.lossScale;
        }
        /** Returns last gradient clipping group count (0 if no clipping yet). */
        getLastGradClipGroupCount() {
          return this._lastGradClipGroupCount;
        }
        /** Consolidated training stats snapshot. */
        getTrainingStats() {
          return {
            gradNorm: this._lastGradNorm ?? 0,
            gradNormRaw: this._lastRawGradNorm,
            lossScale: this._mixedPrecision.lossScale,
            optimizerStep: this._optimizerStep,
            mp: {
              good: this._mixedPrecisionState.goodSteps,
              bad: this._mixedPrecisionState.badSteps,
              overflowCount: this._mixedPrecisionState.overflowCount || 0,
              scaleUps: this._mixedPrecisionState.scaleUpEvents || 0,
              scaleDowns: this._mixedPrecisionState.scaleDownEvents || 0,
              lastOverflowStep: this._lastOverflowStep
            }
          };
        }
        /** Utility: adjust rate for accumulation mode (use result when switching to 'sum' to mimic 'average'). */
        static adjustRateForAccumulation(rate, accumulationSteps, reduction) {
          if (reduction === "sum" && accumulationSteps > 1)
            return rate / accumulationSteps;
          return rate;
        }
        // Evolution wrapper delegates to network/network.evolve.ts implementation.
        async evolve(set, options) {
          const { evolveNetwork: evolveNetwork2 } = await Promise.resolve().then(() => (init_network_evolve(), network_evolve_exports));
          return evolveNetwork2.call(this, set, options);
        }
        /**
         * Tests the network's performance on a given dataset.
         * Calculates the average error over the dataset using a specified cost function.
         * Uses `noTraceActivate` for efficiency as gradients are not needed.
         * Handles dropout scaling if dropout was used during training.
         *
         * @param {{ input: number[]; output: number[] }[]} set - The test dataset, an array of objects with `input` and `output` arrays.
         * @param {function} [cost=methods.Cost.MSE] - The cost function to evaluate the error. Defaults to Mean Squared Error.
         * @returns {{ error: number; time: number }} An object containing the calculated average error over the dataset and the time taken for the test in milliseconds.
         */
        test(set, cost) {
          if (!Array.isArray(set) || set.length === 0) {
            throw new Error("Test set is empty or not an array.");
          }
          for (const sample of set) {
            if (!Array.isArray(sample.input) || sample.input.length !== this.input) {
              throw new Error(
                `Test sample input size mismatch: expected ${this.input}, got ${sample.input ? sample.input.length : "undefined"}`
              );
            }
            if (!Array.isArray(sample.output) || sample.output.length !== this.output) {
              throw new Error(
                `Test sample output size mismatch: expected ${this.output}, got ${sample.output ? sample.output.length : "undefined"}`
              );
            }
          }
          let error = 0;
          const costFn = cost || Cost.mse;
          const start2 = Date.now();
          this.nodes.forEach((node) => {
            if (node.type === "hidden") node.mask = 1;
          });
          const previousDropout = this.dropout;
          if (this.dropout > 0) {
            this.dropout = 0;
          }
          set.forEach((data) => {
            const output = this.noTraceActivate(data.input);
            error += costFn(data.output, output);
          });
          this.dropout = previousDropout;
          return { error: error / set.length, time: Date.now() - start2 };
        }
        /** Lightweight tuple serializer delegating to network.serialize.ts */
        serialize() {
          return serialize.call(this);
        }
        /**
         * Creates a Network instance from serialized data produced by `serialize()`.
         * Reconstructs the network structure and state based on the provided arrays.
         *
         * @param {any[]} data - The serialized network data array, typically obtained from `network.serialize()`.
         *                       Expected format: `[activations, states, squashNames, connectionData, inputSize, outputSize]`.
         * @param {number} [inputSize] - Optional input size override.
         * @param {number} [outputSize] - Optional output size override.
         * @returns {Network} A new Network instance reconstructed from the serialized data.
         * @static
         */
        /** Static lightweight tuple deserializer delegate */
        static deserialize(data, inputSize, outputSize) {
          return deserialize(data, inputSize, outputSize);
        }
        /**
         * Converts the network into a JSON object representation (latest standard).
         * Includes formatVersion, and only serializes properties needed for full reconstruction.
         * All references are by index. Excludes runtime-only properties (activation, state, traces).
         *
         * @returns {object} A JSON-compatible object representing the network.
         */
        /** Verbose JSON serializer delegate */
        toJSON() {
          return toJSONImpl.call(this);
        }
        /**
         * Reconstructs a network from a JSON object (latest standard).
         * Handles formatVersion, robust error handling, and index-based references.
         * @param {object} json - The JSON object representing the network.
         * @returns {Network} The reconstructed network.
         */
        /** Verbose JSON static deserializer */
        static fromJSON(json) {
          return fromJSONImpl(json);
        }
        /**
         * Creates a new offspring network by performing crossover between two parent networks.
         * This method implements the crossover mechanism inspired by the NEAT algorithm and described
         * in the Instinct paper, combining genes (nodes and connections) from both parents.
         * Fitness scores can influence the inheritance process. Matching genes are inherited randomly,
         * while disjoint/excess genes are typically inherited from the fitter parent (or randomly if fitness is equal or `equal` flag is set).
         *
         * @param {Network} network1 - The first parent network.
         * @param {Network} network2 - The second parent network.
         * @param {boolean} [equal=false] - If true, disjoint and excess genes are inherited randomly regardless of fitness.
         *                                  If false (default), they are inherited from the fitter parent.
         * @returns {Network} A new Network instance representing the offspring.
         * @throws {Error} If the input or output sizes of the parent networks do not match.
         *
         * @see Instinct Algorithm - Section 2 Crossover
         * @see {@link https://medium.com/data-science/neuro-evolution-on-steroids-82bd14ddc2f6}
         * @static
         */
        /** NEAT-style crossover delegate. */
        static crossOver(network1, network2, equal = false) {
          return crossOver(network1, network2, equal);
        }
        /**
         * Sets specified properties (e.g., bias, squash function) for all nodes in the network.
         * Useful for initializing or resetting node properties uniformly.
         *
         * @param {object} values - An object containing the properties and values to set.
         * @param {number} [values.bias] - If provided, sets the bias for all nodes.
         * @param {function} [values.squash] - If provided, sets the squash (activation) function for all nodes.
         *                                     Should be a valid activation function (e.g., from `methods.Activation`).
         */
        set(values) {
          this.nodes.forEach((node) => {
            if (typeof values.bias !== "undefined") {
              node.bias = values.bias;
            }
            if (typeof values.squash !== "undefined") {
              node.squash = values.squash;
            }
          });
        }
        /**
         * Exports the network to ONNX format (JSON object, minimal MLP support).
         * Only standard feedforward architectures and standard activations are supported.
         * Gating, custom activations, and evolutionary features are ignored or replaced with Identity.
         *
         * @returns {import('./onnx').OnnxModel} ONNX model as a JSON object.
         */
        toONNX() {
          return exportToONNX(this);
        }
        /**
         * Creates a fully connected, strictly layered MLP network.
         * @param {number} inputCount - Number of input nodes
         * @param {number[]} hiddenCounts - Array of hidden layer sizes (e.g. [2,3] for two hidden layers)
         * @param {number} outputCount - Number of output nodes
         * @returns {Network} A new, fully connected, layered MLP
         */
        static createMLP(inputCount, hiddenCounts, outputCount) {
          const inputNodes = Array.from(
            { length: inputCount },
            () => new Node2("input")
          );
          const hiddenLayers = hiddenCounts.map(
            (count) => Array.from({ length: count }, () => new Node2("hidden"))
          );
          const outputNodes = Array.from(
            { length: outputCount },
            () => new Node2("output")
          );
          const allNodes = [...inputNodes, ...hiddenLayers.flat(), ...outputNodes];
          const net = new _Network(inputCount, outputCount);
          net.nodes = allNodes;
          let prevLayer = inputNodes;
          for (const layer of hiddenLayers) {
            for (const to of layer) {
              for (const from of prevLayer) {
                from.connect(to);
              }
            }
            prevLayer = layer;
          }
          for (const to of outputNodes) {
            for (const from of prevLayer) {
              from.connect(to);
            }
          }
          net.connections = net.nodes.flatMap((n) => n.connections.out);
          net._topoDirty = true;
          return net;
        }
        /**
         * Rebuilds the network's connections array from all per-node connections.
         * This ensures that the network.connections array is consistent with the actual
         * outgoing connections of all nodes. Useful after manual wiring or node manipulation.
         *
         * @param {Network} net - The network instance to rebuild connections for.
         * @returns {void}
         *
         * Example usage:
         *   Network.rebuildConnections(net);
         */
        static rebuildConnections(net) {
          const allConnections = /* @__PURE__ */ new Set();
          net.nodes.forEach((node) => {
            node.connections.out.forEach((conn) => {
              allConnections.add(conn);
            });
          });
          net.connections = Array.from(allConnections);
        }
      };
    }
  });

  // src/neat/neat.mutation.ts
  function mutate() {
    const methods = (init_methods(), __toCommonJS(methods_exports));
    for (const genome of this.population) {
      if (this.options.adaptiveMutation?.enabled) {
        if (genome._mutRate === void 0) {
          genome._mutRate = this.options.mutationRate !== void 0 ? this.options.mutationRate : this.options.adaptiveMutation.initialRate ?? (this.options.mutationRate || 0.7);
          if (this.options.adaptiveMutation.adaptAmount)
            genome._mutAmount = this.options.mutationAmount || 1;
        }
      }
      const effectiveRate = this.options.mutationRate !== void 0 ? this.options.mutationRate : this.options.adaptiveMutation?.enabled ? genome._mutRate : this.options.mutationRate || 0.7;
      const effectiveAmount = this.options.adaptiveMutation?.enabled && this.options.adaptiveMutation.adaptAmount ? genome._mutAmount ?? (this.options.mutationAmount || 1) : this.options.mutationAmount || 1;
      if (this._getRNG()() <= effectiveRate) {
        for (let iteration = 0; iteration < effectiveAmount; iteration++) {
          let mutationMethod = this.selectMutationMethod(genome, false);
          if (Array.isArray(mutationMethod)) {
            const operatorArray = mutationMethod;
            mutationMethod = operatorArray[Math.floor(this._getRNG()() * operatorArray.length)];
          }
          if (mutationMethod && mutationMethod.name) {
            const beforeNodes = genome.nodes.length;
            const beforeConns = genome.connections.length;
            if (mutationMethod === methods.mutation.ADD_NODE) {
              this._mutateAddNodeReuse(genome);
              try {
                genome.mutate(methods.mutation.MOD_WEIGHT);
              } catch {
              }
              this._invalidateGenomeCaches(genome);
            } else if (mutationMethod === methods.mutation.ADD_CONN) {
              this._mutateAddConnReuse(genome);
              try {
                genome.mutate(methods.mutation.MOD_WEIGHT);
              } catch {
              }
              this._invalidateGenomeCaches(genome);
            } else {
              genome.mutate(mutationMethod);
              if (mutationMethod === methods.mutation.ADD_GATE || mutationMethod === methods.mutation.SUB_NODE || mutationMethod === methods.mutation.SUB_CONN || mutationMethod === methods.mutation.ADD_SELF_CONN || mutationMethod === methods.mutation.ADD_BACK_CONN) {
                this._invalidateGenomeCaches(genome);
              }
            }
            if (this._getRNG()() < EXTRA_CONNECTION_PROBABILITY)
              this._mutateAddConnReuse(genome);
            if (this.options.operatorAdaptation?.enabled) {
              const statsRecord = this._operatorStats.get(
                mutationMethod.name
              ) || {
                success: 0,
                attempts: 0
              };
              statsRecord.attempts++;
              const afterNodes = genome.nodes.length;
              const afterConns = genome.connections.length;
              if (afterNodes > beforeNodes || afterConns > beforeConns)
                statsRecord.success++;
              this._operatorStats.set(mutationMethod.name, statsRecord);
            }
          }
        }
      }
    }
  }
  function mutateAddNodeReuse(genome) {
    if (genome.connections.length === 0) {
      const inputNode = genome.nodes.find((n) => n.type === "input");
      const outputNode = genome.nodes.find((n) => n.type === "output");
      if (inputNode && outputNode) {
        try {
          genome.connect(inputNode, outputNode, 1);
        } catch {
        }
      }
    }
    const enabledConnections = genome.connections.filter(
      (c) => c.enabled !== false
    );
    if (!enabledConnections.length) return;
    const chosenConn = enabledConnections[Math.floor(this._getRNG()() * enabledConnections.length)];
    const fromGeneId = chosenConn.from.geneId;
    const toGeneId = chosenConn.to.geneId;
    const splitKey = fromGeneId + "->" + toGeneId;
    const originalWeight = chosenConn.weight;
    genome.disconnect(chosenConn.from, chosenConn.to);
    let splitRecord = this._nodeSplitInnovations.get(splitKey);
    const NodeClass = (init_node(), __toCommonJS(node_exports)).default;
    if (!splitRecord) {
      const newNode = new NodeClass("hidden");
      const inConn = genome.connect(chosenConn.from, newNode, 1)[0];
      const outConn = genome.connect(newNode, chosenConn.to, originalWeight)[0];
      if (inConn) inConn.innovation = this._nextGlobalInnovation++;
      if (outConn) outConn.innovation = this._nextGlobalInnovation++;
      splitRecord = {
        newNodeGeneId: newNode.geneId,
        inInnov: inConn?.innovation,
        outInnov: outConn?.innovation
      };
      this._nodeSplitInnovations.set(splitKey, splitRecord);
      const toIndex = genome.nodes.indexOf(chosenConn.to);
      const insertIndex = Math.min(toIndex, genome.nodes.length - genome.output);
      genome.nodes.splice(insertIndex, 0, newNode);
    } else {
      const newNode = new NodeClass("hidden");
      newNode.geneId = splitRecord.newNodeGeneId;
      const toIndex = genome.nodes.indexOf(chosenConn.to);
      const insertIndex = Math.min(toIndex, genome.nodes.length - genome.output);
      genome.nodes.splice(insertIndex, 0, newNode);
      const inConn = genome.connect(chosenConn.from, newNode, 1)[0];
      const outConn = genome.connect(newNode, chosenConn.to, originalWeight)[0];
      if (inConn) inConn.innovation = splitRecord.inInnov;
      if (outConn) outConn.innovation = splitRecord.outInnov;
    }
  }
  function mutateAddConnReuse(genome) {
    const candidatePairs = [];
    for (let i = 0; i < genome.nodes.length - genome.output; i++) {
      const fromNode2 = genome.nodes[i];
      for (let j = Math.max(i + 1, genome.input); j < genome.nodes.length; j++) {
        const toNode2 = genome.nodes[j];
        if (!fromNode2.isProjectingTo(toNode2))
          candidatePairs.push([fromNode2, toNode2]);
      }
    }
    if (!candidatePairs.length) return;
    const reuseCandidates = candidatePairs.filter((pair) => {
      const idA2 = pair[0].geneId;
      const idB2 = pair[1].geneId;
      const symmetricKey2 = idA2 < idB2 ? idA2 + "::" + idB2 : idB2 + "::" + idA2;
      return this._connInnovations.has(symmetricKey2);
    });
    const hiddenPairs = reuseCandidates.length ? [] : candidatePairs.filter(
      (pair) => pair[0].type === "hidden" && pair[1].type === "hidden"
    );
    const pool2 = reuseCandidates.length ? reuseCandidates : hiddenPairs.length ? hiddenPairs : candidatePairs;
    const chosenPair = pool2.length === 1 ? pool2[0] : pool2[Math.floor(this._getRNG()() * pool2.length)];
    const fromNode = chosenPair[0];
    const toNode = chosenPair[1];
    const idA = fromNode.geneId;
    const idB = toNode.geneId;
    const symmetricKey = idA < idB ? idA + "::" + idB : idB + "::" + idA;
    if (genome._enforceAcyclic) {
      const createsCycle = (() => {
        const stack = [toNode];
        const seen = /* @__PURE__ */ new Set();
        while (stack.length) {
          const n = stack.pop();
          if (n === fromNode) return true;
          if (seen.has(n)) continue;
          seen.add(n);
          for (const c of n.connections.out) stack.push(c.to);
        }
        return false;
      })();
      if (createsCycle) return;
    }
    const conn = genome.connect(fromNode, toNode)[0];
    if (!conn) return;
    if (this._connInnovations.has(symmetricKey)) {
      conn.innovation = this._connInnovations.get(symmetricKey);
    } else {
      const innov = this._nextGlobalInnovation++;
      conn.innovation = innov;
      this._connInnovations.set(symmetricKey, innov);
      const legacyForward = idA + "::" + idB;
      const legacyReverse = idB + "::" + idA;
      this._connInnovations.set(legacyForward, innov);
      this._connInnovations.set(legacyReverse, innov);
    }
  }
  function ensureMinHiddenNodes(network, multiplierOverride) {
    const maxNodes = this.options.maxNodes || Infinity;
    const minHidden = Math.min(
      this.getMinimumHiddenSize(multiplierOverride),
      maxNodes - network.nodes.filter((n) => n.type !== "hidden").length
    );
    const inputNodes = network.nodes.filter((n) => n.type === "input");
    const outputNodes = network.nodes.filter((n) => n.type === "output");
    let hiddenNodes = network.nodes.filter((n) => n.type === "hidden");
    if (inputNodes.length === 0 || outputNodes.length === 0) {
      try {
        console.warn(
          "Network is missing input or output nodes \u2014 skipping minHidden enforcement"
        );
      } catch {
      }
      return;
    }
    const existingCount = hiddenNodes.length;
    for (let i = existingCount; i < minHidden && network.nodes.length < maxNodes; i++) {
      const NodeClass = (init_node(), __toCommonJS(node_exports)).default;
      const newNode = new NodeClass("hidden");
      network.nodes.push(newNode);
      hiddenNodes.push(newNode);
    }
    for (const hiddenNode of hiddenNodes) {
      if (hiddenNode.connections.in.length === 0) {
        const candidates = inputNodes.concat(
          hiddenNodes.filter((n) => n !== hiddenNode)
        );
        if (candidates.length > 0) {
          const rng = this._getRNG();
          const source = candidates[Math.floor(rng() * candidates.length)];
          try {
            network.connect(source, hiddenNode);
          } catch {
          }
        }
      }
      if (hiddenNode.connections.out.length === 0) {
        const candidates = outputNodes.concat(
          hiddenNodes.filter((n) => n !== hiddenNode)
        );
        if (candidates.length > 0) {
          const rng = this._getRNG();
          const target = candidates[Math.floor(rng() * candidates.length)];
          try {
            network.connect(hiddenNode, target);
          } catch {
          }
        }
      }
    }
    const NetworkClass = (init_network(), __toCommonJS(network_exports)).default;
    NetworkClass.rebuildConnections(network);
  }
  function ensureNoDeadEnds(network) {
    const inputNodes = network.nodes.filter((n) => n.type === "input");
    const outputNodes = network.nodes.filter((n) => n.type === "output");
    const hiddenNodes = network.nodes.filter((n) => n.type === "hidden");
    const hasOutgoing = (node) => node.connections && node.connections.out && node.connections.out.length > 0;
    const hasIncoming = (node) => node.connections && node.connections.in && node.connections.in.length > 0;
    for (const inputNode of inputNodes) {
      if (!hasOutgoing(inputNode)) {
        const candidates = hiddenNodes.length > 0 ? hiddenNodes : outputNodes;
        if (candidates.length > 0) {
          const rng = this._getRNG();
          const target = candidates[Math.floor(rng() * candidates.length)];
          try {
            network.connect(inputNode, target);
          } catch {
          }
        }
      }
    }
    for (const outputNode of outputNodes) {
      if (!hasIncoming(outputNode)) {
        const candidates = hiddenNodes.length > 0 ? hiddenNodes : inputNodes;
        if (candidates.length > 0) {
          const rng = this._getRNG();
          const source = candidates[Math.floor(rng() * candidates.length)];
          try {
            network.connect(source, outputNode);
          } catch {
          }
        }
      }
    }
    for (const hiddenNode of hiddenNodes) {
      if (!hasIncoming(hiddenNode)) {
        const candidates = inputNodes.concat(
          hiddenNodes.filter((n) => n !== hiddenNode)
        );
        if (candidates.length > 0) {
          const rng = this._getRNG();
          const source = candidates[Math.floor(rng() * candidates.length)];
          try {
            network.connect(source, hiddenNode);
          } catch {
          }
        }
      }
      if (!hasOutgoing(hiddenNode)) {
        const candidates = outputNodes.concat(
          hiddenNodes.filter((n) => n !== hiddenNode)
        );
        if (candidates.length > 0) {
          const rng = this._getRNG();
          const target = candidates[Math.floor(rng() * candidates.length)];
          try {
            network.connect(hiddenNode, target);
          } catch {
          }
        }
      }
    }
  }
  function selectMutationMethod(genome, rawReturnForTest = true) {
    const methods = (init_methods(), __toCommonJS(methods_exports));
    const isFFWDirect = this.options.mutation === methods.mutation.FFW;
    const isFFWNested = Array.isArray(this.options.mutation) && this.options.mutation.length === 1 && this.options.mutation[0] === methods.mutation.FFW;
    if ((isFFWDirect || isFFWNested) && rawReturnForTest)
      return methods.mutation.FFW;
    if (isFFWDirect)
      return methods.mutation.FFW[Math.floor(this._getRNG()() * methods.mutation.FFW.length)];
    if (isFFWNested)
      return methods.mutation.FFW[Math.floor(this._getRNG()() * methods.mutation.FFW.length)];
    let pool2 = this.options.mutation;
    if (rawReturnForTest && Array.isArray(pool2) && pool2.length === methods.mutation.FFW.length && pool2.every(
      (m, i) => m && m.name === methods.mutation.FFW[i].name
    )) {
      return methods.mutation.FFW;
    }
    if (pool2.length === 1 && Array.isArray(pool2[0]) && pool2[0].length)
      pool2 = pool2[0];
    if (this.options.phasedComplexity?.enabled && this._phase) {
      pool2 = pool2.filter((m) => !!m);
      if (this._phase === "simplify") {
        const simplifyPool = pool2.filter(
          (m) => m && m.name && m.name.startsWith && m.name.startsWith("SUB_")
        );
        if (simplifyPool.length) pool2 = [...pool2, ...simplifyPool];
      } else if (this._phase === "complexify") {
        const addPool = pool2.filter(
          (m) => m && m.name && m.name.startsWith && m.name.startsWith("ADD_")
        );
        if (addPool.length) pool2 = [...pool2, ...addPool];
      }
    }
    if (this.options.operatorAdaptation?.enabled) {
      const boost = this.options.operatorAdaptation.boost ?? 2;
      const stats = this._operatorStats;
      const augmented = [];
      for (const m of pool2) {
        augmented.push(m);
        const st = stats.get(m.name);
        if (st && st.attempts > 5) {
          const ratio = st.success / st.attempts;
          if (ratio > 0.55) {
            for (let i = 0; i < Math.min(boost, Math.floor(ratio * boost)); i++)
              augmented.push(m);
          }
        }
      }
      pool2 = augmented;
    }
    let mutationMethod = pool2[Math.floor(this._getRNG()() * pool2.length)];
    if (mutationMethod === methods.mutation.ADD_GATE && genome.gates.length >= (this.options.maxGates || Infinity))
      return null;
    if (mutationMethod === methods.mutation.ADD_NODE && genome.nodes.length >= (this.options.maxNodes || Infinity))
      return null;
    if (mutationMethod === methods.mutation.ADD_CONN && genome.connections.length >= (this.options.maxConns || Infinity))
      return null;
    if (this.options.operatorBandit?.enabled) {
      const c = this.options.operatorBandit.c ?? 1.4;
      const minA = this.options.operatorBandit.minAttempts ?? 5;
      const stats = this._operatorStats;
      for (const m of pool2)
        if (!stats.has(m.name)) stats.set(m.name, { success: 0, attempts: 0 });
      const totalAttempts = Array.from(stats.values()).reduce(
        (a, s) => a + s.attempts,
        0
      ) + EPSILON;
      let best = mutationMethod;
      let bestVal = -Infinity;
      for (const m of pool2) {
        const st = stats.get(m.name);
        const mean = st.attempts > 0 ? st.success / st.attempts : 0;
        const bonus = st.attempts < minA ? Infinity : c * Math.sqrt(Math.log(totalAttempts) / (st.attempts + EPSILON));
        const val = mean + bonus;
        if (val > bestVal) {
          bestVal = val;
          best = m;
        }
      }
      mutationMethod = best;
    }
    if (mutationMethod === methods.mutation.ADD_GATE && genome.gates.length >= (this.options.maxGates || Infinity))
      return null;
    if (!this.options.allowRecurrent && (mutationMethod === methods.mutation.ADD_BACK_CONN || mutationMethod === methods.mutation.ADD_SELF_CONN))
      return null;
    return mutationMethod;
  }
  var init_neat_mutation = __esm({
    "src/neat/neat.mutation.ts"() {
      "use strict";
      init_neat_constants();
    }
  });

  // src/neat/neat.multiobjective.ts
  function fastNonDominated(pop) {
    const objectiveDescriptors = this._getObjectives();
    const valuesMatrix = pop.map(
      (genomeItem) => objectiveDescriptors.map((descriptor) => {
        try {
          return descriptor.accessor(genomeItem);
        } catch {
          return 0;
        }
      })
    );
    const vectorDominates = (valuesA, valuesB) => {
      let strictlyBetter = false;
      for (let objectiveIndex = 0; objectiveIndex < valuesA.length; objectiveIndex++) {
        const direction = objectiveDescriptors[objectiveIndex].direction || "max";
        if (direction === "max") {
          if (valuesA[objectiveIndex] < valuesB[objectiveIndex]) return false;
          if (valuesA[objectiveIndex] > valuesB[objectiveIndex])
            strictlyBetter = true;
        } else {
          if (valuesA[objectiveIndex] > valuesB[objectiveIndex]) return false;
          if (valuesA[objectiveIndex] < valuesB[objectiveIndex])
            strictlyBetter = true;
        }
      }
      return strictlyBetter;
    };
    const paretoFronts = [];
    const dominationCounts = new Array(pop.length).fill(0);
    const dominatedIndicesByIndex = pop.map(() => []);
    const firstFrontIndices = [];
    for (let pIndex = 0; pIndex < pop.length; pIndex++) {
      for (let qIndex = 0; qIndex < pop.length; qIndex++) {
        if (pIndex === qIndex) continue;
        if (vectorDominates(valuesMatrix[pIndex], valuesMatrix[qIndex]))
          dominatedIndicesByIndex[pIndex].push(qIndex);
        else if (vectorDominates(valuesMatrix[qIndex], valuesMatrix[pIndex]))
          dominationCounts[pIndex]++;
      }
      if (dominationCounts[pIndex] === 0) firstFrontIndices.push(pIndex);
    }
    let currentFrontIndices = firstFrontIndices;
    let currentFrontRank = 0;
    while (currentFrontIndices.length) {
      const nextFrontIndices = [];
      for (const pIndex of currentFrontIndices) {
        pop[pIndex]._moRank = currentFrontRank;
        for (const qIndex of dominatedIndicesByIndex[pIndex]) {
          dominationCounts[qIndex]--;
          if (dominationCounts[qIndex] === 0) nextFrontIndices.push(qIndex);
        }
      }
      paretoFronts.push(currentFrontIndices.map((i) => pop[i]));
      currentFrontIndices = nextFrontIndices;
      currentFrontRank++;
      if (currentFrontRank > 50) break;
    }
    for (const front of paretoFronts) {
      if (front.length === 0) continue;
      for (const genomeItem of front) genomeItem._moCrowd = 0;
      for (let objectiveIndex = 0; objectiveIndex < objectiveDescriptors.length; objectiveIndex++) {
        const sortedByCurrentObjective = front.slice().sort((genomeA, genomeB) => {
          const valA = objectiveDescriptors[objectiveIndex].accessor(genomeA);
          const valB = objectiveDescriptors[objectiveIndex].accessor(genomeB);
          return valA - valB;
        });
        sortedByCurrentObjective[0]._moCrowd = Infinity;
        sortedByCurrentObjective[sortedByCurrentObjective.length - 1]._moCrowd = Infinity;
        const minVal = objectiveDescriptors[objectiveIndex].accessor(
          sortedByCurrentObjective[0]
        );
        const maxVal = objectiveDescriptors[objectiveIndex].accessor(
          sortedByCurrentObjective[sortedByCurrentObjective.length - 1]
        );
        const valueRange = maxVal - minVal || 1;
        for (let sortedIndex = 1; sortedIndex < sortedByCurrentObjective.length - 1; sortedIndex++) {
          const prevVal = objectiveDescriptors[objectiveIndex].accessor(
            sortedByCurrentObjective[sortedIndex - 1]
          );
          const nextVal = objectiveDescriptors[objectiveIndex].accessor(
            sortedByCurrentObjective[sortedIndex + 1]
          );
          sortedByCurrentObjective[sortedIndex]._moCrowd += (nextVal - prevVal) / valueRange;
        }
      }
    }
    if (this.options.multiObjective?.enabled) {
      this._paretoArchive.push({
        generation: this.generation,
        fronts: paretoFronts.slice(0, 3).map(
          (front) => (
            // map each front (array of Network) to an array of genome IDs
            front.map((genome) => genome._id)
          )
        )
      });
      if (this._paretoArchive.length > 100) this._paretoArchive.shift();
    }
    return paretoFronts;
  }
  var init_neat_multiobjective = __esm({
    "src/neat/neat.multiobjective.ts"() {
      "use strict";
    }
  });

  // src/neat/neat.adaptive.ts
  var neat_adaptive_exports = {};
  __export(neat_adaptive_exports, {
    applyAdaptiveMutation: () => applyAdaptiveMutation,
    applyAncestorUniqAdaptive: () => applyAncestorUniqAdaptive,
    applyComplexityBudget: () => applyComplexityBudget,
    applyMinimalCriterionAdaptive: () => applyMinimalCriterionAdaptive,
    applyOperatorAdaptation: () => applyOperatorAdaptation,
    applyPhasedComplexity: () => applyPhasedComplexity
  });
  function applyComplexityBudget() {
    if (!this.options.complexityBudget?.enabled) return;
    const complexityBudget = this.options.complexityBudget;
    if (complexityBudget.mode === "adaptive") {
      if (!this._cbHistory) this._cbHistory = [];
      this._cbHistory.push(this.population[0]?.score || 0);
      const windowSize = complexityBudget.improvementWindow ?? 10;
      if (this._cbHistory.length > windowSize) this._cbHistory.shift();
      const history = this._cbHistory;
      const improvement = history.length > 1 ? history[history.length - 1] - history[0] : 0;
      let slope = 0;
      if (history.length > 2) {
        const count = history.length;
        let sumIndices = 0, sumScores = 0, sumIndexScore = 0, sumIndexSquared = 0;
        for (let idx = 0; idx < count; idx++) {
          sumIndices += idx;
          sumScores += history[idx];
          sumIndexScore += idx * history[idx];
          sumIndexSquared += idx * idx;
        }
        const denom = count * sumIndexSquared - sumIndices * sumIndices || 1;
        slope = (count * sumIndexScore - sumIndices * sumScores) / denom;
      }
      if (this._cbMaxNodes === void 0)
        this._cbMaxNodes = complexityBudget.maxNodesStart ?? this.input + this.output + 2;
      const baseInc = complexityBudget.increaseFactor ?? 1.1;
      const baseStag = complexityBudget.stagnationFactor ?? 0.95;
      const slopeMag = Math.min(
        2,
        Math.max(-2, slope / (Math.abs(history[0]) + EPSILON))
      );
      const incF = baseInc + 0.05 * Math.max(0, slopeMag);
      const stagF = baseStag - 0.03 * Math.max(0, -slopeMag);
      const noveltyFactor = this._noveltyArchive.length > 5 ? 1 : 0.9;
      if (improvement > 0 || slope > 0)
        this._cbMaxNodes = Math.min(
          complexityBudget.maxNodesEnd ?? this._cbMaxNodes * 4,
          Math.floor(this._cbMaxNodes * incF * noveltyFactor)
        );
      else if (history.length === windowSize)
        this._cbMaxNodes = Math.max(
          complexityBudget.minNodes ?? this.input + this.output + 2,
          Math.floor(this._cbMaxNodes * stagF)
        );
      if (complexityBudget.minNodes !== void 0) {
        this._cbMaxNodes = Math.max(complexityBudget.minNodes, this._cbMaxNodes);
      } else {
        const implicitMin = this.input + this.output + 2;
        if (this._cbMaxNodes < implicitMin) this._cbMaxNodes = implicitMin;
      }
      this.options.maxNodes = this._cbMaxNodes;
      if (complexityBudget.maxConnsStart) {
        if (this._cbMaxConns === void 0)
          this._cbMaxConns = complexityBudget.maxConnsStart;
        if (improvement > 0 || slope > 0)
          this._cbMaxConns = Math.min(
            complexityBudget.maxConnsEnd ?? this._cbMaxConns * 4,
            Math.floor(this._cbMaxConns * incF * noveltyFactor)
          );
        else if (history.length === windowSize)
          this._cbMaxConns = Math.max(
            complexityBudget.maxConnsStart,
            Math.floor(this._cbMaxConns * stagF)
          );
        this.options.maxConns = this._cbMaxConns;
      }
    } else {
      const maxStart = complexityBudget.maxNodesStart ?? this.input + this.output + 2;
      const maxEnd = complexityBudget.maxNodesEnd ?? maxStart * 4;
      const horizon = complexityBudget.horizon ?? 100;
      const t = Math.min(1, this.generation / horizon);
      this.options.maxNodes = Math.floor(maxStart + (maxEnd - maxStart) * t);
    }
  }
  function applyPhasedComplexity() {
    if (!this.options.phasedComplexity?.enabled) return;
    const len = this.options.phasedComplexity.phaseLength ?? 10;
    if (!this._phase) {
      this._phase = this.options.phasedComplexity.initialPhase ?? "complexify";
      this._phaseStartGeneration = this.generation;
    }
    if (this.generation - this._phaseStartGeneration >= len) {
      this._phase = this._phase === "complexify" ? "simplify" : "complexify";
      this._phaseStartGeneration = this.generation;
    }
  }
  function applyMinimalCriterionAdaptive() {
    if (!this.options.minimalCriterionAdaptive?.enabled) return;
    const mcCfg = this.options.minimalCriterionAdaptive;
    if (this._mcThreshold === void 0)
      this._mcThreshold = mcCfg.initialThreshold ?? 0;
    const scores = this.population.map((g) => g.score || 0);
    const accepted = scores.filter((s) => s >= this._mcThreshold).length;
    const prop = scores.length ? accepted / scores.length : 0;
    const targetAcceptance = mcCfg.targetAcceptance ?? 0.5;
    const adjustRate = mcCfg.adjustRate ?? 0.1;
    if (prop > targetAcceptance * 1.05) this._mcThreshold *= 1 + adjustRate;
    else if (prop < targetAcceptance * 0.95) this._mcThreshold *= 1 - adjustRate;
    for (const g of this.population)
      if ((g.score || 0) < this._mcThreshold) g.score = 0;
  }
  function applyAncestorUniqAdaptive() {
    if (!this.options.ancestorUniqAdaptive?.enabled) return;
    const ancestorCfg = this.options.ancestorUniqAdaptive;
    const cooldown = ancestorCfg.cooldown ?? 5;
    if (this.generation - this._lastAncestorUniqAdjustGen < cooldown) return;
    const lineageBlock = this._telemetry[this._telemetry.length - 1]?.lineage;
    const ancUniq = lineageBlock ? lineageBlock.ancestorUniq : void 0;
    if (typeof ancUniq !== "number") return;
    const lowT = ancestorCfg.lowThreshold ?? 0.25;
    const highT = ancestorCfg.highThreshold ?? 0.55;
    const adj = ancestorCfg.adjust ?? 0.01;
    if (ancestorCfg.mode === "epsilon" && this.options.multiObjective?.adaptiveEpsilon?.enabled) {
      if (ancUniq < lowT) {
        this.options.multiObjective.dominanceEpsilon = (this.options.multiObjective.dominanceEpsilon || 0) + adj;
        this._lastAncestorUniqAdjustGen = this.generation;
      } else if (ancUniq > highT) {
        this.options.multiObjective.dominanceEpsilon = Math.max(
          0,
          (this.options.multiObjective.dominanceEpsilon || 0) - adj
        );
        this._lastAncestorUniqAdjustGen = this.generation;
      }
    } else if (ancestorCfg.mode === "lineagePressure") {
      if (!this.options.lineagePressure)
        this.options.lineagePressure = {
          enabled: true,
          mode: "spread",
          strength: 0.01
        };
      const lpRef = this.options.lineagePressure;
      if (ancUniq < lowT) {
        lpRef.strength = (lpRef.strength || 0.01) * 1.15;
        lpRef.mode = "spread";
        this._lastAncestorUniqAdjustGen = this.generation;
      } else if (ancUniq > highT) {
        lpRef.strength = (lpRef.strength || 0.01) * 0.9;
        this._lastAncestorUniqAdjustGen = this.generation;
      }
    }
  }
  function applyAdaptiveMutation() {
    if (!this.options.adaptiveMutation?.enabled) return;
    const adaptCfg = this.options.adaptiveMutation;
    const every = adaptCfg.adaptEvery ?? 1;
    if (!(every <= 1 || this.generation % every === 0)) return;
    const scored = this.population.filter(
      (g) => typeof g.score === "number"
    );
    scored.sort((a, b) => (a.score || 0) - (b.score || 0));
    const mid = Math.floor(scored.length / 2);
    const topHalf = scored.slice(mid);
    const bottomHalf = scored.slice(0, mid);
    const sigmaBase = (adaptCfg.sigma ?? 0.05) * 1.5;
    const minR = adaptCfg.minRate ?? 0.01;
    const maxR = adaptCfg.maxRate ?? 1;
    const strategy = adaptCfg.strategy || "twoTier";
    let anyUp = false, anyDown = false;
    for (let index = 0; index < this.population.length; index++) {
      const genome = this.population[index];
      if (genome._mutRate === void 0) continue;
      let rate = genome._mutRate;
      let delta = this._getRNG()() * 2 - 1;
      delta *= sigmaBase;
      if (strategy === "twoTier") {
        if (topHalf.length === 0 || bottomHalf.length === 0)
          delta = index % 2 === 0 ? Math.abs(delta) : -Math.abs(delta);
        else if (topHalf.includes(genome)) delta = -Math.abs(delta);
        else if (bottomHalf.includes(genome)) delta = Math.abs(delta);
      } else if (strategy === "exploreLow") {
        delta = bottomHalf.includes(genome) ? Math.abs(delta * 1.5) : -Math.abs(delta * 0.5);
      } else if (strategy === "anneal") {
        const progress = Math.min(
          1,
          this.generation / (50 + this.population.length)
        );
        delta *= 1 - progress;
      }
      rate += delta;
      if (rate < minR) rate = minR;
      if (rate > maxR) rate = maxR;
      if (rate > (this.options.adaptiveMutation.initialRate ?? 0.5))
        anyUp = true;
      if (rate < (this.options.adaptiveMutation.initialRate ?? 0.5))
        anyDown = true;
      genome._mutRate = rate;
      if (adaptCfg.adaptAmount) {
        const aSigma = adaptCfg.amountSigma ?? 0.25;
        let aDelta = (this._getRNG()() * 2 - 1) * aSigma;
        if (strategy === "twoTier") {
          if (topHalf.length === 0 || bottomHalf.length === 0)
            aDelta = index % 2 === 0 ? Math.abs(aDelta) : -Math.abs(aDelta);
          else
            aDelta = bottomHalf.includes(genome) ? Math.abs(aDelta) : -Math.abs(aDelta);
        }
        let amt = genome._mutAmount ?? (this.options.mutationAmount || 1);
        amt += aDelta;
        amt = Math.round(amt);
        const minA = adaptCfg.minAmount ?? 1;
        const maxA = adaptCfg.maxAmount ?? 10;
        if (amt < minA) amt = minA;
        if (amt > maxA) amt = maxA;
        genome._mutAmount = amt;
      }
    }
    if (strategy === "twoTier" && !(anyUp && anyDown)) {
      const baseline = this.options.adaptiveMutation.initialRate ?? 0.5;
      const half = Math.floor(this.population.length / 2);
      for (let i = 0; i < this.population.length; i++) {
        const genome = this.population[i];
        if (genome._mutRate === void 0) continue;
        if (i < half) genome._mutRate = Math.min(genome._mutRate + sigmaBase, 1);
        else genome._mutRate = Math.max(genome._mutRate - sigmaBase, 0.01);
      }
    }
  }
  function applyOperatorAdaptation() {
    if (!this.options.operatorAdaptation?.enabled) return;
    const decay = this.options.operatorAdaptation.decay ?? 0.9;
    for (const [k, stat] of this._operatorStats.entries()) {
      stat.success *= decay;
      stat.attempts *= decay;
      this._operatorStats.set(k, stat);
    }
  }
  var init_neat_adaptive = __esm({
    "src/neat/neat.adaptive.ts"() {
      "use strict";
      init_neat_constants();
    }
  });

  // src/neat/neat.lineage.ts
  var neat_lineage_exports = {};
  __export(neat_lineage_exports, {
    buildAnc: () => buildAnc,
    computeAncestorUniqueness: () => computeAncestorUniqueness
  });
  function buildAnc(genome) {
    const ancestorSet = /* @__PURE__ */ new Set();
    if (!Array.isArray(genome._parents)) return ancestorSet;
    const queue = [];
    for (const parentId of genome._parents) {
      queue.push({
        id: parentId,
        depth: 1,
        genomeRef: this.population.find((gm) => gm._id === parentId)
      });
    }
    while (queue.length) {
      const current = queue.shift();
      if (current.depth > ANCESTOR_DEPTH_WINDOW) continue;
      if (current.id != null) ancestorSet.add(current.id);
      if (current.genomeRef && Array.isArray(current.genomeRef._parents)) {
        for (const parentId of current.genomeRef._parents) {
          queue.push({
            id: parentId,
            // Depth increases as we move one layer further away from the focal genome.
            depth: current.depth + 1,
            genomeRef: this.population.find((gm) => gm._id === parentId)
          });
        }
      }
    }
    return ancestorSet;
  }
  function computeAncestorUniqueness() {
    const buildAncestorSet = buildAnc.bind(this);
    let sampledPairCount = 0;
    let jaccardDistanceSum = 0;
    const maxSamplePairs = Math.min(
      MAX_UNIQUENESS_SAMPLE_PAIRS,
      this.population.length * (this.population.length - 1) / 2
    );
    for (let t = 0; t < maxSamplePairs; t++) {
      if (this.population.length < 2) break;
      const indexA = Math.floor(this._getRNG()() * this.population.length);
      let indexB = Math.floor(this._getRNG()() * this.population.length);
      if (indexB === indexA) indexB = (indexB + 1) % this.population.length;
      const ancestorSetA = buildAncestorSet(this.population[indexA]);
      const ancestorSetB = buildAncestorSet(this.population[indexB]);
      if (ancestorSetA.size === 0 && ancestorSetB.size === 0) continue;
      let intersectionCount = 0;
      for (const id of ancestorSetA)
        if (ancestorSetB.has(id)) intersectionCount++;
      const unionSize = ancestorSetA.size + ancestorSetB.size - intersectionCount || 1;
      const jaccardDistance = 1 - intersectionCount / unionSize;
      jaccardDistanceSum += jaccardDistance;
      sampledPairCount++;
    }
    const ancestorUniqueness = sampledPairCount ? +(jaccardDistanceSum / sampledPairCount).toFixed(3) : 0;
    return ancestorUniqueness;
  }
  var ANCESTOR_DEPTH_WINDOW, MAX_UNIQUENESS_SAMPLE_PAIRS;
  var init_neat_lineage = __esm({
    "src/neat/neat.lineage.ts"() {
      "use strict";
      ANCESTOR_DEPTH_WINDOW = 4;
      MAX_UNIQUENESS_SAMPLE_PAIRS = 30;
    }
  });

  // src/neat/neat.telemetry.ts
  var neat_telemetry_exports = {};
  __export(neat_telemetry_exports, {
    applyTelemetrySelect: () => applyTelemetrySelect,
    buildTelemetryEntry: () => buildTelemetryEntry,
    computeDiversityStats: () => computeDiversityStats,
    recordTelemetryEntry: () => recordTelemetryEntry,
    structuralEntropy: () => structuralEntropy
  });
  function applyTelemetrySelect(entry) {
    if (!this._telemetrySelect || !this._telemetrySelect.size)
      return entry;
    const keep = this._telemetrySelect;
    const core = { gen: entry.gen, best: entry.best, species: entry.species };
    for (const key of Object.keys(entry)) {
      if (key in core) continue;
      if (!keep.has(key)) delete entry[key];
    }
    return Object.assign(entry, core);
  }
  function structuralEntropy(graph) {
    const anyG = graph;
    if (anyG._entropyGen === this.generation && typeof anyG._entropyVal === "number")
      return anyG._entropyVal;
    const degreeCounts = {};
    for (const node of graph.nodes) degreeCounts[node.geneId] = 0;
    for (const conn of graph.connections)
      if (conn.enabled) {
        const fromId = conn.from.geneId;
        const toId = conn.to.geneId;
        if (degreeCounts[fromId] !== void 0) degreeCounts[fromId]++;
        if (degreeCounts[toId] !== void 0) degreeCounts[toId]++;
      }
    const degreeHistogram = {};
    const nodeCount = graph.nodes.length || 1;
    for (const nodeId in degreeCounts) {
      const d = degreeCounts[nodeId];
      degreeHistogram[d] = (degreeHistogram[d] || 0) + 1;
    }
    let entropy = 0;
    for (const k in degreeHistogram) {
      const p = degreeHistogram[k] / nodeCount;
      if (p > 0) entropy -= p * Math.log(p + EPSILON);
    }
    anyG._entropyGen = this.generation;
    anyG._entropyVal = entropy;
    return entropy;
  }
  function computeDiversityStats() {
    if (!this.options.diversityMetrics?.enabled) return;
    if (this.options.fastMode && !this._fastModeTuned) {
      const dm = this.options.diversityMetrics;
      if (dm) {
        if (dm.pairSample == null) dm.pairSample = 20;
        if (dm.graphletSample == null) dm.graphletSample = 30;
      }
      if (this.options.novelty?.enabled && this.options.novelty.k == null)
        this.options.novelty.k = 5;
      this._fastModeTuned = true;
    }
    const pairSample = this.options.diversityMetrics.pairSample ?? 40;
    const graphletSample = this.options.diversityMetrics.graphletSample ?? 60;
    const population = this.population;
    const popSize = population.length;
    let compatSum = 0;
    let compatSq = 0;
    let compatCount = 0;
    for (let iter = 0; iter < pairSample; iter++) {
      if (popSize < 2) break;
      const i = Math.floor(this._getRNG()() * popSize);
      let j = Math.floor(this._getRNG()() * popSize);
      if (j === i) j = (j + 1) % popSize;
      const d = this._compatibilityDistance(
        population[i],
        population[j]
      );
      compatSum += d;
      compatSq += d * d;
      compatCount++;
    }
    const meanCompat = compatCount ? compatSum / compatCount : 0;
    const varCompat = compatCount ? Math.max(0, compatSq / compatCount - meanCompat * meanCompat) : 0;
    const entropies = population.map(
      (g) => this._structuralEntropy(g)
    );
    const meanEntropy = entropies.reduce((a, b) => a + b, 0) / (entropies.length || 1);
    const varEntropy = entropies.length ? entropies.reduce(
      (a, b) => a + (b - meanEntropy) * (b - meanEntropy),
      0
    ) / entropies.length : 0;
    const motifCounts = [0, 0, 0, 0];
    for (let iter = 0; iter < graphletSample; iter++) {
      const g = population[Math.floor(this._getRNG()() * popSize)];
      if (!g) break;
      if (g.nodes.length < 3) continue;
      const selectedIdxs = /* @__PURE__ */ new Set();
      while (selectedIdxs.size < 3)
        selectedIdxs.add(Math.floor(this._getRNG()() * g.nodes.length));
      const selectedNodes = Array.from(selectedIdxs).map((i) => g.nodes[i]);
      let edges = 0;
      for (const c of g.connections)
        if (c.enabled) {
          if (selectedNodes.includes(c.from) && selectedNodes.includes(c.to))
            edges++;
        }
      if (edges > 3) edges = 3;
      motifCounts[edges]++;
    }
    const totalMotifs = motifCounts.reduce((a, b) => a + b, 0) || 1;
    let graphletEntropy = 0;
    for (let k = 0; k < motifCounts.length; k++) {
      const p = motifCounts[k] / totalMotifs;
      if (p > 0) graphletEntropy -= p * Math.log(p);
    }
    let lineageMeanDepth = 0;
    let lineageMeanPairDist = 0;
    if (this._lineageEnabled && popSize > 0) {
      const depths = population.map((g) => g._depth ?? 0);
      lineageMeanDepth = depths.reduce((a, b) => a + b, 0) / popSize;
      let lineagePairSum = 0;
      let lineagePairN = 0;
      for (let iter = 0; iter < Math.min(pairSample, popSize * (popSize - 1) / 2); iter++) {
        if (popSize < 2) break;
        const i = Math.floor(this._getRNG()() * popSize);
        let j = Math.floor(this._getRNG()() * popSize);
        if (j === i) j = (j + 1) % popSize;
        lineagePairSum += Math.abs(depths[i] - depths[j]);
        lineagePairN++;
      }
      lineageMeanPairDist = lineagePairN ? lineagePairSum / lineagePairN : 0;
    }
    this._diversityStats = {
      meanCompat,
      varCompat,
      meanEntropy,
      varEntropy,
      graphletEntropy,
      lineageMeanDepth,
      lineageMeanPairDist
    };
  }
  function recordTelemetryEntry(entry) {
    try {
      applyTelemetrySelect.call(this, entry);
    } catch {
    }
    if (!this._telemetry) this._telemetry = [];
    this._telemetry.push(entry);
    try {
      if (this.options.telemetryStream?.enabled && this.options.telemetryStream.onEntry)
        this.options.telemetryStream.onEntry(entry);
    } catch {
    }
    if (this._telemetry.length > 500) this._telemetry.shift();
  }
  function buildTelemetryEntry(fittest) {
    const gen = this.generation;
    let hyperVolumeProxy = 0;
    if (this.options.multiObjective?.enabled) {
      const complexityMetric = this.options.multiObjective.complexityMetric || "connections";
      const primaryObjectiveScores = this.population.map(
        (genome) => genome.score || 0
      );
      const minPrimaryScore = Math.min(...primaryObjectiveScores);
      const maxPrimaryScore = Math.max(...primaryObjectiveScores);
      const paretoFrontSizes = [];
      for (let r = 0; r < 5; r++) {
        const size = this.population.filter(
          (g) => (g._moRank ?? 0) === r
        ).length;
        if (!size) break;
        paretoFrontSizes.push(size);
      }
      for (const genome of this.population) {
        const rank = genome._moRank ?? 0;
        if (rank !== 0) continue;
        const normalizedScore = maxPrimaryScore > minPrimaryScore ? ((genome.score || 0) - minPrimaryScore) / (maxPrimaryScore - minPrimaryScore) : 0;
        const genomeComplexity = complexityMetric === "nodes" ? genome.nodes.length : genome.connections.length;
        hyperVolumeProxy += normalizedScore * (1 / (genomeComplexity + 1));
      }
      const operatorStatsSnapshot = Array.from(
        this._operatorStats.entries()
      ).map(([opName, stats]) => ({
        op: opName,
        succ: stats.success,
        att: stats.attempts
      }));
      const entry2 = {
        gen,
        best: fittest.score,
        species: this._species.length,
        hyper: hyperVolumeProxy,
        fronts: paretoFrontSizes,
        diversity: this._diversityStats,
        ops: operatorStatsSnapshot
      };
      if (!entry2.objImportance) entry2.objImportance = {};
      if (this._lastObjImportance)
        entry2.objImportance = this._lastObjImportance;
      if (this._objectiveAges?.size) {
        entry2.objAges = Array.from(
          this._objectiveAges.entries()
        ).reduce((a, kv) => {
          a[kv[0]] = kv[1];
          return a;
        }, {});
      }
      if (this._pendingObjectiveAdds?.length || this._pendingObjectiveRemoves?.length) {
        entry2.objEvents = [];
        for (const k of this._pendingObjectiveAdds)
          entry2.objEvents.push({ type: "add", key: k });
        for (const k of this._pendingObjectiveRemoves)
          entry2.objEvents.push({ type: "remove", key: k });
        this._objectiveEvents.push(
          ...entry2.objEvents.map((e) => ({ gen, type: e.type, key: e.key }))
        );
        this._pendingObjectiveAdds = [];
        this._pendingObjectiveRemoves = [];
      }
      if (this._lastOffspringAlloc)
        entry2.speciesAlloc = this._lastOffspringAlloc.slice();
      try {
        entry2.objectives = this._getObjectives().map(
          (o) => o.key
        );
      } catch {
      }
      if (this.options.rngState && this._rngState !== void 0)
        entry2.rng = this._rngState;
      if (this._lineageEnabled) {
        const bestGenome = this.population[0];
        const depths = this.population.map(
          (g) => g._depth ?? 0
        );
        this._lastMeanDepth = depths.reduce((a, b) => a + b, 0) / (depths.length || 1);
        const { computeAncestorUniqueness: computeAncestorUniqueness2 } = (init_neat_lineage(), __toCommonJS(neat_lineage_exports));
        const ancestorUniqueness = computeAncestorUniqueness2.call(this);
        entry2.lineage = {
          parents: Array.isArray(bestGenome._parents) ? bestGenome._parents.slice() : [],
          depthBest: bestGenome._depth ?? 0,
          meanDepth: +this._lastMeanDepth.toFixed(2),
          inbreeding: this._prevInbreedingCount,
          ancestorUniq: ancestorUniqueness
        };
      }
      if (this.options.telemetry?.hypervolume && this.options.multiObjective?.enabled)
        entry2.hv = +hyperVolumeProxy.toFixed(4);
      if (this.options.telemetry?.complexity) {
        const nodesArr = this.population.map((g) => g.nodes.length);
        const connsArr = this.population.map(
          (g) => g.connections.length
        );
        const meanNodes = nodesArr.reduce((a, b) => a + b, 0) / (nodesArr.length || 1);
        const meanConns = connsArr.reduce((a, b) => a + b, 0) / (connsArr.length || 1);
        const maxNodes = nodesArr.length ? Math.max(...nodesArr) : 0;
        const maxConns = connsArr.length ? Math.max(...connsArr) : 0;
        const enabledRatios = this.population.map((g) => {
          let enabled = 0, disabled = 0;
          for (const c of g.connections) {
            if (c.enabled === false) disabled++;
            else enabled++;
          }
          return enabled + disabled ? enabled / (enabled + disabled) : 0;
        });
        const meanEnabledRatio = enabledRatios.reduce((a, b) => a + b, 0) / (enabledRatios.length || 1);
        const growthNodes = this._lastMeanNodes !== void 0 ? meanNodes - this._lastMeanNodes : 0;
        const growthConns = this._lastMeanConns !== void 0 ? meanConns - this._lastMeanConns : 0;
        this._lastMeanNodes = meanNodes;
        this._lastMeanConns = meanConns;
        entry2.complexity = {
          meanNodes: +meanNodes.toFixed(2),
          meanConns: +meanConns.toFixed(2),
          maxNodes,
          maxConns,
          meanEnabledRatio: +meanEnabledRatio.toFixed(3),
          growthNodes: +growthNodes.toFixed(2),
          growthConns: +growthConns.toFixed(2),
          budgetMaxNodes: this.options.maxNodes,
          budgetMaxConns: this.options.maxConns
        };
      }
      if (this.options.telemetry?.performance)
        entry2.perf = {
          evalMs: this._lastEvalDuration,
          evolveMs: this._lastEvolveDuration
        };
      return entry2;
    }
    const operatorStatsSnapshotMono = Array.from(
      this._operatorStats.entries()
    ).map(([opName, stats]) => ({
      op: opName,
      succ: stats.success,
      att: stats.attempts
    }));
    const entry = {
      gen,
      best: fittest.score,
      species: this._species.length,
      hyper: hyperVolumeProxy,
      diversity: this._diversityStats,
      ops: operatorStatsSnapshotMono,
      objImportance: {}
    };
    if (this._lastObjImportance)
      entry.objImportance = this._lastObjImportance;
    if (this._objectiveAges?.size)
      entry.objAges = Array.from(
        this._objectiveAges.entries()
      ).reduce((a, kv) => {
        a[kv[0]] = kv[1];
        return a;
      }, {});
    if (this._pendingObjectiveAdds?.length || this._pendingObjectiveRemoves?.length) {
      entry.objEvents = [];
      for (const k of this._pendingObjectiveAdds)
        entry.objEvents.push({ type: "add", key: k });
      for (const k of this._pendingObjectiveRemoves)
        entry.objEvents.push({ type: "remove", key: k });
      this._objectiveEvents.push(
        ...entry.objEvents.map((e) => ({ gen, type: e.type, key: e.key }))
      );
      this._pendingObjectiveAdds = [];
      this._pendingObjectiveRemoves = [];
    }
    if (this._lastOffspringAlloc)
      entry.speciesAlloc = this._lastOffspringAlloc.slice();
    try {
      entry.objectives = this._getObjectives().map(
        (o) => o.key
      );
    } catch {
    }
    if (this.options.rngState && this._rngState !== void 0)
      entry.rng = this._rngState;
    if (this._lineageEnabled) {
      const bestGenome = this.population[0];
      const depths = this.population.map(
        (g) => g._depth ?? 0
      );
      this._lastMeanDepth = depths.reduce((a, b) => a + b, 0) / (depths.length || 1);
      const { buildAnc: buildAnc2 } = (init_neat_lineage(), __toCommonJS(neat_lineage_exports));
      let sampledPairs = 0;
      let jaccardSum = 0;
      const samplePairs = Math.min(
        30,
        this.population.length * (this.population.length - 1) / 2
      );
      for (let t = 0; t < samplePairs; t++) {
        if (this.population.length < 2) break;
        const i = Math.floor(
          this._getRNG()() * this.population.length
        );
        let j = Math.floor(
          this._getRNG()() * this.population.length
        );
        if (j === i) j = (j + 1) % this.population.length;
        const ancestorsA = buildAnc2.call(
          this,
          this.population[i]
        );
        const ancestorsB = buildAnc2.call(
          this,
          this.population[j]
        );
        if (ancestorsA.size === 0 && ancestorsB.size === 0) continue;
        let intersectionCount = 0;
        for (const id of ancestorsA) if (ancestorsB.has(id)) intersectionCount++;
        const union = ancestorsA.size + ancestorsB.size - intersectionCount || 1;
        const jaccardDistance = 1 - intersectionCount / union;
        jaccardSum += jaccardDistance;
        sampledPairs++;
      }
      const ancestorUniqueness = sampledPairs ? +(jaccardSum / sampledPairs).toFixed(3) : 0;
      entry.lineage = {
        parents: Array.isArray(bestGenome._parents) ? bestGenome._parents.slice() : [],
        depthBest: bestGenome._depth ?? 0,
        meanDepth: +this._lastMeanDepth.toFixed(2),
        inbreeding: this._prevInbreedingCount,
        ancestorUniq: ancestorUniqueness
      };
    }
    if (this.options.telemetry?.hypervolume && this.options.multiObjective?.enabled)
      entry.hv = +hyperVolumeProxy.toFixed(4);
    if (this.options.telemetry?.complexity) {
      const nodesArr = this.population.map((g) => g.nodes.length);
      const connsArr = this.population.map(
        (g) => g.connections.length
      );
      const meanNodes = nodesArr.reduce((a, b) => a + b, 0) / (nodesArr.length || 1);
      const meanConns = connsArr.reduce((a, b) => a + b, 0) / (connsArr.length || 1);
      const maxNodes = nodesArr.length ? Math.max(...nodesArr) : 0;
      const maxConns = connsArr.length ? Math.max(...connsArr) : 0;
      const enabledRatios = this.population.map((g) => {
        let en = 0, dis = 0;
        for (const c of g.connections) {
          if (c.enabled === false) dis++;
          else en++;
        }
        return en + dis ? en / (en + dis) : 0;
      });
      const meanEnabledRatio = enabledRatios.reduce((a, b) => a + b, 0) / (enabledRatios.length || 1);
      const growthNodes = this._lastMeanNodes !== void 0 ? meanNodes - this._lastMeanNodes : 0;
      const growthConns = this._lastMeanConns !== void 0 ? meanConns - this._lastMeanConns : 0;
      this._lastMeanNodes = meanNodes;
      this._lastMeanConns = meanConns;
      entry.complexity = {
        meanNodes: +meanNodes.toFixed(2),
        meanConns: +meanConns.toFixed(2),
        maxNodes,
        maxConns,
        meanEnabledRatio: +meanEnabledRatio.toFixed(3),
        growthNodes: +growthNodes.toFixed(2),
        growthConns: +growthConns.toFixed(2),
        budgetMaxNodes: this.options.maxNodes,
        budgetMaxConns: this.options.maxConns
      };
    }
    if (this.options.telemetry?.performance)
      entry.perf = {
        evalMs: this._lastEvalDuration,
        evolveMs: this._lastEvolveDuration
      };
    return entry;
  }
  var init_neat_telemetry = __esm({
    "src/neat/neat.telemetry.ts"() {
      "use strict";
      init_neat_constants();
    }
  });

  // src/neat/neat.pruning.ts
  var neat_pruning_exports = {};
  __export(neat_pruning_exports, {
    applyAdaptivePruning: () => applyAdaptivePruning,
    applyEvolutionPruning: () => applyEvolutionPruning
  });
  function applyEvolutionPruning() {
    const evolutionPruningOpts = this.options.evolutionPruning;
    if (!evolutionPruningOpts || this.generation < (evolutionPruningOpts.startGeneration || 0))
      return;
    const interval = evolutionPruningOpts.interval || 1;
    if ((this.generation - evolutionPruningOpts.startGeneration) % interval !== 0)
      return;
    const rampGenerations = evolutionPruningOpts.rampGenerations || 0;
    let rampFraction = 1;
    if (rampGenerations > 0) {
      const progressThroughRamp = Math.min(
        1,
        Math.max(
          0,
          (this.generation - evolutionPruningOpts.startGeneration) / rampGenerations
        )
      );
      rampFraction = progressThroughRamp;
    }
    const targetSparsityNow = (evolutionPruningOpts.targetSparsity || 0) * rampFraction;
    for (const genome of this.population) {
      if (genome && typeof genome.pruneToSparsity === "function") {
        genome.pruneToSparsity(
          targetSparsityNow,
          evolutionPruningOpts.method || "magnitude"
        );
      }
    }
  }
  function applyAdaptivePruning() {
    if (!this.options.adaptivePruning?.enabled) return;
    const adaptivePruningOpts = this.options.adaptivePruning;
    if (this._adaptivePruneLevel === void 0) this._adaptivePruneLevel = 0;
    const metricName = adaptivePruningOpts.metric || "connections";
    const meanNodeCount = this.population.reduce((acc, g) => acc + g.nodes.length, 0) / (this.population.length || 1);
    const meanConnectionCount = this.population.reduce(
      (acc, g) => acc + g.connections.length,
      0
    ) / (this.population.length || 1);
    const currentMetricValue = metricName === "nodes" ? meanNodeCount : meanConnectionCount;
    if (this._adaptivePruneBaseline === void 0)
      this._adaptivePruneBaseline = currentMetricValue;
    const adaptivePruneBaseline = this._adaptivePruneBaseline;
    const desiredSparsity = adaptivePruningOpts.targetSparsity ?? 0.5;
    const targetRemainingMetric = adaptivePruneBaseline * (1 - desiredSparsity);
    const tolerance = adaptivePruningOpts.tolerance ?? 0.05;
    const adjustRate = adaptivePruningOpts.adjustRate ?? 0.02;
    const normalizedDifference = (currentMetricValue - targetRemainingMetric) / (adaptivePruneBaseline || 1);
    if (Math.abs(normalizedDifference) > tolerance) {
      this._adaptivePruneLevel = Math.max(
        0,
        Math.min(
          desiredSparsity,
          this._adaptivePruneLevel + adjustRate * (normalizedDifference > 0 ? 1 : -1)
        )
      );
      for (const g of this.population)
        if (typeof g.pruneToSparsity === "function")
          g.pruneToSparsity(this._adaptivePruneLevel, "magnitude");
    }
  }
  var init_neat_pruning = __esm({
    "src/neat/neat.pruning.ts"() {
      "use strict";
    }
  });

  // src/neat/neat.evolve.ts
  async function evolve() {
    const startTime = typeof performance !== "undefined" && performance.now ? performance.now() : Date.now();
    if (this.population[this.population.length - 1].score === void 0) {
      await this.evaluate();
    }
    this._objectivesList = void 0;
    try {
      (init_neat_adaptive(), __toCommonJS(neat_adaptive_exports)).applyComplexityBudget.call(this);
    } catch {
    }
    try {
      (init_neat_adaptive(), __toCommonJS(neat_adaptive_exports)).applyPhasedComplexity.call(this);
    } catch {
    }
    this.sort();
    try {
      const currentBest = this.population[0]?.score;
      if (typeof currentBest === "number" && (this._bestScoreLastGen === void 0 || currentBest > this._bestScoreLastGen)) {
        this._bestScoreLastGen = currentBest;
        this._lastGlobalImproveGeneration = this.generation;
      }
    } catch {
    }
    try {
      (init_neat_adaptive(), __toCommonJS(neat_adaptive_exports)).applyMinimalCriterionAdaptive.call(this);
    } catch {
    }
    try {
      this._computeDiversityStats && this._computeDiversityStats();
    } catch {
    }
    if (this.options.multiObjective?.enabled) {
      const populationSnapshot = this.population;
      const paretoFronts = fastNonDominated.call(this, populationSnapshot);
      const objectives = this._getObjectives();
      const crowdingDistances = new Array(
        populationSnapshot.length
      ).fill(0);
      const objectiveValues = objectives.map(
        (obj) => populationSnapshot.map((genome) => obj.accessor(genome))
      );
      for (const front of paretoFronts) {
        const frontIndices = front.map(
          (genome) => this.population.indexOf(genome)
        );
        if (frontIndices.length < 3) {
          frontIndices.forEach((i) => crowdingDistances[i] = Infinity);
          continue;
        }
        for (let oi = 0; oi < objectives.length; oi++) {
          const sortedIdx = [...frontIndices].sort(
            (a, b) => objectiveValues[oi][a] - objectiveValues[oi][b]
          );
          crowdingDistances[sortedIdx[0]] = Infinity;
          crowdingDistances[sortedIdx[sortedIdx.length - 1]] = Infinity;
          const minV = objectiveValues[oi][sortedIdx[0]];
          const maxV = objectiveValues[oi][sortedIdx[sortedIdx.length - 1]];
          for (let k = 1; k < sortedIdx.length - 1; k++) {
            const prev = objectiveValues[oi][sortedIdx[k - 1]];
            const next = objectiveValues[oi][sortedIdx[k + 1]];
            const denom = maxV - minV || 1;
            crowdingDistances[sortedIdx[k]] += (next - prev) / denom;
          }
        }
      }
      const indexMap = /* @__PURE__ */ new Map();
      for (let i = 0; i < populationSnapshot.length; i++)
        indexMap.set(populationSnapshot[i], i);
      this.population.sort((a, b) => {
        const ra = a._moRank ?? 0;
        const rb = b._moRank ?? 0;
        if (ra !== rb) return ra - rb;
        const ia = indexMap.get(a);
        const ib = indexMap.get(b);
        return crowdingDistances[ib] - crowdingDistances[ia];
      });
      for (let i = 0; i < populationSnapshot.length; i++)
        populationSnapshot[i]._moCrowd = crowdingDistances[i];
      if (paretoFronts.length) {
        const first = paretoFronts[0];
        const snapshot = first.map((genome) => ({
          id: genome._id ?? -1,
          score: genome.score || 0,
          nodes: genome.nodes.length,
          connections: genome.connections.length
        }));
        this._paretoArchive.push({
          gen: this.generation,
          size: first.length,
          genomes: snapshot
        });
        if (this._paretoArchive.length > 200) this._paretoArchive.shift();
        if (objectives.length) {
          const vectors = first.map((genome) => ({
            id: genome._id ?? -1,
            values: objectives.map((obj) => obj.accessor(genome))
          }));
          this._paretoObjectivesArchive.push({ gen: this.generation, vectors });
          if (this._paretoObjectivesArchive.length > 200)
            this._paretoObjectivesArchive.shift();
        }
      }
      if (this.options.multiObjective?.adaptiveEpsilon?.enabled && paretoFronts.length) {
        const cfg = this.options.multiObjective.adaptiveEpsilon;
        const target = cfg.targetFront ?? Math.max(3, Math.floor(Math.sqrt(this.population.length)));
        const adjust = cfg.adjust ?? 2e-3;
        const minE = cfg.min ?? 0;
        const maxE = cfg.max ?? 0.5;
        const cooldown = cfg.cooldown ?? 2;
        if (this.generation - this._lastEpsilonAdjustGen >= cooldown) {
          const currentSize = paretoFronts[0].length;
          let eps = this.options.multiObjective.dominanceEpsilon || 0;
          if (currentSize > target * 1.2) eps = Math.min(maxE, eps + adjust);
          else if (currentSize < target * 0.8) eps = Math.max(minE, eps - adjust);
          this.options.multiObjective.dominanceEpsilon = eps;
          this._lastEpsilonAdjustGen = this.generation;
        }
      }
      if (this.options.multiObjective?.pruneInactive?.enabled) {
        const cfg = this.options.multiObjective.pruneInactive;
        const window2 = cfg.window ?? 5;
        const rangeEps = cfg.rangeEps ?? 1e-6;
        const protect = /* @__PURE__ */ new Set([
          "fitness",
          "complexity",
          ...cfg.protect || []
        ]);
        const objsList = this._getObjectives();
        const ranges = {};
        for (const obj of objsList) {
          let min = Infinity, max = -Infinity;
          for (const genome of this.population) {
            const v = obj.accessor(genome);
            if (v < min) min = v;
            if (v > max) max = v;
          }
          ranges[obj.key] = { min, max };
        }
        const toRemove = [];
        for (const obj of objsList) {
          if (protect.has(obj.key)) continue;
          const objRange = ranges[obj.key];
          const span = objRange.max - objRange.min;
          if (span < rangeEps) {
            const count = (this._objectiveStale.get(obj.key) || 0) + 1;
            this._objectiveStale.set(obj.key, count);
            if (count >= window2) toRemove.push(obj.key);
          } else {
            this._objectiveStale.set(obj.key, 0);
          }
        }
        if (toRemove.length && this.options.multiObjective?.objectives) {
          this.options.multiObjective.objectives = this.options.multiObjective.objectives.filter(
            (obj) => !toRemove.includes(obj.key)
          );
          this._objectivesList = void 0;
        }
      }
    }
    try {
      (init_neat_adaptive(), __toCommonJS(neat_adaptive_exports)).applyAncestorUniqAdaptive.call(this);
    } catch {
    }
    if (this.options.speciation) {
      try {
        this._speciate();
      } catch {
      }
      try {
        this._applyFitnessSharing();
      } catch {
      }
      try {
        const opts = this.options;
        if (opts.autoCompatTuning?.enabled) {
          const tgt = opts.autoCompatTuning.target ?? opts.targetSpecies ?? Math.max(2, Math.round(Math.sqrt(this.population.length)));
          const obs = this._species.length || 1;
          const err = tgt - obs;
          const rate = opts.autoCompatTuning.adjustRate ?? 0.01;
          const minC = opts.autoCompatTuning.minCoeff ?? 0.1;
          const maxC = opts.autoCompatTuning.maxCoeff ?? 5;
          let factor = 1 - rate * Math.sign(err);
          if (err === 0)
            factor = 1 + (this._getRNG()() - 0.5) * rate * 0.5;
          opts.excessCoeff = Math.min(
            maxC,
            Math.max(minC, opts.excessCoeff * factor)
          );
          opts.disjointCoeff = Math.min(
            maxC,
            Math.max(minC, opts.disjointCoeff * factor)
          );
        }
      } catch {
      }
      this.sort();
      try {
        if (this.options.speciesAllocation?.extendedHistory) {
        } else {
          if (!this._speciesHistory || this._speciesHistory.length === 0 || this._speciesHistory[this._speciesHistory.length - 1].generation !== this.generation) {
            this._speciesHistory.push({
              generation: this.generation,
              stats: this._species.map((species) => ({
                id: species.id,
                size: species.members.length,
                best: species.bestScore,
                lastImproved: species.lastImproved
              }))
            });
            if (this._speciesHistory.length > 200)
              this._speciesHistory.shift();
          }
        }
      } catch {
      }
    }
    const fittest = Network3.fromJSON(this.population[0].toJSON());
    fittest.score = this.population[0].score;
    this._computeDiversityStats();
    try {
      const currentObjKeys = this._getObjectives().map(
        (obj) => obj.key
      );
      const dyn = this.options.multiObjective?.dynamic;
      if (this.options.multiObjective?.enabled) {
        if (dyn?.enabled) {
          const addC = dyn.addComplexityAt ?? Infinity;
          const addE = dyn.addEntropyAt ?? Infinity;
          if (this.generation + 1 >= addC && !currentObjKeys.includes("complexity")) {
            this.registerObjective(
              "complexity",
              "min",
              (genome) => genome.connections.length
            );
            this._pendingObjectiveAdds.push("complexity");
          }
          if (this.generation + 1 >= addE && !currentObjKeys.includes("entropy")) {
            this.registerObjective(
              "entropy",
              "max",
              (genome) => this._structuralEntropy(genome)
            );
            this._pendingObjectiveAdds.push("entropy");
          }
          if (currentObjKeys.includes("entropy") && dyn.dropEntropyOnStagnation != null) {
            const stagnGen = dyn.dropEntropyOnStagnation;
            if (this.generation >= stagnGen && !this._entropyDropped) {
              if (this.options.multiObjective?.objectives) {
                this.options.multiObjective.objectives = this.options.multiObjective.objectives.filter(
                  (obj) => obj.key !== "entropy"
                );
                this._objectivesList = void 0;
                this._pendingObjectiveRemoves.push("entropy");
                this._entropyDropped = this.generation;
              }
            }
          } else if (!currentObjKeys.includes("entropy") && this._entropyDropped && dyn.readdEntropyAfter != null) {
            if (this.generation - this._entropyDropped >= dyn.readdEntropyAfter) {
              this.registerObjective(
                "entropy",
                "max",
                (genome) => this._structuralEntropy(genome)
              );
              this._pendingObjectiveAdds.push("entropy");
              this._entropyDropped = void 0;
            }
          }
        } else if (this.options.multiObjective.autoEntropy) {
          const addAt = 3;
          if (this.generation >= addAt && !currentObjKeys.includes("entropy")) {
            this.registerObjective(
              "entropy",
              "max",
              (genome) => this._structuralEntropy(genome)
            );
            this._pendingObjectiveAdds.push("entropy");
          }
        }
      }
      for (const k of currentObjKeys)
        this._objectiveAges.set(k, (this._objectiveAges.get(k) || 0) + 1);
      for (const added of this._pendingObjectiveAdds)
        this._objectiveAges.set(added, 0);
    } catch {
    }
    try {
      const mo = this.options.multiObjective;
      if (mo?.enabled && mo.pruneInactive && mo.pruneInactive.enabled === false) {
        const keys = this._getObjectives().map((obj) => obj.key);
        if (keys.includes("fitness") && keys.length > 1 && !this._fitnessSuppressedOnce) {
          this._suppressFitnessObjective = true;
          this._fitnessSuppressedOnce = true;
          this._objectivesList = void 0;
        }
      }
    } catch {
    }
    let objImportance = null;
    try {
      const objsList = this._getObjectives();
      if (objsList.length) {
        objImportance = {};
        const pop = this.population;
        for (const obj of objsList) {
          const vals = pop.map((genome) => obj.accessor(genome));
          const min = Math.min(...vals);
          const max = Math.max(...vals);
          const mean = vals.reduce((a, b) => a + b, 0) / vals.length;
          const varV = vals.reduce(
            (a, b) => a + (b - mean) * (b - mean),
            0
          ) / (vals.length || 1);
          objImportance[obj.key] = { range: max - min, var: varV };
        }
        this._lastObjImportance = objImportance;
      }
    } catch {
    }
    if (this.options.telemetry?.enabled || true) {
      const telemetry = (init_neat_telemetry(), __toCommonJS(neat_telemetry_exports));
      const entry = telemetry.buildTelemetryEntry.call(this, fittest);
      telemetry.recordTelemetryEntry.call(this, entry);
    }
    if ((fittest.score ?? -Infinity) > this._bestGlobalScore) {
      this._bestGlobalScore = fittest.score ?? -Infinity;
      this._lastGlobalImproveGeneration = this.generation;
    }
    const newPopulation = [];
    const elitismCount = Math.max(
      0,
      Math.min(this.options.elitism || 0, this.population.length)
    );
    for (let i = 0; i < elitismCount; i++) {
      const elite = this.population[i];
      if (elite) newPopulation.push(elite);
    }
    const desiredPop = Math.max(0, this.options.popsize || 0);
    const remainingSlotsAfterElites = Math.max(
      0,
      desiredPop - newPopulation.length
    );
    const provenanceCount = Math.max(
      0,
      Math.min(this.options.provenance || 0, remainingSlotsAfterElites)
    );
    for (let i = 0; i < provenanceCount; i++) {
      if (this.options.network) {
        newPopulation.push(Network3.fromJSON(this.options.network.toJSON()));
      } else {
        newPopulation.push(
          new Network3(this.input, this.output, {
            minHidden: this.options.minHidden
          })
        );
      }
    }
    if (this.options.speciation && this._species.length > 0) {
      this._suppressTournamentError = true;
      const remaining = desiredPop - newPopulation.length;
      if (remaining > 0) {
        const ageCfg = this.options.speciesAgeBonus || {};
        const youngT = ageCfg.youngThreshold ?? 5;
        const youngM = ageCfg.youngMultiplier ?? 1.3;
        const oldT = ageCfg.oldThreshold ?? 30;
        const oldM = ageCfg.oldMultiplier ?? 0.7;
        const speciesAdjusted = this._species.map((species) => {
          const base = species.members.reduce(
            (a, member) => a + (member.score || 0),
            0
          );
          const age = this.generation - species.lastImproved;
          if (age <= youngT) return base * youngM;
          if (age >= oldT) return base * oldM;
          return base;
        });
        const totalAdj = speciesAdjusted.reduce((a, b) => a + b, 0) || 1;
        const minOff = this.options.speciesAllocation?.minOffspring ?? 1;
        const rawShares = this._species.map(
          (_, idx) => speciesAdjusted[idx] / totalAdj * remaining
        );
        const offspringAlloc = rawShares.map(
          (s) => Math.floor(s)
        );
        for (let i = 0; i < offspringAlloc.length; i++)
          if (offspringAlloc[i] < minOff && remaining >= this._species.length * minOff)
            offspringAlloc[i] = minOff;
        let allocated = offspringAlloc.reduce((a, b) => a + b, 0);
        let slotsLeft = remaining - allocated;
        const remainders = rawShares.map((s, i) => ({
          i,
          frac: s - Math.floor(s)
        }));
        remainders.sort((a, b) => b.frac - a.frac);
        for (const remainderEntry of remainders) {
          if (slotsLeft <= 0) break;
          offspringAlloc[remainderEntry.i]++;
          slotsLeft--;
        }
        if (slotsLeft < 0) {
          const order = offspringAlloc.map((v, i) => ({ i, v })).sort((a, b) => b.v - a.v);
          for (const orderEntry of order) {
            if (slotsLeft === 0) break;
            if (offspringAlloc[orderEntry.i] > minOff) {
              offspringAlloc[orderEntry.i]--;
              slotsLeft++;
            }
          }
        }
        this._lastOffspringAlloc = this._species.map(
          (species, i) => ({
            id: species.id,
            alloc: offspringAlloc[i] || 0
          })
        );
        this._prevInbreedingCount = this._lastInbreedingCount;
        this._lastInbreedingCount = 0;
        offspringAlloc.forEach((count, idx) => {
          if (count <= 0) return;
          const species = this._species[idx];
          this._sortSpeciesMembers(species);
          const survivors = species.members.slice(
            0,
            Math.max(
              1,
              Math.floor(
                species.members.length * (this.options.survivalThreshold || 0.5)
              )
            )
          );
          for (let k = 0; k < count; k++) {
            const parentA = survivors[Math.floor(this._getRNG()() * survivors.length)];
            let parentB;
            if (this.options.crossSpeciesMatingProb && this._species.length > 1 && this._getRNG()() < (this.options.crossSpeciesMatingProb || 0)) {
              let otherIdx = idx;
              let guard = 0;
              while (otherIdx === idx && guard++ < 5)
                otherIdx = Math.floor(this._getRNG()() * this._species.length);
              const otherSpecies = this._species[otherIdx];
              this._sortSpeciesMembers(otherSpecies);
              const otherParents = otherSpecies.members.slice(
                0,
                Math.max(
                  1,
                  Math.floor(
                    otherSpecies.members.length * (this.options.survivalThreshold || 0.5)
                  )
                )
              );
              parentB = otherParents[Math.floor(this._getRNG()() * otherParents.length)];
            } else {
              parentB = survivors[Math.floor(this._getRNG()() * survivors.length)];
            }
            const child = Network3.crossOver(
              parentA,
              parentB,
              this.options.equal || false
            );
            child._reenableProb = this.options.reenableProb;
            child._id = this._nextGenomeId++;
            if (this._lineageEnabled) {
              child._parents = [
                parentA._id,
                parentB._id
              ];
              const d1 = parentA._depth ?? 0;
              const d2 = parentB._depth ?? 0;
              child._depth = 1 + Math.max(d1, d2);
              if (parentA._id === parentB._id)
                this._lastInbreedingCount++;
            }
            newPopulation.push(child);
          }
        });
        this._suppressTournamentError = false;
      }
    } else {
      this._suppressTournamentError = true;
      const toBreed = Math.max(0, desiredPop - newPopulation.length);
      for (let i = 0; i < toBreed; i++) newPopulation.push(this.getOffspring());
      this._suppressTournamentError = false;
    }
    for (const genome of newPopulation) {
      if (!genome) continue;
      this.ensureMinHiddenNodes(genome);
      this.ensureNoDeadEnds(genome);
    }
    this.population = newPopulation;
    try {
      (init_neat_pruning(), __toCommonJS(neat_pruning_exports)).applyEvolutionPruning.call(this);
    } catch {
    }
    try {
      (init_neat_pruning(), __toCommonJS(neat_pruning_exports)).applyAdaptivePruning.call(this);
    } catch {
    }
    this.mutate();
    try {
      (init_neat_adaptive(), __toCommonJS(neat_adaptive_exports)).applyAdaptiveMutation.call(this);
    } catch {
    }
    this.population.forEach((genome) => {
      if (genome._compatCache) delete genome._compatCache;
    });
    this.population.forEach((genome) => genome.score = void 0);
    this.generation++;
    if (this.options.speciation) this._updateSpeciesStagnation();
    if ((this.options.globalStagnationGenerations || 0) > 0 && this.generation - this._lastGlobalImproveGeneration > (this.options.globalStagnationGenerations || 0)) {
      const replaceFraction = 0.2;
      const startIdx = Math.max(
        this.options.elitism || 0,
        Math.floor(this.population.length * (1 - replaceFraction))
      );
      for (let i = startIdx; i < this.population.length; i++) {
        const fresh = new Network3(this.input, this.output, {
          minHidden: this.options.minHidden
        });
        fresh.score = void 0;
        fresh._reenableProb = this.options.reenableProb;
        fresh._id = this._nextGenomeId++;
        if (this._lineageEnabled) {
          fresh._parents = [];
          fresh._depth = 0;
        }
        try {
          this.ensureMinHiddenNodes(fresh);
          this.ensureNoDeadEnds(fresh);
          const hiddenCount = fresh.nodes.filter((n) => n.type === "hidden").length;
          if (hiddenCount === 0) {
            const NodeCls = (init_node(), __toCommonJS(node_exports)).default;
            const newNode = new NodeCls("hidden");
            fresh.nodes.splice(fresh.nodes.length - fresh.output, 0, newNode);
            const inputNodes = fresh.nodes.filter((n) => n.type === "input");
            const outputNodes = fresh.nodes.filter(
              (n) => n.type === "output"
            );
            if (inputNodes.length && outputNodes.length) {
              try {
                fresh.connect(inputNodes[0], newNode, 1);
              } catch {
              }
              try {
                fresh.connect(newNode, outputNodes[0], 1);
              } catch {
              }
            }
          }
        } catch {
        }
        this.population[i] = fresh;
      }
      this._lastGlobalImproveGeneration = this.generation;
    }
    if (this.options.reenableProb !== void 0) {
      let reenableSuccessTotal = 0, reenableAttemptsTotal = 0;
      for (const genome of this.population) {
        reenableSuccessTotal += genome._reenableSuccess || 0;
        reenableAttemptsTotal += genome._reenableAttempts || 0;
        genome._reenableSuccess = 0;
        genome._reenableAttempts = 0;
      }
      if (reenableAttemptsTotal > 20) {
        const ratio = reenableSuccessTotal / reenableAttemptsTotal;
        const target = 0.3;
        const delta = ratio - target;
        this.options.reenableProb = Math.min(
          0.9,
          Math.max(0.05, this.options.reenableProb - delta * 0.1)
        );
      }
    }
    try {
      (init_neat_adaptive(), __toCommonJS(neat_adaptive_exports)).applyOperatorAdaptation.call(this);
    } catch {
    }
    const endTime = typeof performance !== "undefined" && performance.now ? performance.now() : Date.now();
    this._lastEvolveDuration = endTime - startTime;
    try {
      if (!this._speciesHistory) this._speciesHistory = [];
      if (!this.options.speciesAllocation?.extendedHistory) {
        if (this._speciesHistory.length === 0 || this._speciesHistory[this._speciesHistory.length - 1].generation !== this.generation) {
          this._speciesHistory.push({
            generation: this.generation,
            stats: this._species.map((species) => ({
              id: species.id,
              size: species.members.length,
              best: species.bestScore,
              lastImproved: species.lastImproved
            }))
          });
          if (this._speciesHistory.length > 200)
            this._speciesHistory.shift();
        }
      }
    } catch {
    }
    return fittest;
  }
  var init_neat_evolve = __esm({
    "src/neat/neat.evolve.ts"() {
      "use strict";
      init_network();
      init_neat_multiobjective();
    }
  });

  // src/neat/neat.evaluate.ts
  async function evaluate() {
    const options = this.options || {};
    if (options.fitnessPopulation) {
      if (options.clear)
        this.population.forEach((g) => g.clear && g.clear());
      await this.fitness(this.population);
    } else {
      for (const genome of this.population) {
        if (options.clear && genome.clear) genome.clear();
        const fitnessValue = await this.fitness(genome);
        genome.score = fitnessValue;
      }
    }
    try {
      const noveltyOptions = options.novelty;
      if (noveltyOptions?.enabled && typeof noveltyOptions.descriptor === "function") {
        const kNeighbors = Math.max(1, noveltyOptions.k || 3);
        const blendFactor = noveltyOptions.blendFactor ?? 0.3;
        const descriptors = this.population.map((g) => {
          try {
            return noveltyOptions.descriptor(g) || [];
          } catch {
            return [];
          }
        });
        const distanceMatrix = [];
        for (let i = 0; i < descriptors.length; i++) {
          distanceMatrix[i] = [];
          for (let j = 0; j < descriptors.length; j++) {
            if (i === j) {
              distanceMatrix[i][j] = 0;
              continue;
            }
            const descA = descriptors[i];
            const descB = descriptors[j];
            let sqSum = 0;
            const commonLen = Math.min(descA.length, descB.length);
            for (let t = 0; t < commonLen; t++) {
              const delta = (descA[t] || 0) - (descB[t] || 0);
              sqSum += delta * delta;
            }
            distanceMatrix[i][j] = Math.sqrt(sqSum);
          }
        }
        for (let i = 0; i < this.population.length; i++) {
          const sortedRow = distanceMatrix[i].toSorted((a, b) => a - b);
          const neighbours = sortedRow.slice(1, kNeighbors + 1);
          const novelty = neighbours.length ? neighbours.reduce((a, b) => a + b, 0) / neighbours.length : 0;
          this.population[i]._novelty = novelty;
          if (typeof this.population[i].score === "number") {
            this.population[i].score = (1 - blendFactor) * this.population[i].score + blendFactor * novelty;
          }
          if (!this._noveltyArchive) this._noveltyArchive = [];
          const archiveAddThreshold = noveltyOptions.archiveAddThreshold ?? Infinity;
          if (noveltyOptions.archiveAddThreshold === 0 || novelty > archiveAddThreshold) {
            if (this._noveltyArchive.length < 200)
              this._noveltyArchive.push({ desc: descriptors[i], novelty });
          }
        }
      }
    } catch {
    }
    if (!this._diversityStats) this._diversityStats = {};
    try {
      const entropySharingOptions = options.entropySharingTuning;
      if (entropySharingOptions?.enabled) {
        const targetVar = entropySharingOptions.targetEntropyVar ?? 0.2;
        const adjustRate = entropySharingOptions.adjustRate ?? 0.1;
        const minSigma = entropySharingOptions.minSigma ?? 0.1;
        const maxSigma = entropySharingOptions.maxSigma ?? 10;
        const currentVarEntropy = this._diversityStats.varEntropy;
        if (typeof currentVarEntropy === "number") {
          let sigma = this.options.sharingSigma ?? 0;
          if (currentVarEntropy < targetVar * 0.9)
            sigma = Math.max(minSigma, sigma * (1 - adjustRate));
          else if (currentVarEntropy > targetVar * 1.1)
            sigma = Math.min(maxSigma, sigma * (1 + adjustRate));
          this.options.sharingSigma = sigma;
        }
      }
    } catch {
    }
    try {
      const entropyCompatOptions = options.entropyCompatTuning;
      if (entropyCompatOptions?.enabled) {
        const meanEntropy = this._diversityStats.meanEntropy;
        const targetEntropy = entropyCompatOptions.targetEntropy ?? 0.5;
        const deadband = entropyCompatOptions.deadband ?? 0.05;
        const adjustRate = entropyCompatOptions.adjustRate ?? 0.05;
        let threshold = this.options.compatibilityThreshold ?? 3;
        if (typeof meanEntropy === "number") {
          if (meanEntropy < targetEntropy - deadband)
            threshold = Math.max(
              entropyCompatOptions.minThreshold ?? 0.5,
              threshold * (1 - adjustRate)
            );
          else if (meanEntropy > targetEntropy + deadband)
            threshold = Math.min(
              entropyCompatOptions.maxThreshold ?? 10,
              threshold * (1 + adjustRate)
            );
          this.options.compatibilityThreshold = threshold;
        }
      }
    } catch {
    }
    try {
      if (this.options.speciation && (this.options.targetSpecies || this.options.compatAdjust || this.options.speciesAllocation?.extendedHistory)) {
        this._speciate();
      }
    } catch {
    }
    try {
      const autoDistanceCoeffOptions = this.options.autoDistanceCoeffTuning;
      if (autoDistanceCoeffOptions?.enabled && this.options.speciation) {
        const connectionSizes = this.population.map(
          (g) => g.connections.length
        );
        const meanSize = connectionSizes.reduce((a, b) => a + b, 0) / (connectionSizes.length || 1);
        const connVar = connectionSizes.reduce(
          (a, b) => a + (b - meanSize) * (b - meanSize),
          0
        ) / (connectionSizes.length || 1);
        const adjustRate = autoDistanceCoeffOptions.adjustRate ?? 0.05;
        const minCoeff = autoDistanceCoeffOptions.minCoeff ?? 0.05;
        const maxCoeff = autoDistanceCoeffOptions.maxCoeff ?? 8;
        if (this._lastConnVar === void 0 || this._lastConnVar === null) {
          this._lastConnVar = connVar;
          try {
            this.options.excessCoeff = Math.min(
              maxCoeff,
              (this.options.excessCoeff ?? 1) * (1 + adjustRate)
            );
            this.options.disjointCoeff = Math.min(
              maxCoeff,
              (this.options.disjointCoeff ?? 1) * (1 + adjustRate)
            );
          } catch {
          }
        }
        if (connVar < this._lastConnVar * 0.95) {
          this.options.excessCoeff = Math.min(
            maxCoeff,
            this.options.excessCoeff * (1 + adjustRate)
          );
          this.options.disjointCoeff = Math.min(
            maxCoeff,
            this.options.disjointCoeff * (1 + adjustRate)
          );
        } else if (connVar > this._lastConnVar * 1.05) {
          this.options.excessCoeff = Math.max(
            minCoeff,
            this.options.excessCoeff * (1 - adjustRate)
          );
          this.options.disjointCoeff = Math.max(
            minCoeff,
            this.options.disjointCoeff * (1 - adjustRate)
          );
        }
        this._lastConnVar = connVar;
      }
    } catch {
    }
    try {
      if (this.options.multiObjective?.enabled && this.options.multiObjective.autoEntropy) {
        if (!this.options.multiObjective.dynamic?.enabled) {
          const keys = this._getObjectives().map((o) => o.key);
          if (!keys.includes("entropy")) {
            this.registerObjective(
              "entropy",
              "max",
              (g) => this._structuralEntropy(g)
            );
            this._pendingObjectiveAdds.push("entropy");
            this._objectivesList = void 0;
          }
        }
      }
    } catch {
    }
  }
  var init_neat_evaluate = __esm({
    "src/neat/neat.evaluate.ts"() {
      "use strict";
    }
  });

  // src/neat/neat.helpers.ts
  function spawnFromParent(parentGenome, mutateCount = 1) {
    const clone = parentGenome.clone ? parentGenome.clone() : (init_network(), __toCommonJS(network_exports)).default.fromJSON(
      parentGenome.toJSON()
    );
    clone.score = void 0;
    clone._reenableProb = this.options.reenableProb;
    clone._id = this._nextGenomeId++;
    clone._parents = [parentGenome._id];
    clone._depth = (parentGenome._depth ?? 0) + 1;
    this.ensureMinHiddenNodes(clone);
    this.ensureNoDeadEnds(clone);
    for (let mutationIndex = 0; mutationIndex < mutateCount; mutationIndex++) {
      try {
        let selectedMutationMethod = this.selectMutationMethod(
          clone,
          false
        );
        if (Array.isArray(selectedMutationMethod)) {
          const candidateMutations = selectedMutationMethod;
          selectedMutationMethod = candidateMutations[Math.floor(this._getRNG()() * candidateMutations.length)];
        }
        if (selectedMutationMethod && selectedMutationMethod.name) {
          clone.mutate(selectedMutationMethod);
        }
      } catch {
      }
    }
    this._invalidateGenomeCaches(clone);
    return clone;
  }
  function addGenome(genome, parents) {
    try {
      genome.score = void 0;
      genome._reenableProb = this.options.reenableProb;
      genome._id = this._nextGenomeId++;
      genome._parents = Array.isArray(parents) ? parents.slice() : [];
      genome._depth = 0;
      if (genome._parents.length) {
        const parentDepths = genome._parents.map(
          (pid) => this.population.find((g) => g._id === pid)
        ).filter(Boolean).map((g) => g._depth ?? 0);
        genome._depth = parentDepths.length ? Math.max(...parentDepths) + 1 : 1;
      }
      this.ensureMinHiddenNodes(genome);
      this.ensureNoDeadEnds(genome);
      this._invalidateGenomeCaches(genome);
      this.population.push(genome);
    } catch (error) {
      this.population.push(genome);
    }
  }
  function createPool(seedNetwork) {
    try {
      this.population = [];
      const poolSize = this.options?.popsize || 50;
      for (let genomeIndex = 0; genomeIndex < poolSize; genomeIndex++) {
        const genomeCopy = seedNetwork ? Network3.fromJSON(seedNetwork.toJSON()) : new Network3(this.input, this.output, {
          minHidden: this.options?.minHidden
        });
        genomeCopy.score = void 0;
        try {
          this.ensureNoDeadEnds(genomeCopy);
        } catch {
        }
        genomeCopy._reenableProb = this.options.reenableProb;
        genomeCopy._id = this._nextGenomeId++;
        if (this._lineageEnabled) {
          genomeCopy._parents = [];
          genomeCopy._depth = 0;
        }
        this.population.push(genomeCopy);
      }
    } catch {
    }
  }
  var init_neat_helpers = __esm({
    "src/neat/neat.helpers.ts"() {
      "use strict";
      init_network();
    }
  });

  // src/neat/neat.objectives.ts
  function _getObjectives() {
    if (this._objectivesList) return this._objectivesList;
    const objectivesList = [];
    if (!this._suppressFitnessObjective) {
      objectivesList.push({
        key: "fitness",
        direction: "max",
        /**
         * Default accessor extracts the `score` property from a genome.
         *
         * @example
         * ```ts
         * // genome.score is used as the fitness metric by default
         * const value = defaultAccessor(genome);
         * ```
         */
        accessor: (genome) => genome.score || 0
      });
    }
    if (this.options.multiObjective?.enabled && Array.isArray(this.options.multiObjective.objectives)) {
      for (const candidateObjective of this.options.multiObjective.objectives) {
        if (!candidateObjective || !candidateObjective.key || typeof candidateObjective.accessor !== "function")
          continue;
        objectivesList.push(candidateObjective);
      }
    }
    this._objectivesList = objectivesList;
    return objectivesList;
  }
  function registerObjective(key, direction, accessor) {
    if (!this.options.multiObjective)
      this.options.multiObjective = { enabled: true };
    const multiObjectiveOptions = this.options.multiObjective;
    if (!multiObjectiveOptions.objectives) multiObjectiveOptions.objectives = [];
    multiObjectiveOptions.objectives = multiObjectiveOptions.objectives.filter(
      (existingObjective) => existingObjective.key !== key
    );
    multiObjectiveOptions.objectives.push({ key, direction, accessor });
    this._objectivesList = void 0;
  }
  function clearObjectives() {
    if (this.options.multiObjective?.objectives)
      this.options.multiObjective.objectives = [];
    this._objectivesList = void 0;
  }
  var init_neat_objectives = __esm({
    "src/neat/neat.objectives.ts"() {
      "use strict";
    }
  });

  // src/neat/neat.diversity.ts
  function structuralEntropy2(graph) {
    const outDegrees = graph.nodes.map(
      (node) => (
        // each node exposes connections.out array in current architecture
        node.connections.out.length
      )
    );
    const totalOut = outDegrees.reduce((acc, v) => acc + v, 0) || 1;
    const probabilities = outDegrees.map((d) => d / totalOut).filter((p) => p > 0);
    let entropy = 0;
    for (const p of probabilities) {
      entropy -= p * Math.log(p);
    }
    return entropy;
  }
  function arrayMean(values) {
    if (!values.length) return 0;
    return values.reduce((sum, v) => sum + v, 0) / values.length;
  }
  function arrayVariance(values) {
    if (!values.length) return 0;
    const m = arrayMean(values);
    return arrayMean(values.map((v) => (v - m) * (v - m)));
  }
  function computeDiversityStats2(population, compatibilityComputer) {
    if (!population.length) return void 0;
    const lineageDepths = [];
    for (const genome of population) {
      if (typeof genome._depth === "number") {
        lineageDepths.push(genome._depth);
      }
    }
    const lineageMeanDepth = arrayMean(lineageDepths);
    let depthPairAbsDiffSum = 0;
    let depthPairCount = 0;
    for (let i = 0; i < lineageDepths.length && i < 30; i++) {
      for (let j = i + 1; j < lineageDepths.length && j < 30; j++) {
        depthPairAbsDiffSum += Math.abs(lineageDepths[i] - lineageDepths[j]);
        depthPairCount++;
      }
    }
    const lineageMeanPairDist = depthPairCount ? depthPairAbsDiffSum / depthPairCount : 0;
    const nodeCounts = population.map((g) => g.nodes.length);
    const connectionCounts = population.map((g) => g.connections.length);
    const meanNodes = arrayMean(nodeCounts);
    const meanConns = arrayMean(connectionCounts);
    const nodeVar = arrayVariance(nodeCounts);
    const connVar = arrayVariance(connectionCounts);
    let compatSum = 0;
    let compatPairCount = 0;
    for (let i = 0; i < population.length && i < 25; i++) {
      for (let j = i + 1; j < population.length && j < 25; j++) {
        compatSum += compatibilityComputer._compatibilityDistance(
          population[i],
          population[j]
        );
        compatPairCount++;
      }
    }
    const meanCompat = compatPairCount ? compatSum / compatPairCount : 0;
    const graphletEntropy = arrayMean(
      population.map((g) => structuralEntropy2(g))
    );
    return {
      lineageMeanDepth,
      lineageMeanPairDist,
      meanNodes,
      meanConns,
      nodeVar,
      connVar,
      meanCompat,
      graphletEntropy,
      population: population.length
    };
  }
  var init_neat_diversity = __esm({
    "src/neat/neat.diversity.ts"() {
      "use strict";
      init_network();
    }
  });

  // src/neat/neat.compat.ts
  function _fallbackInnov(connection) {
    const fromIndex = connection.from?.index ?? 0;
    const toIndex = connection.to?.index ?? 0;
    return fromIndex * 1e5 + toIndex;
  }
  function _compatibilityDistance(genomeA, genomeB) {
    if (!this._compatCacheGen || this._compatCacheGen !== this.generation) {
      this._compatCacheGen = this.generation;
      this._compatDistCache = /* @__PURE__ */ new Map();
    }
    const key = genomeA._id < genomeB._id ? `${genomeA._id}|${genomeB._id}` : `${genomeB._id}|${genomeA._id}`;
    const cacheMap = this._compatDistCache;
    if (cacheMap.has(key)) return cacheMap.get(key);
    const getCache = (network) => {
      if (!network._compatCache) {
        const list = network.connections.map((conn) => [
          conn.innovation ?? this._fallbackInnov(conn),
          conn.weight
        ]);
        list.sort((x, y) => x[0] - y[0]);
        network._compatCache = list;
      }
      return network._compatCache;
    };
    const aList = getCache(genomeA);
    const bList = getCache(genomeB);
    let indexA = 0, indexB = 0;
    let matchingCount = 0, disjoint = 0, excess = 0;
    let weightDifferenceSum = 0;
    const maxInnovA = aList.length ? aList[aList.length - 1][0] : 0;
    const maxInnovB = bList.length ? bList[bList.length - 1][0] : 0;
    while (indexA < aList.length && indexB < bList.length) {
      const [innovA, weightA] = aList[indexA];
      const [innovB, weightB] = bList[indexB];
      if (innovA === innovB) {
        matchingCount++;
        weightDifferenceSum += Math.abs(weightA - weightB);
        indexA++;
        indexB++;
      } else if (innovA < innovB) {
        if (innovA > maxInnovB) excess++;
        else disjoint++;
        indexA++;
      } else {
        if (innovB > maxInnovA) excess++;
        else disjoint++;
        indexB++;
      }
    }
    if (indexA < aList.length) excess += aList.length - indexA;
    if (indexB < bList.length) excess += bList.length - indexB;
    const N = Math.max(1, Math.max(aList.length, bList.length));
    const avgWeightDiff = matchingCount ? weightDifferenceSum / matchingCount : 0;
    const opts = this.options;
    const dist = opts.excessCoeff * excess / N + opts.disjointCoeff * disjoint / N + opts.weightDiffCoeff * avgWeightDiff;
    cacheMap.set(key, dist);
    return dist;
  }
  var init_neat_compat = __esm({
    "src/neat/neat.compat.ts"() {
      "use strict";
    }
  });

  // src/neat/neat.speciation.ts
  function _speciate() {
    this._prevSpeciesMembers.clear();
    for (const species of this._species) {
      const prevMemberSet = /* @__PURE__ */ new Set();
      for (const member of species.members)
        prevMemberSet.add(member._id);
      this._prevSpeciesMembers.set(species.id, prevMemberSet);
    }
    this._species.forEach((species) => species.members = []);
    for (const genome of this.population) {
      let assignedToExisting = false;
      for (const species of this._species) {
        const compatDist = this._compatibilityDistance(
          genome,
          species.representative
        );
        if (compatDist < (this.options.compatibilityThreshold || 3)) {
          species.members.push(genome);
          assignedToExisting = true;
          break;
        }
      }
      if (!assignedToExisting) {
        const speciesId = this._nextSpeciesId++;
        this._species.push({
          id: speciesId,
          members: [genome],
          representative: genome,
          lastImproved: this.generation,
          bestScore: genome.score || -Infinity
        });
        this._speciesCreated.set(speciesId, this.generation);
      }
    }
    this._species = this._species.filter(
      (species) => species.members.length > 0
    );
    this._species.forEach((species) => {
      species.representative = species.members[0];
    });
    const ageProtection = this.options.speciesAgeProtection || {
      grace: 3,
      oldPenalty: 0.5
    };
    for (const species of this._species) {
      const createdGen = this._speciesCreated.get(species.id) ?? this.generation;
      const speciesAge = this.generation - createdGen;
      if (speciesAge >= (ageProtection.grace ?? 3) * 10) {
        const penalty = ageProtection.oldPenalty ?? 0.5;
        if (penalty < 1)
          species.members.forEach((member) => {
            if (typeof member.score === "number") member.score *= penalty;
          });
      }
    }
    if (this.options.speciation && (this.options.targetSpecies || 0) > 0) {
      const targetSpeciesCount = this.options.targetSpecies;
      const observedSpeciesCount = this._species.length;
      const adjustConfig = this.options.compatAdjust;
      const smoothingWindow = Math.max(1, adjustConfig.smoothingWindow || 1);
      const alpha = 2 / (smoothingWindow + 1);
      this._compatSpeciesEMA = this._compatSpeciesEMA === void 0 ? observedSpeciesCount : this._compatSpeciesEMA + alpha * (observedSpeciesCount - this._compatSpeciesEMA);
      const smoothedSpecies = this._compatSpeciesEMA;
      const speciesError = targetSpeciesCount - smoothedSpecies;
      this._compatIntegral = this._compatIntegral * (adjustConfig.decay || 0.95) + speciesError;
      const delta = (adjustConfig.kp || 0) * speciesError + (adjustConfig.ki || 0) * this._compatIntegral;
      let newThreshold = (this.options.compatibilityThreshold || 3) - delta;
      const minThreshold = adjustConfig.minThreshold || 0.5;
      const maxThreshold = adjustConfig.maxThreshold || 10;
      if (newThreshold < minThreshold) {
        newThreshold = minThreshold;
        this._compatIntegral = 0;
      }
      if (newThreshold > maxThreshold) {
        newThreshold = maxThreshold;
        this._compatIntegral = 0;
      }
      this.options.compatibilityThreshold = newThreshold;
    }
    if (this.options.autoCompatTuning?.enabled) {
      const autoTarget = this.options.autoCompatTuning.target ?? this.options.targetSpecies ?? Math.max(2, Math.round(Math.sqrt(this.population.length)));
      const observedForTuning = this._species.length || 1;
      const tuningError = autoTarget - observedForTuning;
      const adjustRate = this.options.autoCompatTuning.adjustRate ?? 0.01;
      const minCoeff = this.options.autoCompatTuning.minCoeff ?? 0.1;
      const maxCoeff = this.options.autoCompatTuning.maxCoeff ?? 5;
      const factor = 1 - adjustRate * Math.sign(tuningError);
      let effectiveFactor = factor;
      if (tuningError === 0) {
        effectiveFactor = 1 + (this._getRNG()() - 0.5) * adjustRate * 0.5;
      }
      this.options.excessCoeff = Math.min(
        maxCoeff,
        Math.max(minCoeff, this.options.excessCoeff * effectiveFactor)
      );
      this.options.disjointCoeff = Math.min(
        maxCoeff,
        Math.max(minCoeff, this.options.disjointCoeff * effectiveFactor)
      );
    }
    if (this.options.speciesAllocation?.extendedHistory) {
      const stats = this._species.map((species) => {
        const sizes = species.members.map((member) => ({
          nodes: member.nodes.length,
          conns: member.connections.length,
          score: member.score || 0,
          nov: member._novelty || 0,
          ent: this._structuralEntropy(member)
        }));
        const avg = (arr) => arr.length ? arr.reduce((a, b) => a + b, 0) / arr.length : 0;
        let compatSum = 0;
        let compatCount = 0;
        for (let i = 0; i < species.members.length && i < 10; i++)
          for (let j = i + 1; j < species.members.length && j < 10; j++) {
            compatSum += this._compatibilityDistance(
              species.members[i],
              species.members[j]
            );
            compatCount++;
          }
        const meanCompat = compatCount ? compatSum / compatCount : 0;
        const last = this._speciesLastStats.get(species.id);
        const meanNodes = avg(sizes.map((s) => s.nodes));
        const meanConns = avg(sizes.map((s) => s.conns));
        const deltaMeanNodes = last ? meanNodes - last.meanNodes : 0;
        const deltaMeanConns = last ? meanConns - last.meanConns : 0;
        const deltaBestScore = last ? species.bestScore - last.best : 0;
        const createdGen = this._speciesCreated.get(species.id) ?? this.generation;
        const speciesAge = this.generation - createdGen;
        let turnoverRate = 0;
        const prevSet = this._prevSpeciesMembers.get(species.id);
        if (prevSet && species.members.length) {
          let newCount = 0;
          for (const member of species.members)
            if (!prevSet.has(member._id)) newCount++;
          turnoverRate = newCount / species.members.length;
        }
        const varCalc = (arr) => {
          if (!arr.length) return 0;
          const mean = avg(arr);
          return avg(arr.map((v) => (v - mean) * (v - mean)));
        };
        const varNodes = varCalc(sizes.map((s) => s.nodes));
        const varConns = varCalc(sizes.map((s) => s.conns));
        let innovSum = 0;
        let innovCount = 0;
        let maxInnov = -Infinity;
        let minInnov = Infinity;
        let enabled = 0;
        let disabled = 0;
        for (const member of species.members)
          for (const conn of member.connections) {
            const innov = conn.innovation ?? this._fallbackInnov(conn);
            innovSum += innov;
            innovCount++;
            if (innov > maxInnov) maxInnov = innov;
            if (innov < minInnov) minInnov = innov;
            if (conn.enabled === false) disabled++;
            else enabled++;
          }
        const meanInnovation = innovCount ? innovSum / innovCount : 0;
        const innovationRange = isFinite(maxInnov) && isFinite(minInnov) && maxInnov > minInnov ? maxInnov - minInnov : 0;
        const enabledRatio = enabled + disabled > 0 ? enabled / (enabled + disabled) : 0;
        return {
          id: species.id,
          size: species.members.length,
          best: species.bestScore,
          lastImproved: species.lastImproved,
          age: speciesAge,
          meanNodes,
          meanConns,
          meanScore: avg(sizes.map((s) => s.score)),
          meanNovelty: avg(sizes.map((s) => s.nov)),
          meanCompat,
          meanEntropy: avg(sizes.map((s) => s.ent)),
          varNodes,
          varConns,
          deltaMeanNodes,
          deltaMeanConns,
          deltaBestScore,
          turnoverRate,
          meanInnovation,
          innovationRange,
          enabledRatio
        };
      });
      for (const st of stats)
        this._speciesLastStats.set(st.id, {
          meanNodes: st.meanNodes,
          meanConns: st.meanConns,
          best: st.best
        });
      this._speciesHistory.push({ generation: this.generation, stats });
    } else {
      this._speciesHistory.push({
        generation: this.generation,
        stats: this._species.map((species) => ({
          id: species.id,
          size: species.members.length,
          best: species.bestScore,
          lastImproved: species.lastImproved
        }))
      });
    }
    if (this._speciesHistory.length > 200) this._speciesHistory.shift();
  }
  function _applyFitnessSharing() {
    const sharingSigma = this.options.sharingSigma || 0;
    if (sharingSigma > 0) {
      this._species.forEach((species) => {
        const members = species.members;
        for (let i = 0; i < members.length; i++) {
          const memberI = members[i];
          if (typeof memberI.score !== "number") continue;
          let shareSum = 0;
          for (let j = 0; j < members.length; j++) {
            const memberJ = members[j];
            const dist = i === j ? 0 : this._compatibilityDistance(memberI, memberJ);
            if (dist < sharingSigma) {
              const ratio = dist / sharingSigma;
              shareSum += 1 - ratio * ratio;
            }
          }
          if (shareSum <= 0) shareSum = 1;
          memberI.score = memberI.score / shareSum;
        }
      });
    } else {
      this._species.forEach((species) => {
        const size = species.members.length;
        species.members.forEach((member) => {
          if (typeof member.score === "number")
            member.score = member.score / size;
        });
      });
    }
  }
  function _sortSpeciesMembers(sp) {
    sp.members.sort((a, b) => (b.score || 0) - (a.score || 0));
  }
  function _updateSpeciesStagnation() {
    const stagnationWindow = this.options.stagnationGenerations || 15;
    this._species.forEach((species) => {
      this._sortSpeciesMembers(species);
      const top = species.members[0];
      if ((top.score || -Infinity) > species.bestScore) {
        species.bestScore = top.score || -Infinity;
        species.lastImproved = this.generation;
      }
    });
    const survivors = this._species.filter(
      (species) => this.generation - species.lastImproved <= stagnationWindow
    );
    if (survivors.length) this._species = survivors;
  }
  var init_neat_speciation = __esm({
    "src/neat/neat.speciation.ts"() {
      "use strict";
    }
  });

  // src/neat/neat.species.ts
  function getSpeciesStats() {
    const speciesArray = this._species;
    return speciesArray.map((species) => ({
      id: species.id,
      size: species.members.length,
      bestScore: species.bestScore,
      lastImproved: species.lastImproved
    }));
  }
  function getSpeciesHistory() {
    const speciesHistory = this._speciesHistory;
    if (this.options?.speciesAllocation?.extendedHistory) {
      for (const generationEntry of speciesHistory) {
        for (const speciesStat of generationEntry.stats) {
          if ("innovationRange" in speciesStat && "enabledRatio" in speciesStat)
            continue;
          const speciesObj = this._species.find(
            (s) => s.id === speciesStat.id
          );
          if (speciesObj && speciesObj.members && speciesObj.members.length) {
            let maxInnovation = -Infinity;
            let minInnovation = Infinity;
            let enabledCount = 0;
            let disabledCount = 0;
            for (const member of speciesObj.members) {
              for (const connection of member.connections) {
                const innovationId = connection.innovation ?? this._fallbackInnov?.(connection) ?? 0;
                if (innovationId > maxInnovation) maxInnovation = innovationId;
                if (innovationId < minInnovation) minInnovation = innovationId;
                if (connection.enabled === false) disabledCount++;
                else enabledCount++;
              }
            }
            speciesStat.innovationRange = isFinite(maxInnovation) && isFinite(minInnovation) && maxInnovation > minInnovation ? maxInnovation - minInnovation : 0;
            speciesStat.enabledRatio = enabledCount + disabledCount ? enabledCount / (enabledCount + disabledCount) : 0;
          }
        }
      }
    }
    return speciesHistory;
  }
  var init_neat_species = __esm({
    "src/neat/neat.species.ts"() {
      "use strict";
    }
  });

  // src/neat/neat.telemetry.exports.ts
  function exportTelemetryJSONL() {
    return this._telemetry.map((entry) => JSON.stringify(entry)).join("\n");
  }
  function exportTelemetryCSV(maxEntries = 500) {
    const recentTelemetry = Array.isArray(this._telemetry) ? this._telemetry.slice(-maxEntries) : [];
    if (!recentTelemetry.length) return "";
    const headerInfo = collectTelemetryHeaderInfo(recentTelemetry);
    const headers = buildTelemetryHeaders(headerInfo);
    const csvLines = [headers.join(",")];
    for (const telemetryEntry of recentTelemetry) {
      csvLines.push(serializeTelemetryEntry(telemetryEntry, headers));
    }
    return csvLines.join("\n");
  }
  function collectTelemetryHeaderInfo(entries) {
    const baseKeys = /* @__PURE__ */ new Set();
    const complexityKeys = /* @__PURE__ */ new Set();
    const perfKeys = /* @__PURE__ */ new Set();
    const lineageKeys = /* @__PURE__ */ new Set();
    const diversityLineageKeys = /* @__PURE__ */ new Set();
    let includeOps = false;
    let includeObjectives = false;
    let includeObjAges = false;
    let includeSpeciesAlloc = false;
    let includeObjEvents = false;
    let includeObjImportance = false;
    for (const entry of entries) {
      Object.keys(entry).forEach((k) => {
        if (k !== "complexity" && k !== "perf" && k !== "ops" && k !== HEADER_FRONTS) {
          baseKeys.add(k);
        }
      });
      if (Array.isArray(entry.fronts)) baseKeys.add(HEADER_FRONTS);
      if (entry.complexity)
        Object.keys(entry.complexity).forEach((k) => complexityKeys.add(k));
      if (entry.perf) Object.keys(entry.perf).forEach((k) => perfKeys.add(k));
      if (entry.lineage)
        Object.keys(entry.lineage).forEach((k) => lineageKeys.add(k));
      if (entry.diversity) {
        if ("lineageMeanDepth" in entry.diversity)
          diversityLineageKeys.add("lineageMeanDepth");
        if ("lineageMeanPairDist" in entry.diversity)
          diversityLineageKeys.add("lineageMeanPairDist");
      }
      if ("rng" in entry) baseKeys.add("rng");
      if (Array.isArray(entry.ops) && entry.ops.length) includeOps = true;
      if (Array.isArray(entry.objectives)) includeObjectives = true;
      if (entry.objAges) includeObjAges = true;
      if (Array.isArray(entry.speciesAlloc)) includeSpeciesAlloc = true;
      if (Array.isArray(entry.objEvents) && entry.objEvents.length)
        includeObjEvents = true;
      if (entry.objImportance) includeObjImportance = true;
    }
    return {
      baseKeys,
      complexityKeys,
      perfKeys,
      lineageKeys,
      diversityLineageKeys,
      includeOps,
      includeObjectives,
      includeObjAges,
      includeSpeciesAlloc,
      includeObjEvents,
      includeObjImportance
    };
  }
  function buildTelemetryHeaders(info) {
    const headers = [
      ...info.baseKeys,
      ...[...info.complexityKeys].map((k) => `${COMPLEXITY_PREFIX}${k}`),
      ...[...info.perfKeys].map((k) => `${PERF_PREFIX}${k}`),
      ...[...info.lineageKeys].map((k) => `${LINEAGE_PREFIX}${k}`),
      ...[...info.diversityLineageKeys].map((k) => `${DIVERSITY_PREFIX}${k}`)
    ];
    if (info.includeOps) headers.push(HEADER_OPS);
    if (info.includeObjectives) headers.push(HEADER_OBJECTIVES);
    if (info.includeObjAges) headers.push(HEADER_OBJ_AGES);
    if (info.includeSpeciesAlloc) headers.push(HEADER_SPECIES_ALLOC);
    if (info.includeObjEvents) headers.push(HEADER_OBJ_EVENTS);
    if (info.includeObjImportance) headers.push(HEADER_OBJ_IMPORTANCE);
    return headers;
  }
  function serializeTelemetryEntry(entry, headers) {
    const row = [];
    for (const header of headers) {
      switch (true) {
        // Grouped complexity metrics
        case header.startsWith(COMPLEXITY_PREFIX): {
          const key = header.slice(COMPLEXITY_PREFIX.length);
          row.push(
            entry.complexity && key in entry.complexity ? JSON.stringify(entry.complexity[key]) : ""
          );
          break;
        }
        // Grouped performance metrics
        case header.startsWith(PERF_PREFIX): {
          const key = header.slice(PERF_PREFIX.length);
          row.push(
            entry.perf && key in entry.perf ? JSON.stringify(entry.perf[key]) : ""
          );
          break;
        }
        // Grouped lineage metrics
        case header.startsWith(LINEAGE_PREFIX): {
          const key = header.slice(LINEAGE_PREFIX.length);
          row.push(
            entry.lineage && key in entry.lineage ? JSON.stringify(entry.lineage[key]) : ""
          );
          break;
        }
        // Grouped diversity metrics
        case header.startsWith(DIVERSITY_PREFIX): {
          const key = header.slice(DIVERSITY_PREFIX.length);
          row.push(
            entry.diversity && key in entry.diversity ? JSON.stringify(entry.diversity[key]) : ""
          );
          break;
        }
        // Array-like and optional multi-value columns
        case header === HEADER_FRONTS: {
          row.push(
            Array.isArray(entry.fronts) ? JSON.stringify(entry.fronts) : ""
          );
          break;
        }
        case header === HEADER_OPS: {
          row.push(Array.isArray(entry.ops) ? JSON.stringify(entry.ops) : "");
          break;
        }
        case header === HEADER_OBJECTIVES: {
          row.push(
            Array.isArray(entry.objectives) ? JSON.stringify(entry.objectives) : ""
          );
          break;
        }
        case header === HEADER_OBJ_AGES: {
          row.push(entry.objAges ? JSON.stringify(entry.objAges) : "");
          break;
        }
        case header === HEADER_SPECIES_ALLOC: {
          row.push(
            Array.isArray(entry.speciesAlloc) ? JSON.stringify(entry.speciesAlloc) : ""
          );
          break;
        }
        case header === HEADER_OBJ_EVENTS: {
          row.push(
            Array.isArray(entry.objEvents) ? JSON.stringify(entry.objEvents) : ""
          );
          break;
        }
        case header === HEADER_OBJ_IMPORTANCE: {
          row.push(
            entry.objImportance ? JSON.stringify(entry.objImportance) : ""
          );
          break;
        }
        // Default: treat as top-level column
        default: {
          row.push(JSON.stringify(entry[header]));
          break;
        }
      }
    }
    return row.join(",");
  }
  function exportSpeciesHistoryCSV(maxEntries = 200) {
    if (!Array.isArray(this._speciesHistory)) this._speciesHistory = [];
    if (!this._speciesHistory.length && Array.isArray(this._species) && this._species.length) {
      const stats = this._species.map((sp) => ({
        /** Unique identifier for the species (or -1 when missing). */
        id: sp.id ?? -1,
        /** Current size (number of members) in the species. */
        size: Array.isArray(sp.members) ? sp.members.length : 0,
        /** Best score observed in the species (fallback 0). */
        best: sp.bestScore ?? 0,
        /** Generation index when the species last improved (fallback 0). */
        lastImproved: sp.lastImproved ?? 0
      }));
      this._speciesHistory.push({ generation: this.generation || 0, stats });
    }
    const recentHistory = this._speciesHistory.slice(-maxEntries);
    if (!recentHistory.length) {
      return "generation,id,size,best,lastImproved";
    }
    const headerKeySet = /* @__PURE__ */ new Set(["generation"]);
    for (const entry of recentHistory)
      for (const speciesStat of entry.stats)
        Object.keys(speciesStat).forEach((k) => headerKeySet.add(k));
    const headers = Array.from(headerKeySet);
    return buildSpeciesHistoryCsv(recentHistory, headers);
  }
  function buildSpeciesHistoryCsv(recentHistory, headers) {
    const lines = [headers.join(",")];
    for (const historyEntry of recentHistory) {
      for (const speciesStat of historyEntry.stats) {
        const rowCells = [];
        for (const header of headers) {
          if (header === HEADER_GENERATION) {
            rowCells.push(JSON.stringify(historyEntry.generation));
            continue;
          }
          rowCells.push(JSON.stringify(speciesStat[header]));
        }
        lines.push(rowCells.join(","));
      }
    }
    return lines.join("\n");
  }
  var COMPLEXITY_PREFIX, PERF_PREFIX, LINEAGE_PREFIX, DIVERSITY_PREFIX, HEADER_FRONTS, HEADER_OPS, HEADER_OBJECTIVES, HEADER_OBJ_AGES, HEADER_SPECIES_ALLOC, HEADER_OBJ_EVENTS, HEADER_OBJ_IMPORTANCE, HEADER_GENERATION;
  var init_neat_telemetry_exports = __esm({
    "src/neat/neat.telemetry.exports.ts"() {
      "use strict";
      COMPLEXITY_PREFIX = "complexity.";
      PERF_PREFIX = "perf.";
      LINEAGE_PREFIX = "lineage.";
      DIVERSITY_PREFIX = "diversity.";
      HEADER_FRONTS = "fronts";
      HEADER_OPS = "ops";
      HEADER_OBJECTIVES = "objectives";
      HEADER_OBJ_AGES = "objAges";
      HEADER_SPECIES_ALLOC = "speciesAlloc";
      HEADER_OBJ_EVENTS = "objEvents";
      HEADER_OBJ_IMPORTANCE = "objImportance";
      HEADER_GENERATION = "generation";
    }
  });

  // src/neat/neat.selection.ts
  function sort() {
    this.population.sort(
      (a, b) => (b.score ?? 0) - (a.score ?? 0)
    );
  }
  function getParent() {
    const selectionOptions = this.options.selection;
    const selectionName = selectionOptions?.name;
    const getRngFactory = this._getRNG.bind(this);
    const population = this.population;
    switch (selectionName) {
      case "POWER":
        if (population[0]?.score !== void 0 && population[1]?.score !== void 0 && population[0].score < population[1].score) {
          this.sort();
        }
        const selectedIndex = Math.floor(
          Math.pow(getRngFactory()(), selectionOptions.power || 1) * population.length
        );
        return population[selectedIndex];
      case "FITNESS_PROPORTIONATE":
        let totalFitness = 0;
        let mostNegativeScore = 0;
        population.forEach((individual) => {
          mostNegativeScore = Math.min(mostNegativeScore, individual.score ?? 0);
          totalFitness += individual.score ?? 0;
        });
        const minFitnessShift = Math.abs(mostNegativeScore);
        totalFitness += minFitnessShift * population.length;
        const threshold = getRngFactory()() * totalFitness;
        let cumulative = 0;
        for (const individual of population) {
          cumulative += (individual.score ?? 0) + minFitnessShift;
          if (threshold < cumulative) return individual;
        }
        return population[Math.floor(getRngFactory()() * population.length)];
      case "TOURNAMENT":
        if ((selectionOptions.size || 2) > population.length) {
          if (!this._suppressTournamentError) {
            throw new Error("Tournament size must be less than population size.");
          }
          return population[Math.floor(getRngFactory()() * population.length)];
        }
        const tournamentSize = selectionOptions.size || 2;
        const tournamentParticipants = [];
        for (let i = 0; i < tournamentSize; i++) {
          tournamentParticipants.push(
            population[Math.floor(getRngFactory()() * population.length)]
          );
        }
        tournamentParticipants.sort((a, b) => (b.score ?? 0) - (a.score ?? 0));
        for (let i = 0; i < tournamentParticipants.length; i++) {
          if (getRngFactory()() < (selectionOptions.probability ?? 0.5) || i === tournamentParticipants.length - 1)
            return tournamentParticipants[i];
        }
        break;
      default:
        return population[0];
    }
    return population[0];
  }
  function getFittest() {
    const population = this.population;
    if (population[population.length - 1].score === void 0) {
      this.evaluate();
    }
    if (population[1] && (population[0].score ?? 0) < (population[1].score ?? 0)) {
      this.sort();
    }
    return population[0];
  }
  function getAverage() {
    const population = this.population;
    if (population[population.length - 1].score === void 0) {
      this.evaluate();
    }
    const totalScore = population.reduce(
      (sum, genome) => sum + (genome.score ?? 0),
      0
    );
    return totalScore / population.length;
  }
  var init_neat_selection = __esm({
    "src/neat/neat.selection.ts"() {
      "use strict";
    }
  });

  // src/neat/neat.export.ts
  var neat_export_exports = {};
  __export(neat_export_exports, {
    exportPopulation: () => exportPopulation,
    exportState: () => exportState,
    fromJSONImpl: () => fromJSONImpl2,
    importPopulation: () => importPopulation,
    importStateImpl: () => importStateImpl,
    toJSONImpl: () => toJSONImpl2
  });
  function exportPopulation() {
    return this.population.map((genome) => genome.toJSON());
  }
  function importPopulation(populationJSON) {
    const Network7 = (init_network(), __toCommonJS(network_exports)).default;
    this.population = populationJSON.map(
      (serializedGenome) => Network7.fromJSON(serializedGenome)
    );
    this.options.popsize = this.population.length;
  }
  function exportState() {
    const { toJSONImpl: toJSONImpl3, exportPopulation: exportPopulation2 } = (init_neat_export(), __toCommonJS(neat_export_exports));
    return {
      neat: toJSONImpl3.call(this),
      population: exportPopulation2.call(this)
    };
  }
  function importStateImpl(stateBundle, fitnessFunction) {
    if (!stateBundle || typeof stateBundle !== "object")
      throw new Error("Invalid state bundle");
    const neatInstance = this.fromJSON(stateBundle.neat, fitnessFunction);
    if (Array.isArray(stateBundle.population))
      neatInstance.import(stateBundle.population);
    return neatInstance;
  }
  function toJSONImpl2() {
    return {
      input: this.input,
      output: this.output,
      generation: this.generation,
      options: this.options,
      nodeSplitInnovations: Array.from(
        this._nodeSplitInnovations.entries()
      ),
      connInnovations: Array.from(this._connInnovations.entries()),
      nextGlobalInnovation: this._nextGlobalInnovation
    };
  }
  function fromJSONImpl2(neatJSON, fitnessFunction) {
    const NeatClass = this;
    const neatInstance = new NeatClass(
      neatJSON.input,
      neatJSON.output,
      fitnessFunction,
      neatJSON.options || {}
    );
    neatInstance.generation = neatJSON.generation || 0;
    if (Array.isArray(neatJSON.nodeSplitInnovations))
      neatInstance._nodeSplitInnovations = new Map(neatJSON.nodeSplitInnovations);
    if (Array.isArray(neatJSON.connInnovations))
      neatInstance._connInnovations = new Map(neatJSON.connInnovations);
    if (typeof neatJSON.nextGlobalInnovation === "number")
      neatInstance._nextGlobalInnovation = neatJSON.nextGlobalInnovation;
    return neatInstance;
  }
  var init_neat_export = __esm({
    "src/neat/neat.export.ts"() {
      "use strict";
    }
  });

  // src/neat.ts
  var neat_exports = {};
  __export(neat_exports, {
    default: () => Neat
  });
  var Neat;
  var init_neat = __esm({
    "src/neat.ts"() {
      "use strict";
      init_network();
      init_methods();
      init_selection();
      init_node();
      init_neat_mutation();
      init_neat_evolve();
      init_neat_evaluate();
      init_neat_helpers();
      init_neat_objectives();
      init_neat_diversity();
      init_neat_multiobjective();
      init_neat_compat();
      init_neat_speciation();
      init_neat_species();
      init_neat_telemetry_exports();
      init_neat_selection();
      init_neat_export();
      Neat = class _Neat {
        input;
        output;
        fitness;
        options;
        population = [];
        generation = 0;
        // Deterministic RNG state (lazy init)
        /**
         * Internal numeric state for the deterministic xorshift RNG when no user RNG
         * is provided. Stored as a 32-bit unsigned integer.
         */
        _rngState;
        /**
         * Cached RNG function; created lazily and seeded from `_rngState` when used.
         */
        _rng;
        // Internal bookkeeping and caches (kept permissive during staggered migration)
        /** Array of current species (internal representation). */
        _species = [];
        /** Operator statistics used by adaptive operator selection. */
        _operatorStats = /* @__PURE__ */ new Map();
        /** Map of node-split innovations used to reuse innovation ids for node splits. */
        _nodeSplitInnovations = /* @__PURE__ */ new Map();
        /** Map of connection innovations keyed by a string identifier. */
        _connInnovations = /* @__PURE__ */ new Map();
        /** Counter for issuing global innovation numbers when explicit numbers are used. */
        _nextGlobalInnovation = 1;
        /** Counter for assigning unique genome ids. */
        _nextGenomeId = 1;
        /** Whether lineage metadata should be recorded on genomes. */
        _lineageEnabled = false;
        /** Last observed count of inbreeding (used for detecting excessive cloning). */
        _lastInbreedingCount = 0;
        /** Previous inbreeding count snapshot. */
        _prevInbreedingCount = 0;
        /** Optional phase marker for multi-stage experiments. */
        _phase;
        /** Telemetry buffer storing diagnostic snapshots per generation. */
        _telemetry = [];
        /** Map of species id -> set of member genome ids from previous generation. */
        _prevSpeciesMembers = /* @__PURE__ */ new Map();
        /** Last recorded stats per species id. */
        _speciesLastStats = /* @__PURE__ */ new Map();
        /** Time-series history of species stats (for exports/telemetry). */
        _speciesHistory = [];
        /** Archive of Pareto front metadata for multi-objective tracking. */
        _paretoArchive = [];
        /** Archive storing Pareto objectives snapshots. */
        _paretoObjectivesArchive = [];
        /** Novelty archive used by novelty search (behavior representatives). */
        _noveltyArchive = [];
        /** Map tracking stale counts for objectives by key. */
        _objectiveStale = /* @__PURE__ */ new Map();
        /** Map tracking ages for objectives by key. */
        _objectiveAges = /* @__PURE__ */ new Map();
        /** Queue of recent objective activation/deactivation events for telemetry. */
        _objectiveEvents = [];
        /** Pending objective keys to add during safe phases. */
        _pendingObjectiveAdds = [];
        /** Pending objective keys to remove during safe phases. */
        _pendingObjectiveRemoves = [];
        /** Last allocated offspring set (used by adaptive allocators). */
        _lastOffspringAlloc;
        /** Adaptive prune level for complexity control (optional). */
        _adaptivePruneLevel;
        /** Duration of the last evaluation run (ms). */
        _lastEvalDuration;
        /** Duration of the last evolve run (ms). */
        _lastEvolveDuration;
        /** Cached diversity metrics (computed lazily). */
        _diversityStats;
        /** Cached list of registered objectives. */
        _objectivesList;
        /** Generation index where the last global improvement occurred. */
        _lastGlobalImproveGeneration = 0;
        /** Best score observed in the last generation (used for improvement detection). */
        _bestScoreLastGen;
        // Speciation controller state
        /** Map of speciesId -> creation generation for bookkeeping. */
        _speciesCreated = /* @__PURE__ */ new Map();
        /** Exponential moving average for compatibility threshold (adaptive speciation). */
        _compatSpeciesEMA;
        /** Integral accumulator used by adaptive compatibility controllers. */
        _compatIntegral = 0;
        /** Generation when epsilon compatibility was last adjusted. */
        _lastEpsilonAdjustGen = -Infinity;
        /** Generation when ancestor uniqueness adjustment was last applied. */
        _lastAncestorUniqAdjustGen = -Infinity;
        // Adaptive minimal criterion & complexity
        /** Adaptive minimal criterion threshold (optional). */
        _mcThreshold;
        // Lightweight RNG accessor used throughout migrated modules
        _getRNG() {
          if (!this._rng) {
            const optRng = this.options?.rng;
            if (typeof optRng === "function") this._rng = optRng;
            else {
              if (this._rngState === void 0) {
                let seed = (Date.now() ^ (this.population.length + 1) * 2654435761) >>> 0;
                if (seed === 0) seed = 439041101;
                this._rngState = seed >>> 0;
              }
              this._rng = () => {
                let x = this._rngState >>> 0;
                x ^= x << 13;
                x >>>= 0;
                x ^= x >> 17;
                x >>>= 0;
                x ^= x << 5;
                x >>>= 0;
                this._rngState = x >>> 0;
                return (x >>> 0) / 4294967295;
              };
            }
          }
          return this._rng;
        }
        // Delegate ensureMinHiddenNodes to migrated mutation helper for smaller class surface
        /**
         * Ensure a network has the minimum number of hidden nodes according to
         * configured policy. Delegates to migrated helper implementation.
         *
         * @param network Network instance to adjust.
         * @param multiplierOverride Optional multiplier to override configured policy.
         */
        ensureMinHiddenNodes(network, multiplierOverride) {
          return ensureMinHiddenNodes.call(this, network, multiplierOverride);
        }
        /**
         * Construct a new Neat instance.
         * Kept permissive during staged migration; accepts the same signature tests expect.
         *
         * @example
         * // Create a neat instance for 3 inputs and 1 output with default options
         * const neat = new Neat(3, 1, (net) => evaluateFitness(net));
         */
        constructor(input, output, fitness, options = {}) {
          this.input = input ?? 0;
          this.output = output ?? 0;
          this.fitness = fitness ?? ((n) => 0);
          this.options = options || {};
          const opts = this.options;
          if (opts.popsize === void 0) opts.popsize = 50;
          if (opts.elitism === void 0) opts.elitism = 0;
          if (opts.provenance === void 0) opts.provenance = 0;
          if (opts.mutationRate === void 0) opts.mutationRate = 0.7;
          if (opts.mutationAmount === void 0) opts.mutationAmount = 1;
          if (opts.fitnessPopulation === void 0) opts.fitnessPopulation = false;
          if (opts.clear === void 0) opts.clear = false;
          if (opts.equal === void 0) opts.equal = false;
          if (opts.compatibilityThreshold === void 0)
            opts.compatibilityThreshold = 3;
          if (opts.maxNodes === void 0) opts.maxNodes = Infinity;
          if (opts.maxConns === void 0) opts.maxConns = Infinity;
          if (opts.maxGates === void 0) opts.maxGates = Infinity;
          if (opts.excessCoeff === void 0) opts.excessCoeff = 1;
          if (opts.disjointCoeff === void 0) opts.disjointCoeff = 1;
          if (opts.weightDiffCoeff === void 0) opts.weightDiffCoeff = 0.5;
          if (opts.mutation === void 0)
            opts.mutation = mutation.ALL ? mutation.ALL.slice() : mutation.FFW ? [mutation.FFW] : [];
          if (opts.selection === void 0) {
            opts.selection = selection && selection.TOURNAMENT || selection?.TOURNAMENT || selection.FITNESS_PROPORTIONATE;
          }
          if (opts.crossover === void 0)
            opts.crossover = crossover ? crossover.SINGLE_POINT : void 0;
          if (opts.novelty === void 0) opts.novelty = { enabled: false };
          if (opts.diversityMetrics === void 0)
            opts.diversityMetrics = { enabled: true };
          if (opts.fastMode && opts.diversityMetrics) {
            if (opts.diversityMetrics.pairSample == null)
              opts.diversityMetrics.pairSample = 20;
            if (opts.diversityMetrics.graphletSample == null)
              opts.diversityMetrics.graphletSample = 30;
            if (opts.novelty?.enabled && opts.novelty.k == null) opts.novelty.k = 5;
          }
          this._noveltyArchive = [];
          if (opts.speciation === void 0) opts.speciation = false;
          if (opts.multiObjective && opts.multiObjective.enabled && !Array.isArray(opts.multiObjective.objectives))
            opts.multiObjective.objectives = [];
          this.population = this.population || [];
          try {
            if (this.options.network !== void 0)
              this.createPool(this.options.network);
            else if (this.options.popsize) this.createPool(null);
          } catch {
          }
          if (this.options.lineage?.enabled || this.options.provenance > 0)
            this._lineageEnabled = true;
          if (this.options.lineageTracking === true)
            this._lineageEnabled = true;
          if (options.lineagePressure?.enabled && this._lineageEnabled !== true) {
            this._lineageEnabled = true;
          }
        }
        /**
         * Evolves the population by selecting, mutating, and breeding genomes.
         * This method is delegated to `src/neat/neat.evolve.ts` during the migration.
         *
         * @example
         * // Run a single evolution step (async)
         * await neat.evolve();
         */
        async evolve() {
          return evolve.call(this);
        }
        async evaluate() {
          return evaluate.call(this);
        }
        /**
         * Create initial population pool. Delegates to helpers if present.
         */
        createPool(network) {
          try {
            if (createPool && typeof createPool === "function")
              return createPool.call(this, network);
          } catch {
          }
          this.population = [];
          const poolSize = this.options.popsize || 50;
          for (let idx = 0; idx < poolSize; idx++) {
            const genomeCopy = network ? Network3.fromJSON(network.toJSON()) : new Network3(this.input, this.output, {
              minHidden: this.options.minHidden
            });
            genomeCopy.score = void 0;
            try {
              this.ensureNoDeadEnds(genomeCopy);
            } catch {
            }
            genomeCopy._reenableProb = this.options.reenableProb;
            genomeCopy._id = this._nextGenomeId++;
            if (this._lineageEnabled) {
              genomeCopy._parents = [];
              genomeCopy._depth = 0;
            }
            this.population.push(genomeCopy);
          }
        }
        // RNG snapshot / restore helpers used by tests
        /**
         * Return the current opaque RNG numeric state used by the instance.
         * Useful for deterministic test replay and debugging.
         */
        snapshotRNGState() {
          return this._rngState;
        }
        /**
         * Restore a previously-snapshotted RNG state. This restores the internal
         * seed but does not re-create the RNG function until next use.
         *
         * @param state Opaque numeric RNG state produced by `snapshotRNGState()`.
         */
        restoreRNGState(state) {
          this._rngState = state;
          this._rng = void 0;
        }
        /**
         * Import an RNG state (alias for restore; kept for compatibility).
         * @param state Numeric RNG state.
         */
        importRNGState(state) {
          this._rngState = state;
          this._rng = void 0;
        }
        /**
         * Export the current RNG state for external persistence or tests.
         */
        exportRNGState() {
          return this._rngState;
        }
        /**
         * Generates an offspring by crossing over two parent networks.
         * Uses the crossover method described in the Instinct algorithm.
         * @returns A new network created from two parents.
         * @see {@link https://medium.com/data-science/neuro-evolution-on-steroids-82bd14ddc2f6 Instinct: neuro-evolution on steroids by Thomas Wagenaar}
         */
        getOffspring() {
          let parent1;
          let parent2;
          try {
            parent1 = this.getParent();
          } catch {
            parent1 = this.population[0];
          }
          try {
            parent2 = this.getParent();
          } catch {
            parent2 = this.population[Math.floor(this._getRNG()() * this.population.length)] || this.population[0];
          }
          const offspring = Network3.crossOver(
            parent1,
            parent2,
            this.options.equal || false
          );
          offspring._reenableProb = this.options.reenableProb;
          offspring._id = this._nextGenomeId++;
          if (this._lineageEnabled) {
            offspring._parents = [
              parent1._id,
              parent2._id
            ];
            const depth1 = parent1._depth ?? 0;
            const depth2 = parent2._depth ?? 0;
            offspring._depth = 1 + Math.max(depth1, depth2);
            if (parent1._id === parent2._id)
              this._lastInbreedingCount++;
          }
          this.ensureMinHiddenNodes(offspring);
          this.ensureNoDeadEnds(offspring);
          return offspring;
        }
        /** Emit a standardized warning when evolution loop finds no valid best genome (test hook). */
        _warnIfNoBestGenome() {
          try {
            console.warn(
              "Evolution completed without finding a valid best genome (no fitness improvements recorded)."
            );
          } catch {
          }
        }
        /**
         * Spawn a new genome derived from a single parent while preserving Neat bookkeeping.
         *
         * This helper performs a canonical "clone + slight mutation" workflow while
         * keeping `Neat`'s internal invariants intact. It is intended for callers that
         * want a child genome derived from a single parent but do not want to perform the
         * bookkeeping and registration steps manually. The function deliberately does NOT
         * add the returned child to `this.population` so callers are free to inspect or
         * further modify the child and then register it via `addGenome()` (or push it
         * directly if they understand the consequences).
         *
         * Behavior summary:
         * - Clone the provided `parent` (`parent.clone()` when available, else JSON round-trip).
         * - Clear fitness/score on the child and assign a fresh unique `_id`.
         * - If lineage tracking is enabled, set `(child as any)._parents = [parent._id]`
         *   and `(child as any)._depth = (parent._depth ?? 0) + 1`.
         * - Enforce structural invariants by calling `ensureMinHiddenNodes(child)` and
         *   `ensureNoDeadEnds(child)` so the child is valid for subsequent mutation/evaluation.
         * - Apply `mutateCount` mutations selected via `selectMutationMethod` and driven by
         *   the instance RNG (`_getRNG()`); mutation exceptions are caught and ignored to
         *   preserve best-effort behavior during population seeding/expansion.
         * - Invalidate per-genome caches with `_invalidateGenomeCaches(child)` before return.
         *
         * Important: the returned child is not registered in `Neat.population` — call
         * `addGenome(child, [parentId])` to insert it and keep telemetry/lineage consistent.
         *
         * @param parent - Source genome to derive from. Must be a `Network` instance.
         * @param mutateCount - Number of mutation operations to apply to the spawned child (default: 1).
         * @returns A new `Network` instance derived from `parent`. The child is unregistered.
         */
        spawnFromParent(parent, mutateCount = 1) {
          return spawnFromParent.call(this, parent, mutateCount);
        }
        /**
         * Register an externally-created genome into the `Neat` population.
         *
         * Use this method when code constructs or mutates a `Network` outside of the
         * usual reproduction pipeline and needs to insert it into `neat.population`
         * while preserving lineage, id assignment, and structural invariants. The
         * method performs best-effort safety actions and falls back to pushing the
         * genome even if invariant enforcement throws, which mirrors the forgiving
         * behavior used in dynamic population expansion.
         *
         * Behavior summary:
         * - Clears the genome's `score` and assigns `_id` using Neat's counter.
         * - When lineage is enabled, attaches the provided `parents` array (copied)
         *   and estimates `_depth` as `max(parent._depth) + 1` when parent ids are
         *   resolvable from the current population.
         * - Enforces structural invariants (`ensureMinHiddenNodes` and
         *   `ensureNoDeadEnds`) and invalidates caches via
         *   `_invalidateGenomeCaches(genome)`.
         * - Pushes the genome into `this.population`.
         *
         * Note: Because depth estimation requires parent objects to be discoverable
         * in `this.population`, callers that generate intermediate parent genomes
         * should register them via `addGenome` before relying on automatic depth
         * estimation for their children.
         *
         * @param genome - The external `Network` to add.
         * @param parents - Optional array of parent ids to record on the genome.
         */
        addGenome(genome, parents) {
          return addGenome.call(this, genome, parents);
        }
        /**
         * Selects a mutation method for a given genome based on constraints.
         * Ensures that the mutation respects the maximum nodes, connections, and gates.
         * @param genome - The genome to mutate.
         * @returns The selected mutation method or null if no valid method is available.
         */
        selectMutationMethod(genome, rawReturnForTest = true) {
          try {
            return selectMutationMethod.call(this, genome, rawReturnForTest);
          } catch {
            return null;
          }
        }
        /** Delegate ensureNoDeadEnds to mutation module (added for backward compat). */
        ensureNoDeadEnds(network) {
          try {
            return ensureNoDeadEnds.call(this, network);
          } catch {
            return;
          }
        }
        /** Minimum hidden size considering explicit minHidden or multiplier policy. */
        getMinimumHiddenSize(multiplierOverride) {
          const o = this.options;
          if (typeof o.minHidden === "number") return o.minHidden;
          const mult = multiplierOverride ?? o.minHiddenMultiplier;
          if (typeof mult === "number" && isFinite(mult)) {
            return Math.max(0, Math.round(mult * (this.input + this.output)));
          }
          return 0;
        }
        /** Produce `count` deterministic random samples using instance RNG. */
        sampleRandom(count) {
          const rng = this._getRNG();
          const arr = [];
          for (let i = 0; i < count; i++) arr.push(rng());
          return arr;
        }
        /** Internal: return cached objective descriptors, building if stale. */
        _getObjectives() {
          return _getObjectives.call(this);
        }
        /** Public helper returning just the objective keys (tests rely on). */
        getObjectiveKeys() {
          return this._getObjectives().map(
            (obj) => obj.key
          );
        }
        /** Invalidate per-genome caches (compatibility distance, forward pass, etc.). */
        _invalidateGenomeCaches(genome) {
          if (!genome || typeof genome !== "object") return;
          delete genome._compatCache;
          delete genome._outputCache;
          delete genome._traceCache;
        }
        /** Compute and cache diversity statistics used by telemetry & tests. */
        _computeDiversityStats() {
          this._diversityStats = computeDiversityStats2(this.population, this);
        }
        // Removed thin wrappers _structuralEntropy and _fastNonDominated; modules used directly where needed.
        /** Compatibility wrapper retained for tests that reference (neat as any)._structuralEntropy */
        _structuralEntropy(genome) {
          return structuralEntropy2(genome);
        }
        /**
         * Applies mutations to the population based on the mutation rate and amount.
         * Each genome is mutated using the selected mutation methods.
         * Slightly increases the chance of ADD_CONN mutation for more connectivity.
         */
        mutate() {
          return mutate.call(this);
        }
        // Perform ADD_NODE honoring global innovation reuse mapping
        _mutateAddNodeReuse(genome) {
          return mutateAddNodeReuse.call(this, genome);
        }
        _mutateAddConnReuse(genome) {
          return mutateAddConnReuse.call(this, genome);
        }
        // --- Speciation helpers (properly scoped) ---
        _fallbackInnov(conn) {
          return _fallbackInnov.call(this, conn);
        }
        _compatibilityDistance(netA, netB) {
          return _compatibilityDistance.call(this, netA, netB);
        }
        /**
         * Assign genomes into species based on compatibility distance and maintain species structures.
         * This function creates new species for unassigned genomes and prunes empty species.
         * It also records species-level history used for telemetry and adaptive controllers.
         */
        _speciate() {
          return _speciate.call(this);
        }
        /**
         * Apply fitness sharing within species. When `sharingSigma` > 0 this uses a kernel-based
         * sharing; otherwise it falls back to classic per-species averaging. Sharing reduces
         * effective fitness for similar genomes to promote diversity.
         */
        _applyFitnessSharing() {
          return _applyFitnessSharing.call(this);
        }
        /**
         * Sort members of a species in-place by descending score.
         * @param sp - Species object with `members` array.
         */
        _sortSpeciesMembers(sp) {
          return _sortSpeciesMembers.call(this, sp);
        }
        /**
         * Update species stagnation tracking and remove species that exceeded the allowed stagnation.
         */
        _updateSpeciesStagnation() {
          return _updateSpeciesStagnation.call(this);
        }
        /**
         * Return a concise summary for each current species.
         *
         * Educational context: In NEAT, populations are partitioned into species based
         * on genetic compatibility. Each species groups genomes that are similar so
         * selection and reproduction can preserve diversity between groups. This
         * accessor provides a lightweight view suitable for telemetry, visualization
         * and teaching examples without exposing full genome objects.
         *
         * The returned array contains objects with these fields:
         * - id: numeric species identifier
         * - size: number of members currently assigned to the species
         * - bestScore: the best observed fitness score for the species
         * - lastImproved: generation index when the species last improved its best score
         *
         * Notes for learners:
         * - Species sizes and lastImproved are typical signals used to detect
         *   stagnation and apply protective or penalizing measures.
         * - This function intentionally avoids returning full member lists to
         *   prevent accidental mutation of internal state; use `getSpeciesHistory`
         *   for richer historical data.
         *
         * @returns An array of species summary objects.
         */
        getSpeciesStats() {
          return getSpeciesStats.call(this);
        }
        /**
         * Returns the historical species statistics recorded each generation.
         *
         * Educational context: Species history captures per-generation snapshots
         * of species-level metrics (size, best score, last improvement) and is
         * useful for plotting trends, teaching about speciation dynamics, and
         * driving adaptive controllers.
         *
         * The returned array contains entries with a `generation` index and a
         * `stats` array containing per-species summaries recorded at that
         * generation.
         *
         * @returns An array of generation-stamped species stat snapshots.
         */
        getSpeciesHistory() {
          return getSpeciesHistory.call(this);
        }
        /**
         * Returns the number of entries currently stored in the novelty archive.
         *
         * Educational context: The novelty archive stores representative behaviors
         * used by behavior-based novelty search. Monitoring its size helps teach
         * how behavioral diversity accumulates over time and can be used to
         * throttle archive growth.
         *
         * @returns Number of archived behaviors.
         */
        getNoveltyArchiveSize() {
          return this._noveltyArchive ? this._noveltyArchive.length : 0;
        }
        /**
         * Returns compact multi-objective metrics for each genome in the current
         * population. The metrics include Pareto rank and crowding distance (if
         * computed), along with simple size and score measures useful in
         * instructional contexts.
         *
         * @returns Array of per-genome MO metric objects.
         */
        getMultiObjectiveMetrics() {
          return this.population.map((genome) => ({
            rank: genome._moRank ?? 0,
            crowding: genome._moCrowd ?? 0,
            score: genome.score || 0,
            nodes: genome.nodes.length,
            connections: genome.connections.length
          }));
        }
        /**
         * Returns a summary of mutation/operator statistics used by operator
         * adaptation and bandit selection.
         *
         * Educational context: Operator statistics track how often mutation
         * operators are attempted and how often they succeed. These counters are
         * used by adaptation mechanisms to bias operator selection towards
         * successful operators.
         *
         * @returns Array of { name, success, attempts } objects.
         */
        getOperatorStats() {
          return Array.from(this._operatorStats.entries()).map(
            ([operatorName, stats]) => ({
              name: operatorName,
              success: stats.success,
              attempts: stats.attempts
            })
          );
        }
        /**
         * Manually apply evolution-time pruning once using the current generation
         * index and configuration in `options.evolutionPruning`.
         *
         * Educational usage: While pruning normally occurs automatically inside
         * the evolve loop, exposing this method lets learners trigger the pruning
         * logic in isolation to observe its effect on network sparsity.
         *
         * Implementation detail: Delegates to the migrated helper in
         * `neat.pruning.ts` so the core class surface remains thin.
         */
        applyEvolutionPruning() {
          try {
            (init_neat_pruning(), __toCommonJS(neat_pruning_exports)).applyEvolutionPruning.call(this);
          } catch {
          }
        }
        /**
         * Run the adaptive pruning controller once. This adjusts the internal
         * `_adaptivePruneLevel` based on the configured metric (nodes or
         * connections) and invokes per-genome pruning when an adjustment is
         * warranted.
         *
         * Educational usage: Allows step-wise observation of how the adaptive
         * controller converges population complexity toward a target sparsity.
         */
        applyAdaptivePruning() {
          try {
            (init_neat_pruning(), __toCommonJS(neat_pruning_exports)).applyAdaptivePruning.call(this);
          } catch {
          }
        }
        /**
         * Return the internal telemetry buffer.
         *
         * Telemetry entries are produced per-generation when telemetry is enabled
         * and include diagnostic metrics (diversity, performance, lineage, etc.).
         * This accessor returns the raw buffer for external inspection or export.
         *
         * @returns Array of telemetry snapshot objects.
         */
        getTelemetry() {
          return this._telemetry;
        }
        /**
         * Export telemetry as JSON Lines (one JSON object per line).
         *
         * Useful for piping telemetry to external loggers or analysis tools.
         *
         * @returns A newline-separated string of JSON objects.
         */
        exportTelemetryJSONL() {
          return exportTelemetryJSONL.call(this);
        }
        /**
         * Export recent telemetry entries as CSV.
         *
         * The exporter attempts to flatten commonly-used nested fields (complexity,
         * perf, lineage) into columns. This is a best-effort exporter intended for
         * human inspection and simple ingestion.
         *
         * @param maxEntries Maximum number of recent telemetry entries to include.
         * @returns CSV string (may be empty when no telemetry present).
         */
        exportTelemetryCSV(maxEntries = 500) {
          return exportTelemetryCSV.call(this, maxEntries);
        }
        /**
         * Export telemetry as CSV with flattened columns for common nested fields.
         */
        clearTelemetry() {
          this._telemetry = [];
        }
        /** Clear all collected telemetry entries. */
        getObjectives() {
          return this._getObjectives().map((o) => ({
            key: o.key,
            direction: o.direction
          }));
        }
        getObjectiveEvents() {
          return this._objectiveEvents.slice();
        }
        /** Get recent objective add/remove events. */
        getLineageSnapshot(limit = 20) {
          return this.population.slice(0, limit).map((genome) => ({
            id: genome._id ?? -1,
            parents: Array.isArray(genome._parents) ? genome._parents.slice() : []
          }));
        }
        /**
         * Return an array of {id, parents} for the first `limit` genomes in population.
         */
        exportSpeciesHistoryCSV(maxEntries = 200) {
          return exportSpeciesHistoryCSV.call(this, maxEntries);
        }
        /**
         * Export species history as CSV.
         *
         * Produces rows for each recorded per-species stat entry within the
         * specified window. Useful for quick inspection or spreadsheet analysis.
         *
         * @param maxEntries Maximum history entries to include (default: 200).
         * @returns CSV string (may be empty).
         */
        getParetoFronts(maxFronts = 3) {
          if (!this.options.multiObjective?.enabled) return [[...this.population]];
          const fronts = [];
          for (let frontIdx = 0; frontIdx < maxFronts; frontIdx++) {
            const front = this.population.filter(
              (genome) => (genome._moRank ?? 0) === frontIdx
            );
            if (!front.length) break;
            fronts.push(front);
          }
          return fronts;
        }
        /**
         * Return the latest cached diversity statistics.
         *
         * Educational context: diversity metrics summarize how genetically and
         * behaviorally spread the population is. They can include lineage depth,
         * pairwise genetic distances, and other aggregated measures used by
         * adaptive controllers, novelty search, and telemetry. This accessor returns
         * whatever precomputed diversity object the Neat instance holds (may be
         * undefined if not computed for the current generation).
         *
         * @returns Arbitrary diversity summary object or undefined.
         */
        getDiversityStats() {
          return this._diversityStats;
        }
        registerObjective(key, direction, accessor) {
          return registerObjective.call(this, key, direction, accessor);
        }
        /**
         * Register a custom objective for multi-objective optimization.
         *
         * Educational context: multi-objective optimization lets you optimize for
         * multiple, potentially conflicting goals (e.g., maximize fitness while
         * minimizing complexity). Each objective is identified by a unique key and
         * an accessor function mapping a genome to a numeric score. Registering an
         * objective makes it visible to the internal MO pipeline and clears any
         * cached objective list so changes take effect immediately.
         *
         * @param key Unique objective key.
         * @param direction 'min' or 'max' indicating optimization direction.
         * @param accessor Function mapping a genome to a numeric objective value.
         */
        /**
         * Clear all registered multi-objective objectives.
         *
         * Removes any objectives configured for multi-objective optimization and
         * clears internal caches. Useful for tests or when reconfiguring the MO
         * setup at runtime.
         */
        clearObjectives() {
          return clearObjectives.call(this);
        }
        // Advanced archives & performance accessors
        /**
         * Get recent Pareto archive entries (meta information about archived fronts).
         *
         * Educational context: when performing multi-objective search we may store
         * representative Pareto-front snapshots over time. This accessor returns the
         * most recent archive entries up to the provided limit.
         *
         * @param maxEntries Maximum number of entries to return (default: 50).
         * @returns Array of archived Pareto metadata entries.
         */
        getParetoArchive(maxEntries = 50) {
          return this._paretoArchive.slice(-maxEntries);
        }
        /**
         * Export Pareto front archive as JSON Lines for external analysis.
         *
         * Each line is a JSON object representing one archived Pareto snapshot.
         *
         * @param maxEntries Maximum number of entries to include (default: 100).
         * @returns Newline-separated JSON objects.
         */
        exportParetoFrontJSONL(maxEntries = 100) {
          const slice = this._paretoObjectivesArchive.slice(-maxEntries);
          return slice.map((e) => JSON.stringify(e)).join("\n");
        }
        /**
         * Return recent performance statistics (durations in milliseconds) for the
         * most recent evaluation and evolve operations.
         *
         * Provides wall-clock timing useful for profiling and teaching how runtime
         * varies with network complexity or population settings.
         *
         * @returns Object with { lastEvalMs, lastEvolveMs }.
         */
        getPerformanceStats() {
          return {
            lastEvalMs: this._lastEvalDuration,
            lastEvolveMs: this._lastEvolveDuration
          };
        }
        // Utility exports / maintenance
        /**
         * Export species history as JSON Lines for storage and analysis.
         *
         * Each line is a JSON object containing a generation index and per-species
         * stats recorded at that generation. Useful for long-term tracking.
         *
         * @param maxEntries Maximum history entries to include (default: 200).
         * @returns Newline-separated JSON objects.
         */
        exportSpeciesHistoryJSONL(maxEntries = 200) {
          const slice = this._speciesHistory.slice(-maxEntries);
          return slice.map((e) => JSON.stringify(e)).join("\n");
        }
        /**
         * Reset the novelty archive (clear entries).
         *
         * The novelty archive is used to keep representative behaviors for novelty
         * search. Clearing it removes stored behaviors.
         */
        resetNoveltyArchive() {
          this._noveltyArchive = [];
        }
        /**
         * Clear the Pareto archive.
         *
         * Removes any stored Pareto-front snapshots retained by the algorithm.
         */
        clearParetoArchive() {
          this._paretoArchive = [];
        }
        /**
         * Sorts the population in descending order of fitness scores.
         * Ensures that the fittest genomes are at the start of the population array.
         */
        sort() {
          return sort.call(this);
        }
        /**
         * Selects a parent genome for breeding based on the selection method.
         * Supports multiple selection strategies, including POWER, FITNESS_PROPORTIONATE, and TOURNAMENT.
         * @returns The selected parent genome.
         * @throws Error if tournament size exceeds population size.
         */
        getParent() {
          return getParent.call(this);
        }
        /**
         * Retrieves the fittest genome from the population.
         * Ensures that the population is evaluated and sorted before returning the result.
         * @returns The fittest genome in the population.
         */
        getFittest() {
          return getFittest.call(this);
        }
        /**
         * Calculates the average fitness score of the population.
         * Ensures that the population is evaluated before calculating the average.
         * @returns The average fitness score of the population.
         */
        getAverage() {
          return getAverage.call(this);
        }
        /**
         * Exports the current population as an array of JSON objects.
         * Useful for saving the state of the population for later use.
         * @returns An array of JSON representations of the population.
         */
        export() {
          return exportPopulation.call(this);
        }
        /**
         * Imports a population from an array of JSON objects.
         * Replaces the current population with the imported one.
         * @param json - An array of JSON objects representing the population.
         */
        import(json) {
          return importPopulation.call(this, json);
        }
        /**
         * Convenience: export full evolutionary state (meta + population genomes).
         * Combines innovation registries and serialized genomes for easy persistence.
         */
        exportState() {
          return exportState.call(this);
        }
        /**
         * Convenience: restore full evolutionary state previously produced by exportState().
         * @param bundle Object with shape { neat, population }
         * @param fitness Fitness function to attach
         */
        static importState(bundle, fitness) {
          return importStateImpl.call(_Neat, bundle, fitness);
        }
        /**
         * Import a previously exported state bundle and rehydrate a Neat instance.
         */
        // Serialize NEAT meta (without population) for persistence of innovation history
        toJSON() {
          return toJSONImpl2.call(this);
        }
        static fromJSON(json, fitness) {
          return fromJSONImpl2.call(_Neat, json, fitness);
        }
      };
    }
  });

  // test/examples/asciiMaze/browserTerminalUtility.ts
  var BrowserTerminalUtility = class _BrowserTerminalUtility {
    /** Default minimum progress percentage that counts as sufficiently solved. */
    static #DefaultMinProgressToPass = 60;
    /** Default maximum number of evolutionary attempts before aborting. */
    static #DefaultMaxAttemptCount = 10;
    /** Backwards compatibility alias for attempt count (deprecated). */
    static deprecatedTriesKey = "tries";
    /** Resolve (or locate) the host element used for output. */
    static #resolveHostElement(container) {
      return container ?? (typeof document !== "undefined" ? document.getElementById("ascii-maze-output") : null);
    }
    /**
     * Create a clearer that clears a DOM container's contents.
     * If no container is provided it will try to use an element with id "ascii-maze-output".
     */
    static createTerminalClearer(container) {
      const hostElement = this.#resolveHostElement(container);
      return () => {
        if (hostElement) hostElement.innerHTML = "";
      };
    }
    /**
     * Same semantics as the Node version: repeatedly call evolveFn until success or threshold reached.
     */
    static async evolveUntilSolved(evolveFn, minProgressToPass = _BrowserTerminalUtility.#DefaultMinProgressToPass, maxAttemptCount = _BrowserTerminalUtility.#DefaultMaxAttemptCount) {
      let attemptCount = 0;
      let lastResult = {
        success: false,
        progress: 0
      };
      while (attemptCount < maxAttemptCount) {
        attemptCount++;
        const { finalResult } = await evolveFn();
        lastResult = finalResult;
        if (finalResult.success || finalResult.progress >= minProgressToPass) {
          return { finalResult, attemptCount, tries: attemptCount };
        }
      }
      return { finalResult: lastResult, attemptCount, tries: attemptCount };
    }
  };

  // test/examples/asciiMaze/mazeUtils.ts
  var MazeUtils = class _MazeUtils {
    /**
     * Shared set of wall characters (box-drawing + hash). Kept private to avoid
     * reallocation in hot code paths. Use `encodeMaze` to convert ASCII mazes.
     */
    static #WALL_CHARS = /* @__PURE__ */ new Set([
      "#",
      "\u2550",
      "\u2551",
      "\u2554",
      "\u2557",
      "\u255A",
      "\u255D",
      "\u2560",
      "\u2563",
      "\u2566",
      "\u2569",
      "\u256C"
    ]);
    // Movement vectors used by BFS (N, E, S, W). Private to avoid accidental external use.
    // Marked readonly to signal these vectors are constant and must not be mutated.
    /** Movement vectors used by BFS (North, East, South, West). */
    static #DIRECTIONS = [
      [0, -1],
      [1, 0],
      [0, 1],
      [-1, 0]
    ];
    /**
     * Convert a coordinate pair into the canonical key string `"x,y"`.
     *
     * @param coord - Coordinate pair `[x, y]` to stringify.
     * @returns Canonical string key suitable for Map/Set storage.
     * @example MazeUtils.posKey([2,3]) // -> '2,3'
     */
    static posKey(coord) {
      const [x, y] = coord;
      return `${x},${y}`;
    }
    /**
     * Return up to the last `n` items from `arr` as a new array.
     * This implementation is allocation-friendly for hot paths: it preallocates
     * the output array and copies only the required suffix.
     *
     * @param arr - Source array (may be undefined).
     * @param n - Maximum number of trailing elements to return.
     * @returns New array containing up to the last `n` items of `arr`.
     * @example
     * MazeUtils.tail([1,2,3,4], 2) // -> [3,4]
     */
    static tail(arr, n) {
      if (!Array.isArray(arr) || n <= 0) return [];
      const length = arr.length;
      const startIndex = Math.max(0, length - n);
      const resultLength = length - startIndex;
      const result = new Array(resultLength);
      let writeIndex = 0;
      for (let readIndex = startIndex; readIndex < length; readIndex++) {
        result[writeIndex++] = arr[readIndex];
      }
      return result;
    }
    /**
     * Return the last element of an array or undefined when empty.
     *
     * This helper prefers `Array.prototype.at` when available (ES2022+), but
     * falls back gracefully for older runtimes.
     *
     * @param arr - Array to read from.
     * @returns The last item or undefined.
     */
    static safeLast(arr) {
      if (!Array.isArray(arr) || arr.length === 0) return void 0;
      return arr.at ? arr.at(-1) : arr[arr.length - 1];
    }
    /**
     * Push a value onto a bounded history buffer and trim the head if needed.
     * This helper preserves in-place semantics (the original array reference is
     * returned and mutated) which callers may rely on for performance.
     *
     * @param buffer - Existing buffer (may be undefined). If undefined a new
     *  single-element array containing `value` is returned.
     * @param value - Value to push onto the buffer.
     * @param maxLen - Maximum length to retain. When the buffer exceeds this
     *  length the oldest entries are removed from the head.
     * @returns The updated buffer containing the new value and trimmed to maxLen.
     * @example
     * const buf = [1,2]; MazeUtils.pushHistory(buf, 3, 3) // -> [1,2,3]
     */
    static pushHistory(buffer, value, maxLen) {
      if (!Array.isArray(buffer)) return [value];
      buffer.push(value);
      const excessCount = buffer.length - maxLen;
      if (excessCount > 0) {
        if (excessCount === 1) {
          buffer.shift();
        } else {
          buffer.splice(0, excessCount);
        }
      }
      return buffer;
    }
    /**
     * Converts an ASCII/Unicode maze (array of strings) into a 2D numeric array for processing by the agent.
     *
     * Encoding:
     *   '#' = -1 (wall/obstacle)
     *   Box drawing characters (═,║,╔,╗,╚,╝,╠,╣,╦,╩,╬) = -1 (wall/obstacle)
     *   '.' = 0 (open path)
     *   'E' = 1 (exit/goal)
     *   'S' = 2 (start position)
     *   any other character = 0 (treated as open path)
     *
     * @param asciiMaze - Array of strings representing the maze.
     * @returns 2D array of numbers encoding the maze elements.
     */
    static encodeMaze(asciiMaze) {
      const wallChars = _MazeUtils.#WALL_CHARS;
      const codeMap = /* @__PURE__ */ new Map([
        [".", 0],
        ["E", 1],
        ["S", 2]
      ]);
      return asciiMaze.map((rowString, rowIndex) => {
        const rowLength = rowString.length;
        const encodedRow = new Array(rowLength);
        for (let colIndex = 0; colIndex < rowLength; colIndex++) {
          const cellChar = rowString[colIndex];
          if (wallChars.has(cellChar)) {
            encodedRow[colIndex] = -1;
            continue;
          }
          encodedRow[colIndex] = codeMap.get(cellChar) ?? 0;
        }
        return encodedRow;
      });
    }
    /**
     * Finds the (x, y) position of a given character in the ASCII maze.
     * @param asciiMaze - Array of strings representing the maze.
     * @param char - Character to find (e.g., 'S' for start, 'E' for exit).
     * @returns [x, y] coordinates of the character.
     * @throws Error if the character is not found in the maze.
     */
    static findPosition(asciiMaze, char) {
      const rowCount = asciiMaze.length;
      for (let rowIndex = 0; rowIndex < rowCount; rowIndex++) {
        const rowString = asciiMaze[rowIndex];
        if (!rowString) continue;
        const columnIndex = rowString.indexOf(char);
        if (columnIndex !== -1) {
          return [columnIndex, rowIndex];
        }
      }
      throw new Error(`Character ${char} not found in maze`);
    }
    /**
     * Computes the shortest path distance between two points in the maze using BFS.
     * Returns Infinity if no path exists.
     * @param encodedMaze - 2D array representation of the maze.
     * @param start - [x, y] start position.
     * @param goal - [x, y] goal position.
     * @returns Shortest path length (number of steps), or Infinity if unreachable.
     */
    static bfsDistance(encodedMaze, start2, goal) {
      const [startX, startY] = start2;
      const [goalX, goalY] = goal;
      const height = encodedMaze.length;
      const width = encodedMaze[0].length;
      if (startY < 0 || startY >= height || startX < 0 || startX >= width || goalY < 0 || goalY >= height || goalX < 0 || goalX >= width)
        return Infinity;
      if (encodedMaze[startY][startX] === -1 || encodedMaze[goalY][goalX] === -1)
        return Infinity;
      if (startX === goalX && startY === goalY) return 0;
      const cellCount = height * width;
      const flatMaze = new Int8Array(cellCount);
      for (let y = 0, dest = 0; y < height; y++) {
        const row = encodedMaze[y];
        for (let x = 0; x < width; x++, dest++) {
          flatMaze[dest] = row[x] === -1 ? -1 : 0;
        }
      }
      const distances = new Int32Array(cellCount);
      for (let i = 0; i < cellCount; i++) distances[i] = -1;
      const startIndex = startY * width + startX;
      const goalIndex = goalY * width + goalX;
      distances[startIndex] = 0;
      const queue = new Int32Array(cellCount);
      let head = 0;
      let tail = 0;
      queue[tail++] = startIndex;
      const northOffset = -width;
      const southOffset = width;
      while (head < tail) {
        const currentIndex = queue[head++];
        const currentDistance = distances[currentIndex];
        if (currentIndex === goalIndex) return currentDistance;
        const currentY = currentIndex / width | 0;
        const currentX = currentIndex - currentY * width;
        for (let dir = 0; dir < 4; dir++) {
          let neighborIndex;
          switch (dir) {
            case 0:
              if (currentY === 0) continue;
              neighborIndex = currentIndex + northOffset;
              break;
            case 1:
              if (currentX + 1 >= width) continue;
              neighborIndex = currentIndex + 1;
              break;
            case 2:
              if (currentY + 1 >= height) continue;
              neighborIndex = currentIndex + southOffset;
              break;
            default:
              if (currentX === 0) continue;
              neighborIndex = currentIndex - 1;
          }
          if (flatMaze[neighborIndex] !== -1 && distances[neighborIndex] === -1) {
            distances[neighborIndex] = currentDistance + 1;
            if (neighborIndex === goalIndex) return currentDistance + 1;
            queue[tail++] = neighborIndex;
          }
        }
      }
      return Infinity;
    }
    /**
     * Calculates the agent's progress toward the exit as a percentage.
     * Progress is measured as the proportion of the shortest path covered from start to exit.
     * @param encodedMaze - 2D array representation of the maze.
     * @param currentPos - [x, y] current agent position.
     * @param startPos - [x, y] start position.
     * @param exitPos - [x, y] exit position.
     * @returns Progress percentage (0-100).
     */
    static calculateProgress(encodedMaze, currentPos, startPos, exitPos) {
      const totalDistance = _MazeUtils.bfsDistance(encodedMaze, startPos, exitPos);
      if (totalDistance === 0) return 100;
      const remainingDistance = _MazeUtils.bfsDistance(
        encodedMaze,
        currentPos,
        exitPos
      );
      return Math.min(
        100,
        Math.max(
          0,
          Math.round((totalDistance - remainingDistance) / totalDistance * 100)
        )
      );
    }
    /**
     * Calculates progress using a precomputed distance map (goal-centric BFS distances).
     * Faster alternative to repeated BFS calls. Distance map holds distance from each cell TO the exit (goal).
     * @param distanceMap - 2D array of distances (Infinity for walls/unreachable)
     * @param currentPos - Agent current position [x,y]
     * @param startPos - Start position [x,y]
     * @returns Progress percentage (0-100)
     */
    static calculateProgressFromDistanceMap(distanceMap, currentPos, startPos) {
      const [startX, startY] = startPos;
      const [currentX, currentY] = currentPos;
      const totalDistance = distanceMap[startY]?.[startX];
      const remaining = distanceMap[currentY]?.[currentX];
      if (totalDistance == null || remaining == null || !isFinite(totalDistance) || totalDistance <= 0)
        return 0;
      const prog = (totalDistance - remaining) / totalDistance * 100;
      return Math.min(100, Math.max(0, Math.round(prog)));
    }
    /**
     * Builds a full distance map (Manhattan shortest path lengths via BFS) from a goal cell to every reachable cell.
     * Walls are marked as Infinity. Unreachable cells remain Infinity.
     * @param encodedMaze - 2D maze encoding
     * @param goal - [x,y] goal position (typically exit)
     */
    static buildDistanceMap(encodedMaze, goal) {
      const {
        width,
        height,
        distances,
        WALL_VALUE,
        UNREACHABLE_VALUE
      } = _MazeUtils.buildDistanceMapFlat(encodedMaze, goal);
      const result = Array.from(
        { length: height },
        () => new Array(width)
      );
      for (let rowIndex = 0, flatIndex = 0; rowIndex < height; rowIndex++) {
        const resultRow = result[rowIndex];
        for (let colIndex = 0; colIndex < width; colIndex++, flatIndex++) {
          const cellDistance = distances[flatIndex];
          resultRow[colIndex] = cellDistance === WALL_VALUE || cellDistance === UNREACHABLE_VALUE ? Infinity : cellDistance;
        }
      }
      return result;
    }
    /**
     * High-performance variant of `buildDistanceMap` that returns a flat Int32Array
     * distance buffer with metadata. This minimizes allocations and GC pressure for
     * large mazes and is the recommended API for performance-sensitive code.
     *
     * Encoding in the returned `distances` buffer:
     *  - wall cells => WALL_VALUE (number, -2)
     *  - unreachable cells => UNREACHABLE_VALUE (number, -1)
     *  - reachable cells => non-negative distance (0 ..)
     *
     * The returned object contains the flat buffer plus `width` and `height` so
     * callers can translate between (x,y) and flat indices: index = y*width + x.
     *
     * Note: this API intentionally avoids converting the typed buffer back into
     * nested `number[][]` to keep allocation minimal; use `buildDistanceMap` if
     * you require the legacy `number[][]` shape.
     *
     * @param encodedMaze - 2D maze encoding
     * @param goal - [x,y] goal position (typically exit)
     * @returns Object with `width`, `height`, and `distances` (Int32Array).
     * @example
     * const flat = MazeUtils.buildDistanceMapFlat(encoded, [5,3]);
     * const idx = 3 * flat.width + 5; // y*width + x
     * console.log(flat.distances[idx]); // -2 wall, -1 unreachable, >=0 distance
     */
    static buildDistanceMapFlat(encodedMaze, goal) {
      const height = encodedMaze.length;
      const width = encodedMaze[0].length;
      const WALL_VALUE = -2;
      const UNREACHABLE_VALUE = -1;
      const cellCount = width * height;
      const distances = new Int32Array(cellCount);
      for (let flatInitIndex = 0; flatInitIndex < cellCount; flatInitIndex++)
        distances[flatInitIndex] = UNREACHABLE_VALUE;
      const [goalX, goalY] = goal;
      if (goalY < 0 || goalY >= height || goalX < 0 || goalX >= width || encodedMaze[goalY][goalX] === -1) {
        for (let rowIndex = 0, flatDest = 0; rowIndex < height; rowIndex++) {
          const row = encodedMaze[rowIndex];
          for (let colIndex = 0; colIndex < width; colIndex++, flatDest++) {
            if (row[colIndex] === -1) distances[flatDest] = WALL_VALUE;
          }
        }
        return { width, height, distances, WALL_VALUE, UNREACHABLE_VALUE };
      }
      for (let rowIndex = 0, flatDest = 0; rowIndex < height; rowIndex++) {
        const row = encodedMaze[rowIndex];
        for (let colIndex = 0; colIndex < width; colIndex++, flatDest++) {
          if (row[colIndex] === -1) distances[flatDest] = WALL_VALUE;
        }
      }
      const goalIndex = goalY * width + goalX;
      distances[goalIndex] = 0;
      const queue = new Int32Array(cellCount);
      let queueHead = 0;
      let queueTail = 0;
      queue[queueTail++] = goalIndex;
      const northOffset = -width;
      const southOffset = width;
      while (queueHead < queueTail) {
        const currentIndex = queue[queueHead++];
        const currentDistance = distances[currentIndex];
        const currentRow = currentIndex / width | 0;
        const currentCol = currentIndex - currentRow * width;
        for (let dir = 0; dir < 4; dir++) {
          let neighborFlatIndex;
          switch (dir) {
            case 0:
              if (currentRow === 0) continue;
              neighborFlatIndex = currentIndex + northOffset;
              break;
            case 1:
              if (currentCol + 1 >= width) continue;
              neighborFlatIndex = currentIndex + 1;
              break;
            case 2:
              if (currentRow + 1 >= height) continue;
              neighborFlatIndex = currentIndex + southOffset;
              break;
            default:
              if (currentCol === 0) continue;
              neighborFlatIndex = currentIndex - 1;
          }
          if (distances[neighborFlatIndex] === UNREACHABLE_VALUE) {
            distances[neighborFlatIndex] = currentDistance + 1;
            queue[queueTail++] = neighborFlatIndex;
          }
        }
      }
      return { width, height, distances, WALL_VALUE, UNREACHABLE_VALUE };
    }
  };

  // test/examples/asciiMaze/browserLogger.ts
  var ANSI_256_MAP = Object.freeze({
    205: "#ff6ac1",
    93: "#b48bf2",
    154: "#a6d189",
    51: "#00bcd4",
    226: "#ffd166",
    214: "#ff9f43",
    196: "#ff3b30",
    46: "#00e676",
    123: "#6ec6ff",
    177: "#caa6ff",
    80: "#00bfa5",
    121: "#9bdc8a",
    203: "#ff6b9f",
    99: "#6b62d6",
    44: "#00a9e0",
    220: "#ffd54f",
    250: "#ececec",
    45: "#00aaff",
    201: "#ff4fc4",
    231: "#ffffff",
    218: "#ffc6d3",
    217: "#ffcdb5",
    117: "#6fb3ff",
    118: "#6ee07a",
    48: "#00a300",
    57: "#2f78ff",
    33: "#1e90ff",
    87: "#00d7ff",
    159: "#cfeeff",
    208: "#ff8a00",
    197: "#ff5ea6",
    234: "#0e1114",
    23: "#123044",
    17: "#000b16",
    16: "#000000",
    39: "#0078ff"
  });
  var FONT_WEIGHT_BOLD = "700";
  var SGR_RESET = 0;
  var SGR_BOLD = 1;
  var SGR_BOLD_OFF = 22;
  var SGR_FG_EXTENDED = 38;
  var SGR_BG_EXTENDED = 48;
  var SGR_FG_DEFAULT = 39;
  var SGR_BG_DEFAULT = 49;
  var HTML_ESCAPE_PRESENCE = /[&<>]/;
  var BASIC_FG_COLORS = Object.freeze([
    "#000000",
    "#800000",
    "#008000",
    "#808000",
    "#000080",
    "#800080",
    "#008080",
    "#c0c0c0"
  ]);
  var BRIGHT_FG_COLORS = Object.freeze([
    "#808080",
    "#ff0000",
    "#00ff00",
    "#ffff00",
    "#0000ff",
    "#ff00ff",
    "#00ffff",
    "#ffffff"
  ]);
  function escapeHtml(raw) {
    if (!HTML_ESCAPE_PRESENCE.test(raw)) return raw;
    return raw.replace(/&/g, "&amp;").replace(/</g, "&lt;").replace(/>/g, "&gt;");
  }
  function ensurePre(container) {
    const hostElement = container ?? (typeof document !== "undefined" ? document.getElementById("ascii-maze-output") : null);
    if (!hostElement) return null;
    let preElement = hostElement.querySelector("pre");
    if (!preElement) {
      preElement = document.createElement("pre");
      preElement.style.fontFamily = "monospace";
      preElement.style.whiteSpace = "pre";
      preElement.style.margin = "0";
      preElement.style.padding = "4px";
      preElement.style.fontSize = "10px";
      hostElement.appendChild(preElement);
    }
    return preElement;
  }
  var AnsiHtmlConverter = class _AnsiHtmlConverter {
    /**
     * Global regex used to locate SGR parameter sequences. Reset before each parse.
     * `([0-9;]*)` captures the parameter list which may be empty (equivalent to reset).
     */
    static #SgrSequencePattern = /\x1b\[([0-9;]*)m/g;
    /** Marker inserted for newline during streaming conversion (literal `<br/>`). */
    static #HtmlNewline = "<br/>";
    /** Small object pool for converter instances (avoid GC churn under heavy logging). */
    static #Pool = [];
    static #POOL_SIZE_LIMIT = 32;
    // Safety cap – logging lines are short, pool doesn't need to grow large.
    /** Cache mapping style signature -> opening span tag for reuse. */
    static #StyleCache = /* @__PURE__ */ new Map();
    // Per-instance mutable state (cleared between uses via #resetForInput).
    #input = "";
    #htmlOutput = "";
    #lastProcessedIndex = 0;
    // Current style fields.
    #currentColor;
    #currentBackground;
    #currentFontWeight;
    #hasActiveStyle = false;
    #currentStyleSpanStart = "";
    // Scratch array reused for parsed numeric codes (grown as needed, not shrunk).
    #parsedCodes = [];
    constructor() {
    }
    /** Acquire a converter instance (from pool or new). */
    static #acquire(input) {
      const instance = this.#Pool.pop() ?? new _AnsiHtmlConverter();
      instance.#resetForInput(input);
      return instance;
    }
    /** Return a used instance back into the pool (bounded). */
    static #release(instance) {
      if (this.#Pool.length < this.#POOL_SIZE_LIMIT) {
        this.#Pool.push(instance);
      }
    }
    /** Public entry point: convert ANSI encoded text into HTML (single pass, pooled). */
    static convert(input) {
      const instance = this.#acquire(input);
      try {
        instance.#process();
        return instance.#htmlOutput;
      } finally {
        this.#release(instance);
      }
    }
    /** Prepare internal state for a fresh parse. */
    #resetForInput(input) {
      this.#input = input;
      this.#htmlOutput = "";
      this.#lastProcessedIndex = 0;
      this.#resetStyles();
      _AnsiHtmlConverter.#SgrSequencePattern.lastIndex = 0;
    }
    /** Main processing loop: walk all SGR sequences and emit transformed HTML. */
    #process() {
      let ansiMatch;
      while ((ansiMatch = _AnsiHtmlConverter.#SgrSequencePattern.exec(this.#input)) !== null) {
        this.#emitPlainTextSegment(ansiMatch.index);
        this.#applyRawCodeSequence(ansiMatch[1]);
        this.#lastProcessedIndex = _AnsiHtmlConverter.#SgrSequencePattern.lastIndex;
      }
      this.#emitPlainTextSegment(this.#input.length);
    }
    /** Emit plain (non-ANSI) text between the previous index and the supplied stop. */
    #emitPlainTextSegment(stopExclusive) {
      if (this.#lastProcessedIndex >= stopExclusive) return;
      const rawChunk = this.#input.substring(
        this.#lastProcessedIndex,
        stopExclusive
      );
      if (!rawChunk) return;
      if (!rawChunk.includes("\n")) {
        const escapedSingle = escapeHtml(rawChunk);
        this.#htmlOutput += this.#wrapIfStyled(escapedSingle);
        return;
      }
      let segmentStart = 0;
      for (let scanIndex = 0; scanIndex <= rawChunk.length; scanIndex++) {
        const isEnd = scanIndex === rawChunk.length;
        const isNewline = !isEnd && rawChunk.charCodeAt(scanIndex) === 10;
        if (isNewline || isEnd) {
          if (scanIndex > segmentStart) {
            const sub = rawChunk.substring(segmentStart, scanIndex);
            this.#htmlOutput += this.#wrapIfStyled(escapeHtml(sub));
          }
          if (isNewline) this.#htmlOutput += _AnsiHtmlConverter.#HtmlNewline;
          segmentStart = scanIndex + 1;
        }
      }
    }
    /** Apply a raw parameter string (could be empty meaning reset) to update style state. */
    #applyRawCodeSequence(rawCodes) {
      if (rawCodes === "") {
        this.#resetStyles();
        return;
      }
      let accumulator = "";
      let parsedCount = 0;
      for (let charIndex = 0; charIndex < rawCodes.length; charIndex++) {
        const character = rawCodes[charIndex];
        if (character === ";") {
          if (accumulator) {
            this.#parsedCodes[parsedCount++] = parseInt(accumulator, 10);
            accumulator = "";
          }
        } else {
          accumulator += character;
        }
      }
      if (accumulator)
        this.#parsedCodes[parsedCount++] = parseInt(accumulator, 10);
      this.#applyParsedCodes(parsedCount);
      this.#rebuildStyleSpanStart();
    }
    /** Apply parsed numeric codes currently buffered in #parsedCodes (length = count). */
    #applyParsedCodes(parsedCount) {
      for (let codeIndex = 0; codeIndex < parsedCount; codeIndex++) {
        const ansiCode = this.#parsedCodes[codeIndex];
        switch (true) {
          case ansiCode === SGR_RESET: {
            this.#resetStyles();
            break;
          }
          case ansiCode === SGR_BOLD: {
            this.#currentFontWeight = FONT_WEIGHT_BOLD;
            this.#hasActiveStyle = true;
            break;
          }
          case ansiCode === SGR_BOLD_OFF: {
            this.#currentFontWeight = void 0;
            this.#hasActiveStyle = Boolean(
              this.#currentColor || this.#currentBackground || this.#currentFontWeight
            );
            break;
          }
          case (ansiCode === SGR_FG_EXTENDED && this.#parsedCodes[codeIndex + 1] === 5): {
            const paletteIndex = this.#parsedCodes[codeIndex + 2];
            if (paletteIndex != null) {
              const mapped = ANSI_256_MAP[paletteIndex];
              if (mapped) {
                this.#currentColor = mapped;
                this.#hasActiveStyle = true;
              }
            }
            codeIndex += 2;
            break;
          }
          case (ansiCode === SGR_BG_EXTENDED && this.#parsedCodes[codeIndex + 1] === 5): {
            const paletteIndex = this.#parsedCodes[codeIndex + 2];
            if (paletteIndex != null) {
              const mapped = ANSI_256_MAP[paletteIndex];
              if (mapped) {
                this.#currentBackground = mapped;
                this.#hasActiveStyle = true;
              }
            }
            codeIndex += 2;
            break;
          }
          case (ansiCode >= 30 && ansiCode <= 37): {
            this.#currentColor = BASIC_FG_COLORS[ansiCode - 30];
            this.#hasActiveStyle = true;
            break;
          }
          case (ansiCode >= 90 && ansiCode <= 97): {
            this.#currentColor = BRIGHT_FG_COLORS[ansiCode - 90];
            this.#hasActiveStyle = true;
            break;
          }
          case ansiCode === SGR_FG_DEFAULT: {
            this.#currentColor = void 0;
            this.#hasActiveStyle = Boolean(
              this.#currentBackground || this.#currentFontWeight
            );
            break;
          }
          case ansiCode === SGR_BG_DEFAULT: {
            this.#currentBackground = void 0;
            this.#hasActiveStyle = Boolean(
              this.#currentColor || this.#currentFontWeight
            );
            break;
          }
          default: {
          }
        }
      }
    }
    /** Reset style-related state to defaults (SGR 0 or empty parameter list). */
    #resetStyles() {
      this.#currentColor = this.#currentBackground = this.#currentFontWeight = void 0;
      this.#hasActiveStyle = false;
      this.#currentStyleSpanStart = "";
    }
    /** Rebuild the opening span tag (if any style active) using deterministic property ordering. */
    #rebuildStyleSpanStart() {
      if (!this.#hasActiveStyle) {
        this.#currentStyleSpanStart = "";
        return;
      }
      const signatureColor = this.#currentColor ?? "";
      const signatureBg = this.#currentBackground ?? "";
      const signatureWeight = this.#currentFontWeight ?? "";
      const signature = `${signatureColor}|${signatureBg}|${signatureWeight}`;
      const cached = _AnsiHtmlConverter.#StyleCache.get(signature);
      if (cached) {
        this.#currentStyleSpanStart = cached;
        return;
      }
      const styleFragments = [];
      if (signatureColor) styleFragments.push(`color: ${signatureColor}`);
      if (signatureBg) styleFragments.push(`background: ${signatureBg}`);
      if (signatureWeight) styleFragments.push(`font-weight: ${signatureWeight}`);
      const built = styleFragments.length ? `<span style="${styleFragments.join(";")}">` : "";
      _AnsiHtmlConverter.#StyleCache.set(signature, built);
      this.#currentStyleSpanStart = built;
    }
    /** Wrap a text segment with current style if active. */
    #wrapIfStyled(text) {
      return this.#currentStyleSpanStart ? `${this.#currentStyleSpanStart}${text}</span>` : text;
    }
    /** Convert ANSI-coded text to HTML (newlines already streamed into `<br/>`). */
    static formatWithNewlines(input) {
      return this.convert(input);
    }
  };
  function createBrowserLogger(container) {
    return (...args) => {
      const logPreElement = ensurePre(container);
      let logOptions = void 0;
      if (args.length) {
        const lastArgument = MazeUtils.safeLast(args);
        if (lastArgument && typeof lastArgument === "object" && "prepend" in lastArgument) {
          logOptions = lastArgument;
          args.pop();
        }
      }
      let combinedText = "";
      for (let argumentIndex = 0; argumentIndex < args.length; argumentIndex++) {
        if (argumentIndex) combinedText += " ";
        const argumentValue = args[argumentIndex];
        combinedText += typeof argumentValue === "string" ? argumentValue : JSON.stringify(argumentValue);
      }
      if (!logPreElement) return;
      const html = AnsiHtmlConverter.formatWithNewlines(combinedText) + "<br/>";
      if (logOptions && logOptions.prepend) {
        logPreElement.insertAdjacentHTML("afterbegin", html);
        logPreElement.scrollTop = 0;
      } else {
        logPreElement.insertAdjacentHTML("beforeend", html);
        logPreElement.scrollTop = logPreElement.scrollHeight;
      }
    };
  }

  // test/examples/asciiMaze/colors.ts
  var colors = {
    // Basic formatting
    reset: "\x1B[0m",
    // Reset all attributes
    bright: "\x1B[1m",
    // Bright/bold text
    dim: "\x1B[2m",
    // Dim text
    // Neon foreground colors (expanded palette)
    neonPink: "\x1B[38;5;205m",
    // Neon pink
    neonPurple: "\x1B[38;5;93m",
    // Neon purple
    neonLime: "\x1B[38;5;154m",
    // Neon lime green
    neonAqua: "\x1B[38;5;51m",
    // Neon aqua
    neonYellow: "\x1B[38;5;226m",
    // Neon yellow
    neonOrange: "\x1B[38;5;214m",
    // Neon orange (brighter)
    neonRed: "\x1B[38;5;196m",
    // Neon red
    neonGreen: "\x1B[38;5;46m",
    // Neon green
    neonSky: "\x1B[38;5;123m",
    // Neon sky blue
    neonViolet: "\x1B[38;5;177m",
    // Neon violet
    neonTurquoise: "\x1B[38;5;80m",
    // Neon turquoise
    neonMint: "\x1B[38;5;121m",
    // Neon mint
    neonCoral: "\x1B[38;5;203m",
    // Neon coral
    neonIndigo: "\x1B[38;5;99m",
    // Neon indigo
    neonTeal: "\x1B[38;5;44m",
    // Neon teal
    neonGold: "\x1B[38;5;220m",
    // Neon gold
    neonSilver: "\x1B[38;5;250m",
    // Neon silver
    neonBlue: "\x1B[38;5;45m",
    // Neon blue (extra)
    neonMagenta: "\x1B[38;5;201m",
    // Neon magenta (extra)
    neonCyan: "\x1B[38;5;87m",
    // Neon cyan (extra)
    neonWhite: "\x1B[38;5;231m",
    // Neon white (brightest)
    neonRose: "\x1B[38;5;218m",
    // Neon rose
    neonPeach: "\x1B[38;5;217m",
    // Neon peach
    neonAzure: "\x1B[38;5;117m",
    // Neon azure
    neonChartreuse: "\x1B[38;5;118m",
    // Neon chartreuse
    neonSpring: "\x1B[38;5;48m",
    // Neon spring green
    neonAmber: "\x1B[38;5;214m",
    // Neon amber (duplicate of orange, for clarity)
    neonFuchsia: "\x1B[38;5;207m",
    // Neon fuchsia
    // TRON primary colors (foreground)
    blueCore: "\x1B[38;5;39m",
    // Primary TRON blue
    cyanNeon: "\x1B[38;5;87m",
    // Electric cyan
    blueNeon: "\x1B[38;5;45m",
    // Bright neon blue
    whiteNeon: "\x1B[38;5;159m",
    // Electric white-blue
    orangeNeon: "\x1B[38;5;208m",
    // TRON orange (for contrast)
    magentaNeon: "\x1B[38;5;201m",
    // Digital magenta
    // Base colors (foreground)
    red: "\x1B[38;5;197m",
    // Program termination red
    green: "\x1B[38;5;118m",
    // User/CLU green
    yellow: "\x1B[38;5;220m",
    // Warning yellow
    blue: "\x1B[38;5;33m",
    // Deep blue
    cyan: "\x1B[38;5;51m",
    // Light cyan
    // Neon background colors (expanded palette)
    bgNeonPink: "\x1B[48;5;205m",
    bgNeonPurple: "\x1B[48;5;93m",
    bgNeonLime: "\x1B[48;5;154m",
    bgNeonAqua: "\x1B[48;5;51m",
    bgNeonYellow: "\x1B[48;5;226m",
    bgNeonOrange: "\x1B[48;5;214m",
    bgNeonRed: "\x1B[48;5;196m",
    bgNeonGreen: "\x1B[48;5;46m",
    bgNeonSky: "\x1B[48;5;123m",
    bgNeonViolet: "\x1B[48;5;177m",
    bgNeonTurquoise: "\x1B[48;5;80m",
    bgNeonMint: "\x1B[48;5;121m",
    bgNeonCoral: "\x1B[48;5;203m",
    bgNeonIndigo: "\x1B[48;5;99m",
    bgNeonTeal: "\x1B[48;5;44m",
    bgNeonGold: "\x1B[48;5;220m",
    bgNeonSilver: "\x1B[48;5;250m",
    bgNeonBlue: "\x1B[48;5;45m",
    // Neon blue background (extra)
    bgNeonMagenta: "\x1B[48;5;201m",
    // Neon magenta background (extra)
    bgNeonCyan: "\x1B[48;5;87m",
    // Neon cyan background (extra)
    bgNeonWhite: "\x1B[48;5;231m",
    // Neon white background (brightest)
    bgNeonRose: "\x1B[48;5;218m",
    // Neon rose background
    bgNeonPeach: "\x1B[48;5;217m",
    // Neon peach background
    bgNeonAzure: "\x1B[48;5;117m",
    // Neon azure background
    bgNeonChartreuse: "\x1B[48;5;118m",
    // Neon chartreuse background
    bgNeonSpring: "\x1B[48;5;48m",
    // Neon spring green background
    bgNeonAmber: "\x1B[48;5;214m",
    // Neon amber background (duplicate of orange, for clarity)
    bgNeonFuchsia: "\x1B[48;5;207m",
    // Neon fuchsia background
    // TRON background colors
    bgBlueCore: "\x1B[48;5;39m",
    // Primary TRON blue background
    bgCyanNeon: "\x1B[48;5;87m",
    // Electric cyan background (for agent)
    bgBlueNeon: "\x1B[48;5;45m",
    // Bright neon blue background
    bgWhiteNeon: "\x1B[48;5;159m",
    // Electric white-blue background
    bgOrangeNeon: "\x1B[48;5;208m",
    // TRON orange background
    bgMagentaNeon: "\x1B[48;5;201m",
    // Digital magenta background
    // Common backgrounds
    bgRed: "\x1B[48;5;197m",
    // Program termination red background
    bgGreen: "\x1B[48;5;118m",
    // User/CLU green background
    bgYellow: "\x1B[48;5;220m",
    // Warning yellow background
    bgBlue: "\x1B[48;5;33m",
    // Deep blue background
    // Maze-specific colors
    darkWallBg: "\x1B[48;5;17m",
    // Dark blue for walls
    darkWallText: "\x1B[38;5;17m",
    // Dark blue text for wall symbols
    floorBg: "\x1B[48;5;234m",
    // Almost black for empty floor
    floorText: "\x1B[38;5;234m",
    // Almost black text for floor symbols
    gridLineBg: "\x1B[48;5;23m",
    // Subtle grid line color
    gridLineText: "\x1B[38;5;23m",
    // Subtle grid line text
    // Special highlights
    bgBlack: "\x1B[48;5;16m",
    // Pure black background
    pureBlue: "\x1B[38;5;57;1m",
    // Vibrant system blue
    pureOrange: "\x1B[38;5;214;1m",
    // Vibrant TRON orange (for CLU/villains)
    pureGreen: "\x1B[38;5;46;1m"
    // Pure green for user programs
  };

  // test/examples/asciiMaze/networkVisualization.ts
  var NetworkVisualization = class _NetworkVisualization {
    // Internal layout constants (private)
    static #ARROW = "  \u2500\u2500\u25B6  ";
    static #ARROW_WIDTH = _NetworkVisualization.#ARROW.length;
    static #TOTAL_WIDTH = 150;
    // Overall visualization width
    /** Activation range buckets (ordered, positive to negative). */
    static #ACTIVATION_RANGES = [
      { min: 2, max: Infinity, label: "v-high+" },
      { min: 1, max: 2, label: "high+" },
      { min: 0.5, max: 1, label: "mid+" },
      { min: 0.1, max: 0.5, label: "low+" },
      { min: -0.1, max: 0.1, label: "zero\xB1" },
      { min: -0.5, max: -0.1, label: "low-" },
      { min: -1, max: -0.5, label: "mid-" },
      { min: -2, max: -1, label: "high-" },
      { min: -Infinity, max: -2, label: "v-high-" }
    ];
    /** Scratch array for connection counts (reused / grown). @remarks Non-reentrant. */
    static #ConnectionCountsScratch = new Int32Array(16);
    static #ConnectionCountsLen = 0;
    /** Scratch list for building output rows before join. @remarks Non-reentrant. */
    static #ScratchRows = [];
    /** Scratch list for header construction. */
    static #ScratchHeaderParts = [];
    /**
     * Pads a string to a specific width with alignment options.
     *
     * @param str - String to pad.
     * @param width - Target width for the string.
     * @param padChar - Character to use for padding (default: space).
     * @param align - Alignment option ('left', 'center', or 'right').
     * @returns Padded string of specified width with chosen alignment.
     */
    static pad(str, width, padChar = " ", align = "center") {
      str = str ?? "";
      const len = str.replace(/\x1b\[[0-9;]*m/g, "").length;
      if (len >= width) return str;
      const padLen = width - len;
      if (align === "left") return str + padChar.repeat(padLen);
      if (align === "right") return padChar.repeat(padLen) + str;
      const left = Math.floor(padLen / 2);
      const right = padLen - left;
      return padChar.repeat(left) + str + padChar.repeat(right);
    }
    /**
     * Gets activation value from a node, with safety checks.
     * For output nodes, ensures values are properly clamped between 0 and 1.
     *
     * @param node - Neural network node object.
     * @returns Cleaned and normalized activation value.
     */
    static #getNodeValue(node) {
      if (typeof node.activation === "number" && isFinite(node.activation) && !isNaN(node.activation)) {
        if (node.type === "output") {
          return Math.max(0, Math.min(1, node.activation));
        }
        return Math.max(-999, Math.min(999, node.activation));
      }
      return 0;
    }
    /**
     * Gets the appropriate color for an activation value based on its range.
     * Uses a TRON-inspired color palette for activation values.
     *
     * @param value - Activation value to colorize.
     * @returns ANSI color code for the value.
     */
    static #getActivationColor(value) {
      if (value >= 2) return colors.bgOrangeNeon + colors.bright;
      if (value >= 1) return colors.orangeNeon;
      if (value >= 0.5) return colors.cyanNeon;
      if (value >= 0.1) return colors.neonGreen;
      if (value >= -0.1) return colors.whiteNeon;
      if (value >= -0.5) return colors.blue;
      if (value >= -1) return colors.blueCore;
      if (value >= -2) return colors.bgNeonAqua + colors.bright;
      return colors.bgNeonViolet + colors.neonSilver;
    }
    /**
     * Formats a numeric value for display with color based on its value.
     *
     * @param v - Numeric value to format.
     * @returns Colorized string representation of the value.
     */
    static #fmtColoredValue(v) {
      if (typeof v !== "number" || isNaN(v) || !isFinite(v)) return " 0.000";
      const color = this.#getActivationColor(v);
      let formattedValue;
      formattedValue = (v >= 0 ? " " : "") + v.toFixed(6);
      return color + formattedValue + colors.reset;
    }
    /**
     * Format a node display with a colored symbol and its colored numeric value.
     * `extra` can include any trailing text (already colorized) and may include a leading space.
     */
    static #formatNode(symbolColor, symbol, node, extra) {
      const value = _NetworkVisualization.#getNodeValue(node);
      const fmt = _NetworkVisualization.#fmtColoredValue(value);
      const sym = `${symbolColor}${symbol}${colors.reset}`;
      return `${sym}${fmt}${extra ?? ""}`;
    }
    /**
     * Groups hidden nodes into layers based on their connections.
     *
     * @param inputNodes - Array of input nodes.
     * @param hiddenNodes - Array of hidden nodes.
     * @param outputNodes - Array of output nodes.
     * @returns Array of hidden node arrays, each representing a layer.
     */
    static #groupHiddenByLayer(inputNodes, hiddenNodes, outputNodes) {
      if (hiddenNodes.length === 0) return [];
      let layers = [];
      let prevLayer = inputNodes;
      let remaining = [...hiddenNodes];
      while (remaining.length > 0) {
        const currentLayer = remaining.filter(
          (h) => h.connections && h.connections.in && h.connections.in.length > 0 && h.connections.in.every((conn) => prevLayer.includes(conn.from))
        );
        if (currentLayer.length === 0) {
          layers.push(remaining);
          break;
        }
        layers.push(currentLayer);
        prevLayer = currentLayer;
        remaining = remaining.filter((h) => !currentLayer.includes(h));
      }
      return layers;
    }
    /**
     * Groups nodes by their activation values to create meaningful average representations.
     * Creates more granular grouping based on activation ranges.
     *
     * @param nodes - Array of neural network nodes to group.
     * @returns Object containing groups of nodes and corresponding labels.
     */
    static #groupNodesByActivation(nodes) {
      const activations = nodes.map(
        (node) => _NetworkVisualization.#getNodeValue(node)
      );
      const groups = [];
      const labels = [];
      for (const range of _NetworkVisualization.#ACTIVATION_RANGES) {
        const nodesInRange = nodes.filter(
          (_, i) => activations[i] >= range.min && activations[i] < range.max
        );
        if (nodesInRange.length > 0) {
          groups.push(nodesInRange);
          labels.push(range.label);
        }
      }
      return { groups, labels };
    }
    /**
     * Prepares hidden layers for display, condensing large layers
     * to show all nodes as averages with meaningful distribution.
     *
     * @param hiddenLayers - Array of hidden layer node arrays.
     * @param maxVisiblePerLayer - Maximum number of nodes to display per layer.
     * @returns Object containing display-ready layers and metrics.
     */
    static #prepareHiddenLayersForDisplay(hiddenLayers, maxVisiblePerLayer = 10) {
      const MAX_VISIBLE = maxVisiblePerLayer;
      const averageNodes = {};
      const displayLayers = [];
      const layerDisplayCounts = [];
      hiddenLayers.forEach((layer, layerIdx) => {
        if (layer.length <= MAX_VISIBLE) {
          displayLayers.push([...layer]);
          layerDisplayCounts.push(layer.length);
        } else {
          const {
            avgNodes,
            count
          } = _NetworkVisualization.#createAverageNodesForLargeLayer({
            layer,
            layerIndex: layerIdx,
            maxVisible: MAX_VISIBLE,
            averageNodesStore: averageNodes
          });
          displayLayers.push(avgNodes);
          layerDisplayCounts.push(count);
        }
      });
      return { displayLayers, layerDisplayCounts, averageNodes };
    }
    /**
     * Create average nodes representation for a large hidden layer.
     * Decomposed from #prepareHiddenLayersForDisplay for clarity.
     */
    static #createAverageNodesForLargeLayer(params) {
      const { layer, layerIndex, maxVisible, averageNodesStore } = params;
      const { groups, labels } = _NetworkVisualization.#groupNodesByActivation(
        layer
      );
      const { finalGroups, finalLabels } = groups.length > maxVisible ? _NetworkVisualization.#rankMergeAndOrderGroups({
        groups,
        labels,
        maxVisible
      }) : { finalGroups: groups, finalLabels: labels };
      const averageNodes = finalGroups.map(
        (group, groupIndex) => _NetworkVisualization.#buildAverageNode({
          group,
          groupIndex,
          layerIndex,
          label: finalLabels[groupIndex],
          averageNodesStore
        })
      );
      return { avgNodes: averageNodes, count: averageNodes.length };
    }
    /** Build a single average node descriptor from a group. */
    static #buildAverageNode(params) {
      const { group, groupIndex, layerIndex, label, averageNodesStore } = params;
      const avgKey = `layer${layerIndex}-avg-${groupIndex}`;
      const sum = group.reduce(
        (runningTotal, node) => runningTotal + _NetworkVisualization.#getNodeValue(node),
        0
      );
      const avgValue = group.length ? sum / group.length : 0;
      averageNodesStore[avgKey] = { avgValue, count: group.length };
      return {
        id: -1 * (layerIndex * 1e3 + groupIndex),
        uuid: avgKey,
        type: "hidden",
        activation: avgValue,
        isAverage: true,
        avgCount: group.length,
        label
      };
    }
    /** Rank groups by size, merge overflow into one group, then order by activation semantics. */
    static #rankMergeAndOrderGroups(params) {
      const { groups, labels, maxVisible } = params;
      const groupMeta = groups.map((group, index) => ({
        group,
        label: labels[index],
        size: group.length
      }));
      const ranked = _NetworkVisualization.#safeToSorted(
        groupMeta,
        (a, b) => b.size - a.size
      );
      const cutPoint = Math.max(0, maxVisible - 1);
      const top = ranked.slice(0, cutPoint);
      const remainder = ranked.slice(cutPoint);
      if (remainder.length)
        top.push(_NetworkVisualization.#mergeOverflowGroups(remainder));
      const ordered = _NetworkVisualization.#safeToSorted(
        top,
        _NetworkVisualization.#activationLabelComparator
      );
      return {
        finalGroups: ordered.map((m) => m.group),
        finalLabels: ordered.map((m) => m.label)
      };
    }
    /** Merge overflow group metadata into a single synthetic bucket. */
    static #mergeOverflowGroups(metadataList) {
      return metadataList.reduce(
        (acc, current) => {
          acc.group.push(...current.group);
          acc.size += current.size;
          return acc;
        },
        { group: [], label: "other\xB1", size: 0 }
      );
    }
    /** Safe wrapper around ES2023 Array.prototype.toSorted with graceful fallback. */
    static #safeToSorted(array, compare) {
      const anyArray = array;
      if (typeof anyArray.toSorted === "function")
        return anyArray.toSorted(compare);
      return [...array].sort(compare);
    }
    /** Comparator for activation range label ordering (heuristic). */
    static #activationLabelComparator(a, b) {
      const aNeg = a.label.includes("-");
      const bNeg = b.label.includes("-");
      if (aNeg !== bNeg) return aNeg ? 1 : -1;
      const veryA = a.label.startsWith("v-high");
      const veryB = b.label.startsWith("v-high");
      if (veryA !== veryB) return veryA ? -1 : 1;
      const highA = a.label.includes("high");
      const highB = b.label.includes("high");
      if (highA !== highB) return highA ? -1 : 1;
      return 0;
    }
    /**
     * Utility to create a visualization node from a neataptic node.
     *
     * @param node - Neural network node object.
     * @param index - Index of the node in the network.
     * @returns Visualization node object.
     */
    static #toVisualizationNode(node, index) {
      const id = typeof node.index === "number" ? node.index : index;
      return {
        id,
        uuid: String(id),
        type: node.type,
        activation: node.activation,
        bias: node.bias
      };
    }
    /** Categorize nodes in a single pass (avoids 3 separate filter passes). */
    static #categorizeNodes(network) {
      const inputNodes = [];
      const hiddenNodes = [];
      const outputNodes = [];
      const nodes = network.nodes || [];
      for (let index = 0; index < nodes.length; index++) {
        const node = nodes[index];
        const viz = _NetworkVisualization.#toVisualizationNode(node, index);
        switch (node.type) {
          case "input":
          case "constant":
            inputNodes.push(viz);
            break;
          case "hidden":
            hiddenNodes.push(viz);
            break;
          case "output":
            outputNodes.push(viz);
            break;
          default:
            break;
        }
      }
      return {
        inputNodes,
        hiddenNodes,
        outputNodes,
        inputCountDetected: inputNodes.length
      };
    }
    /** Ensure connection-count scratch buffer is large enough. */
    static #ensureConnectionScratch(required) {
      if (_NetworkVisualization.#ConnectionCountsScratch.length < required) {
        let newSize = _NetworkVisualization.#ConnectionCountsScratch.length;
        while (newSize < required) newSize *= 2;
        _NetworkVisualization.#ConnectionCountsScratch = new Int32Array(newSize);
      }
      return _NetworkVisualization.#ConnectionCountsScratch;
    }
    /** Compute connection counts between sequential layer boundaries. */
    static #computeConnectionCounts(network, inputNodes, hiddenLayers, outputNodes) {
      const numHiddenLayers = hiddenLayers.length;
      const arrows = numHiddenLayers > 0 ? numHiddenLayers + 1 : 1;
      const scratch = _NetworkVisualization.#ensureConnectionScratch(arrows);
      scratch.fill(0, 0, arrows);
      _NetworkVisualization.#ConnectionCountsLen = arrows;
      const inputIdSet = new Set(inputNodes.map((n) => Number(n.id)));
      const outputIdSet = new Set(outputNodes.map((n) => Number(n.id)));
      const hiddenSets = hiddenLayers.map(
        (layer) => new Set(layer.map((n) => Number(n.id)))
      );
      const connections = network.connections || [];
      for (let ci = 0; ci < connections.length; ci++) {
        const conn = connections[ci];
        const fromIdx = Number(conn.from?.index ?? -1);
        const toIdx = Number(conn.to?.index ?? -1);
        if (inputIdSet.has(fromIdx)) {
          if (hiddenSets[0] && hiddenSets[0].has(toIdx)) scratch[0]++;
          else if (hiddenSets.length === 0 && outputIdSet.has(toIdx))
            scratch[0]++;
          continue;
        }
        for (let h = 0; h < hiddenSets.length; h++) {
          const fromSet = hiddenSets[h];
          if (!fromSet.has(fromIdx)) continue;
          const lastHidden = h === hiddenSets.length - 1;
          if (!lastHidden) {
            const toSet = hiddenSets[h + 1];
            if (toSet.has(toIdx)) {
              scratch[1 + h]++;
              break;
            }
          } else {
            if (outputIdSet.has(toIdx)) {
              scratch[hiddenSets.length]++;
              break;
            }
          }
        }
      }
      return scratch;
    }
    /** Build header string. */
    static #buildHeader(inputCount, hiddenLayers, outputCount, connectionCounts) {
      const numHiddenLayers = hiddenLayers.length;
      const { columnWidth } = _NetworkVisualization.#computeLayout(
        numHiddenLayers
      );
      const parts = _NetworkVisualization.#ScratchHeaderParts;
      parts.length = 0;
      parts.push(
        _NetworkVisualization.#buildHeaderSegment({
          prefix: `${colors.blueCore}\u2551`,
          label: `${colors.neonGreen}Input Layer [${inputCount}]${colors.reset}`,
          width: columnWidth - 1
        })
      );
      parts.push(
        _NetworkVisualization.#formatHeaderArrow(connectionCounts[0] ?? 0)
      );
      for (let hiddenLayerIndex = 0; hiddenLayerIndex < numHiddenLayers; hiddenLayerIndex++) {
        parts.push(
          _NetworkVisualization.pad(
            `${colors.cyanNeon}Hidden ${hiddenLayerIndex + 1} [${hiddenLayers[hiddenLayerIndex].length}]${colors.reset}`,
            columnWidth
          )
        );
        parts.push(
          _NetworkVisualization.#formatHeaderArrow(
            connectionCounts[hiddenLayerIndex + 1] || 0
          )
        );
      }
      parts.push(
        _NetworkVisualization.pad(
          `${colors.orangeNeon}Output Layer [${outputCount}]${colors.reset}`,
          columnWidth,
          " ",
          "center"
        ) + `${colors.blueCore}\u2551${colors.reset}`
      );
      return parts.join("");
    }
    /** Build a single header segment with optional prefix. */
    static #buildHeaderSegment(params) {
      const { prefix = "", label, width } = params;
      return prefix + _NetworkVisualization.pad(label, width, " ", "center");
    }
    /** Format a header arrow segment including connection count label. */
    static #formatHeaderArrow(connectionCount) {
      const text = `${colors.blueNeon}${connectionCount} ${_NetworkVisualization.#ARROW.trim()}${colors.reset}`;
      return _NetworkVisualization.pad(text, _NetworkVisualization.#ARROW_WIDTH);
    }
    /** Build legend footer lines. */
    static #buildLegend() {
      return [
        // Spacer
        `${colors.blueCore}\u2551       ${_NetworkVisualization.pad(" ", 140)} \u2551${colors.reset}`,
        `${colors.blueCore}\u2551       ${_NetworkVisualization.pad(
          "Arrows indicate feed-forward flow.",
          140,
          " ",
          "left"
        )} ${colors.blueCore}\u2551${colors.reset}`,
        `${colors.blueCore}\u2551       ${_NetworkVisualization.pad(" ", 140)} \u2551${colors.reset}`,
        `${colors.blueCore}\u2551       ${_NetworkVisualization.pad(
          `${colors.whiteNeon}Legend:  ${colors.neonGreen}\u25CF${colors.reset}=Input                    ${colors.cyanNeon}\u25A0${colors.reset}=Hidden                    ${colors.orangeNeon}\u25B2${colors.reset}=Output`,
          140,
          " ",
          "left"
        )} ${colors.blueCore}\u2551${colors.reset}`,
        `${colors.blueCore}\u2551       ${_NetworkVisualization.pad(
          `${colors.whiteNeon}Groups:  ${colors.bgOrangeNeon}${colors.bright}v-high+${colors.reset}=Very high positive   ${colors.orangeNeon}high+${colors.reset}=High positive    ${colors.cyanNeon}mid+${colors.reset}=Medium positive    ${colors.neonGreen}low+${colors.reset}=Low positive`,
          140,
          " ",
          "left"
        )} ${colors.blueCore}\u2551${colors.reset}`,
        `${colors.blueCore}\u2551       ${_NetworkVisualization.pad(
          `${colors.whiteNeon}         zero\xB1${colors.reset}=Near zero`,
          140,
          " ",
          "left"
        )} ${colors.blueCore}\u2551${colors.reset}`,
        `${colors.blueCore}\u2551       ${_NetworkVisualization.pad(
          `         ${colors.bgBlueCore}${colors.bright}v-high-${colors.reset}=Very high negative   ${colors.blueNeon}${colors.bright}high-${colors.reset}=High negative    ${colors.blueCore}mid-${colors.reset}=Medium negative    ${colors.blue}low-${colors.reset}=Low negative`,
          140,
          " ",
          "left"
        )} ${colors.blueCore}\u2551${colors.reset}`
      ];
    }
    /** Build row strings for body. */
    static #buildRows(params, columnWidth) {
      const context = _NetworkVisualization.#buildRowsInit(params);
      const {
        maxRows,
        rows,
        inputDisplayNodes,
        outputDisplayNodes,
        numHiddenLayers,
        inputCount,
        outputCount,
        inputNodes,
        displayLayers,
        connectionCounts
      } = context;
      for (let rowIndex = 0; rowIndex < maxRows; rowIndex++) {
        let line = "";
        line += _NetworkVisualization.#buildInputCell({
          rowIndex,
          inputCount,
          columnWidth,
          inputDisplayNodes
        });
        line += _NetworkVisualization.#buildFirstArrowCell({
          rowIndex,
          inputCount,
          inputNodes,
          displayLayers,
          connectionCounts
        });
        for (let layerIndex = 0; layerIndex < numHiddenLayers; layerIndex++) {
          line += _NetworkVisualization.#buildHiddenLayerCell({
            rowIndex,
            layerIndex,
            columnWidth,
            displayLayers
          });
          line += _NetworkVisualization.#buildInterLayerArrowCell({
            rowIndex,
            layerIndex,
            numHiddenLayers,
            displayLayers,
            connectionCounts,
            outputCount
          });
        }
        line += _NetworkVisualization.#buildOutputCell({
          rowIndex,
          outputCount,
          outputDisplayNodes,
          columnWidth
        });
        rows.push(line);
      }
      return rows.slice();
    }
    /** Initialize reusable structures for row building. */
    static #buildRowsInit(params) {
      const {
        inputCount,
        outputCount,
        inputNodes,
        displayLayers,
        layerDisplayCounts,
        outputNodes,
        connectionCounts
      } = params;
      const maxRows = Math.max(inputCount, ...layerDisplayCounts, outputCount);
      const rows = _NetworkVisualization.#ScratchRows;
      rows.length = 0;
      const inputDisplayNodes = Array.from(
        { length: inputCount },
        (_, idx) => inputNodes[idx] || { activation: 0 }
      );
      const outputDisplayNodes = Array.from(
        { length: outputCount },
        (_, idx) => outputNodes[idx] || { activation: 0 }
      );
      return {
        maxRows,
        rows,
        inputDisplayNodes,
        outputDisplayNodes,
        numHiddenLayers: displayLayers.length,
        inputCount,
        outputCount,
        inputNodes,
        displayLayers,
        connectionCounts
      };
    }
    /** Build cell for an input row (including label). */
    static #buildInputCell(params) {
      const { rowIndex, inputCount, columnWidth, inputDisplayNodes } = params;
      if (rowIndex >= inputCount)
        return _NetworkVisualization.pad("", columnWidth);
      const INPUT_LABELS6 = [
        "compass",
        "openN",
        "openE",
        "openS",
        "openW",
        "progress"
      ];
      const node = inputDisplayNodes[rowIndex];
      const label = rowIndex < 6 ? INPUT_LABELS6[rowIndex] : "";
      const labelStr = label ? ` ${colors.whiteNeon}${label}${colors.reset}` : "";
      return _NetworkVisualization.pad(
        `${colors.blueCore}\u2551   ${_NetworkVisualization.#formatNode(
          colors.neonGreen,
          "\u25CF",
          node,
          labelStr
        )}`,
        columnWidth,
        " ",
        "left"
      );
    }
    /** Build arrow cell between input and first hidden layer. */
    static #buildFirstArrowCell(params) {
      const {
        rowIndex,
        inputCount,
        inputNodes,
        displayLayers,
        connectionCounts
      } = params;
      const firstHiddenTotal = displayLayers[0]?.length || 0;
      const totalInputs = Math.min(inputCount, inputNodes.length);
      const base = `${colors.blueNeon}${_NetworkVisualization.#ARROW}${colors.reset}`;
      if (rowIndex === 0 && totalInputs && firstHiddenTotal) {
        const nodeProportion = Math.ceil(
          (connectionCounts[0] || 0) / Math.max(1, totalInputs)
        );
        return _NetworkVisualization.pad(
          `${colors.blueNeon}${nodeProportion} \u2500\u2500\u25B6${colors.reset}`,
          _NetworkVisualization.#ARROW_WIDTH
        );
      }
      if (rowIndex < inputCount && rowIndex < firstHiddenTotal && totalInputs && firstHiddenTotal) {
        const nodeProportion = Math.ceil(
          (connectionCounts[0] || 0) / Math.max(3, totalInputs * 2)
        );
        return _NetworkVisualization.pad(
          `${colors.blueNeon}${nodeProportion} \u2500\u2500\u25B6${colors.reset}`,
          _NetworkVisualization.#ARROW_WIDTH
        );
      }
      return _NetworkVisualization.pad(base, _NetworkVisualization.#ARROW_WIDTH);
    }
    /** Build hidden layer node cell. */
    static #buildHiddenLayerCell(params) {
      const { rowIndex, layerIndex, columnWidth, displayLayers } = params;
      const layer = displayLayers[layerIndex];
      if (rowIndex >= layer.length)
        return _NetworkVisualization.pad(" ", columnWidth);
      const node = layer[rowIndex];
      if (node.isAverage) {
        const labelText = node.label ? `${node.label} ` : "";
        const extra = ` ${colors.dim}(${labelText}avg of ${node.avgCount})${colors.reset}`;
        return _NetworkVisualization.pad(
          _NetworkVisualization.#formatNode(colors.cyanNeon, "\u25A0", node, extra),
          columnWidth,
          " ",
          "left"
        );
      }
      return _NetworkVisualization.pad(
        _NetworkVisualization.#formatNode(colors.cyanNeon, "\u25A0", node),
        columnWidth,
        " ",
        "left"
      );
    }
    /** Build arrow cell either between hidden layers or from last hidden to outputs. */
    static #buildInterLayerArrowCell(params) {
      const {
        rowIndex,
        layerIndex,
        numHiddenLayers,
        displayLayers,
        connectionCounts,
        outputCount
      } = params;
      const layer = displayLayers[layerIndex];
      const arrowPlaceholder = `${colors.blueNeon}${_NetworkVisualization.#ARROW}${colors.reset}`;
      const isLast = layerIndex === numHiddenLayers - 1;
      if (!isLast) {
        const connCount = connectionCounts[layerIndex + 1] || 0;
        if (rowIndex === 0) {
          const currentLayerSize = layer.length || 1;
          const nodeProportion = Math.ceil(
            connCount / Math.max(3, currentLayerSize * 2)
          );
          return _NetworkVisualization.pad(
            `${colors.blueNeon}${nodeProportion} \u2500\u2500\u25B6${colors.reset}`,
            _NetworkVisualization.#ARROW_WIDTH
          );
        }
        if (rowIndex < layer.length && rowIndex < (displayLayers[layerIndex + 1]?.length || 0)) {
          const currentLayerSize = layer.length || 1;
          const proportion = Math.max(
            1,
            Math.min(5, Math.ceil(connCount / Math.max(3, currentLayerSize)))
          );
          return _NetworkVisualization.pad(
            `${colors.blueNeon}${proportion} \u2500\u2500\u25B6${colors.reset}`,
            _NetworkVisualization.#ARROW_WIDTH
          );
        }
        return _NetworkVisualization.pad(
          arrowPlaceholder,
          _NetworkVisualization.#ARROW_WIDTH
        );
      }
      const lastConnCount = connectionCounts[numHiddenLayers] || 0;
      if (rowIndex === 0) {
        const lastLayerSize = layer.length || 1;
        const nodeProportion = Math.ceil(
          lastConnCount / Math.max(3, lastLayerSize * 2)
        );
        return _NetworkVisualization.pad(
          `${colors.blueNeon}${nodeProportion} \u2500\u2500\u25B6${colors.reset}`,
          _NetworkVisualization.#ARROW_WIDTH
        );
      }
      if (rowIndex < layer.length && rowIndex < outputCount) {
        const lastLayerSize = layer.length || 1;
        const proportion = Math.max(
          1,
          Math.min(5, Math.ceil(lastConnCount / Math.max(5, lastLayerSize * 2)))
        );
        return _NetworkVisualization.pad(
          `${colors.blueNeon}${proportion} \u2500\u2500\u25B6${colors.reset}`,
          _NetworkVisualization.#ARROW_WIDTH
        );
      }
      return _NetworkVisualization.pad(
        arrowPlaceholder,
        _NetworkVisualization.#ARROW_WIDTH
      );
    }
    /** Build output layer cell. */
    static #buildOutputCell(params) {
      const { rowIndex, outputCount, outputDisplayNodes, columnWidth } = params;
      if (rowIndex >= outputCount)
        return _NetworkVisualization.pad("", columnWidth);
      const node = outputDisplayNodes[rowIndex];
      return _NetworkVisualization.pad(
        _NetworkVisualization.#formatNode(colors.orangeNeon, "\u25B2", node),
        columnWidth,
        " ",
        "left"
      ) + `${colors.blueCore}\u2551${colors.reset}`;
    }
    /**
     * Generate a multi-line, colorized ASCII summary of the provided neural network.
     * The output includes:
     * - Layer headers with node counts and approximate connection counts between layers.
     * - Node activation values (numeric + color) for inputs, hidden (or averaged groups), and outputs.
     * - Condensed legend explaining symbols and activation grouping ranges.
     *
     * Hidden layer condensation: For large hidden layers, nodes are grouped into activation buckets;
     * each bucket is displayed as a single "average" virtual node whose value is the mean activation.
     * Buckets beyond the configured visible limit are merged into an "other±" meta-group.
     *
     * Performance: Uses internal scratch buffers to minimize intermediate allocations. Sorting relies
     * on ES2023 `toSorted` when available (with a stable fallback) ensuring deterministic grouping.
     *
     * @param network - The neural network (expects `nodes` and optional `connections`).
     * @returns Formatted multi-line string ready for terminal output (ANSI colors included).
     * @example
     * ```ts
     * import { NetworkVisualization } from './networkVisualization';
     * const ascii = NetworkVisualization.visualizeNetworkSummary(myNetwork);
     * console.log(ascii);
     * ```
     */
    static visualizeNetworkSummary(network) {
      const categorized = _NetworkVisualization.#categorizeNodes(network);
      const INPUT_COUNT = categorized.inputCountDetected || 18;
      const OUTPUT_COUNT = 4;
      const hiddenLayers = _NetworkVisualization.#groupHiddenByLayer(
        categorized.inputNodes,
        categorized.hiddenNodes,
        categorized.outputNodes
      );
      const prepared = _NetworkVisualization.#prepareHiddenLayersForDisplay(
        hiddenLayers
      );
      const connectionCounts = _NetworkVisualization.#computeConnectionCounts(
        network,
        categorized.inputNodes,
        hiddenLayers,
        categorized.outputNodes
      );
      const { columnWidth } = _NetworkVisualization.#computeLayout(
        hiddenLayers.length
      );
      const header = _NetworkVisualization.#buildHeader(
        INPUT_COUNT,
        hiddenLayers,
        OUTPUT_COUNT,
        connectionCounts
      );
      const rows = _NetworkVisualization.#buildRows(
        {
          inputCount: INPUT_COUNT,
          outputCount: OUTPUT_COUNT,
          inputNodes: categorized.inputNodes,
          displayLayers: prepared.displayLayers,
          layerDisplayCounts: prepared.layerDisplayCounts,
          outputNodes: categorized.outputNodes,
          connectionCounts
        },
        columnWidth
      );
      const legendLines = _NetworkVisualization.#buildLegend();
      return [header, ...rows, ...legendLines].join("\n");
    }
    /** Compute layout derived widths for given hidden layer count. */
    static #computeLayout(numHiddenLayers) {
      const numLayers = 2 + numHiddenLayers;
      const numArrows = numLayers - 1;
      const availableWidth = _NetworkVisualization.#TOTAL_WIDTH - numArrows * _NetworkVisualization.#ARROW_WIDTH;
      const columnWidth = Math.floor(availableWidth / numLayers);
      return { columnWidth };
    }
  };

  // test/examples/asciiMaze/mazeVisualization.ts
  var MazeVisualization = class _MazeVisualization {
    // Shared set of wall characters (private implementation detail).
    // Provide a public getter for backward compatibility.
    static #WALL_CHARS = /* @__PURE__ */ new Set([
      "#",
      "\u2550",
      "\u2551",
      "\u2554",
      "\u2557",
      "\u255A",
      "\u255D",
      "\u2560",
      "\u2563",
      "\u2566",
      "\u2569",
      "\u256C"
    ]);
    static get WALL_CHARS() {
      return _MazeVisualization.#WALL_CHARS;
    }
    /** Return the last element of an array or undefined when empty. */
    static #last(arr) {
      return MazeUtils.safeLast(arr);
    }
    /** Convert a [x,y] pair to the canonical 'x,y' key. */
    static #posKey([x, y]) {
      return `${x},${y}`;
    }
    /**
     * Renders a single maze cell with proper coloring based on its content and agent location.
     *
     * Applies appropriate colors and styling to each cell in the maze:
     * - Different colors for walls, open paths, start and exit positions
     * - Highlights the agent's current position
     * - Marks cells that are part of the agent's path
     * - Renders box drawing characters as walls with proper styling
     *
     * @param cell - The character representing the cell ('S', 'E', '#', '.' etc.)
     * @param x - X-coordinate of the cell
     * @param y - Y-coordinate of the cell
     * @param agentX - X-coordinate of the agent's current position
     * @param agentY - Y-coordinate of the agent's current position
     * @param path - Optional set of visited coordinates in "x,y" format
     * @returns Colorized string representing the cell
     */
    static renderCell(cell, x, y, agentX, agentY, path) {
      const wallChars = _MazeVisualization.WALL_CHARS;
      if (x === agentX && y === agentY) {
        if (cell === "S")
          return `${colors.bgBlack}${colors.orangeNeon}S${colors.reset}`;
        if (cell === "E")
          return `${colors.bgBlack}${colors.orangeNeon}E${colors.reset}`;
        return `${colors.bgBlack}${colors.orangeNeon}A${colors.reset}`;
      }
      if (cell === "S")
        return `${colors.bgBlack}${colors.orangeNeon}S${colors.reset}`;
      if (cell === "E")
        return `${colors.bgBlack}${colors.orangeNeon}E${colors.reset}`;
      if (cell === ".") {
        if (path && path.has(`${x},${y}`))
          return `${colors.floorBg}${colors.orangeNeon}\u2022${colors.reset}`;
        return `${colors.floorBg}${colors.gridLineText}.${colors.reset}`;
      }
      if (wallChars.has(cell)) {
        return `${colors.bgBlack}${colors.blueNeon}${cell}${colors.reset}`;
      }
      return cell;
    }
    /**
     * Renders the entire maze as a colored ASCII string, showing the agent and its path.
     *
     * Converts the maze data structure into a human-readable, colorized representation showing:
     * - The maze layout with walls and open paths
     * - The start and exit positions
     * - The agent's current position
     * - The path the agent has taken (if provided)
     *
     * @param asciiMaze - Array of strings representing the maze layout
     * @param [agentX, agentY] - Current position of the agent
     * @param path - Optional array of positions representing the agent's path
     * @returns A multi-line string with the visualized maze
     */
    static visualizeMaze(asciiMaze, [agentX, agentY], path) {
      let visitedPositions = void 0;
      if (path) {
        visitedPositions = /* @__PURE__ */ new Set();
        for (const p of path) visitedPositions.add(_MazeVisualization.#posKey(p));
      }
      return asciiMaze.map(
        (row, y) => [...row].map(
          (cell, x) => this.renderCell(cell, x, y, agentX, agentY, visitedPositions)
        ).join("")
      ).join("\n");
    }
    /**
     * Prints a summary of the agent's attempt, including success, steps, and efficiency.
     *
     * Provides performance metrics about the agent's solution attempt:
     * - Whether it successfully reached the exit
     * - How many steps it took
     * - How efficient the path was compared to the optimal BFS distance
     *
     * @param currentBest - Object containing the simulation results, network, and generation
     * @param maze - Array of strings representing the maze layout
     * @param forceLog - Function used for logging output
     */
    static printMazeStats(currentBest, maze, forceLog) {
      const { result, generation } = currentBest;
      const successColor = result.success ? colors.cyanNeon : colors.neonRed;
      const startPos = MazeUtils.findPosition(maze, "S");
      const exitPos = MazeUtils.findPosition(maze, "E");
      const optimalLength = MazeUtils.bfsDistance(
        MazeUtils.encodeMaze(maze),
        startPos,
        exitPos
      );
      const FRAME_WIDTH = 148;
      const LEFT_PAD = 7;
      const RIGHT_PAD = 1;
      const CONTENT_WIDTH = FRAME_WIDTH - LEFT_PAD - RIGHT_PAD;
      forceLog(
        `${colors.blueCore}\u2551${NetworkVisualization.pad(" ", FRAME_WIDTH, " ")}${colors.blueCore}\u2551${colors.reset}`
      );
      forceLog(
        `${colors.blueCore}\u2551${NetworkVisualization.pad(" ", FRAME_WIDTH, " ")}${colors.blueCore}\u2551${colors.reset}`
      );
      forceLog(
        `${colors.blueCore}\u2551${" ".repeat(LEFT_PAD)}${NetworkVisualization.pad(
          `${colors.neonSilver}Success:${colors.neonIndigo} ${successColor}${result.success ? "YES" : "NO"}`,
          CONTENT_WIDTH,
          " ",
          "left"
        )}${" ".repeat(RIGHT_PAD)}${colors.blueCore}\u2551${colors.reset}`
      );
      forceLog(
        `${colors.blueCore}\u2551${" ".repeat(LEFT_PAD)}${NetworkVisualization.pad(
          `${colors.neonSilver}Generation:${colors.neonIndigo} ${successColor}${generation}`,
          CONTENT_WIDTH,
          " ",
          "left"
        )}${" ".repeat(RIGHT_PAD)}\u2551${colors.reset}`
      );
      forceLog(
        `${colors.blueCore}\u2551${" ".repeat(LEFT_PAD)}${NetworkVisualization.pad(
          `${colors.neonSilver}Fitness:${colors.neonOrange} ${result.fitness.toFixed(2)}`,
          CONTENT_WIDTH,
          " ",
          "left"
        )}${" ".repeat(RIGHT_PAD)}\u2551${colors.reset}`
      );
      forceLog(
        `${colors.blueCore}\u2551${" ".repeat(LEFT_PAD)}${NetworkVisualization.pad(
          `${colors.neonSilver}Steps taken:${colors.neonIndigo} ${result.steps}`,
          CONTENT_WIDTH,
          " ",
          "left"
        )}${" ".repeat(RIGHT_PAD)}\u2551${colors.reset}`
      );
      forceLog(
        `${colors.blueCore}\u2551${" ".repeat(LEFT_PAD)}${NetworkVisualization.pad(
          `${colors.neonSilver}Path length:${colors.neonIndigo} ${result.path.length}${colors.blueCore}`,
          CONTENT_WIDTH,
          " ",
          "left"
        )}${" ".repeat(RIGHT_PAD)}\u2551${colors.reset}`
      );
      forceLog(
        `${colors.blueCore}\u2551${" ".repeat(LEFT_PAD)}${NetworkVisualization.pad(
          `${colors.neonSilver}Optimal distance to exit:${colors.neonYellow} ${optimalLength}`,
          CONTENT_WIDTH,
          " ",
          "left"
        )}${" ".repeat(RIGHT_PAD)}\u2551${colors.reset}`
      );
      forceLog(
        `${colors.blueCore}\u2551${NetworkVisualization.pad(" ", FRAME_WIDTH, " ")}${colors.blueCore}\u2551${colors.reset}`
      );
      if (result.success) {
        const pathLength = result.path.length - 1;
        const efficiency = Math.min(
          100,
          Math.round(optimalLength / pathLength * 100)
        ).toFixed(1);
        const overhead = (pathLength / optimalLength * 100 - 100).toFixed(1);
        const uniqueCells = /* @__PURE__ */ new Set();
        let revisitedCells = 0;
        let directionChanges = 0;
        let lastDirection = null;
        for (let i = 0; i < result.path.length; i++) {
          const [x, y] = result.path[i];
          const cellKey = `${x},${y}`;
          if (uniqueCells.has(cellKey)) {
            revisitedCells++;
          } else {
            uniqueCells.add(cellKey);
          }
          if (i > 0) {
            const [prevX, prevY] = result.path[i - 1];
            const dx = x - prevX;
            const dy = y - prevY;
            let currentDirection = "";
            if (dx > 0) currentDirection = "E";
            else if (dx < 0) currentDirection = "W";
            else if (dy > 0) currentDirection = "S";
            else if (dy < 0) currentDirection = "N";
            if (lastDirection !== null && currentDirection !== lastDirection) {
              directionChanges++;
            }
            lastDirection = currentDirection;
          }
        }
        const mazeWidth = maze[0].length;
        const mazeHeight = maze.length;
        const encodedMaze = MazeUtils.encodeMaze(maze);
        let walkableCells = 0;
        for (let y = 0; y < mazeHeight; y++) {
          for (let x = 0; x < mazeWidth; x++) {
            if (encodedMaze[y][x] !== -1) {
              walkableCells++;
            }
          }
        }
        const coveragePercent = (uniqueCells.size / walkableCells * 100).toFixed(1);
        forceLog(
          `${colors.blueCore}\u2551${" ".repeat(LEFT_PAD)}${NetworkVisualization.pad(
            `${colors.neonSilver}Path efficiency:      ${colors.neonIndigo} ${optimalLength}/${pathLength} (${efficiency}%)`,
            CONTENT_WIDTH,
            " ",
            "left"
          )}${" ".repeat(RIGHT_PAD)}\u2551${colors.reset}`
        );
        forceLog(
          `${colors.blueCore}\u2551${" ".repeat(LEFT_PAD)}${NetworkVisualization.pad(
            `${colors.neonSilver}Optimal steps:        ${colors.neonIndigo} ${optimalLength}`,
            CONTENT_WIDTH,
            " ",
            "left"
          )}${" ".repeat(RIGHT_PAD)}\u2551${colors.reset}`
        );
        forceLog(
          `${colors.blueCore}\u2551${" ".repeat(LEFT_PAD)}${NetworkVisualization.pad(
            `${colors.neonSilver}Path overhead:        ${colors.neonIndigo} ${overhead}% longer than optimal`,
            CONTENT_WIDTH,
            " ",
            "left"
          )}${" ".repeat(RIGHT_PAD)}\u2551${colors.reset}`
        );
        forceLog(
          `${colors.blueCore}\u2551${" ".repeat(LEFT_PAD)}${NetworkVisualization.pad(
            `${colors.neonSilver}Direction changes:    ${colors.neonIndigo} ${directionChanges}`,
            CONTENT_WIDTH,
            " ",
            "left"
          )}${" ".repeat(RIGHT_PAD)}\u2551${colors.reset}`
        );
        forceLog(
          `${colors.blueCore}\u2551${" ".repeat(LEFT_PAD)}${NetworkVisualization.pad(
            `${colors.neonSilver}Unique cells visited: ${colors.neonIndigo} ${uniqueCells.size} (${coveragePercent}% of maze)`,
            CONTENT_WIDTH,
            " ",
            "left"
          )}${" ".repeat(RIGHT_PAD)}\u2551${colors.reset}`
        );
        forceLog(
          `${colors.blueCore}\u2551${" ".repeat(LEFT_PAD)}${NetworkVisualization.pad(
            `${colors.neonSilver}Cells revisited:      ${colors.neonIndigo} ${revisitedCells} times`,
            CONTENT_WIDTH,
            " ",
            "left"
          )}${" ".repeat(RIGHT_PAD)}\u2551${colors.reset}`
        );
        forceLog(
          `${colors.blueCore}\u2551${" ".repeat(LEFT_PAD)}${NetworkVisualization.pad(
            `${colors.neonSilver}Decisions per cell:   ${colors.neonIndigo} ${(directionChanges / uniqueCells.size).toFixed(2)}`,
            CONTENT_WIDTH,
            " ",
            "left"
          )}${" ".repeat(RIGHT_PAD)}\u2551${colors.reset}`
        );
        forceLog(
          `${colors.blueCore}\u2551${" ".repeat(LEFT_PAD)}${NetworkVisualization.pad(
            `${colors.neonOrange}Agent successfully navigated the maze!`,
            CONTENT_WIDTH,
            " ",
            "left"
          )}${" ".repeat(RIGHT_PAD)}\u2551${colors.reset}`
        );
      } else {
        const lastPos = _MazeVisualization.#last(result.path) ?? startPos;
        const bestProgress = MazeUtils.calculateProgress(
          MazeUtils.encodeMaze(maze),
          lastPos,
          startPos,
          exitPos
        );
        const uniqueCells = /* @__PURE__ */ new Set();
        for (const [x, y] of result.path) {
          uniqueCells.add(`${x},${y}`);
        }
        forceLog(
          `${colors.blueCore}\u2551${" ".repeat(LEFT_PAD)}${NetworkVisualization.pad(
            `${colors.neonSilver}Best progress toward exit:      ${colors.neonIndigo} ${bestProgress}%`,
            CONTENT_WIDTH,
            " ",
            "left"
          )}${" ".repeat(RIGHT_PAD)}\u2551${colors.reset}`
        );
        forceLog(
          `${colors.blueCore}\u2551${" ".repeat(LEFT_PAD)}${NetworkVisualization.pad(
            `${colors.neonSilver}Shortest possible steps:        ${colors.neonIndigo} ${optimalLength}`,
            CONTENT_WIDTH,
            " ",
            "left"
          )}${" ".repeat(RIGHT_PAD)}\u2551${colors.reset}`
        );
        forceLog(
          `${colors.blueCore}\u2551${" ".repeat(LEFT_PAD)}${NetworkVisualization.pad(
            `${colors.neonSilver}Unique cells visited:           ${colors.neonIndigo} ${uniqueCells.size}`,
            CONTENT_WIDTH,
            " ",
            "left"
          )}${" ".repeat(RIGHT_PAD)}\u2551${colors.reset}`
        );
        forceLog(
          `${colors.blueCore}\u2551${" ".repeat(LEFT_PAD)}${NetworkVisualization.pad(
            `${colors.neonSilver}Agent trying to reach the exit. ${colors.neonIndigo}`,
            CONTENT_WIDTH,
            " ",
            "left"
          )}${" ".repeat(RIGHT_PAD)}\u2551${colors.reset}`
        );
      }
    }
    /**
     * Displays a colored progress bar for agent progress.
     *
     * Creates a visual representation of the agent's progress toward the exit
     * as a horizontal bar with appropriate coloring based on percentage.
     *
     * @param progress - Progress percentage (0-100)
     * @param length - Length of the progress bar in characters (default: 60)
     * @returns A string containing the formatted progress bar
     */
    static displayProgressBar(progress, length = 60) {
      const filledLength = Math.max(
        0,
        Math.min(length, Math.floor(length * progress / 100))
      );
      const startChar = `${colors.blueCore}|>|`;
      const endChar = `${colors.blueCore}|<|`;
      const fillChar = `${colors.neonOrange}\u2550`;
      const emptyChar = `${colors.neonIndigo}:`;
      const pointerChar = `${colors.neonOrange}\u25B6`;
      let bar = "";
      bar += startChar;
      if (filledLength > 0) {
        bar += fillChar.repeat(filledLength - 1);
        bar += pointerChar;
      }
      const emptyLength = length - filledLength;
      if (emptyLength > 0) {
        bar += emptyChar.repeat(emptyLength);
      }
      bar += endChar;
      const color = progress < 30 ? colors.neonYellow : progress < 70 ? colors.orangeNeon : colors.cyanNeon;
      return `${color}${bar}${colors.reset} ${progress}%`;
    }
    /**
     * Formats elapsed time in a human-readable way.
     *
     * Converts seconds into appropriate units (seconds, minutes, hours)
     * for more intuitive display of time durations.
     *
     * @param seconds - Time in seconds
     * @returns Formatted string (e.g., "5.3s", "2m 30s", "1h 15m")
     */
    static formatElapsedTime(seconds) {
      if (seconds < 60) return `${seconds.toFixed(1)}s`;
      if (seconds < 3600) {
        const minutes2 = Math.floor(seconds / 60);
        const remainingSeconds = seconds % 60;
        return `${minutes2}m ${remainingSeconds.toFixed(0)}s`;
      }
      const hours = Math.floor(seconds / 3600);
      const minutes = Math.floor(seconds % 3600 / 60);
      return `${hours}h ${minutes}m`;
    }
  };

  // test/examples/asciiMaze/dashboardManager.ts
  var DashboardManager = class _DashboardManager {
    #solvedMazes = [];
    #solvedMazeKeys = /* @__PURE__ */ new Set();
    #currentBest = null;
    #lastTelemetry = null;
    #lastBestFitness = null;
    #bestFitnessHistory = [];
    #complexityNodesHistory = [];
    #complexityConnsHistory = [];
    #hypervolumeHistory = [];
    #progressHistory = [];
    #speciesCountHistory = [];
    #lastDetailedStats = null;
    #runStartTs = null;
    #perfStart = null;
    #lastGeneration = null;
    #lastUpdateTs = null;
    #logFn;
    #clearFn;
    #archiveFn;
    static #HISTORY_MAX = 500;
    static #FRAME_INNER_WIDTH = 148;
    static #LEFT_PADDING = 7;
    static #RIGHT_PADDING = 1;
    static #STAT_LABEL_WIDTH = 28;
    static #ARCHIVE_SPARK_WIDTH = 64;
    // spark width in archive blocks
    static #GENERAL_SPARK_WIDTH = 64;
    // spark width in live panel
    static #SOLVED_LABEL_WIDTH = 22;
    // label width in archive stats
    static #HISTORY_EXPORT_WINDOW = 200;
    // samples exported in telemetry details
    static #SPARK_BLOCKS = Object.freeze([
      "\u2581",
      "\u2582",
      "\u2583",
      "\u2584",
      "\u2585",
      "\u2586",
      "\u2587",
      "\u2588"
    ]);
    static #DELTA_EPSILON = 1e-9;
    static #TOP_OPERATOR_LIMIT = 6;
    static #TOP_MUTATION_LIMIT = 8;
    static #TOP_SPECIES_LIMIT = 5;
    static #LAYER_INFER_LOOP_MULTIPLIER = 4;
    static #LABEL_PATH_EFF = "Path efficiency";
    static #LABEL_PATH_OVER = "Path overhead";
    static #LABEL_UNIQUE = "Unique cells visited";
    static #LABEL_REVISITS = "Cells revisited";
    static #LABEL_STEPS = "Steps";
    static #LABEL_FITNESS = "Fitness";
    static #LABEL_ARCH = "Architecture";
    static #FRAME_SINGLE_LINE_CHAR = "\u2550";
    static #FRAME_BRIDGE_TOP = "\u2566\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2566";
    static #FRAME_BRIDGE_BOTTOM = "\u2569\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2569";
    static #EVOLVING_SECTION_LINE = "\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550";
    static get FRAME_INNER_WIDTH() {
      return _DashboardManager.#FRAME_INNER_WIDTH;
    }
    static get LEFT_PADDING() {
      return _DashboardManager.#LEFT_PADDING;
    }
    static get RIGHT_PADDING() {
      return _DashboardManager.#RIGHT_PADDING;
    }
    static get CONTENT_WIDTH() {
      return _DashboardManager.#FRAME_INNER_WIDTH - _DashboardManager.#LEFT_PADDING - _DashboardManager.#RIGHT_PADDING;
    }
    static get STAT_LABEL_WIDTH() {
      return _DashboardManager.#STAT_LABEL_WIDTH;
    }
    static get HISTORY_MAX() {
      return _DashboardManager.#HISTORY_MAX;
    }
    /**
     * Create a new DashboardManager.
     *
     * @param clearFn Function that clears the live dashboard region (terminal or DOM). Required.
     * @param logFn Function used for streaming live panel lines. Required.
     * @param archiveFn Optional function used to prepend/append solved-maze archive blocks (separate area / element).
     *
     * Defensive notes:
     * - Non-function arguments are coerced to no-ops to avoid runtime crashes in mixed environments (browser / node tests).
     * - All three functions are stored as private fields (#clearFn, #logFn, #archiveFn) for later reuse.
     */
    constructor(clearFn, logFn, archiveFn) {
      const noop = () => {
      };
      this.#clearFn = typeof clearFn === "function" ? clearFn : noop;
      this.#logFn = typeof logFn === "function" ? logFn : noop;
      this.#archiveFn = typeof archiveFn === "function" ? archiveFn : void 0;
    }
    /** Emit a blank padded line inside the frame to avoid duplication. */
    #logBlank() {
      this.#logFn(
        `${colors.blueCore}\u2551${NetworkVisualization.pad(
          " ",
          _DashboardManager.FRAME_INNER_WIDTH,
          " "
        )}${colors.blueCore}\u2551${colors.reset}`
      );
    }
    /**
     * Format a single statistic line (label + value) framed for the dashboard.
     *
     * Educational goals:
     * - Demonstrates consistent alignment via fixed label column width.
     * - Centralizes color application so other helpers (`#appendSolvedPathStats`, etc.) remain lean.
     * - Shows simple, allocation‑aware string building without external libs.
     *
     * Steps:
     * 1. Canonicalize label (ensure trailing colon) for uniform appearance.
     * 2. Pad label to `labelWidth` (left aligned) creating a fixed column.
     * 3. Normalize the value to string (numbers preserved; null/undefined become literal strings for transparency).
     * 4. Compose colored content segment (`label` + single space + `value`).
     * 5. Left/right pad inside the frame content width and wrap with vertical border glyphs.
     *
     * Performance notes:
     * - O(L) where L = composed string length; dominated by `padEnd` + `NetworkVisualization.pad`.
     * - Avoids template churn inside loops by keeping construction linear.
     * - No truncation: labels longer than `labelWidth` intentionally overflow to surface overly verbose labels during development.
     *
     * Determinism: Pure formatting; no external state or randomness.
     * Reentrancy: Safe; relies only on parameters and static sizing constants.
     * Edge cases: Empty label yields just a colon after canonicalization (":"); nullish values become "null" / "undefined" explicitly.
     *
     * @param label Descriptive metric label (colon appended if missing).
     * @param value Metric value (string or number) displayed after a space.
     * @param colorLabel ANSI / style token for the label portion.
     * @param colorValue ANSI / style token for the value portion.
     * @param labelWidth Fixed width for the label column (default derives from class constant).
     * @returns Fully framed, colorized line ready for logging.
     * @example
     * const line = (dashboard as any)["#formatStat"]("Fitness", 12.34);
     * // => "║  Fitness: 12.34  ... ║" (color codes omitted here)
     */
    #formatStat(label, value, colorLabel = colors.neonSilver, colorValue = colors.cyanNeon, labelWidth = _DashboardManager.#STAT_LABEL_WIDTH) {
      const canonicalLabel = label.endsWith(":") ? label : `${label}:`;
      const paddedLabel = canonicalLabel.padEnd(labelWidth, " ");
      const valueString = typeof value === "number" ? `${value}` : String(value);
      const coloredContent = `${colorLabel}${paddedLabel}${colorValue} ${valueString}${colors.reset}`;
      const leftPadSpaces = " ".repeat(_DashboardManager.LEFT_PADDING);
      const framed = `${colors.blueCore}\u2551${leftPadSpaces}${NetworkVisualization.pad(
        coloredContent,
        _DashboardManager.CONTENT_WIDTH,
        " ",
        "left"
      )}${" ".repeat(_DashboardManager.RIGHT_PADDING)}${colors.blueCore}\u2551${colors.reset}`;
      return framed;
    }
    /**
     * Convert the tail of a numeric series into a compact Unicode sparkline.
     *
     * Educational intent: illustrates how a simple per-frame trend visualization
     * can be produced without external dependencies, while keeping allocation
     * costs minimal for frequent refreshes (every generation / UI frame).
     *
     * Steps:
     * 1. Slice the most recent `width` samples (via `MazeUtils.tail`) — bounded O(width).
     * 2. Filter out non‑finite samples (defensive; telemetry may contain NaN during warmup).
     * 3. Scan once to derive `minValue` / `maxValue` (range baseline).
     * 4. Map each sample to an index in the precomputed block ramp (#SPARK_BLOCKS).
     * 5. Append corresponding block characters into a single result string.
     *
     * Performance notes:
     * - Single pass min/max + single pass mapping: O(n) with n = min(series.length, width).
     * - No intermediate arrays beyond the tail slice (which reuses existing util) & final string builder.
     * - Uses descriptive local names to keep code educational; hot path is still trivial compared to rendering.
     * - Avoids `Math.min(...spread)` / `Array.prototype.map` to prevent temporary arrays & GC churn.
     *
     * Determinism: Pure function of input array slice (no randomness, no external state).
     * Reentrancy: Safe; no shared mutable scratch used.
     * Edge cases: Returns empty string for empty / all non‑finite input; collapses zero range to uniform block.
     *
     * @param series Numeric history (older -> newer) to visualize.
     * @param width Maximum number of most recent samples to encode (default 32); values <= 0 produce ''.
     * @returns Sparkline string (length <= width). Empty string when insufficient valid data.
     * @example
     * // Given recent fitness scores
     * const spark = dashboardManager["#buildSparkline"]([10,11,11.5,12,13], 4); // -> e.g. "▃▄▆█"
     */
    #buildSparkline(series, width = 32) {
      if (!Array.isArray(series) || !series.length || width <= 0) return "";
      const tailSlice = MazeUtils.tail(series, width);
      const sampleCount = tailSlice.length;
      if (!sampleCount) return "";
      let writeIndex = 0;
      for (let readIndex = 0; readIndex < sampleCount; readIndex++) {
        const sampleValue = tailSlice[readIndex];
        if (Number.isFinite(sampleValue)) {
          tailSlice[writeIndex++] = sampleValue;
        }
      }
      if (writeIndex === 0) return "";
      let minValue = Infinity;
      let maxValue = -Infinity;
      for (let scanIndex = 0; scanIndex < writeIndex; scanIndex++) {
        const value = tailSlice[scanIndex];
        if (value < minValue) minValue = value;
        if (value > maxValue) maxValue = value;
      }
      let valueRange = maxValue - minValue;
      if (Math.abs(valueRange) < _DashboardManager.#DELTA_EPSILON) {
        valueRange = _DashboardManager.#DELTA_EPSILON;
      }
      const blocks = _DashboardManager.#SPARK_BLOCKS;
      const blocksCount = blocks.length - 1;
      let sparkline = "";
      for (let encodeIndex = 0; encodeIndex < writeIndex; encodeIndex++) {
        const normalized = (tailSlice[encodeIndex] - minValue) / valueRange;
        const blockIndex = Math.min(
          blocksCount,
          Math.max(0, Math.floor(normalized * blocksCount))
        );
        sparkline += blocks[blockIndex];
      }
      return sparkline;
    }
    /** Create a lightweight key for a maze (dedupe solved mazes). */
    #getMazeKey(maze) {
      return maze.join("");
    }
    /** Wrapper to append solved archive block (public logic retained from original). */
    #appendSolvedToArchive(solved, displayNumber) {
      if (!this.#archiveFn) return;
      const blockLines = [];
      this.#appendSolvedHeader(blockLines, solved, displayNumber);
      this.#appendSolvedSparklines(blockLines, solved.network);
      this.#appendSolvedMaze(blockLines, solved);
      this.#appendSolvedPathStats(blockLines, solved);
      this.#appendSolvedFooterAndEmit(blockLines);
    }
    /**
     * redraw
     *
     * Clear + repaint the live dashboard frame while updating rich stats snapshot.
     *
     * Steps (delegated to focused helpers for readability & GC awareness):
     * 1. beginFrameRefresh: clear terminal region & print static frame header.
     * 2. printCurrentBestSection: conditionally render evolving section (network, maze, stats, progress).
     * 3. updateDetailedStatsSnapshot: build/export metrics & sparklines using scratch arrays (bounded histories).
     * 4. Emit a spacer line to preserve the original layout rhythm.
     *
     * Performance considerations:
     * - Reuses `#scratch` arrays to avoid per-frame allocations when deriving top lists.
     * - Histories are already bounded (HISTORY_MAX) so sparkline work is O(width).
     * - Early exit when no telemetry & no current best yet.
     *
     * Determinism: Purely formatting & aggregation (no randomness).
     * Reentrancy: Not reentrant (mutates internal state and shared scratch buffers). One instance per run.
     * @param currentMaze Maze currently being evolved.
     * @param neat Optional NEAT implementation instance for population-level stats.
     */
    redraw(currentMaze, neat) {
      this.#lastUpdateTs = globalThis.performance?.now?.() ?? Date.now();
      this.#beginFrameRefresh();
      if (this.#currentBest) this.#printCurrentBestSection(currentMaze);
      this.#updateDetailedStatsSnapshot(neat);
      this.#logBlank();
    }
    /** Shared scratch allocations reused across redraw cycles to reduce GC churn. */
    #scratch = { scores: [], speciesSizes: [], operatorStats: [], mutationEntries: [] };
    /** Clear & print static frame top. (Step 1 of redraw) */
    #beginFrameRefresh() {
      this.#clearFn();
      this.#printTopFrame();
    }
    /**
     * Build the rich detailed stats snapshot consumed by external telemetry observers.
     *
     * Educational overview:
     * This method aggregates multiple orthogonal evolution signals (fitness trends, structural complexity,
     * diversity, Pareto front geometry, operator acceptance, mutation frequencies, species distribution, etc.) into
     * one immutable plain object assigned to `#lastDetailedStats`. It is invoked once per redraw cycle (not per
     * individual genome evaluation) to amortize cost and keep UI refresh predictable.
     *
     * Steps (high‑level):
     * 1. Guard: if we have neither telemetry nor a current best candidate, skip work (no data yet).
     * 2. Destructure relevant sub-snapshots from the raw telemetry (complexity, perf, lineage, diversity, objectives...).
     * 3. Derive population statistics via `#computePopulationStats` (mean/median/species/enabled ratio) and patch gaps
     *    with the current best's fitness / species count as reasonable fallbacks for early generations.
     * 4. Generate sparkline trend strings for tracked bounded histories (fitness, nodes, conns, hypervolume, progress, species).
     * 5. Derive Pareto front size metrics & novelty archive size (defensive wrappers to tolerate optional APIs).
     * 6. Compute operator acceptance, top mutation operator counts, and largest species sizes (scratch-buffer reuse inside helpers).
     * 7. Compute best fitness delta (difference vs previous sample) for quick “is improving” signal.
     * 8. Assemble and assign a consolidated snapshot object with timestamps & derived boolean flags (e.g. simplifyPhaseActive).
     *
     * Performance notes:
     * - All history arrays are already bounded (HISTORY_MAX); sparkline generation is O(width) each.
     * - Sorting work (operator / mutation / species) is limited to top-N extraction with small fixed caps (config constants).
     * - Uses defensive optional chaining + nullish coalescing to avoid cascading throws; a single try/catch wraps overall build.
     * - Allocations: one snapshot object + a handful of small arrays (top lists). Histories are sliced lazily via helper.
     *
     * Determinism: Pure aggregation of previously captured deterministic data. No RNG usage.
     * Reentrancy: Not reentrant; mutates `#lastDetailedStats`. Acceptable because a single dashboard instance services one run.
     * Failure handling: Any unexpected error aborts this build silently (stats are opportunistic, UI remains functional).
     *
     * @param neat Optional NEAT engine instance (used for population stats, operator stats, novelty archive size, species sizes).
     */
    #updateDetailedStatsSnapshot(neat) {
      const telemetry = this.#lastTelemetry;
      if (!telemetry && !this.#currentBest) return;
      try {
        const complexitySnapshot = telemetry?.complexity;
        const perfSnapshot = telemetry?.perf;
        const lineageSnapshot = telemetry?.lineage;
        const diversitySnapshot = telemetry?.diversity;
        const rawFrontsArray = Array.isArray(telemetry?.fronts) ? telemetry.fronts : null;
        const objectivesSnapshot = telemetry?.objectives;
        const hypervolumeValue = telemetry?.hyper;
        const mutationStatsObj = telemetry?.mutationStats || telemetry?.mutation?.stats;
        const bestFitnessValue = this.#currentBest?.result?.fitness;
        const saturationFractionValue = this.#currentBest?.result?.saturationFraction;
        const actionEntropyValue = this.#currentBest?.result?.actionEntropy;
        const populationStats = this.#computePopulationStats(neat);
        if (populationStats.mean == null && typeof bestFitnessValue === "number") {
          populationStats.mean = +bestFitnessValue.toFixed(2);
        }
        if (populationStats.median == null && typeof bestFitnessValue === "number") {
          populationStats.median = +bestFitnessValue.toFixed(2);
        }
        if (populationStats.speciesCount == null && typeof telemetry?.species === "number") {
          populationStats.speciesCount = telemetry.species;
        }
        const sparkWidth = _DashboardManager.#GENERAL_SPARK_WIDTH;
        const sparklines = {
          fitness: this.#buildSparkline(this.#bestFitnessHistory, sparkWidth) || null,
          nodes: this.#buildSparkline(this.#complexityNodesHistory, sparkWidth) || null,
          conns: this.#buildSparkline(this.#complexityConnsHistory, sparkWidth) || null,
          hyper: this.#buildSparkline(this.#hypervolumeHistory, sparkWidth) || null,
          progress: this.#buildSparkline(this.#progressHistory, sparkWidth) || null,
          species: this.#buildSparkline(this.#speciesCountHistory, sparkWidth) || null
        };
        const firstFrontSize = rawFrontsArray?.[0]?.length || 0;
        const paretoFrontSizes = rawFrontsArray ? rawFrontsArray.map((front) => front?.length || 0) : null;
        const noveltyArchiveSize = this.#safeInvoke(
          () => neat?.getNoveltyArchiveSize ? neat.getNoveltyArchiveSize() : null,
          null
        );
        const operatorAcceptance = this.#computeOperatorAcceptance(neat);
        const topMutations = this.#computeTopMutations(mutationStatsObj);
        const topSpeciesSizes = this.#computeTopSpeciesSizes(neat);
        const bestFitnessDelta = (() => {
          if (typeof bestFitnessValue !== "number") return null;
          const previousSample = this.#bestFitnessHistory.at(-2) ?? null;
          if (previousSample == null) return null;
          return +(bestFitnessValue - previousSample).toFixed(3);
        })();
        this.#lastDetailedStats = {
          generation: this.#currentBest?.generation || 0,
          bestFitness: typeof bestFitnessValue === "number" ? bestFitnessValue : null,
          bestFitnessDelta,
          saturationFraction: typeof saturationFractionValue === "number" ? saturationFractionValue : null,
          actionEntropy: typeof actionEntropyValue === "number" ? actionEntropyValue : null,
          populationMean: populationStats.mean,
          populationMedian: populationStats.median,
          enabledConnRatio: populationStats.enabledRatio,
          complexity: complexitySnapshot || null,
          simplifyPhaseActive: !!(complexitySnapshot && (complexitySnapshot.growthNodes < 0 || complexitySnapshot.growthConns < 0)),
          perf: perfSnapshot || null,
          lineage: lineageSnapshot || null,
          diversity: diversitySnapshot || null,
          speciesCount: populationStats.speciesCount,
          topSpeciesSizes,
          objectives: objectivesSnapshot || null,
          paretoFrontSizes,
          firstFrontSize,
          hypervolume: typeof hypervolumeValue === "number" ? hypervolumeValue : null,
          noveltyArchiveSize,
          operatorAcceptance,
          topMutations,
          mutationStats: mutationStatsObj || null,
          trends: sparklines,
          histories: {
            bestFitness: this.#sliceHistoryForExport(this.#bestFitnessHistory),
            nodes: this.#sliceHistoryForExport(this.#complexityNodesHistory),
            conns: this.#sliceHistoryForExport(this.#complexityConnsHistory),
            hyper: this.#sliceHistoryForExport(this.#hypervolumeHistory),
            progress: this.#sliceHistoryForExport(this.#progressHistory),
            species: this.#sliceHistoryForExport(this.#speciesCountHistory)
          },
          timestamp: Date.now()
        };
      } catch {
      }
    }
    /**
     * Aggregate basic population-wide statistics (mean & median fitness, species count, enabled connection ratio).
     *
     * Educational intent:
     * Centralizes lightweight descriptive statistics needed for trend visualization and telemetry export
     * while demonstrating reuse of a shared scratch array to minimize per-generation allocations.
     *
     * Steps:
     * 1. Guard & early return if the provided engine instance lacks a population array.
     * 2. Reuse `#scratch.scores` (cleared in-place) to collect numeric fitness scores.
     * 3. Count total vs enabled connections across genomes to derive an enabled ratio (structural sparsity signal).
     * 4. Compute mean in a single pass over the scores scratch array.
     * 5. Clone & sort scores (ascending) to compute median (keeps original order intact for any other readers).
     * 6. Derive species count defensively (array length or null when absent).
     * 7. Return a small plain object (all numbers formatted to 2 decimals where derived) — consumers may patch
     *    missing values later (see fallback logic in `#updateDetailedStatsSnapshot`).
     *
     * Complexity:
     * - Score collection: O(G) with G = population size.
     * - Connection scan: O(E) with E = total number of connection entries (linear).
     * - Sorting for median: O(G log G) — acceptable for modest populations; if G became very large, a selection
     *   algorithm (nth_element style) could replace the sort (document trade-offs first if changed).
     *
     * Performance notes:
     * - Reuses a single scores scratch array (cleared via length reset) to avoid churn.
     * - Uses numeric formatting only at final aggregation (minimizes intermediate string creation).
     * - Avoids repeated optional chaining in inner loops by shallow local references.
     *
     * Determinism: Pure function of the provided `neat.population` snapshot (iteration order is respected).
     * Reentrancy: Safe; scratch array is instance-scoped but method is not expected to be invoked concurrently.
     * Edge cases: Empty / missing population returns all-null fields; division by zero guarded by connection count checks.
     *
     * @param neat NEAT-like engine instance exposing `population`, optional `species` collection.
     * @returns Object with `mean`, `median`, `speciesCount`, `enabledRatio` (each nullable when not derivable).
     */
    #computePopulationStats(neat) {
      if (!neat || !Array.isArray(neat.population) || neat.population.length === 0) {
        return {
          mean: null,
          median: null,
          speciesCount: null,
          enabledRatio: null
        };
      }
      const { scores } = this.#scratch;
      scores.length = 0;
      let enabledConnectionsCount = 0;
      let totalConnectionsCount = 0;
      for (const genome of neat.population) {
        if (typeof genome?.score === "number") scores.push(genome.score);
        const genomeConns = genome?.connections;
        if (Array.isArray(genomeConns)) {
          for (const connection of genomeConns) {
            totalConnectionsCount++;
            if (connection?.enabled !== false) enabledConnectionsCount++;
          }
        }
      }
      let mean = null;
      let median = null;
      if (scores.length) {
        let sum = 0;
        for (let scoreIndex = 0; scoreIndex < scores.length; scoreIndex++) {
          sum += scores[scoreIndex];
        }
        mean = +(sum / scores.length).toFixed(2);
        const sortedScores = [...scores].sort((a, b) => a - b);
        const middleIndex = Math.floor(sortedScores.length / 2);
        const medianRaw = sortedScores.length % 2 === 0 ? (sortedScores[middleIndex - 1] + sortedScores[middleIndex]) / 2 : sortedScores[middleIndex];
        median = +medianRaw.toFixed(2);
      }
      const enabledRatio = totalConnectionsCount ? +(enabledConnectionsCount / totalConnectionsCount).toFixed(2) : null;
      const speciesCount = Array.isArray(neat.species) ? neat.species.length : null;
      return { mean, median, speciesCount, enabledRatio };
    }
    /**
     * Derive a ranked list of operator acceptance percentages from the (optional) evolution engine.
     *
     * Educational focus:
     * - Demonstrates defensive integration with a loosely‑typed external API (`getOperatorStats`).
     * - Shows how to reuse an instance scratch buffer to avoid per‑refresh allocations.
     * - Illustrates compact ranking logic (copy + sort + slice) while preserving original raw snapshot.
     *
     * Acceptance definition:
     *   acceptancePct = (success / max(1, attempts)) * 100   (formatted to 2 decimals)
     *   A zero attempts count is clamped to 1 to avoid division by zero; this treats a (success>0, attempts==0)
     *   anomaly as full success rather than NaN — acceptable for a resilience‑biased dashboard.
     *
     * Steps:
     * 1. Guard: verify `neat.getOperatorStats` is a function (else return null to signal absence of data).
     * 2. Safe invoke inside try/catch (engines may throw while stats are initializing).
     * 3. Filter raw entries into `#scratch.operatorStats` keeping only { name:string, success:number, attempts:number }.
     * 4. Create a ranked copy sorted by descending acceptance ratio (stable for ties in modern JS engines).
     * 5. Map the top N (`#TOP_OPERATOR_LIMIT`) into a lightweight exported shape `{ name, acceptancePct }`.
     * 6. Return `null` when no valid entries remain after filtering (downstream rendering can simply skip the block).
     *
     * Complexity:
     * - Let K be the number of operator entries. Filtering O(K); sort O(K log K); slice/map O(min(N, K)).
     * - K is typically tiny (single digits), so the impact per redraw is negligible.
     *
     * Performance notes:
     * - Scratch buffer cleared via length reset (no new array each call).
     * - Only one extra array allocation (`rankedCopy`) for isolation of sort side‑effects.
     * - Formatting (toFixed) deferred until final mapping to limit transient string creation.
     *
     * Determinism: Pure given the operator stats snapshot (no randomness). Relies on stable `Array.prototype.sort` for tie ordering.
     * Reentrancy: Safe under single‑threaded assumption; scratch buffer is reused but not shared across concurrent calls.
     * Edge cases & error handling:
     * - Missing API / thrown error => null.
     * - Malformed entries (missing numeric fields) silently excluded.
     * - Division by zero avoided via denominator clamp.
     * - Empty post‑filter set => null (consistent sentinel).
     *
     * @param neat Optional engine exposing `getOperatorStats(): Array<{name:string, success:number, attempts:number}>`.
     * @returns Array of top operators with acceptance percentages or null when unavailable / no data.
     * @example
     * const acceptance = (dashboard as any)["#computeOperatorAcceptance"](neatInstance);
     * // => [ { name: 'mutateAddNode', acceptancePct: 62.5 }, ... ] or null
     */
    #computeOperatorAcceptance(neat) {
      if (typeof neat?.getOperatorStats !== "function") return null;
      let rawOperatorStats;
      try {
        rawOperatorStats = neat.getOperatorStats();
      } catch {
        return null;
      }
      if (!Array.isArray(rawOperatorStats) || rawOperatorStats.length === 0)
        return null;
      const scratchBuffer = this.#scratch.operatorStats;
      scratchBuffer.length = 0;
      for (const operatorStat of rawOperatorStats) {
        if (operatorStat && typeof operatorStat.name === "string" && typeof operatorStat.success === "number" && typeof operatorStat.attempts === "number") {
          scratchBuffer.push(operatorStat);
        }
      }
      if (!scratchBuffer.length) return null;
      const rankedCopy = [...scratchBuffer].sort((leftStat, rightStat) => {
        const leftAcceptance = leftStat.success / Math.max(1, leftStat.attempts);
        const rightAcceptance = rightStat.success / Math.max(1, rightStat.attempts);
        if (rightAcceptance !== leftAcceptance)
          return rightAcceptance - leftAcceptance;
        return 0;
      });
      const limit = Math.min(
        _DashboardManager.#TOP_OPERATOR_LIMIT,
        rankedCopy.length
      );
      const acceptanceList = [];
      for (let rankIndex = 0; rankIndex < limit; rankIndex++) {
        const rankedStat = rankedCopy[rankIndex];
        const acceptancePct = +(100 * rankedStat.success / Math.max(1, rankedStat.attempts)).toFixed(2);
        acceptanceList.push({ name: rankedStat.name, acceptancePct });
      }
      return acceptanceList.length ? acceptanceList : null;
    }
    /**
     * Produce a ranked list of the most frequent mutation operators observed so far.
     *
     * Educational focus:
     * - Demonstrates reuse of an in-place scratch tuple array to avoid allocation churn.
     * - Shows defensive extraction from a loosely-typed stats object (filtering only numeric counts).
     * - Illustrates a simple top-N selection pattern (sort + bounded slice) with explicit caps.
     *
     * Steps:
     * 1. Guard: return null if `mutationStats` is not a plain object.
     * 2. Clear and repopulate `#scratch.mutationEntries` with `[name, count]` tuples for numeric fields.
     * 3. Early return null when no valid entries collected (simplifies downstream rendering conditions).
     * 4. Sort the scratch array in-place by descending count (highest frequency first) using descriptive comparator param names.
     * 5. Take the top N (bounded by `#TOP_MUTATION_LIMIT`) and map to output objects `{ name, count }`.
     * 6. Return the resulting array (guaranteed non-empty) or null if absent.
     *
     * Complexity:
     * - Collection: O(K) with K = enumerable keys on `mutationStats`.
     * - Sort: O(K log K); K is typically modest (dozens at most) so overhead is negligible.
     * - Slice/map: O(min(N, K)).
     *
     * Performance notes:
     * - Scratch array is reused (length reset) preventing repeated allocation of tuple arrays each frame.
     * - In-place sort avoids cloning (`[...entries]`) found in earlier version, eliminating one transient array.
     * - Comparator accesses tuple indices directly, avoiding destructuring overhead in the hot call.
     *
     * Determinism: Pure transformation of the provided stats snapshot; no randomness.
     * Reentrancy: Safe for single-threaded invocation pattern; scratch state is not shared across instances.
     * Edge cases:
     * - Non-object or empty object => null.
     * - Non-numeric values silently skipped.
     * - Negative counts retained (still sorted numerically) under the assumption they signal net effects; could be filtered if undesired.
     *
     * @param mutationStats Arbitrary object mapping mutation operator names to numeric invocation counts.
     * @returns Array of top mutation operators (name + count) or null when no data.
     * @example
     * const top = (dashboard as any)["#computeTopMutations"]({ addNode: 42, addConn: 17 });
     * // => [ { name: 'addNode', count: 42 }, { name: 'addConn', count: 17 } ]
     */
    #computeTopMutations(mutationStats) {
      if (!mutationStats || typeof mutationStats !== "object") return null;
      const mutationEntriesScratch = this.#scratch.mutationEntries;
      mutationEntriesScratch.length = 0;
      for (const mutationName of Object.keys(mutationStats)) {
        const occurrenceCount = mutationStats[mutationName];
        if (typeof occurrenceCount === "number" && Number.isFinite(occurrenceCount)) {
          mutationEntriesScratch.push([mutationName, occurrenceCount]);
        }
      }
      if (!mutationEntriesScratch.length) return null;
      mutationEntriesScratch.sort(
        (leftEntry, rightEntry) => rightEntry[1] - leftEntry[1]
      );
      const limit = Math.min(
        _DashboardManager.#TOP_MUTATION_LIMIT,
        mutationEntriesScratch.length
      );
      const topMutations = [];
      for (let rankIndex = 0; rankIndex < limit; rankIndex++) {
        const [mutationName, occurrenceCount] = mutationEntriesScratch[rankIndex];
        topMutations.push({ name: mutationName, count: occurrenceCount });
      }
      return topMutations;
    }
    /**
     * Compute the sizes (member counts) of the largest species (Top-N) in the current population snapshot.
     *
     * Educational focus:
     * - Demonstrates reuse of an integer scratch array to avoid new allocations every redraw.
     * - Highlights a simple pattern for extracting a Top-N ranking from a small set (in-place sort + bounded copy).
     * - Shows defensive handling of loosely-typed engine data (species objects may omit `members`).
     *
     * Steps:
     * 1. Guard: return null when `neat.species` is absent or empty.
     * 2. Repopulate `#scratch.speciesSizes` with numeric member counts (fallback 0 when ambiguous).
     * 3. In-place sort scratch array descending (largest first).
     * 4. Copy the first N (`#TOP_SPECIES_LIMIT`) values into a new output array for immutability to callers.
     * 5. Return the ranked sizes or null when no data.
     *
     * Complexity:
     * - Let S = species count. Population: O(S). Sort: O(S log S). Copy: O(min(S, N)). S is typically modest, so cost is trivial.
     *
     * Performance notes:
     * - Reuses a single scratch array (cleared via length assignment) to avoid allocation churn.
     * - In-place sort avoids creating an additional clone (`[...scratch]`), reducing temporary memory.
     * - Output array is sized at most `#TOP_SPECIES_LIMIT` (small, bounded allocation) for downstream display safety.
     *
     * Determinism: Pure function of the `neat.species` snapshot (ordering depends only on numerical counts; stable for equal sizes because JS sort is stable in modern engines but equal sizes preserve original order).
     * Reentrancy: Safe under single-threaded invocation pattern (scratch array reused but not shared concurrently).
     * Edge cases:
     * - Missing / non-array / empty species list => null.
     * - Species object missing `members` => treated as size 0.
     * - Negative member counts (unexpected) retained and sorted numerically; could be filtered if a real engine produced them.
     *
     * @param neat Optional NEAT-like engine instance exposing an array `species` with `members` arrays.
     * @returns Array of top species sizes (descending) or null when no species present.
     * @example
     * const sizes = (dashboard as any)["#computeTopSpeciesSizes"](neat);
     * // => [34, 21, 10] (up to 5 elements) or null
     */
    #computeTopSpeciesSizes(neat) {
      if (!Array.isArray(neat?.species) || neat.species.length === 0) return null;
      const speciesSizesScratch = this.#scratch.speciesSizes;
      speciesSizesScratch.length = 0;
      for (const speciesEntry of neat.species) {
        const sizeValue = Array.isArray(speciesEntry?.members) ? speciesEntry.members.length : 0;
        speciesSizesScratch.push(sizeValue);
      }
      if (!speciesSizesScratch.length) return null;
      speciesSizesScratch.sort((leftSize, rightSize) => rightSize - leftSize);
      const limit = Math.min(
        _DashboardManager.#TOP_SPECIES_LIMIT,
        speciesSizesScratch.length
      );
      const topSpeciesSizes = [];
      for (let rankIndex = 0; rankIndex < limit; rankIndex++) {
        topSpeciesSizes.push(speciesSizesScratch[rankIndex]);
      }
      return topSpeciesSizes;
    }
    /** Safe invoke wrapper returning fallback on throw. */
    #safeInvoke(fn, fallback) {
      try {
        return fn();
      } catch {
        return fallback;
      }
    }
    /**
     * Append the top header lines for a solved maze archive block.
     *
     * Format mirrors other framed sections: a top border, a centered label line
     * identifying the solved ordinal and generation, and one spacer line to
     * visually separate from subsequent sparkline + maze content.
     *
     * We keep this lean: no dynamic width calculations beyond centering, and we
     * avoid extra temporary arrays (push directly into the provided accumulator).
     *
     * @param blockLines Accumulator array mutated by appending formatted lines.
     * @param solved Object containing result + generation metadata.
     * @param displayNumber 1-based solved maze index for user-friendly labeling.
     */
    #appendSolvedHeader(blockLines, solved, displayNumber) {
      const innerWidth = _DashboardManager.FRAME_INNER_WIDTH;
      blockLines.push(
        `${colors.blueCore}\u2554${NetworkVisualization.pad(
          "\u2550".repeat(innerWidth),
          innerWidth,
          "\u2550"
        )}\u2557${colors.reset}`
      );
      const { result, generation } = solved;
      const rawFitness = result?.fitness;
      const formattedFitness = typeof rawFitness === "number" && Number.isFinite(rawFitness) ? rawFitness.toFixed(2) : "n/a";
      const title = ` SOLVED #${Math.max(
        1,
        displayNumber
      )} (GEN ${generation})  FITNESS ${formattedFitness} `;
      const leftPaddingSize = Math.max(
        0,
        Math.floor((innerWidth - title.length) / 2)
      );
      const rightPaddingSize = Math.max(
        0,
        innerWidth - title.length - leftPaddingSize
      );
      blockLines.push(
        `${colors.blueCore}\u2551${" ".repeat(leftPaddingSize)}${colors.orangeNeon}${title}${colors.blueCore}${" ".repeat(rightPaddingSize)}\u2551${colors.reset}`
      );
      blockLines.push(
        `${colors.blueCore}\u2551${NetworkVisualization.pad(" ", innerWidth, " ")}\u2551${colors.reset}`
      );
    }
    /**
     * Append solved-run sparklines plus a one-line architecture summary.
     *
     * Additions over the original implementation:
     * - Includes current network architecture (layer sizes) using arrow formatting ("I <=> H1 <=> ... <=> O").
     * - Consolidates architecture here (removed separate later architecture line to avoid duplication).
     * - Retains aligned label formatting via shared `#formatStat` helper for consistency.
     *
     * Architecture derivation:
     * - Uses `#deriveArchitecture` (returns e.g. "6 - 6 - 5 - 4").
     * - Converts hyphen-delimited form to bi-directional arrow form replacing " - " with " <=> " for clearer layer transitions.
     * - Skips line when result is 'n/a'.
     *
     * Steps:
     * 1. Build architecture string (if derivable) and push as first line.
     * 2. For each tracked history series build a sparkline (bounded width) and push if non-empty.
     * 3. Emit a trailing blank framed line as a visual separator before maze rendering.
     *
     * Determinism: Pure formatting/read-only usage of snapshot histories & network.
     * Reentrancy: Safe; only mutates provided accumulator.
     * Edge cases: Empty histories yield omitted lines; architecture omitted when unknown.
     *
     * @param blockLines Accumulator mutated in place.
     * @param network Network whose architecture will be summarized; optional (can be nullish).
     */
    #appendSolvedSparklines(blockLines, network) {
      const solvedLabelWidth = _DashboardManager.#SOLVED_LABEL_WIDTH;
      const solvedStat = (label, value) => this.#formatStat(
        label,
        value,
        colors.neonSilver,
        colors.cyanNeon,
        solvedLabelWidth
      );
      const pushIf = (label, value) => {
        if (value) blockLines.push(solvedStat(label, value));
      };
      if (network) {
        let architectureRaw = "n/a";
        try {
          architectureRaw = this.#deriveArchitecture(network);
        } catch {
          architectureRaw = "n/a";
        }
        if (architectureRaw !== "n/a") {
          const arrowArchitecture = architectureRaw.split(/\s*-\s*/).join(" <=> ");
          pushIf(_DashboardManager.#LABEL_ARCH, arrowArchitecture);
        }
      }
      const archiveWidth = _DashboardManager.#ARCHIVE_SPARK_WIDTH;
      pushIf(
        "Fitness trend",
        this.#buildSparkline(this.#bestFitnessHistory, archiveWidth)
      );
      pushIf(
        "Nodes trend",
        this.#buildSparkline(this.#complexityNodesHistory, archiveWidth)
      );
      pushIf(
        "Conns trend",
        this.#buildSparkline(this.#complexityConnsHistory, archiveWidth)
      );
      pushIf(
        "Hypervol trend",
        this.#buildSparkline(this.#hypervolumeHistory, archiveWidth)
      );
      pushIf(
        "Progress trend",
        this.#buildSparkline(this.#progressHistory, archiveWidth)
      );
      pushIf(
        "Species trend",
        this.#buildSparkline(this.#speciesCountHistory, archiveWidth)
      );
      blockLines.push(
        `${colors.blueCore}\u2551${NetworkVisualization.pad(
          " ",
          _DashboardManager.FRAME_INNER_WIDTH,
          " "
        )}${colors.blueCore}\u2551${colors.reset}`
      );
    }
    /**
     * Append a centered maze visualization for a newly solved maze.
     *
     * The visualization is produced by `MazeVisualization.visualizeMaze`, which
     * returns either a multi‑line string or an array of row strings. We normalize
     * the output to an array and then emit each row framed inside the dashboard
     * box. Rows are padded horizontally to the fixed `FRAME_INNER_WIDTH` so that
     * varying maze sizes (small corridors vs larger layouts) remain visually
     * centered and consistent with surrounding stats blocks.
     *
     * Steps (educational):
     * 1. Determine the terminal path position (last coordinate) – used to draw the agent end state.
     * 2. Generate a textual maze representation (string[] or string) including the path highlight.
     * 3. Normalize to an array of raw row strings (split on newlines if needed).
     * 4. Pad each row to the inner frame width (acts as horizontal centering) and push framed lines to `blockLines`.
     *
     * Performance & ES2023 notes:
     * - Uses `Array.prototype.at(-1)` for the final path coordinate (clearer than `path[path.length-1]`).
     * - Avoids the previous join/split round‑trip (now pads & pushes in a single pass), reducing temporary string allocations.
     * - Relies on local constants to minimize repeated property lookups (`innerWidth`).
     *
     * Determinism: purely formatting; does not mutate input arrays or rely on random state.
     * Reentrancy: safe (no shared scratch buffers used here).
     *
     * @param blockLines - Accumulated output lines for the solved maze archive block (mutated in place by appending framed rows).
     * @param solved - Object containing the raw `maze` character grid and a `result` with a `path` of `[x,y]` coordinates.
     * @remarks The `result.path` is expected to include the start cell; if empty, a fallback position `[0,0]` is used (rare edge case for defensive coding in examples).
     */
    #appendSolvedMaze(blockLines, solved) {
      const pathCoordinates = solved.result.path;
      const endPosition = pathCoordinates?.at(-1) ?? [0, 0];
      const visualization = MazeVisualization.visualizeMaze(
        solved.maze,
        endPosition,
        pathCoordinates ?? []
      );
      const rawLines = Array.isArray(visualization) ? visualization : visualization.split("\n");
      const innerWidth = _DashboardManager.FRAME_INNER_WIDTH;
      for (const rawLine of rawLines) {
        const paddedRow = NetworkVisualization.pad(rawLine, innerWidth, " ");
        blockLines.push(
          `${colors.blueCore}\u2551${NetworkVisualization.pad(
            paddedRow,
            innerWidth,
            " "
          )}${colors.blueCore}\u2551${colors.reset}`
        );
      }
    }
    /**
     * Compute and append human‑readable path efficiency statistics for a solved maze.
     *
     * Metrics exposed (educational rationale):
     * - Path efficiency: optimal BFS distance vs actual traversed length – demonstrates how close evolution came to shortest path.
     * - Path overhead: percent longer than optimal – highlights wasted exploration after reaching a viable route.
     * - Unique cells visited / revisits: proxy for exploration vs dithering; useful to tune mutation operators.
     * - Steps: raw action count taken (often equals `pathLength`).
     * - Fitness: final scalar used for selection (displayed with two decimals for compactness).
     *
     * Steps:
     * 1. Derive aggregated path metrics via `#computePathMetrics` (encapsulates BFS optimal distance + visitation stats).
     * 2. Format each metric with consistent label width & colors using `formatStat` (keeps styling centralized).
     * 3. Push each formatted line to the `blockLines` accumulator.
     *
     * Performance notes:
     * - Single metrics object reused for string interpolation (no intermediate arrays created).
     * - Uses template literals directly; minimal extra allocations beyond the final output strings.
     * - Order is fixed to preserve snapshot diff stability for external log parsers.
     *
     * Determinism: relies on deterministic BFS + pure counting; no randomness.
     * Reentrancy: safe; no shared mutable scratch state.
     *
     * @param blockLines - Accumulator array mutated by appending formatted stat lines.
     * @param solved - Object holding the `maze` layout and `result` containing at least `path`, `steps`, and `fitness`.
     */
    #appendSolvedPathStats(blockLines, solved) {
      const metrics = this.#computePathMetrics(solved.maze, solved.result);
      const labelWidth = _DashboardManager.#SOLVED_LABEL_WIDTH;
      const solvedStat = (label, value) => this.#formatStat(
        label,
        value,
        colors.neonSilver,
        colors.cyanNeon,
        labelWidth
      );
      blockLines.push(
        solvedStat(
          _DashboardManager.#LABEL_PATH_EFF,
          `${metrics.optimalLength}/${metrics.pathLength} (${metrics.efficiencyPct}%)`
        )
      );
      blockLines.push(
        solvedStat(
          _DashboardManager.#LABEL_PATH_OVER,
          `${metrics.overheadPct}% longer than optimal`
        )
      );
      blockLines.push(
        solvedStat(
          _DashboardManager.#LABEL_UNIQUE,
          `${metrics.uniqueCellsVisited}`
        )
      );
      blockLines.push(
        solvedStat(
          _DashboardManager.#LABEL_REVISITS,
          `${metrics.revisitedCells} times`
        )
      );
      blockLines.push(
        solvedStat(_DashboardManager.#LABEL_STEPS, `${metrics.totalSteps}`)
      );
      blockLines.push(
        solvedStat(
          _DashboardManager.#LABEL_FITNESS,
          `${metrics.fitnessValue.toFixed(2)}`
        )
      );
    }
    /** Emit footer & send archive block to logger. */
    static #CACHED_SOLVED_FOOTER_BORDER = null;
    /**
     * Append the solved-archive footer border and emit the accumulated block to the archive logger.
     *
     * Implementation notes:
     * - Reuses an internal cached bottom-border string to avoid recomputing the padded border on every solved maze.
     * - Emits the block as a single joined payload for efficiency; falls back to a line-wise append if the
     *   archive function throws or is not compatible with the single-string API.
     * - Clears the provided `blockLines` accumulator in-place after emission so callers (and tests) can reuse the
     *   same array as a scratch buffer, reducing GC churn in tight loops.
     *
     * Steps (inline):
     * 1. Ensure cached border exists (lazy-init).
     * 2. Append the bottom border to the provided accumulator.
     * 3. Attempt single-string emission with `{ prepend: true }`.
     * 4. On failure, fallback to line-by-line emission using the archive function or a no-op.
     * 5. Clear the accumulator for reuse.
     *
     * @param blockLines Mutable accumulator of framed lines representing a solved maze archive block. This
     *   function will append the closing border and emit the payload; the array will be emptied on return.
     * @example
     * const lines: string[] = [];
     * // ... various helpers push frame header, stats, maze rows into `lines` ...
     * (dashboard as any)["#appendSolvedFooterAndEmit"](lines);
     */
    #appendSolvedFooterAndEmit(blockLines) {
      const innerFrameWidth = _DashboardManager.FRAME_INNER_WIDTH;
      if (_DashboardManager.#CACHED_SOLVED_FOOTER_BORDER === null) {
        _DashboardManager.#CACHED_SOLVED_FOOTER_BORDER = `${colors.blueCore}\u255A${NetworkVisualization.pad(
          "\u2550".repeat(innerFrameWidth),
          innerFrameWidth,
          "\u2550"
        )}\u255D${colors.reset}`;
      }
      blockLines.push(_DashboardManager.#CACHED_SOLVED_FOOTER_BORDER);
      try {
        this.#archiveFn(blockLines.join("\n"), { prepend: true });
        blockLines.length = 0;
        return;
      } catch {
        const archiveAppend = this.#archiveFn ?? (() => {
        });
        for (let lineIndex = 0; lineIndex < blockLines.length; lineIndex++) {
          archiveAppend(blockLines[lineIndex]);
        }
        blockLines.length = 0;
      }
    }
    /**
     * Compute derived path metrics for a solved (or partially solved) maze run.
     *
     * Metrics returned (educational focus):
     * - optimalLength: Shortest possible path length (BFS over encoded maze). Provides a baseline for efficiency.
     * - pathLength: Actual traversed path length (steps between first & last coordinate). Used for overhead calculations.
     * - efficiencyPct: (optimal / actual * 100) clamped to 100%. Indicates how close the agent was to an optimal route.
     * - overheadPct: Percent the actual path exceeds optimal ((actual/optimal)*100 - 100). Negative values are clamped to 0 in practice by optimal <= path.
     * - uniqueCellsVisited: Distinct grid cells in the path – proxy for exploration breadth.
     * - revisitedCells: Times a cell coordinate was encountered after the first visit – proxy for dithering / loops.
     * - totalSteps: Reported step counter from the result object (may equal pathLength, but kept separate for clarity / future divergence like wait actions).
     * - fitnessValue: Raw fitness scalar copied through for convenience (avoids re-threading the original result where only metrics are needed).
     *
     * Steps:
     * 1. Locate start 'S' and exit 'E' positions in the maze (single pass each via MazeUtils helpers).
     * 2. Run BFS to obtain the optimal shortest path length between S and E (O(C) with C = cell count).
     * 3. Derive actual path length from provided coordinate list (defensive against empty / single-node path).
     * 4. Compute efficiency & overhead percentages with divide-by-zero guards (fallback to 0.0 when ambiguous).
     * 5. Count unique vs revisited cells in a single pass through the path (O(P) with P = pathLength+1 nodes).
     * 6. Return an immutable plain object used by formatting helpers.
     *
     * Complexity:
     * - BFS: O(C) where C = maze cell count.
     * - Path scan: O(P) where P = number of coordinates in path.
     * - Overall: O(C + P) per invocation, acceptable for archive-time formatting (not in a hot inner evolution loop).
     *
     * Determinism: Fully deterministic given identical maze + path (no randomness, stable BFS ordering assumed from MazeUtils implementation).
     * Reentrancy: Safe (allocates only local structures: Set + return object).
     * Memory: Extra allocations are bounded (Set size <= P). Suitable for occasional solved-maze archival.
     *
     * Edge cases handled:
     * - Empty or single-coordinate path: pathLength coerces to 0; efficiency & overhead emit '0.0'.
     * - Unreachable BFS (negative / non-positive optimalLength): treated as 0 for ratios (prevents NaN/Infinity).
     * - Division by zero avoided via guards; percentages formatted with one decimal place.
     *
     * @param maze Maze layout as array of row strings containing 'S' and 'E'.
     * @param result Evaluation result containing at least { path, steps, fitness }.
     * @returns Object with path + efficiency metrics (see description).
     * @example
     * const metrics = dashboard.#computePathMetrics(maze, { path, steps: path.length, fitness });
     * console.log(metrics.efficiencyPct); // e.g. '87.5'
     */
    #computePathMetrics(maze, result) {
      const startPosition = MazeUtils.findPosition(maze, "S");
      const exitPosition = MazeUtils.findPosition(maze, "E");
      const bfsLength = MazeUtils.bfsDistance(
        MazeUtils.encodeMaze(maze),
        startPosition,
        exitPosition
      );
      const optimalLength = typeof bfsLength === "number" ? bfsLength : 0;
      const rawPathLength = Math.max(0, result.path.length - 1);
      let efficiencyPct = "0.0";
      let overheadPct = "0.0";
      if (rawPathLength > 0 && optimalLength > 0) {
        const efficiency = Math.min(1, optimalLength / rawPathLength) * 100;
        efficiencyPct = efficiency.toFixed(1);
        const overhead = rawPathLength / optimalLength * 100 - 100;
        overheadPct = overhead.toFixed(1);
      }
      const uniqueCells = /* @__PURE__ */ new Set();
      let revisitedCells = 0;
      for (const [cellX, cellY] of result.path) {
        const key = `${cellX},${cellY}`;
        if (uniqueCells.has(key)) revisitedCells++;
        else uniqueCells.add(key);
      }
      return {
        optimalLength,
        pathLength: rawPathLength,
        efficiencyPct,
        overheadPct,
        uniqueCellsVisited: uniqueCells.size,
        revisitedCells,
        totalSteps: result.steps,
        fitnessValue: result.fitness
      };
    }
    /**
     * Infer a compact, human‑readable architecture string (e.g. "3 - 5 - 2" or "4 - 8 - 8 - 1").
     *
     * Supports several internal network representations encountered in examples:
     * 1. Layered form: `network.layers = [layer0, layer1, ...]` where each layer has `nodes` or is an array.
     * 2. Flat node list: `network.nodes = [...]` each node declaring a `type` ('input' | 'hidden' | 'output'). Hidden layers are
     *    approximated by a simple topological layering pass: we iteratively collect hidden nodes whose inbound connection sources
     *    are already assigned to earlier layers. Remaining nodes after no progress count as a single ambiguous layer (safety / cycle guard).
     * 3. Scalar fallback: numeric `input` & `output` counts (no hidden layers) -> returns "I - O".
     *
     * Steps:
     * 1. Early null/undefined guard.
     * 2. If a layered structure exists (>=2 layers) derive each layer size in order and return immediately (fast path).
     * 3. Else if a flat node list exists, split into input / hidden / output categories.
     * 4. If no hidden nodes: use explicit numeric counts (prefer explicit `input`/`output` props if present).
     * 5. Perform iterative hidden layer inference with a safety iteration cap to avoid infinite loops for malformed cyclic graphs.
     * 6. Assemble final size list: input size, inferred hidden sizes, output size.
     * 7. Fallback: if only scalar counts available, return them; otherwise 'n/a'.
     *
     * Algorithmic notes:
     * - Hidden layering pass is O(H * E_in) where H = hidden nodes, E_in = mean in-degree, acceptable for formatting/UI.
     * - The safety cap (`hiddenCount * LAYER_INFER_LOOP_MULTIPLIER`) prevents pathological spins on cyclic graphs lacking
     *   proper DAG layering; any leftover hidden nodes are grouped into a terminal bucket for transparency.
     * - We intentionally avoid mutating the original node objects (pure inspection) to keep side‑effects nil.
     *
     * Determinism: given a stable ordering of `network.nodes` and their connections, output is deterministic.
     * Reentrancy: safe; all state kept in local sets/arrays.
     *
     * @param networkInstance Arbitrary network-like object from examples or NEAT internals.
     * @returns Architecture string in the form "Input - Hidden... - Output" or 'n/a' if shape cannot be inferred.
     * @example
     * // Layered network
     * deriveArchitecture({ layers:[ {nodes:[1,2,3]}, {nodes:[4,5]}, {nodes:[6,7]} ] }) => "3 - 2 - 2"
     * @example
     * // Flat node list with inferred hidden tiers
     * deriveArchitecture({ nodes:[{type:'input'}, {type:'hidden'}, {type:'output'}] }) => "1 - 1 - 1"
     */
    #deriveArchitecture(networkInstance) {
      if (!networkInstance) return "n/a";
      const layerArray = networkInstance.layers;
      if (Array.isArray(layerArray) && layerArray.length >= 2) {
        const layerSizes = [];
        for (const layerRef of layerArray) {
          const size = Array.isArray(layerRef?.nodes) ? layerRef.nodes.length : Array.isArray(layerRef) ? layerRef.length : 0;
          layerSizes.push(size);
        }
        return layerSizes.join(" - ");
      }
      const flatNodes = networkInstance.nodes;
      if (Array.isArray(flatNodes)) {
        const inputNodes = flatNodes.filter(
          (nodeItem) => nodeItem.type === "input"
        );
        const outputNodes = flatNodes.filter(
          (nodeItem) => nodeItem.type === "output"
        );
        const hiddenNodesAll = flatNodes.filter(
          (nodeItem) => nodeItem.type === "hidden"
        );
        if (!hiddenNodesAll.length) {
          if (typeof networkInstance.input === "number" && typeof networkInstance.output === "number") {
            return `${networkInstance.input} - ${networkInstance.output}`;
          }
          return `${inputNodes.length} - ${outputNodes.length}`;
        }
        const assignedNodes = new Set(inputNodes);
        let remainingHidden = hiddenNodesAll.slice();
        const inferredHiddenSizes = [];
        const safetyLimit = hiddenNodesAll.length * _DashboardManager.#LAYER_INFER_LOOP_MULTIPLIER;
        let iterationCounter = 0;
        while (remainingHidden.length && iterationCounter < safetyLimit) {
          iterationCounter++;
          const currentLayer = remainingHidden.filter(
            (hiddenNode) => hiddenNode.connections?.in?.every(
              (conn) => assignedNodes.has(conn.from)
            )
          );
          if (!currentLayer.length) {
            inferredHiddenSizes.push(remainingHidden.length);
            break;
          }
          inferredHiddenSizes.push(currentLayer.length);
          for (const nodeRef of currentLayer) assignedNodes.add(nodeRef);
          remainingHidden = remainingHidden.filter(
            (nodeCandidate) => !assignedNodes.has(nodeCandidate)
          );
        }
        return [
          `${inputNodes.length}`,
          ...inferredHiddenSizes.map((hiddenSize) => `${hiddenSize}`),
          `${outputNodes.length}`
        ].join(" - ");
      }
      if (typeof networkInstance.input === "number" && typeof networkInstance.output === "number") {
        return `${networkInstance.input} - ${networkInstance.output}`;
      }
      return "n/a";
    }
    /**
     * Ingest an evolution engine update (generation tick or improved candidate) and refresh live + archived displays.
     *
     * High‑level responsibilities:
     * 1. Lazy initialize timing anchors (wall clock + perf) on first call.
     * 2. Stash generation/time metadata for later telemetry sampling.
     * 3. Update the current best candidate reference.
     * 4. Archive a newly solved maze (once per unique layout) with rich stats.
     * 5. Pull the latest telemetry snapshot from the NEAT instance (if provided) and update bounded history buffers.
     * 6. Redraw the live ASCII dashboard (network summary, maze, stats, progress bar).
     * 7. Emit a structured telemetry payload (custom DOM event + postMessage + optional hook) for external consumers.
     *
     * Performance notes:
     * - History buffers are bounded (HISTORY_MAX) using push-with-trim helpers; memory growth is capped.
     * - Telemetry extraction takes only the last snapshot (`safeLast`) to minimize per-tick work.
     * - All formatting for the archive occurs only when a maze is first solved (amortized, infrequent).
     * - Uses `performance.now()` when available for higher‑resolution generation throughput metrics.
     *
     * Determinism: All state changes here are observational (no RNG). Ordering of history pushes is fixed.
     * Reentrancy: Not safe (instance maintains mutable internal single-run state). Use one instance per run.
     * Side‑effects: Console / logger output, optional DOM events (browser), optional parent frame messaging.
     *
     * @param maze - Current maze layout under evolution (array of row strings).
     * @param result - Candidate evaluation result (expects fields: fitness, path, success, progress, etc.).
     * @param network - Network associated with the candidate result.
     * @param generation - Current generation number reported by the engine.
     * @param neatInstance - Optional NEAT framework instance exposing `getTelemetry()` and optional stats helpers.
     * @example
     * dashboard.update(maze, evaluationResult, genome.network, generation, neat);
     */
    update(maze, result, network, generation, neatInstance) {
      if (this.#runStartTs == null) {
        this.#runStartTs = Date.now();
        this.#perfStart = globalThis.performance?.now?.() ?? this.#runStartTs;
      }
      this.#lastUpdateTs = globalThis.performance?.now?.() ?? Date.now();
      this.#lastGeneration = generation;
      this.#currentBest = { result, network, generation };
      if (result?.success) {
        const solvedMazeKey = this.#getMazeKey(maze);
        if (!this.#solvedMazeKeys.has(solvedMazeKey)) {
          this.#solvedMazes.push({ maze, result, network, generation });
          this.#solvedMazeKeys.add(solvedMazeKey);
          const displayOrdinal = this.#solvedMazes.length;
          this.#appendSolvedToArchive(
            { maze, result, network, generation },
            displayOrdinal
          );
        }
      }
      const telemetrySeries = neatInstance?.getTelemetry?.();
      if (Array.isArray(telemetrySeries) && telemetrySeries.length) {
        this.#lastTelemetry = MazeUtils.safeLast(telemetrySeries);
        const latestFitness = this.#currentBest?.result?.fitness;
        if (typeof latestFitness === "number") {
          this.#lastBestFitness = latestFitness;
          this.#bestFitnessHistory = MazeUtils.pushHistory(
            this.#bestFitnessHistory,
            latestFitness,
            _DashboardManager.HISTORY_MAX
          );
        }
        const complexitySnapshot = this.#lastTelemetry?.complexity;
        if (complexitySnapshot) {
          if (typeof complexitySnapshot.meanNodes === "number") {
            this.#complexityNodesHistory = MazeUtils.pushHistory(
              this.#complexityNodesHistory,
              complexitySnapshot.meanNodes,
              _DashboardManager.HISTORY_MAX
            );
          }
          if (typeof complexitySnapshot.meanConns === "number") {
            this.#complexityConnsHistory = MazeUtils.pushHistory(
              this.#complexityConnsHistory,
              complexitySnapshot.meanConns,
              _DashboardManager.HISTORY_MAX
            );
          }
        }
        const hyperVolumeLatest = this.#lastTelemetry?.hyper;
        if (typeof hyperVolumeLatest === "number") {
          this.#hypervolumeHistory = MazeUtils.pushHistory(
            this.#hypervolumeHistory,
            hyperVolumeLatest,
            _DashboardManager.HISTORY_MAX
          );
        }
        const progressFraction = this.#currentBest?.result?.progress;
        if (typeof progressFraction === "number") {
          this.#progressHistory = MazeUtils.pushHistory(
            this.#progressHistory,
            progressFraction,
            _DashboardManager.HISTORY_MAX
          );
        }
        const speciesCountSnapshot = this.#lastTelemetry?.species;
        if (typeof speciesCountSnapshot === "number") {
          this.#speciesCountHistory = MazeUtils.pushHistory(
            this.#speciesCountHistory,
            speciesCountSnapshot,
            _DashboardManager.HISTORY_MAX
          );
        }
      }
      this.redraw(maze, neatInstance);
      try {
        const elapsedMs = this.#perfStart != null && globalThis.performance?.now ? globalThis.performance.now() - this.#perfStart : this.#runStartTs ? Date.now() - this.#runStartTs : 0;
        const generationsPerSecond = elapsedMs > 0 ? generation / (elapsedMs / 1e3) : 0;
        const payload = {
          type: "asciiMaze:telemetry",
          generation,
          bestFitness: this.#lastBestFitness,
          progress: this.#currentBest?.result?.progress ?? null,
          speciesCount: this.#speciesCountHistory.at(-1) ?? null,
          gensPerSec: +generationsPerSecond.toFixed(3),
          timestamp: Date.now(),
          details: this.#lastDetailedStats || null
        };
        if (typeof window !== "undefined") {
          try {
            window.dispatchEvent(
              new CustomEvent("asciiMazeTelemetry", { detail: payload })
            );
          } catch {
          }
          try {
            if (window.parent && window.parent !== window)
              window.parent.postMessage(payload, "*");
          } catch {
          }
          window.asciiMazeLastTelemetry = payload;
        }
        try {
          this._telemetryHook && this._telemetryHook(payload);
        } catch {
        }
      } catch {
      }
    }
    /**
     * Return the most recent telemetry snapshot including rich details.
     * Details may be null if not yet populated.
     * @returns Snapshot object with generation, fitness, progress and detail block.
     */
    getLastTelemetry() {
      const elapsedMs = this.#perfStart != null && typeof performance !== "undefined" ? performance.now() - this.#perfStart : this.#runStartTs ? Date.now() - this.#runStartTs : 0;
      const generation = this.#lastGeneration ?? 0;
      const gensPerSec = elapsedMs > 0 ? generation / (elapsedMs / 1e3) : 0;
      return {
        generation,
        bestFitness: this.#lastBestFitness,
        progress: this.#currentBest?.result?.progress ?? null,
        speciesCount: MazeUtils.safeLast(this.#speciesCountHistory) ?? null,
        gensPerSec: +gensPerSec.toFixed(3),
        // Expose the last update time if available; convert high-resolution perf time to
        // wall-clock ms when possible so consumers receive an absolute timestamp.
        timestamp: this.#resolveLastUpdateWallMs(),
        details: this.#lastDetailedStats || null
      };
    }
    /**
     * Resolve the stored last-update timestamp to a wall-clock millisecond value.
     * If the stored value is a high-resolution perf.now() reading, convert it to
     * Date.now() anchored by the recorded `#runStartTs` / `#perfStart` pair. If no
     * last-update is available fall back to Date.now().
     */
    #resolveLastUpdateWallMs() {
      if (this.#lastUpdateTs == null) return Date.now();
      if (this.#perfStart != null && typeof globalThis.performance?.now === "function" && this.#runStartTs != null) {
        return this.#runStartTs + (this.#lastUpdateTs - this.#perfStart);
      }
      return this.#lastUpdateTs;
    }
    /**
     * Print the static top frame (dashboard title header) once at construction / first redraw.
     *
     * Educational focus:
     * - Demonstrates consistent frame construction (symmetric width) using shared constants.
     * - Shows explicit centering math for a colored title while measuring width from an uncolored template.
     * - Avoids ad‑hoc IIFEs: clearer sequential steps improve readability for newcomers.
     *
     * Steps:
     * 1. Emit a solid single‑line top border (full inner width).
     * 2. Emit a bridge line (visual taper) using preconfigured characters.
     * 3. Center and print the title "ASCII maze" with color accents, preserving frame alignment.
     * 4. Emit a lower bridge line to transition into evolving content sections.
     *
     * Centering approach:
     * - We compute visible width using an uncolored template string (box glyph + spaces + raw title + trailing glyph).
     * - Remaining horizontal space is split; a slight left‑bias (ceil on left) improves stability with odd widths.
     * - ANSI color codes are injected only after padding is determined so they don't skew calculations.
     *
     * Performance notes:
     * - Only a handful of short-lived strings are created; cost is negligible (runs once per session).
     * - Uses direct `this.#logFn` calls (no intermediate array joins) to keep GC pressure minimal.
     *
     * Determinism: Pure formatting (no randomness). Reentrancy not required (idempotent semantics acceptable).
     * Edge cases: If the frame width shrinks below the label length, padding clamps to zero and label is still printed.
     *
     * @example
     * (dashboard as any)["#printTopFrame"](); // Emits header block
     */
    #printTopFrame() {
      const innerWidth = _DashboardManager.FRAME_INNER_WIDTH;
      this.#logFn(
        `${colors.blueCore}\u2554${NetworkVisualization.pad(
          _DashboardManager.#FRAME_SINGLE_LINE_CHAR,
          innerWidth,
          _DashboardManager.#FRAME_SINGLE_LINE_CHAR
        )}\u2557${colors.reset}`
      );
      this.#logFn(
        `${colors.blueCore}\u255A${NetworkVisualization.pad(
          _DashboardManager.#FRAME_BRIDGE_TOP,
          innerWidth,
          _DashboardManager.#FRAME_SINGLE_LINE_CHAR
        )}\u255D${colors.reset}`
      );
      const uncoloredTemplate = "\u2551 ASCII maze \u2551";
      const templateLength = uncoloredTemplate.length;
      const remainingSpace = innerWidth - templateLength;
      const leftPaddingCount = Math.max(0, Math.ceil(remainingSpace / 2)) + 1;
      const rightPaddingCount = Math.max(0, remainingSpace - leftPaddingCount);
      const coloredTitleSegment = `\u2551 ${colors.neonYellow}ASCII maze${colors.blueCore} \u2551`;
      const centeredTitleLine = `${colors.blueCore}${" ".repeat(
        leftPaddingCount
      )}${coloredTitleSegment}${" ".repeat(rightPaddingCount)}${colors.reset}`;
      this.#logFn(centeredTitleLine);
      this.#logFn(
        `${colors.blueCore}\u2554${NetworkVisualization.pad(
          _DashboardManager.#FRAME_BRIDGE_BOTTOM,
          innerWidth,
          _DashboardManager.#FRAME_SINGLE_LINE_CHAR
        )}\u2557${colors.reset}`
      );
    }
    /** Orchestrate printing of evolving section (network + maze + stats + progress). */
    #printCurrentBestSection(currentMaze) {
      const generation = this.#currentBest.generation;
      const sectionLine = _DashboardManager.#EVOLVING_SECTION_LINE;
      this.#logFn(
        `${colors.blueCore}\u2560${NetworkVisualization.pad(
          sectionLine,
          _DashboardManager.FRAME_INNER_WIDTH,
          "\u2550"
        )}${colors.blueCore}\u2563${colors.reset}`
      );
      this.#logFn(
        `${colors.blueCore}\u2551${NetworkVisualization.pad(
          `${colors.orangeNeon}EVOLVING (GEN ${generation})`,
          _DashboardManager.FRAME_INNER_WIDTH,
          " "
        )}${colors.blueCore}\u2551${colors.reset}`
      );
      this.#logFn(
        `${colors.blueCore}\u2560${NetworkVisualization.pad(
          sectionLine,
          _DashboardManager.FRAME_INNER_WIDTH,
          "\u2550"
        )}${colors.blueCore}\u2563${colors.reset}`
      );
      this.#logBlank();
      this.#printNetworkSummary();
      this.#printLiveMaze(currentMaze);
      this.#printLiveStats(currentMaze);
      this.#printProgressBar();
    }
    /** Print network summary visualization. */
    #printNetworkSummary() {
      this.#logBlank();
      this.#logFn(
        NetworkVisualization.visualizeNetworkSummary(this.#currentBest.network)
      );
      this.#logBlank();
    }
    /**
     * Render (and frame) the live maze for the current best candidate.
     *
     * Educational focus:
     * - Demonstrates safe use of `Array.prototype.at(-1)` for final coordinate extraction.
     * - Streams framed rows directly to the logger (avoids building one large joined string).
     * - Normalizes flexible visualization return types (string or string[]) into a unified iteration path.
     *
     * Steps:
     * 1. Resolve the agent's last path position (fallback `[0,0]` if path absent) for end‑marker highlighting.
     * 2. Ask `MazeVisualization.visualizeMaze` for a textual representation containing the path overlay.
     * 3. Normalize the result into an array of raw row strings (split on newlines when a single string is returned).
     * 4. For each row, pad to the fixed frame width and emit a framed line (borders + color) via `#logFn`.
     * 5. Surround the block with blank spacer lines for visual separation from adjacent sections.
     *
     * Performance notes:
     * - Avoids intermediate `.map().join()` allocation; writes each row immediately (lower peak memory for large mazes).
     * - Uses a local `innerWidth` alias to prevent repeated static property lookups in the hot loop.
     * - Only allocates one padded string per row (the framing template is assembled inline).
     *
     * Determinism: Pure formatting based on current maze + candidate path (no randomness).
     * Reentrancy: Not designed for concurrent invocation but method is self‑contained (no shared scratch mutation).
     * Edge cases:
     * - Empty visualization yields just spacer lines.
     * - Extremely long rows are hard-clipped visually by frame padding (consistent with rest of dashboard design).
     *
     * @param currentMaze Current maze layout (array of row strings) being evolved.
     */
    #printLiveMaze(currentMaze) {
      const pathCoordinates = this.#currentBest.result.path;
      const endOfPathPosition = pathCoordinates?.at(-1) ?? [0, 0];
      const rawVisualization = MazeVisualization.visualizeMaze(
        currentMaze,
        endOfPathPosition,
        pathCoordinates
      );
      const visualizationLines = Array.isArray(
        rawVisualization
      ) ? rawVisualization : rawVisualization.split("\n");
      const innerWidth = _DashboardManager.FRAME_INNER_WIDTH;
      this.#logBlank();
      for (const unpaddedRow of visualizationLines) {
        const paddedRow = NetworkVisualization.pad(unpaddedRow, innerWidth, " ");
        this.#logFn(
          `${colors.blueCore}\u2551${paddedRow}${colors.blueCore}\u2551${colors.reset}`
        );
      }
      this.#logBlank();
    }
    static #INT32_SCRATCH_POOL = [];
    /**
     * Render the live statistics block for the current best candidate.
     *
     * Enhancements over the original:
     * - Provides a concise JSDoc with parameter & example usage.
     * - Uses a small Int32Array pooling strategy for temporary numeric scratch space to reduce
     *   short-lived allocation churn during frequent redraws.
     * - Employs descriptive local variable names and step-level inline comments for clarity.
     *
     * Steps:
     * 1. Guard and emit a small spacer when no current best candidate exists.
     * 2. Rent a temporary typed-array buffer to hold derived numeric summary values.
     * 3. Populate the buffer with fitness, steps, and progress (scaled where appropriate).
     * 4. Emit a small, framed summary via existing `#formatStat` helper to preserve dashboard styling.
     * 5. Delegate the detailed printing to `MazeVisualization.printMazeStats` (keeps single-responsibility).
     * 6. Return the rented buffer to the internal pool and emit a trailing spacer.
     *
     * @param currentMaze Current maze layout used to compute/print maze-specific stats.
     * @example
     * // invoked internally by `update()` during redraw
     * (dashboard as any)["#printLiveStats"](maze);
     */
    #printLiveStats(currentMaze) {
      this.#logBlank();
      const currentBestCandidate = this.#currentBest;
      if (!currentBestCandidate) {
        this.#logBlank();
        return;
      }
      const rentInt32 = (requestedLength) => {
        const pooled = _DashboardManager.#INT32_SCRATCH_POOL.pop();
        if (pooled && pooled.length >= requestedLength)
          return pooled.subarray(0, requestedLength);
        return new Int32Array(requestedLength);
      };
      const releaseInt32 = (buffer) => {
        if (_DashboardManager.#INT32_SCRATCH_POOL.length < 8) {
          _DashboardManager.#INT32_SCRATCH_POOL.push(buffer);
        }
      };
      const scratch = rentInt32(3);
      const reportedFitness = currentBestCandidate.result?.fitness;
      scratch[0] = typeof reportedFitness === "number" && Number.isFinite(reportedFitness) ? Math.round(reportedFitness * 100) : 0;
      const reportedSteps = Number(currentBestCandidate.result?.steps ?? 0);
      scratch[1] = Number.isFinite(reportedSteps) ? reportedSteps : 0;
      const reportedProgress = Number(currentBestCandidate.result?.progress ?? 0);
      scratch[2] = Number.isFinite(reportedProgress) ? Math.round(reportedProgress * 100) : 0;
      const formattedFitness = (scratch[0] / 100).toFixed(2);
      const formattedSteps = `${scratch[1]}`;
      const formattedProgress = `${scratch[2]}%`;
      const liveLabelWidth = _DashboardManager.#SOLVED_LABEL_WIDTH;
      const liveStat = (label, value) => this.#formatStat(
        label,
        value,
        colors.neonSilver,
        colors.cyanNeon,
        liveLabelWidth
      );
      this.#logFn(liveStat("Fitness", formattedFitness));
      this.#logFn(liveStat("Steps", formattedSteps));
      this.#logFn(liveStat("Progress", formattedProgress));
      MazeVisualization.printMazeStats(
        currentBestCandidate,
        currentMaze,
        this.#logFn
      );
      releaseInt32(scratch);
      this.#logBlank();
    }
    /** Print progress bar lines. */
    #printProgressBar() {
      const padBlank = () => this.#logFn(
        `${colors.blueCore}\u2551${NetworkVisualization.pad(
          " ",
          _DashboardManager.FRAME_INNER_WIDTH,
          " "
        )}${colors.blueCore}\u2551${colors.reset}`
      );
      padBlank();
      const bar = `Progress to exit: ${MazeVisualization.displayProgressBar(
        this.#currentBest.result.progress
      )}`;
      this.#logFn(
        `${colors.blueCore}\u2551${NetworkVisualization.pad(
          " " + colors.neonSilver + bar + colors.reset,
          _DashboardManager.FRAME_INNER_WIDTH,
          " "
        )}${colors.blueCore}\u2551${colors.reset}`
      );
      padBlank();
    }
    reset() {
      this.#solvedMazes = [];
      this.#solvedMazeKeys.clear();
      this.#currentBest = null;
    }
    /**
     * Produce an immutable tail slice of a bounded numeric history buffer.
     *
     * Educational focus:
     * - Encapsulates export window logic so callers don't duplicate clamp arithmetic.
     * - Demonstrates a micro-optimized manual copy for partial slices while using
     *   the native fast path (`Array.prototype.slice`) when returning the full buffer.
     * - Adds defensive guards for null / non-array input (returns empty array) to simplify callers.
     *
     * Steps:
     * 1. Guard: if the provided reference is not a non-empty array, return a new empty array.
     * 2. Compute the starting index for the export window (clamped to 0).
     * 3. If the window spans the entire history, return a shallow copy via `.slice()` (fast path).
     * 4. Allocate an output array sized exactly to the window length.
     * 5. Manually copy values (forward loop) to avoid creating an intermediate subarray before clone.
     * 6. Return the populated tail slice (caller receives an independent array).
     *
     * Complexity:
     * - Let N = history length, W = export window size (<= HISTORY_EXPORT_WINDOW).
     * - Computation: O(min(N, W)) element copies.
     * - Memory: O(min(N, W)) for the returned array.
     *
     * Performance notes:
     * - Manual copy avoids constructing a temporary array then cloning it; though engines optimize slice well,
     *   the explicit loop keeps intent clear and allows descriptive index naming for style compliance.
     * - Uses descriptive loop index (`offsetIndex`) instead of a terse variable to satisfy style guidelines.
     *
     * Determinism: Pure function of input array contents and static window constant.
     * Reentrancy: Safe (no shared mutable state). Input array is never mutated.
     * Edge cases:
     * - Null / undefined / non-array -> returns [].
     * - Empty array -> returns [].
     * - HISTORY_EXPORT_WINDOW >= history length -> returns shallow clone of entire history.
     *
     * @param history Source numeric history buffer (may be longer than export window).
     * @returns New array containing up to `HISTORY_EXPORT_WINDOW` most recent samples (oldest first inside the window).
     */
    #sliceHistoryForExport(history) {
      if (!Array.isArray(history) || !history.length) return [];
      const startIndex = Math.max(
        0,
        history.length - _DashboardManager.#HISTORY_EXPORT_WINDOW
      );
      if (startIndex === 0) return history.slice();
      const windowLength = history.length - startIndex;
      const windowSlice = new Array(windowLength);
      for (let offsetIndex = 0; offsetIndex < windowLength; offsetIndex++) {
        windowSlice[offsetIndex] = history[startIndex + offsetIndex];
      }
      return windowSlice;
    }
  };

  // src/neataptic.ts
  init_neat();
  init_network();
  init_node();
  init_layer();
  init_group();
  init_connection();

  // src/architecture/architect.ts
  init_node();
  init_layer();
  init_group();
  init_network();
  init_methods();
  init_connection();

  // src/neataptic.ts
  init_methods();
  init_config();
  init_multi();

  // test/examples/asciiMaze/mazeVision.ts
  var MazeVision = class _MazeVision {
    /**
     * Direction table mapping cardinal direction to [dx, dy, index].
     *
     * Each entry is a tuple where the first two values are the X/Y delta to
     * reach the neighbor and the third value is the canonical direction index
     * used across the class (0 = N, 1 = E, 2 = S, 3 = W).
     * @type {readonly [number, number, number][]}
     */
    static #DIRECTION_DELTAS = [
      [0, -1, 0],
      // N
      [1, 0, 1],
      // E
      [0, 1, 2],
      // S
      [-1, 0, 3]
      // W
    ];
    // Tunable private constants
    /** Number of cardinal directions (N, E, S, W). */
    static #DIRECTION_COUNT = 4;
    /**
     * Scalar step per compass direction used to encode the compass into a single
     * continuous value: 0 = N, 0.25 = E, 0.5 = S, 0.75 = W.
     */
    static #COMPASS_STEP = 0.25;
    /** Offset to compute the opposite direction (half of direction count). */
    static #OPPOSITE_OFFSET = 2;
    /** Horizon (max path length) at which a neighbor is considered "open". */
    static #OPENNESS_HORIZON = 1e3;
    /** Horizon used when selecting compass preference from a distance map. */
    static #COMPASS_HORIZON = 5e3;
    /** Small scalar used to encourage backtracking from dead-ends. */
    static #BACKTRACK_SIGNAL = 1e-3;
    /** Absolute clip applied to step-delta used when computing progress signal. */
    static #PROGRESS_CLIP = 2;
    /** Scale applied to clipped progress delta before adding to neutral baseline. */
    static #PROGRESS_SCALE = 4;
    /** Neutral progress value returned when progress cannot be computed reliably. */
    static #PROGRESS_NEUTRAL = 0.5;
    /**
     * Pooled scratch buffers reused across `buildInputs6` invocations to avoid
     * per-call allocations in hot paths. These are class-private and must be
     * initialized (via `fill`) at the start of each call.
     *
     * IMPORTANT: Because these buffers are reused, `buildInputs6` is not
     * reentrant and callers should not rely on the buffers' contents after
     * calling the method. See `buildInputs6` JSDoc `@remarks` for details.
     */
    static #SCRATCH_NEIGHBOR_X = new Int32Array(_MazeVision.#DIRECTION_COUNT);
    static #SCRATCH_NEIGHBOR_Y = new Int32Array(_MazeVision.#DIRECTION_COUNT);
    static #SCRATCH_NEIGHBOR_PATH = new Float32Array(_MazeVision.#DIRECTION_COUNT);
    static #SCRATCH_NEIGHBOR_REACH = new Uint8Array(_MazeVision.#DIRECTION_COUNT);
    static #SCRATCH_NEIGHBOR_OPEN = new Float32Array(_MazeVision.#DIRECTION_COUNT);
    // Raw distance to exit per neighbor (NaN when not present). Pooled to avoid
    // per-call allocation; follows same non-reentrancy warning as other buffers.
    /**
     * Pooled buffer holding the raw distance-to-exit for each neighbor when a
     * `distanceToExitMap` is provided. Values are `NaN` when missing.
     */
    static #SCRATCH_NEIGHBOR_RAWDIST = new Float32Array(
      _MazeVision.#DIRECTION_COUNT
    );
    // Small helpers
    /**
     * Return a neutral 6-element input vector used when inputs are invalid or
     * incomplete. The progress element is set to the neutral baseline.
     * @returns {[number, number, number, number, number, number]}
     *  [compassScalar, openN, openE, openS, openW, progressDelta]
     */
    static #neutralInput() {
      return [0, 0, 0, 0, 0, _MazeVision.#PROGRESS_NEUTRAL];
    }
    /**
     * Fast bounds check for a 2D grid.
     * @param grid - 2D numeric grid where each row is an array.
     * @param col - X coordinate (column index).
     * @param row - Y coordinate (row index).
     * @returns True when the coordinate is within the grid bounds.
     */
    static #isWithinBounds(grid, col, row) {
      return Array.isArray(grid) && row >= 0 && row < grid.length && Array.isArray(grid[row]) && col >= 0 && col < grid[row].length;
    }
    /**
     * Return true if the cell at [col,row] is within bounds and not a wall.
     * @param grid - Encoded maze where `-1` represents a wall.
     * @param col - Column (x) coordinate.
     * @param row - Row (y) coordinate.
     * @returns True when the cell exists and is open (not -1).
     */
    static #isCellOpen(grid, col, row) {
      return _MazeVision.#isWithinBounds(grid, col, row) && grid[row][col] !== -1;
    }
    /**
     * Compute the opposite cardinal direction index.
     * @param direction - Direction index in range [0, #DIRECTION_COUNT).
     * @returns Opposite direction index (e.g. 0 -> 2, 1 -> 3).
     */
    static #opposite(direction) {
      return (direction + _MazeVision.#OPPOSITE_OFFSET) % _MazeVision.#DIRECTION_COUNT;
    }
    /**
     * Build the 6-element input vector consumed by the agent's network.
     *
     * The returned array has the shape: [compassScalar, openN, openE, openS, openW, progressDelta].
     *
     * @param encodedMaze - 2D grid where `-1` is a wall and `0+` is free space.
     * @param agentPosition - Agent coordinates as `[x, y]`.
     * @param exitPosition - Exit coordinates as `[x, y]` used as geometric fallback for compass.
     * @param distanceToExitMap - Optional distance-to-exit 2D map (same shape as `encodedMaze`).
     * @param previousStepDistance - Optional scalar distance-to-exit from the previous step.
     * @param currentStepDistance - Scalar distance-to-exit for the current step.
     * @param previousAction - Optional previous action index (0=N,1=E,2=S,3=W) to encourage backtracking.
     * @returns A 6-element number array with the vision inputs described above.
     *
     * @remarks
     * - This method reuses internal pooled scratch buffers (`#SCRATCH_*`) to avoid
     *   allocations on hot paths. Because the buffers are reused, the method is
     *   not reentrant and should not be called concurrently from multiple
     *   contexts if they share the same process/thread.
     * - Scratch buffers are initialized (via `.fill`) on each call so no state is
     *   leaked between invocations.
     */
    static buildInputs6(encodedMaze, agentPosition, exitPosition, distanceToExitMap, previousStepDistance, currentStepDistance, previousAction) {
      if (!Array.isArray(encodedMaze) || encodedMaze.length === 0)
        return _MazeVision.#neutralInput();
      const [agentX, agentY] = agentPosition;
      if (!Number.isFinite(agentX) || !Number.isFinite(agentY))
        return _MazeVision.#neutralInput();
      if (!_MazeVision.#isWithinBounds(encodedMaze, agentX, agentY))
        return _MazeVision.#neutralInput();
      const opennessHorizon = _MazeVision.#OPENNESS_HORIZON;
      const compassHorizon = _MazeVision.#COMPASS_HORIZON;
      const DIR_N = 0;
      const DIR_E = 1;
      const DIR_S = 2;
      const DIR_W = 3;
      const D_COUNT = _MazeVision.#DIRECTION_COUNT;
      const neighborX = _MazeVision.#SCRATCH_NEIGHBOR_X;
      const neighborY = _MazeVision.#SCRATCH_NEIGHBOR_Y;
      const neighborPath = _MazeVision.#SCRATCH_NEIGHBOR_PATH;
      const neighborReach = _MazeVision.#SCRATCH_NEIGHBOR_REACH;
      const neighborOpen = _MazeVision.#SCRATCH_NEIGHBOR_OPEN;
      const directionDeltas = _MazeVision.#DIRECTION_DELTAS;
      const distMap = distanceToExitMap;
      neighborPath.fill(Infinity);
      neighborReach.fill(0);
      neighborOpen.fill(0);
      const currentCellDist = Number.isFinite(distMap?.[agentY]?.[agentX]) ? distMap[agentY][agentX] : void 0;
      const hasCurrentCellDist = currentCellDist != null && Number.isFinite(currentCellDist);
      const neighborRaw = _MazeVision.#SCRATCH_NEIGHBOR_RAWDIST;
      neighborRaw.fill(NaN);
      for (let d = 0; d < D_COUNT; d++) {
        const delta = directionDeltas[d];
        const deltaX = delta[0];
        const deltaY = delta[1];
        const directionIndex = delta[2];
        const neighborCol = agentX + deltaX;
        const neighborRow = agentY + deltaY;
        neighborX[directionIndex] = neighborCol;
        neighborY[directionIndex] = neighborRow;
        const neighborRowRef = encodedMaze[neighborRow];
        if (!neighborRowRef || neighborRowRef[neighborCol] === -1) {
          neighborPath[directionIndex] = Infinity;
          neighborReach[directionIndex] = 0;
          neighborOpen[directionIndex] = 0;
          neighborRaw[directionIndex] = NaN;
          continue;
        }
        const distRow = distMap && distMap[neighborRow];
        const rawDistance = distRow ? distRow[neighborCol] : void 0;
        neighborRaw[directionIndex] = Number.isFinite(rawDistance) ? rawDistance : NaN;
        const hasValidDistance = rawDistance != null && Number.isFinite(rawDistance);
        neighborReach[directionIndex] = 1;
        if (hasValidDistance && hasCurrentCellDist && rawDistance < currentCellDist) {
          const pathLength = 1 + rawDistance;
          neighborPath[directionIndex] = pathLength <= opennessHorizon ? pathLength : Infinity;
          neighborOpen[directionIndex] = 0;
        } else {
          neighborPath[directionIndex] = Infinity;
          neighborOpen[directionIndex] = 0;
        }
      }
      let minPath = Infinity;
      for (let directionIndex = 0; directionIndex < D_COUNT; directionIndex++) {
        if (neighborReach[directionIndex] && Number.isFinite(neighborPath[directionIndex]) && neighborPath[directionIndex] < minPath)
          minPath = neighborPath[directionIndex];
      }
      if (minPath < Infinity) {
        for (let directionIndex = 0; directionIndex < D_COUNT; directionIndex++) {
          if (neighborReach[directionIndex] && Number.isFinite(neighborPath[directionIndex])) {
            neighborOpen[directionIndex] = neighborPath[directionIndex] === minPath ? 1 : minPath / neighborPath[directionIndex];
          }
        }
      }
      let openN = neighborOpen[DIR_N];
      let openE = neighborOpen[DIR_E];
      let openS = neighborOpen[DIR_S];
      let openW = neighborOpen[DIR_W];
      if (openN === 0 && openE === 0 && openS === 0 && openW === 0 && previousAction != null) {
        const oppositeDirection = _MazeVision.#opposite(previousAction);
        switch (oppositeDirection) {
          case DIR_N:
            if (_MazeVision.#isCellOpen(encodedMaze, agentX, agentY - 1))
              openN = _MazeVision.#BACKTRACK_SIGNAL;
            break;
          case DIR_E:
            if (_MazeVision.#isCellOpen(encodedMaze, agentX + 1, agentY))
              openE = _MazeVision.#BACKTRACK_SIGNAL;
            break;
          case DIR_S:
            if (_MazeVision.#isCellOpen(encodedMaze, agentX, agentY + 1))
              openS = _MazeVision.#BACKTRACK_SIGNAL;
            break;
          case DIR_W:
            if (_MazeVision.#isCellOpen(encodedMaze, agentX - 1, agentY))
              openW = _MazeVision.#BACKTRACK_SIGNAL;
            break;
        }
      }
      let bestDirection = 0;
      if (distanceToExitMap) {
        let minCompassPathLength = Infinity;
        let found = false;
        for (let directionIndex = 0; directionIndex < D_COUNT; directionIndex++) {
          const neighborCachedRaw = neighborRaw[directionIndex];
          if (Number.isFinite(neighborCachedRaw)) {
            const pathLength = neighborCachedRaw + 1;
            if (pathLength < minCompassPathLength && pathLength <= compassHorizon) {
              minCompassPathLength = pathLength;
              bestDirection = directionIndex;
              found = true;
            }
          }
        }
        if (!found) {
          const deltaToExitX = exitPosition[0] - agentX;
          const deltaToExitY = exitPosition[1] - agentY;
          bestDirection = Math.abs(deltaToExitX) > Math.abs(deltaToExitY) ? deltaToExitX > 0 ? 1 : 3 : deltaToExitY > 0 ? 2 : 0;
        }
      } else {
        const deltaToExitX = exitPosition[0] - agentX;
        const deltaToExitY = exitPosition[1] - agentY;
        bestDirection = Math.abs(deltaToExitX) > Math.abs(deltaToExitY) ? deltaToExitX > 0 ? 1 : 3 : deltaToExitY > 0 ? 2 : 0;
      }
      const compassScalar = bestDirection * _MazeVision.#COMPASS_STEP;
      let progress = _MazeVision.#PROGRESS_NEUTRAL;
      if (previousStepDistance != null && Number.isFinite(previousStepDistance) && Number.isFinite(currentStepDistance)) {
        const delta = previousStepDistance - currentStepDistance;
        const clipped = Math.max(
          -_MazeVision.#PROGRESS_CLIP,
          Math.min(_MazeVision.#PROGRESS_CLIP, delta)
        );
        progress = _MazeVision.#PROGRESS_NEUTRAL + clipped / _MazeVision.#PROGRESS_SCALE;
      }
      return [compassScalar, openN, openE, openS, openW, progress];
    }
  };

  // test/examples/asciiMaze/mazeMovement.ts
  var MazeMovement = class _MazeMovement {
    /**
     * Maximum number of simulation steps before terminating (safety cap)
     * @internal
     */
    static #DEFAULT_MAX_STEPS = 3e3;
    /**
     * Number of recent moves tracked for oscillation detection
     * @internal
     */
    static #MOVE_HISTORY_LENGTH = 6;
    // Named private constants to replace magic numbers and document intent.
    /** Reward scale applied to shaping terms (smaller reduces selection pressure) */
    static #REWARD_SCALE = 0.5;
    /** Strong penalty multiplier for short A->B oscillations */
    static #LOOP_PENALTY = 10;
    // multiplied by rewardScale
    /** Penalty applied when returning to a recent cell (memory-based) */
    static #MEMORY_RETURN_PENALTY = 2;
    // multiplied by rewardScale
    /** Per-visit penalty for repeated visits to same cell */
    static #REVISIT_PENALTY_PER_VISIT = 0.2;
    // per extra visit, multiplied by rewardScale
    /** Visits threshold to trigger termination/harsh penalty */
    static #VISIT_TERMINATION_THRESHOLD = 10;
    /** Extremely harsh penalty for invalid moves (used sparingly) */
    static #INVALID_MOVE_PENALTY_HARSH = 1e3;
    /** Mild penalty for invalid moves to preserve learning signal */
    static #INVALID_MOVE_PENALTY_MILD = 10;
    // Saturation / collapse thresholds and penalties
    /** Probability threshold indicating overconfidence (near-deterministic) */
    static #OVERCONFIDENT_PROB = 0.985;
    /** Secondary-probability threshold used with overconfidence detection */
    static #SECOND_PROB_LOW = 0.01;
    /** Threshold for flat-collapse detection using log-std of outputs */
    static #LOGSTD_FLAT_THRESHOLD = 0.01;
    /** Penalty when network appears overconfident */
    static #OVERCONFIDENT_PENALTY = 0.25;
    // * rewardScale
    /** Penalty for flat collapse (no variance in outputs) */
    static #FLAT_COLLAPSE_PENALTY = 0.35;
    // * rewardScale
    /** Minimum saturations before applying bias adjustments */
    static #SATURATION_ADJUST_MIN = 6;
    /** Interval (in steps) used for saturation bias adjustment checks */
    static #SATURATION_ADJUST_INTERVAL = 5;
    /** Clamp for adaptive bias adjustments */
    static #BIAS_CLAMP = 5;
    /** Scaling factor used when adjusting biases to mitigate saturation */
    static #BIAS_ADJUST_FACTOR = 0.5;
    // Convenience thresholds and tuning knobs (centralized to avoid magic literals)
    /** Warmup steps where exploration is encouraged */
    static #EPSILON_WARMUP_STEPS = 10;
    /** Steps-stagnant threshold to consider very stagnant (high epsilon) */
    static #EPSILON_STAGNANT_HIGH_THRESHOLD = 12;
    /** Steps-stagnant threshold to consider moderate stagnation */
    static #EPSILON_STAGNANT_MED_THRESHOLD = 6;
    /** Saturation count that triggers epsilon-increase behavior */
    static #EPSILON_SATURATION_TRIGGER = 3;
    /** Length used to detect tiny A->B oscillations */
    static #OSCILLATION_DETECT_LENGTH = 4;
    /** Saturation penalty trigger (>=) */
    static #SATURATION_PENALTY_TRIGGER = 5;
    /** Period (in steps) to escalate saturation penalty */
    static #SATURATION_PENALTY_PERIOD = 10;
    /** Start step for global break bonus when breaking long stagnation */
    static #GLOBAL_BREAK_BONUS_START = 10;
    /** Per-step bonus for global break beyond the start threshold */
    static #GLOBAL_BREAK_BONUS_PER_STEP = 0.01;
    /** Cap for the global break bonus */
    static #GLOBAL_BREAK_BONUS_CAP = 0.5;
    /** Number of steps since improvement to begin repetition penalty scaling */
    static #REPETITION_PENALTY_START = 4;
    /** Weight for entropy bonus on failed runs */
    static #ENTROPY_BONUS_WEIGHT = 4;
    // Vision input layout indices (groups used by hasGuidance checks)
    /** Start index of LOS group within vision vector */
    static #VISION_LOS_START = 8;
    /** Start index of gradient group within vision vector */
    static #VISION_GRAD_START = 12;
    /** Number of elements in each vision group (LOS / Gradient) */
    static #VISION_GROUP_LEN = 4;
    // Proximity/exploration tuning
    /** Distance (in cells) within which greedy proximity moves are prioritized */
    static #PROXIMITY_GREEDY_DISTANCE = 2;
    /** Distance threshold to reduce epsilon exploration near goal */
    static #PROXIMITY_SUPPRESS_EXPLOR_DIST = 5;
    /** Initial epsilon for epsilon-greedy exploration */
    static #EPSILON_INITIAL = 0.35;
    /** Epsilon used when the agent is highly stagnant */
    static #EPSILON_STAGNANT_HIGH = 0.5;
    /** Epsilon used for moderate stagnation */
    static #EPSILON_STAGNANT_MED = 0.25;
    /** Epsilon used when network saturations are detected */
    static #EPSILON_SATURATIONS = 0.3;
    /** Minimum epsilon allowed when near the goal */
    static #EPSILON_MIN_NEAR_GOAL = 0.05;
    /** Streak length used to trigger forced exploration */
    static #NO_MOVE_STREAK_THRESHOLD = 5;
    // Local area stagnation
    /** Size of the recent-positions sliding window for local stagnation detection */
    static #LOCAL_WINDOW = 30;
    /** Max span (in cells) considered "local" for oscillation penalties */
    static #LOCAL_AREA_SPAN_THRESHOLD = 5;
    /** Steps without improvement before local-area stagnation penalty applies */
    static #LOCAL_AREA_STAGNATION_STEPS = 8;
    /** Amount applied to local area penalty when tight oscillation detected (multiplied by rewardScale) */
    static #LOCAL_AREA_PENALTY_AMOUNT = 0.05;
    // Progress reward shaping
    /** Base reward for making forward progress toward the exit */
    static #PROGRESS_REWARD_BASE = 0.3;
    /** Additional progress reward scaled by network confidence */
    static #PROGRESS_REWARD_CONF_SCALE = 0.7;
    /** Multiplier applied per step-since-improvement for extra reward shaping */
    static #PROGRESS_STEPS_MULT = 0.02;
    /** Maximum steps-based progress contribution (times rewardScale) */
    static #PROGRESS_STEPS_MAX = 0.5;
    // times rewardScale
    /** Scale applied to raw distance-delta when shaping reward */
    static #DISTANCE_DELTA_SCALE = 2;
    /** Base confidence factor for distance-delta shaping */
    static #DISTANCE_DELTA_CONF_BASE = 0.4;
    /** Additional confidence scale applied to distance-delta shaping */
    static #DISTANCE_DELTA_CONF_SCALE = 0.6;
    /** Base penalty applied when a move increases distance to goal (multiplied by rewardScale) */
    static #PROGRESS_AWAY_BASE_PENALTY = 0.05;
    /** Additional scaling applied to away penalty proportional to network confidence */
    static #PROGRESS_AWAY_CONF_SCALE = 0.15;
    // Entropy tuning
    /** Entropy value above which the action distribution is considered too uniform */
    static #ENTROPY_HIGH_THRESHOLD = 0.95;
    /** Entropy value below which the distribution is considered confident */
    static #ENTROPY_CONFIDENT_THRESHOLD = 0.55;
    /** Required gap between top two probs to treat as confident */
    static #ENTROPY_CONFIDENT_DIFF = 0.25;
    /** Small penalty applied when entropy is persistently high */
    static #ENTROPY_PENALTY = 0.03;
    // * rewardScale
    /** Tiny bonus for clear decisions that aid exploration */
    static #EXPLORATION_BONUS_SMALL = 0.015;
    // * rewardScale
    /** Base repetition/backtrack penalty applied when repeating same action without improvement */
    static #REPETITION_PENALTY_BASE = 0.05;
    /** Penalty for making the direct opposite move (when it doesn't improve) */
    static #BACK_MOVE_PENALTY = 0.2;
    // Saturation penalties
    /** Base penalty applied when saturation is detected */
    static #SATURATION_PENALTY_BASE = 0.05;
    // * rewardScale
    /** Escalating penalty applied periodically when saturation persists */
    static #SATURATION_PENALTY_ESCALATE = 0.1;
    // * rewardScale when escalation applies
    // Deep stagnation
    /** Steps without improvement that trigger deep-stagnation handling */
    static #DEEP_STAGNATION_THRESHOLD = 40;
    /** Penalty applied when deep stagnation is detected (non-browser environments) */
    static #DEEP_STAGNATION_PENALTY = 2;
    // * rewardScale
    // Action/output dimension and softmax/entropy tuning
    /** Number of cardinal actions (N,E,S,W) */
    static #ACTION_DIM = 4;
    /** Natural log of ACTION_DIM; used to normalize entropy calculations */
    static #LOG_ACTIONS = Math.log(_MazeMovement.#ACTION_DIM);
    /**
     * Pooled scratch buffers used by `selectDirection` to avoid per-call
     * allocations on the softmax/entropy hot path.
     *
     * @remarks
     * - These are class-private and reused across calls; `selectDirection` is
     *   therefore not reentrant and should not be called concurrently.
     */
    static #SCRATCH_CENTERED = new Float64Array(4);
    static #SCRATCH_EXPS = new Float64Array(4);
    /** Representation for 'no move' direction */
    static #NO_MOVE = -1;
    /** Minimum standard deviation used to prevent division by zero */
    static #STD_MIN = 1e-6;
    /** Thresholds for collapse ratio decisions based on std */
    static #COLLAPSE_STD_THRESHOLD = 0.01;
    /** Secondary threshold used when std indicates medium collapse */
    static #COLLAPSE_STD_MED = 0.03;
    /** Collapse ratio constants used for adaptive temperature */
    /** Full collapse ratio used when std is extremely low */
    static #COLLAPSE_RATIO_FULL = 1;
    /** Partial collapse ratio used for medium collapse */
    static #COLLAPSE_RATIO_HALF = 0.5;
    /** Base and scale used to compute softmax temperature */
    static #TEMPERATURE_BASE = 1;
    /** Scale factor applied when computing adaptive softmax temperature */
    static #TEMPERATURE_SCALE = 1.2;
    // Network history and randomness
    /** History length for recent output snapshots (used for variance diagnostics) */
    static #OUTPUT_HISTORY_LENGTH = 80;
    /**
     * Number of outputs snapshots to keep for variance diagnostics.
     * Larger values smooth variance estimates at the cost of memory.
     */
    /** Small randomness added to fitness to break ties stably */
    static #FITNESS_RANDOMNESS = 0.01;
    // Success fitness constants
    /** Base fitness given for successful maze completion */
    static #SUCCESS_BASE_FITNESS = 650;
    /** Scale applied for remaining steps on success to reward efficiency */
    static #STEP_EFFICIENCY_SCALE = 0.2;
    /** Weight for action-entropy bonus on successful runs */
    static #SUCCESS_ACTION_ENTROPY_SCALE = 5;
    /** Minimum clamp for any successful-run fitness */
    static #MIN_SUCCESS_FITNESS = 150;
    // Exploration / revisiting tuning
    /** Bonus reward for discovering a previously unvisited cell */
    static #NEW_CELL_EXPLORATION_BONUS = 0.3;
    /** Strong penalty factor for revisiting cells */
    static #REVISIT_PENALTY_STRONG = 0.5;
    // Progress shaping constants
    /** Exponent used in non-linear progress shaping */
    static #PROGRESS_POWER = 1.3;
    /** Scale used to convert shaped progress into fitness contribution */
    static #PROGRESS_SCALE = 500;
    /** Node type string used in network node objects */
    static #NODE_TYPE_OUTPUT = "output";
    /** Direction deltas for cardinal moves: N, E, S, W */
    static #DIRECTION_DELTAS = [
      [0, -1],
      // North
      [1, 0],
      // East
      [0, 1],
      // South
      [-1, 0]
      // West
    ];
    /** Lookup table for opposite directions (index -> opposite index). */
    static #OPPOSITE_DIR = [2, 3, 0, 1];
    // ---------------------------------------------------------------------------
    // Pooled / reusable typed-array buffers (non‑reentrant) for simulation state
    // ---------------------------------------------------------------------------
    /** Visited flag per cell (0/1). Reused across simulations. @remarks Non-reentrant. */
    static #VisitedFlags = null;
    /** Visit counts per cell (clamped). @remarks Non-reentrant. */
    static #VisitCounts = null;
    /** Path X coordinates (index-aligned with #PathY). */
    static #PathX = null;
    /** Path Y coordinates (index-aligned with #PathX). */
    static #PathY = null;
    /** Capacity (cells) currently allocated for grid‑dependent arrays. */
    static #GridCapacity = 0;
    /** Capacity (steps) currently allocated for path arrays. */
    static #PathCapacity = 0;
    /** Cached maze width for index calculations. */
    static #CachedWidth = 0;
    /** Cached maze height for bounds validation. */
    static #CachedHeight = 0;
    /** Pooled softmax output (returned as a cloned plain array). */
    static #SOFTMAX = new Float64Array(4);
    /** Seedable PRNG state (Mulberry32 style). Undefined => Math.random(). */
    static #PRNGState = null;
    // ---------------------------------------------------------------------------
    // Internal mutable run-scoped state (replaces (MazeMovement as any).foo uses)
    // ---------------------------------------------------------------------------
    /** Rolling saturation counter used for adaptive penalties */
    static #StateSaturations = 0;
    /** Consecutive steps with no movement to trigger forced exploration */
    static #StateNoMoveStreak = 0;
    /** Previous distance value supplied to vision builder */
    static #StatePrevDistanceStep = void 0;
    /**
     * Enable deterministic pseudo-randomness for simulations executed after this call.
     *
     * Uses a lightweight Mulberry32 generator so repeated runs with the same seed
     * produce identical stochastic choices (epsilon exploration, tie‑breaking, etc.).
     * Because internal buffers are shared, calls are not reentrant / thread‑safe.
     *
     * @param seed 32-bit unsigned integer seed. If 0 is provided a fixed default constant is used.
     * @returns void
     * @example
     * // Ensure reproducible simulation ordering
     * MazeMovement.seedDeterministic(1234);
     * const result = MazeMovement.simulateAgent(network, maze, start, exit);
     */
    static seedDeterministic(seed) {
      _MazeMovement.#PRNGState = seed >>> 0 || 2654435769;
    }
    /**
     * Disable deterministic seeding and return to Math.random based randomness.
     *
     * @returns void
     * @example
     * MazeMovement.clearDeterministicSeed();
     */
    static clearDeterministicSeed() {
      _MazeMovement.#PRNGState = null;
    }
    /** Generate a random float in [0,1). Deterministic when seed set. */
    static #rand() {
      if (_MazeMovement.#PRNGState == null) return Math.random();
      let t = _MazeMovement.#PRNGState += 1831565813;
      t = Math.imul(t ^ t >>> 15, t | 1);
      t ^= t + Math.imul(t ^ t >>> 7, t | 61);
      return ((t ^ t >>> 14) >>> 0) / 4294967296;
    }
    /** Encode (x,y) -> linear cell index. */
    static #index(x, y) {
      return y * _MazeMovement.#CachedWidth + x;
    }
    /** Ensure pooled buffers sized for given maze & path. */
    static #initBuffers(width, height, maxSteps) {
      const cellCount = width * height;
      if (!this.#VisitedFlags || cellCount > this.#GridCapacity) {
        const nextCellCap = _MazeMovement.#nextPow2(cellCount);
        this.#VisitedFlags = new Uint8Array(nextCellCap);
        this.#VisitCounts = new Uint16Array(nextCellCap);
        this.#GridCapacity = nextCellCap;
      } else {
        this.#VisitedFlags.fill(0, 0, cellCount);
        this.#VisitCounts.fill(0, 0, cellCount);
      }
      if (!this.#PathX || maxSteps + 1 > this.#PathCapacity) {
        const nextPathCap = _MazeMovement.#nextPow2(maxSteps + 1);
        this.#PathX = new Int32Array(nextPathCap);
        this.#PathY = new Int32Array(nextPathCap);
        this.#PathCapacity = nextPathCap;
      }
      this.#CachedWidth = width;
      this.#CachedHeight = height;
    }
    /** Next power of two helper (>= n). */
    static #nextPow2(n) {
      let p = 1;
      while (p < n) p <<= 1;
      return p;
    }
    /** Materialize the path arrays into an array<tuple>. */
    static #materializePath(length) {
      const px = _MazeMovement.#PathX;
      const py = _MazeMovement.#PathY;
      const out = new Array(length);
      for (let positionIndex = 0; positionIndex < length; positionIndex++) {
        out[positionIndex] = [px[positionIndex], py[positionIndex]];
      }
      return out;
    }
    /** Return opposite cardinal direction (works for ACTION_DIM even if it changes) */
    static #opposite(direction) {
      return (direction + _MazeMovement.#ACTION_DIM / 2) % _MazeMovement.#ACTION_DIM;
    }
    /** Sum a contiguous group in the vision vector starting at `start`. */
    static #sumVisionGroup(vision, start2) {
      let total = 0;
      const end = start2 + _MazeMovement.#VISION_GROUP_LEN;
      for (let visionIndex = start2; visionIndex < end; visionIndex++)
        total += vision[visionIndex];
      return total;
    }
    /**
     * Compute adaptive epsilon used for epsilon-greedy exploration.
     * Extracted from the main loop to shrink hot path complexity and enable reuse.
     */
    static #computeEpsilon(stepNumber, stepsSinceImprovement, distHere, saturations) {
      let epsilon = 0;
      switch (true) {
        case stepNumber < _MazeMovement.#EPSILON_WARMUP_STEPS:
          epsilon = _MazeMovement.#EPSILON_INITIAL;
          break;
        case stepsSinceImprovement > _MazeMovement.#EPSILON_STAGNANT_HIGH_THRESHOLD:
          epsilon = _MazeMovement.#EPSILON_STAGNANT_HIGH;
          break;
        case stepsSinceImprovement > _MazeMovement.#EPSILON_STAGNANT_MED_THRESHOLD:
          epsilon = _MazeMovement.#EPSILON_STAGNANT_MED;
          break;
        case saturations > _MazeMovement.#EPSILON_SATURATION_TRIGGER:
          epsilon = _MazeMovement.#EPSILON_SATURATIONS;
          break;
        default:
          break;
      }
      if (distHere <= _MazeMovement.#PROXIMITY_SUPPRESS_EXPLOR_DIST)
        epsilon = Math.min(epsilon, _MazeMovement.#EPSILON_MIN_NEAR_GOAL);
      return epsilon;
    }
    /**
     * Helper: is a cell (x,y) within bounds and not a wall?
     */
    static #isCellOpen(encodedMaze, x, y) {
      return y >= 0 && y < encodedMaze.length && x >= 0 && x < encodedMaze[0].length && encodedMaze[y][x] !== -1;
    }
    /**
     * Helper: unified distance lookup. Prefer distance map when available,
     * otherwise fall back to BFS. Keeps callers simple and avoids repeated
     * ternary expressions across the file.
     */
    static #distanceAt(encodedMaze, [x, y], distanceMap) {
      return Number.isFinite(distanceMap?.[y]?.[x]) ? distanceMap[y][x] : Infinity;
    }
    static isValidMove(encodedMaze, positionOrX, yMaybe) {
      if (Array.isArray(positionOrX)) {
        const [x, y] = positionOrX;
        return _MazeMovement.#isCellOpen(encodedMaze, x, y);
      }
      return _MazeMovement.#isCellOpen(
        encodedMaze,
        positionOrX,
        yMaybe
      );
    }
    /**
     * Moves the agent in the specified direction if the move is valid.
     *
     * Handles collision detection with walls and maze boundaries,
     * preventing the agent from making invalid moves.
     *
     * @param encodedMaze - 2D array representation of the maze.
     * @param position - Current [x, y] position of the agent.
     * @param direction - Direction index (0=North, 1=East, 2=South, 3=West, -1=No move).
     * @returns { [number, number] } New position after movement, or original position if move was invalid.
     */
    static moveAgent(encodedMaze, position, direction) {
      if (direction === _MazeMovement.#NO_MOVE) {
        return [position[0], position[1]];
      }
      const nextPosition = [position[0], position[1]];
      if (direction >= 0 && direction < _MazeMovement.#ACTION_DIM) {
        const [dx, dy] = _MazeMovement.#DIRECTION_DELTAS[direction];
        nextPosition[0] += dx;
        nextPosition[1] += dy;
      }
      if (_MazeMovement.isValidMove(encodedMaze, nextPosition)) {
        return nextPosition;
      } else {
        return [position[0], position[1]];
      }
    }
    /**
     * Selects the direction with the highest output value from the neural network.
     * Applies softmax to interpret outputs as probabilities, then uses argmax.
     * Also computes entropy and confidence statistics for analysis.
     *
     * @param outputs - Array of output values from the neural network (length 4).
     * @returns {object} Direction index, softmax probabilities, entropy, and confidence stats.
     */
    static selectDirection(outputs) {
      if (!outputs || outputs.length !== _MazeMovement.#ACTION_DIM) {
        return {
          direction: _MazeMovement.#NO_MOVE,
          softmax: [0, 0, 0, 0],
          entropy: 0,
          maxProb: 0,
          secondProb: 0
        };
      }
      const meanLogit = (outputs[0] + outputs[1] + outputs[2] + outputs[3]) / _MazeMovement.#ACTION_DIM;
      let varianceSum = 0;
      for (let k = 0; k < _MazeMovement.#ACTION_DIM; k++) {
        const delta = outputs[k] - meanLogit;
        varianceSum += delta * delta;
        _MazeMovement.#SCRATCH_CENTERED[k] = delta;
      }
      varianceSum /= _MazeMovement.#ACTION_DIM;
      let stdDev = Math.sqrt(varianceSum);
      if (!Number.isFinite(stdDev) || stdDev < _MazeMovement.#STD_MIN)
        stdDev = _MazeMovement.#STD_MIN;
      const collapseRatio = stdDev < _MazeMovement.#COLLAPSE_STD_THRESHOLD ? _MazeMovement.#COLLAPSE_RATIO_FULL : stdDev < _MazeMovement.#COLLAPSE_STD_MED ? _MazeMovement.#COLLAPSE_RATIO_HALF : 0;
      const temperature = _MazeMovement.#TEMPERATURE_BASE + _MazeMovement.#TEMPERATURE_SCALE * collapseRatio;
      let maxCentered = -Infinity;
      for (let k = 0; k < _MazeMovement.#ACTION_DIM; k++) {
        const v = _MazeMovement.#SCRATCH_CENTERED[k];
        if (v > maxCentered) maxCentered = v;
      }
      let expSum = 0;
      for (let k = 0; k < _MazeMovement.#ACTION_DIM; k++) {
        const expVal = Math.exp(
          (_MazeMovement.#SCRATCH_CENTERED[k] - maxCentered) / temperature
        );
        _MazeMovement.#SCRATCH_EXPS[k] = expVal;
        expSum += expVal;
      }
      if (!expSum) expSum = 1;
      let direction = 0;
      let maxProb = -Infinity;
      let secondProb = 0;
      const pooled = _MazeMovement.#SOFTMAX;
      for (let k = 0; k < _MazeMovement.#ACTION_DIM; k++) {
        const prob = _MazeMovement.#SCRATCH_EXPS[k] / expSum;
        pooled[k] = prob;
        if (prob > maxProb) {
          secondProb = maxProb;
          maxProb = prob;
          direction = k;
        } else if (prob > secondProb) {
          secondProb = prob;
        }
      }
      let entropy = 0;
      for (let k = 0; k < _MazeMovement.#ACTION_DIM; k++) {
        const prob = pooled[k];
        if (prob > 0) entropy += -prob * Math.log(prob);
      }
      entropy /= _MazeMovement.#LOG_ACTIONS;
      return {
        direction,
        softmax: Array.from(pooled),
        entropy,
        maxProb,
        secondProb
      };
    }
    /**
     * Simulates the agent navigating the maze using its neural network.
     *
     * Runs a complete simulation of an agent traversing a maze,
     * using its neural network for decision making. This implementation focuses
     * on a minimalist approach, putting more responsibility on the neural network.
     *
     * @param network - Neural network controlling the agent.
     * @param encodedMaze - 2D array representation of the maze.
     * @param startPos - Starting position [x,y] of the agent.
     * @param exitPos - Exit/goal position [x,y] of the maze.
     * @param maxSteps - Maximum steps allowed before terminating (default 3000).
     * @returns Object containing:
     *   - success: Boolean indicating if exit was reached.
     *   - steps: Number of steps taken.
     *   - path: Array of positions visited.
     *   - fitness: Calculated fitness score for evolution.
     *   - progress: Percentage progress toward exit (0-100).
     */
    static simulateAgent(network, encodedMaze, startPos, exitPos, distanceMap, maxSteps = _MazeMovement.#DEFAULT_MAX_STEPS) {
      const state = _MazeMovement.#initRunState(
        encodedMaze,
        startPos,
        distanceMap,
        maxSteps
      );
      while (state.steps < maxSteps) {
        state.steps++;
        _MazeMovement.#recordVisitAndUpdatePenalties(state, encodedMaze);
        _MazeMovement.#buildVisionAndDistance(
          state,
          encodedMaze,
          exitPos,
          distanceMap
        );
        _MazeMovement.#decideDirection(state, network, encodedMaze, distanceMap);
        _MazeMovement.#maybeApplyProximityGreedy(state, encodedMaze, distanceMap);
        _MazeMovement.#maybeApplyEpsilonExploration(state, encodedMaze);
        _MazeMovement.#maybeForceExploration(state, encodedMaze);
        _MazeMovement.#executeMoveAndRewards(state, encodedMaze, distanceMap);
        _MazeMovement.#applyPostActionPenalties(state);
        if (_MazeMovement.#maybeTerminateDeepStagnation(state)) break;
        if (state.position[0] === exitPos[0] && state.position[1] === exitPos[1]) {
          return _MazeMovement.#finalizeSuccess(state, maxSteps);
        }
      }
      return _MazeMovement.#finalizeFailure(
        state,
        encodedMaze,
        startPos,
        exitPos,
        distanceMap
      );
    }
    // ---------------------------------------------------------------------------
    // Private helper methods (refactored from large simulateAgent body)
    // ---------------------------------------------------------------------------
    /** Internal aggregate simulation state (not exported). */
    static #initRunState(encodedMaze, startPos, distanceMap, maxSteps) {
      _MazeMovement.#StateSaturations = 0;
      _MazeMovement.#StateNoMoveStreak = 0;
      _MazeMovement.#StatePrevDistanceStep = void 0;
      const height = encodedMaze.length;
      const width = encodedMaze[0].length;
      const hasDistanceMap = Array.isArray(distanceMap) && distanceMap.length === height;
      _MazeMovement.#initBuffers(width, height, maxSteps);
      const position = [startPos[0], startPos[1]];
      _MazeMovement.#PathX[0] = position[0];
      _MazeMovement.#PathY[0] = position[1];
      const historyCapacity = _MazeMovement.#MOVE_HISTORY_LENGTH;
      const state = {
        position,
        steps: 0,
        pathLength: 1,
        visitedUniqueCount: 0,
        hasDistanceMap,
        distanceMap,
        minDistanceToExit: hasDistanceMap ? distanceMap[position[1]]?.[position[0]] ?? Infinity : _MazeMovement.#distanceAt(encodedMaze, position, distanceMap),
        progressReward: 0,
        newCellExplorationBonus: 0,
        invalidMovePenalty: 0,
        prevAction: _MazeMovement.#NO_MOVE,
        stepsSinceImprovement: 0,
        lastDistanceGlobal: _MazeMovement.#distanceAt(
          encodedMaze,
          position,
          distanceMap
        ),
        saturatedSteps: 0,
        recentPositions: [],
        localAreaPenalty: 0,
        directionCounts: [0, 0, 0, 0],
        moveHistoryRing: new Int32Array(historyCapacity),
        moveHistoryLength: 0,
        moveHistoryHead: 0,
        currentCellIndex: 0,
        loopPenalty: 0,
        memoryPenalty: 0,
        revisitPenalty: 0,
        visitsAtCurrent: 0,
        distHere: Infinity,
        vision: [],
        actionStats: null,
        direction: _MazeMovement.#NO_MOVE,
        moved: false,
        prevDistance: Infinity,
        earlyTerminate: false
      };
      return state;
    }
    /** Push a cell index into circular history (A->B loop detection). */
    static #pushHistory(state, cellIndex) {
      const { moveHistoryRing, moveHistoryHead, moveHistoryLength } = state;
      const capacity = moveHistoryRing.length;
      moveHistoryRing[moveHistoryHead] = cellIndex;
      state.moveHistoryHead = (moveHistoryHead + 1) % capacity;
      if (moveHistoryLength < capacity) state.moveHistoryLength++;
    }
    /** nth (1-based) from history end; 1 == last; undefined if not present. */
    static #nthFromHistoryEnd(state, n) {
      if (n > state.moveHistoryLength) return void 0;
      const capacity = state.moveHistoryRing.length;
      const index = (state.moveHistoryHead - n + capacity) % capacity;
      return state.moveHistoryRing[index];
    }
    /** Record visit + compute loop/memory/revisit penalties and optionally early terminate. */
    static #recordVisitAndUpdatePenalties(state, encodedMaze) {
      const visitedFlags = _MazeMovement.#VisitedFlags;
      const visitCountsTyped = _MazeMovement.#VisitCounts;
      const rewardScale = _MazeMovement.#REWARD_SCALE;
      const cellIndex = _MazeMovement.#index(state.position[0], state.position[1]);
      state.currentCellIndex = cellIndex;
      if (!visitedFlags[cellIndex]) {
        visitedFlags[cellIndex] = 1;
        state.visitedUniqueCount++;
      }
      visitCountsTyped[cellIndex]++;
      _MazeMovement.#pushHistory(state, cellIndex);
      const visits = state.visitsAtCurrent = visitCountsTyped[cellIndex];
      state.loopPenalty = 0;
      if (state.moveHistoryLength >= _MazeMovement.#OSCILLATION_DETECT_LENGTH) {
        const last = _MazeMovement.#nthFromHistoryEnd(state, 1);
        const secondLast = _MazeMovement.#nthFromHistoryEnd(state, 2);
        const thirdLast = _MazeMovement.#nthFromHistoryEnd(state, 3);
        const fourthLast = _MazeMovement.#nthFromHistoryEnd(state, 4);
        if (last === thirdLast && secondLast !== void 0 && fourthLast !== void 0 && secondLast === fourthLast) {
          state.loopPenalty -= _MazeMovement.#LOOP_PENALTY * rewardScale;
        }
      }
      state.memoryPenalty = 0;
      if (state.moveHistoryLength > 1) {
        for (let scan = 2; scan <= state.moveHistoryLength; scan++) {
          const candidateIndex = _MazeMovement.#nthFromHistoryEnd(state, scan);
          if (candidateIndex === cellIndex) {
            state.memoryPenalty -= _MazeMovement.#MEMORY_RETURN_PENALTY * rewardScale;
            break;
          }
        }
      }
      state.revisitPenalty = 0;
      if (visits > 1) {
        state.revisitPenalty -= _MazeMovement.#REVISIT_PENALTY_PER_VISIT * (visits - 1) * rewardScale;
      }
      if (visits > _MazeMovement.#VISIT_TERMINATION_THRESHOLD) {
        state.invalidMovePenalty -= _MazeMovement.#INVALID_MOVE_PENALTY_HARSH * rewardScale;
        state.earlyTerminate = true;
      }
    }
    /** Build vision inputs & compute distHere for proximity / epsilon logic. */
    static #buildVisionAndDistance(state, encodedMaze, exitPos, distanceMap) {
      if (state.earlyTerminate) return;
      const hasDistanceMap = state.hasDistanceMap;
      const prevDistLocal = hasDistanceMap ? distanceMap[state.position[1]]?.[state.position[0]] ?? void 0 : _MazeMovement.#distanceAt(encodedMaze, state.position, distanceMap);
      const distCurrentLocal = prevDistLocal;
      state.vision = MazeVision.buildInputs6(
        encodedMaze,
        state.position,
        exitPos,
        distanceMap,
        _MazeMovement.#StatePrevDistanceStep,
        distCurrentLocal,
        state.prevAction
      );
      _MazeMovement.#StatePrevDistanceStep = distCurrentLocal;
      state.distHere = hasDistanceMap ? distanceMap[state.position[1]]?.[state.position[0]] ?? Infinity : _MazeMovement.#distanceAt(encodedMaze, state.position, distanceMap);
    }
    /** Activate network, compute direction, update saturation counters & penalties. */
    static #decideDirection(state, network, encodedMaze, distanceMap) {
      if (state.earlyTerminate) return;
      try {
        const outputs = network.activate(state.vision);
        network._lastStepOutputs = MazeUtils.pushHistory(
          network._lastStepOutputs,
          [...outputs],
          _MazeMovement.#OUTPUT_HISTORY_LENGTH
        );
        state.actionStats = _MazeMovement.selectDirection(outputs);
        _MazeMovement.#applySaturationAndBiasAdjust(state, outputs, network);
        state.direction = state.actionStats.direction;
      } catch (error) {
        console.error("Error activating network:", error);
        state.direction = _MazeMovement.#NO_MOVE;
      }
    }
    /** Greedy override when close to exit: choose direction minimizing distance. */
    static #maybeApplyProximityGreedy(state, encodedMaze, distanceMap) {
      if (state.earlyTerminate) return;
      if (state.distHere <= _MazeMovement.#PROXIMITY_GREEDY_DISTANCE) {
        let bestDirection = state.direction;
        let bestDistance = Infinity;
        for (let directionIndex = 0; directionIndex < _MazeMovement.#ACTION_DIM; directionIndex++) {
          const [deltaX, deltaY] = _MazeMovement.#DIRECTION_DELTAS[directionIndex];
          const testX = state.position[0] + deltaX;
          const testY = state.position[1] + deltaY;
          if (!_MazeMovement.isValidMove(encodedMaze, testX, testY)) continue;
          const candidateDistance = _MazeMovement.#distanceAt(
            encodedMaze,
            [testX, testY],
            distanceMap
          );
          if (candidateDistance < bestDistance) {
            bestDistance = candidateDistance;
            bestDirection = directionIndex;
          }
        }
        if (bestDirection != null) state.direction = bestDirection;
      }
    }
    /** Epsilon-greedy exploration override. */
    static #maybeApplyEpsilonExploration(state, encodedMaze) {
      if (state.earlyTerminate) return;
      const epsilon = _MazeMovement.#computeEpsilon(
        state.steps,
        state.stepsSinceImprovement,
        state.distHere,
        _MazeMovement.#StateSaturations
      );
      if (_MazeMovement.#rand() < epsilon) {
        for (let trialIndex = 0; trialIndex < _MazeMovement.#ACTION_DIM; trialIndex++) {
          const candidateDirection = Math.floor(
            _MazeMovement.#rand() * _MazeMovement.#ACTION_DIM
          );
          if (candidateDirection === state.prevAction) continue;
          const [deltaX, deltaY] = _MazeMovement.#DIRECTION_DELTAS[candidateDirection];
          const testX = state.position[0] + deltaX;
          const testY = state.position[1] + deltaY;
          if (_MazeMovement.isValidMove(encodedMaze, testX, testY)) {
            state.direction = candidateDirection;
            break;
          }
        }
      }
    }
    /** Force exploration if no-move streak triggered. */
    static #maybeForceExploration(state, encodedMaze) {
      if (state.earlyTerminate) return;
      if (state.direction === _MazeMovement.#NO_MOVE)
        _MazeMovement.#StateNoMoveStreak++;
      else _MazeMovement.#StateNoMoveStreak = 0;
      if (_MazeMovement.#StateNoMoveStreak >= _MazeMovement.#NO_MOVE_STREAK_THRESHOLD) {
        for (let attemptIndex = 0; attemptIndex < _MazeMovement.#ACTION_DIM; attemptIndex++) {
          const candidateDirection = Math.floor(
            _MazeMovement.#rand() * _MazeMovement.#ACTION_DIM
          );
          const [deltaX, deltaY] = _MazeMovement.#DIRECTION_DELTAS[candidateDirection];
          const testX = state.position[0] + deltaX;
          const testY = state.position[1] + deltaY;
          if (_MazeMovement.isValidMove(encodedMaze, testX, testY)) {
            state.direction = candidateDirection;
            break;
          }
        }
        _MazeMovement.#StateNoMoveStreak = 0;
      }
    }
    /** Execute move and compute progress / exploration rewards. */
    static #executeMoveAndRewards(state, encodedMaze, distanceMap) {
      if (state.earlyTerminate) return;
      state.prevDistance = _MazeMovement.#distanceAt(
        encodedMaze,
        state.position,
        distanceMap
      );
      state.moved = false;
      if (state.direction >= 0 && state.direction < _MazeMovement.#ACTION_DIM) {
        const [deltaX, deltaY] = _MazeMovement.#DIRECTION_DELTAS[state.direction];
        const newX = state.position[0] + deltaX;
        const newY = state.position[1] + deltaY;
        if (_MazeMovement.isValidMove(encodedMaze, newX, newY)) {
          state.position[0] = newX;
          state.position[1] = newY;
          state.moved = true;
        }
      }
      const rewardScale = _MazeMovement.#REWARD_SCALE;
      const pathX = _MazeMovement.#PathX;
      const pathY = _MazeMovement.#PathY;
      if (state.moved) {
        pathX[state.pathLength] = state.position[0];
        pathY[state.pathLength] = state.position[1];
        state.pathLength++;
        MazeUtils.pushHistory(
          state.recentPositions,
          [state.position[0], state.position[1]],
          _MazeMovement.#LOCAL_WINDOW
        );
        _MazeMovement.#maybeApplyLocalAreaPenalty(state, rewardScale);
        const currentDistance = state.hasDistanceMap ? state.distanceMap[state.position[1]]?.[state.position[0]] ?? Infinity : _MazeMovement.#distanceAt(
          encodedMaze,
          state.position,
          state.distanceMap
        );
        const distanceDelta = state.prevDistance - currentDistance;
        const improved = distanceDelta > 0;
        const worsened = !improved && currentDistance > state.prevDistance;
        _MazeMovement.#applyProgressShaping(
          state,
          distanceDelta,
          improved,
          worsened,
          rewardScale
        );
        _MazeMovement.#applyExplorationVisitAdjustment(state, rewardScale);
        if (state.direction >= 0) state.directionCounts[state.direction]++;
        state.minDistanceToExit = Math.min(
          state.minDistanceToExit,
          currentDistance
        );
      } else {
        state.invalidMovePenalty -= _MazeMovement.#INVALID_MOVE_PENALTY_MILD * rewardScale;
      }
      _MazeMovement.#applyGlobalDistanceImprovementBonus(
        state,
        encodedMaze,
        rewardScale
      );
    }
    /** Apply repetition / entropy / saturation penalties & update prevAction. */
    static #applyPostActionPenalties(state) {
      if (state.earlyTerminate) return;
      const rewardScale = _MazeMovement.#REWARD_SCALE;
      _MazeMovement.#applyRepetitionAndBacktrackPenalties(state, rewardScale);
      if (state.moved) state.prevAction = state.direction;
      _MazeMovement.#applyEntropyGuidanceShaping(state, rewardScale);
      _MazeMovement.#applySaturationPenaltyCycle(state, rewardScale);
      state.invalidMovePenalty += state.loopPenalty + state.memoryPenalty + state.revisitPenalty;
    }
    /** Apply local area stagnation penalty if oscillating tightly without improvements. */
    static #maybeApplyLocalAreaPenalty(state, rewardScale) {
      if (state.recentPositions.length !== _MazeMovement.#LOCAL_WINDOW) return;
      let minX = Infinity;
      let maxX = -Infinity;
      let minY = Infinity;
      let maxY = -Infinity;
      for (const [rx, ry] of state.recentPositions) {
        if (rx < minX) minX = rx;
        if (rx > maxX) maxX = rx;
        if (ry < minY) minY = ry;
        if (ry > maxY) maxY = ry;
      }
      const span = maxX - minX + (maxY - minY);
      if (span <= _MazeMovement.#LOCAL_AREA_SPAN_THRESHOLD && state.stepsSinceImprovement > _MazeMovement.#LOCAL_AREA_STAGNATION_STEPS) {
        state.localAreaPenalty -= _MazeMovement.#LOCAL_AREA_PENALTY_AMOUNT * rewardScale;
      }
    }
    /** Progress shaping rewards / penalties based on distance delta. */
    static #applyProgressShaping(state, distanceDelta, improved, worsened, rewardScale) {
      if (improved) {
        const confidence = state.actionStats?.maxProb ?? 1;
        const baseProgress = (_MazeMovement.#PROGRESS_REWARD_BASE + _MazeMovement.#PROGRESS_REWARD_CONF_SCALE * confidence) * rewardScale;
        if (state.stepsSinceImprovement > 0) {
          state.progressReward += Math.min(
            state.stepsSinceImprovement * _MazeMovement.#PROGRESS_STEPS_MULT * rewardScale,
            _MazeMovement.#PROGRESS_STEPS_MAX * rewardScale
          );
        }
        state.progressReward += baseProgress;
        state.stepsSinceImprovement = 0;
        state.progressReward += distanceDelta * _MazeMovement.#DISTANCE_DELTA_SCALE * (_MazeMovement.#DISTANCE_DELTA_CONF_BASE + _MazeMovement.#DISTANCE_DELTA_CONF_SCALE * confidence);
      } else if (worsened) {
        const confidence = state.actionStats?.maxProb ?? 0.5;
        state.progressReward -= (_MazeMovement.#PROGRESS_AWAY_BASE_PENALTY + _MazeMovement.#PROGRESS_AWAY_CONF_SCALE * confidence) * rewardScale;
        state.stepsSinceImprovement++;
      } else {
        state.stepsSinceImprovement++;
      }
    }
    /** Exploration bonus / revisit penalties for the just-visited cell. */
    static #applyExplorationVisitAdjustment(state, rewardScale) {
      if (state.visitsAtCurrent === 1) {
        state.newCellExplorationBonus += _MazeMovement.#NEW_CELL_EXPLORATION_BONUS * rewardScale;
      } else {
        state.newCellExplorationBonus -= _MazeMovement.#REVISIT_PENALTY_STRONG * rewardScale;
      }
    }
    /** Global distance improvement bonus for breaking long stagnation. */
    static #applyGlobalDistanceImprovementBonus(state, encodedMaze, rewardScale) {
      const currentDistanceGlobal = state.hasDistanceMap ? state.distanceMap[state.position[1]]?.[state.position[0]] ?? Infinity : _MazeMovement.#distanceAt(
        encodedMaze,
        state.position,
        state.distanceMap
      );
      if (currentDistanceGlobal < state.lastDistanceGlobal) {
        if (state.stepsSinceImprovement > _MazeMovement.#GLOBAL_BREAK_BONUS_START)
          state.progressReward += Math.min(
            (state.stepsSinceImprovement - _MazeMovement.#GLOBAL_BREAK_BONUS_START) * _MazeMovement.#GLOBAL_BREAK_BONUS_PER_STEP * rewardScale,
            _MazeMovement.#GLOBAL_BREAK_BONUS_CAP * rewardScale
          );
        state.stepsSinceImprovement = 0;
      }
      state.lastDistanceGlobal = currentDistanceGlobal;
    }
    /** Repetition and backward (opposite) move penalties. */
    static #applyRepetitionAndBacktrackPenalties(state, rewardScale) {
      if (state.prevAction === state.direction && state.stepsSinceImprovement > _MazeMovement.#REPETITION_PENALTY_START) {
        state.invalidMovePenalty -= _MazeMovement.#REPETITION_PENALTY_BASE * (state.stepsSinceImprovement - _MazeMovement.#REPETITION_PENALTY_START) * rewardScale;
      }
      if (state.prevAction >= 0 && state.direction >= 0 && state.stepsSinceImprovement > 0 && state.direction === _MazeMovement.#OPPOSITE_DIR[state.prevAction]) {
        state.invalidMovePenalty -= _MazeMovement.#BACK_MOVE_PENALTY * rewardScale;
      }
    }
    /** Entropy / guidance shaping (confidence vs ambiguity). */
    static #applyEntropyGuidanceShaping(state, rewardScale) {
      if (!state.actionStats) return;
      const { entropy, maxProb, secondProb } = state.actionStats;
      const hasGuidance = _MazeMovement.#sumVisionGroup(
        state.vision,
        _MazeMovement.#VISION_LOS_START
      ) > 0 || _MazeMovement.#sumVisionGroup(
        state.vision,
        _MazeMovement.#VISION_GRAD_START
      ) > 0;
      switch (true) {
        case entropy > _MazeMovement.#ENTROPY_HIGH_THRESHOLD:
          state.invalidMovePenalty -= _MazeMovement.#ENTROPY_PENALTY * rewardScale;
          break;
        case (hasGuidance && entropy < _MazeMovement.#ENTROPY_CONFIDENT_THRESHOLD && maxProb - secondProb > _MazeMovement.#ENTROPY_CONFIDENT_DIFF):
          state.newCellExplorationBonus += _MazeMovement.#EXPLORATION_BONUS_SMALL * rewardScale;
          break;
        default:
          break;
      }
    }
    /** Saturation penalty application (periodic escalation). */
    static #applySaturationPenaltyCycle(state, rewardScale) {
      if (_MazeMovement.#StateSaturations < _MazeMovement.#SATURATION_PENALTY_TRIGGER)
        return;
      state.invalidMovePenalty -= _MazeMovement.#SATURATION_PENALTY_BASE * rewardScale;
      if (_MazeMovement.#StateSaturations % _MazeMovement.#SATURATION_PENALTY_PERIOD === 0) {
        state.invalidMovePenalty -= _MazeMovement.#SATURATION_PENALTY_ESCALATE * rewardScale;
      }
    }
    /** Handle saturation/overconfidence detection, penalties and adaptive bias adjustment. */
    static #applySaturationAndBiasAdjust(state, outputs, network) {
      const rewardScale = _MazeMovement.#REWARD_SCALE;
      const overConfident = state.actionStats.maxProb > _MazeMovement.#OVERCONFIDENT_PROB && state.actionStats.secondProb < _MazeMovement.#SECOND_PROB_LOW;
      const meanLogit = outputs.reduce((accumulator, value) => accumulator + value, 0) / _MazeMovement.#ACTION_DIM;
      let varianceSum = 0;
      for (const logit of outputs) {
        const delta = logit - meanLogit;
        varianceSum += delta * delta;
      }
      varianceSum /= _MazeMovement.#ACTION_DIM;
      const logStd = Math.sqrt(varianceSum);
      const flatCollapsed = logStd < _MazeMovement.#LOGSTD_FLAT_THRESHOLD;
      let saturationCounter = _MazeMovement.#StateSaturations;
      if (overConfident || flatCollapsed) {
        saturationCounter++;
        state.saturatedSteps++;
      } else if (saturationCounter > 0) {
        saturationCounter--;
      }
      _MazeMovement.#StateSaturations = saturationCounter;
      if (overConfident) {
        state.invalidMovePenalty -= _MazeMovement.#OVERCONFIDENT_PENALTY * rewardScale;
      }
      if (flatCollapsed) {
        state.invalidMovePenalty -= _MazeMovement.#FLAT_COLLAPSE_PENALTY * rewardScale;
      }
      if (_MazeMovement.#StateSaturations > _MazeMovement.#SATURATION_ADJUST_MIN && state.steps % _MazeMovement.#SATURATION_ADJUST_INTERVAL === 0) {
        try {
          const outputNodes = network.nodes?.filter(
            (node) => node.type === _MazeMovement.#NODE_TYPE_OUTPUT
          );
          if (outputNodes?.length) {
            const meanBias = outputNodes.reduce(
              (total, node) => total + node.bias,
              0
            ) / outputNodes.length;
            for (const node of outputNodes) {
              node.bias = Math.max(
                -_MazeMovement.#BIAS_CLAMP,
                Math.min(
                  _MazeMovement.#BIAS_CLAMP,
                  node.bias - meanBias * _MazeMovement.#BIAS_ADJUST_FACTOR
                )
              );
            }
          }
        } catch {
        }
      }
    }
    /** Check deep stagnation and optionally terminate. */
    static #maybeTerminateDeepStagnation(state) {
      if (state.stepsSinceImprovement > _MazeMovement.#DEEP_STAGNATION_THRESHOLD) {
        const rewardScale = _MazeMovement.#REWARD_SCALE;
        try {
          if (typeof window === "undefined") {
            state.invalidMovePenalty -= _MazeMovement.#DEEP_STAGNATION_PENALTY * rewardScale;
            return true;
          }
        } catch {
          state.invalidMovePenalty -= _MazeMovement.#DEEP_STAGNATION_PENALTY * rewardScale;
          return true;
        }
      }
      return state.earlyTerminate;
    }
    /** Compute entropy from direction counts (shared by success & failure finalization). */
    static #computeActionEntropyFromCounts(directionCounts) {
      const total = directionCounts.reduce((s, v) => s + v, 0) || 1;
      let entropySum = 0;
      for (const count of directionCounts) {
        if (!count) continue;
        const probability = count / total;
        entropySum -= probability * Math.log(probability);
      }
      return entropySum / _MazeMovement.#LOG_ACTIONS;
    }
    /** Build and return result object for success scenario. */
    static #finalizeSuccess(state, maxSteps) {
      const stepEfficiency = maxSteps - state.steps;
      const actionEntropy = _MazeMovement.#computeActionEntropyFromCounts(
        state.directionCounts
      );
      const fitness = _MazeMovement.#SUCCESS_BASE_FITNESS + stepEfficiency * _MazeMovement.#STEP_EFFICIENCY_SCALE + state.progressReward + state.newCellExplorationBonus + state.invalidMovePenalty + actionEntropy * _MazeMovement.#SUCCESS_ACTION_ENTROPY_SCALE;
      const pathMaterialized = _MazeMovement.#materializePath(state.pathLength);
      return {
        success: true,
        steps: state.steps,
        path: pathMaterialized,
        fitness: Math.max(_MazeMovement.#MIN_SUCCESS_FITNESS, fitness),
        progress: 100,
        saturationFraction: state.steps ? state.saturatedSteps / state.steps : 0,
        actionEntropy
      };
    }
    /** Build and return result object for failure scenario. */
    static #finalizeFailure(state, encodedMaze, startPos, exitPos, distanceMap) {
      const pathX = _MazeMovement.#PathX;
      const pathY = _MazeMovement.#PathY;
      const lastPos = [
        pathX[state.pathLength - 1] ?? 0,
        pathY[state.pathLength - 1] ?? 0
      ];
      const progress = distanceMap ? MazeUtils.calculateProgressFromDistanceMap(
        distanceMap,
        lastPos,
        startPos
      ) : MazeUtils.calculateProgress(encodedMaze, lastPos, startPos, exitPos);
      const progressFraction = progress / 100;
      const shapedProgress = Math.pow(progressFraction, _MazeMovement.#PROGRESS_POWER) * _MazeMovement.#PROGRESS_SCALE;
      const explorationScore = state.visitedUniqueCount * 1;
      const actionEntropy = _MazeMovement.#computeActionEntropyFromCounts(
        state.directionCounts
      );
      const entropyBonus = actionEntropy * _MazeMovement.#ENTROPY_BONUS_WEIGHT;
      const saturationPenalty = 0;
      const outputVarPenalty = 0;
      const baseFitness = shapedProgress + explorationScore + state.progressReward + state.newCellExplorationBonus + state.invalidMovePenalty + entropyBonus + state.localAreaPenalty + saturationPenalty + outputVarPenalty;
      const raw = baseFitness + _MazeMovement.#rand() * _MazeMovement.#FITNESS_RANDOMNESS;
      const fitness = raw >= 0 ? raw : -Math.log1p(1 - raw);
      const pathMaterialized = _MazeMovement.#materializePath(state.pathLength);
      return {
        success: false,
        steps: state.steps,
        path: pathMaterialized,
        fitness,
        progress,
        saturationFraction: state.steps ? state.saturatedSteps / state.steps : 0,
        actionEntropy
      };
    }
  };

  // test/examples/asciiMaze/fitness.ts
  var FitnessEvaluator = class _FitnessEvaluator {
    /** Base bonus applied for each unique (visited-once) cell, scaled by proximity. */
    static #EXPLORATION_UNIQUE_CELL_BONUS = 200;
    /** Proximity multiplier base (max factor when distance fraction is 0). */
    static #PROXIMITY_MULTIPLIER_BASE = 1.5;
    /** Proximity multiplier slope (value subtracted times normalized distance). */
    static #PROXIMITY_MULTIPLIER_SLOPE = 0.5;
    /** Fixed success bonus when the exit is reached. */
    static #SUCCESS_BONUS = 5e3;
    /** Baseline efficiency bonus before subtracting overhead penalty. */
    static #EFFICIENCY_BASE = 8e3;
    /** Scale factor converting path overhead percent into penalty. */
    static #EFFICIENCY_PENALTY_SCALE = 80;
    // --- Typed-array scratch buffers (non-reentrant) -------------------------
    /** @internal Scratch array for visit counts (flattened y*width + x). */
    static #VISIT_COUNT_SCRATCH = new Uint16Array(0);
    static #SCRATCH_WIDTH = 0;
    static #SCRATCH_HEIGHT = 0;
    /** Ensure scratch visit-count buffer has capacity for given maze dims. */
    static #ensureVisitScratch(width, height) {
      if (width <= 0 || height <= 0) return;
      if (width === this.#SCRATCH_WIDTH && height === this.#SCRATCH_HEIGHT) {
        this.#VISIT_COUNT_SCRATCH.fill(0);
        return;
      }
      this.#SCRATCH_WIDTH = width;
      this.#SCRATCH_HEIGHT = height;
      this.#VISIT_COUNT_SCRATCH = new Uint16Array(width * height);
    }
    /**
     * Evaluates the fitness of a single neural network based on its performance in a maze simulation.
     *
     * This is the core of the fitness calculation. It runs a simulation of the agent controlled
     * by the given network and then calculates a score based on a combination of factors.
     * A well-designed fitness function is crucial for guiding the evolution towards the desired behavior.
     *
     * The fitness function rewards several key behaviors:
     * - **Progress**: How close did the agent get to the exit? This is the primary driver.
     * - **Success**: A large, fixed bonus is awarded for successfully reaching the exit.
     * - **Efficiency**: If the exit is reached, an additional bonus is given for shorter paths.
     *   This encourages the agent to find the most direct route.
     * - **Exploration**: A bonus is given for each unique cell the agent visits. This encourages
     *   the agent to explore the maze rather than getting stuck in a small area. The exploration
     *   bonus is weighted by the cell's proximity to the exit, rewarding exploration in promising areas.
     *
     * @param network - The neural network to be evaluated.
     * @param encodedMaze - A 2D array representing the maze layout.
     * @param startPosition - The agent's starting coordinates `[x, y]`.
     * @param exitPosition - The maze's exit coordinates `[x, y]`.
     * @param distanceMap - A pre-calculated map of distances from each cell to the exit, for performance.
     * @param maxSteps - The maximum number of steps the agent is allowed to take in the simulation.
     * @returns The final computed fitness score for the network.
     */
    static evaluateNetworkFitness(network, encodedMaze, startPosition, exitPosition, distanceMap, maxAllowedSteps) {
      const result = MazeMovement.simulateAgent(
        network,
        encodedMaze,
        startPosition,
        exitPosition,
        distanceMap,
        maxAllowedSteps
      );
      let explorationBonus = 0;
      const mazeHeight = encodedMaze.length;
      const mazeWidth = encodedMaze[0]?.length || 0;
      _FitnessEvaluator.#ensureVisitScratch(mazeWidth, mazeHeight);
      const visitCountsScratch = _FitnessEvaluator.#VISIT_COUNT_SCRATCH;
      const strideWidth = _FitnessEvaluator.#SCRATCH_WIDTH;
      for (let pathIndex = 0; pathIndex < result.path.length; pathIndex++) {
        const [cellX, cellY] = result.path[pathIndex];
        const flatIndex = cellY * strideWidth + cellX;
        visitCountsScratch[flatIndex]++;
      }
      const dimensionSum = mazeHeight + mazeWidth;
      for (let pathIndex = 0; pathIndex < result.path.length; pathIndex++) {
        const [cellX, cellY] = result.path[pathIndex];
        const flatIndex = cellY * strideWidth + cellX;
        if (visitCountsScratch[flatIndex] !== 1) continue;
        const distanceToExit = distanceMap ? distanceMap[cellY]?.[cellX] ?? Infinity : MazeUtils.bfsDistance(encodedMaze, [cellX, cellY], exitPosition);
        const proximityMultiplier = _FitnessEvaluator.#PROXIMITY_MULTIPLIER_BASE - _FitnessEvaluator.#PROXIMITY_MULTIPLIER_SLOPE * (distanceToExit / dimensionSum);
        explorationBonus += _FitnessEvaluator.#EXPLORATION_UNIQUE_CELL_BONUS * proximityMultiplier;
      }
      visitCountsScratch.fill(0);
      let fitness = result.fitness + explorationBonus;
      if (result.success) {
        fitness += _FitnessEvaluator.#SUCCESS_BONUS;
        const optimalPathLength = distanceMap ? distanceMap[startPosition[1]]?.[startPosition[0]] ?? Infinity : MazeUtils.bfsDistance(encodedMaze, startPosition, exitPosition);
        const pathOverheadPercent = (result.path.length - 1) / optimalPathLength * 100 - 100;
        const efficiencyBonus = Math.max(
          0,
          _FitnessEvaluator.#EFFICIENCY_BASE - pathOverheadPercent * _FitnessEvaluator.#EFFICIENCY_PENALTY_SCALE
        );
        fitness += efficiencyBonus;
      }
      return fitness;
    }
    /**
     * A wrapper function that serves as the default fitness evaluator for the NEAT evolution process.
     *
     * This function acts as an adapter. The main evolution engine (`EvolutionEngine`) works with a
     * standardized `context` object that bundles all the necessary information for an evaluation.
     * This method simply unpacks that context object and passes the individual parameters to the
     * core `evaluateNetworkFitness` function.
     *
     * @param network - The neural network to be evaluated.
     * @param context - An object containing all the necessary data for the fitness evaluation,
     *                  such as the maze, start/exit positions, and simulation configuration.
     * @returns The computed fitness score for the network.
     */
    static defaultFitnessEvaluator(network, context) {
      return _FitnessEvaluator.evaluateNetworkFitness(
        network,
        context.encodedMaze,
        context.startPosition,
        context.exitPosition,
        context.distanceMap,
        context.agentSimConfig.maxSteps
      );
    }
  };

  // test/examples/asciiMaze/evolutionEngine.ts
  var EvolutionEngine = class _EvolutionEngine {
    /**
     * Pooled scratch buffer used by telemetry softmax/entropy calculations.
     * @remarks Non-reentrant: telemetry functions that use this buffer must not be
     * called concurrently (single-threaded runtime assumption holds for Node/browser).
     */
    static #SCRATCH_EXPS = new Float64Array(4);
    /** Reusable empty vector constant to avoid ephemeral allocations from `|| []` fallbacks. */
    static #EMPTY_VEC = [];
    /** Pooled stats buffers (always resident) for means & stds. */
    static #SCRATCH_MEANS = new Float64Array(4);
    static #SCRATCH_STDS = new Float64Array(4);
    /** Kurtosis related buffers allocated lazily when first needed (non-reduced telemetry). */
    static #SCRATCH_KURT;
    static #SCRATCH_M2_RAW = new Float64Array(4);
    static #SCRATCH_M3_RAW;
    static #SCRATCH_M4_RAW;
    /**
     * Small integer scratch buffer used for directional move counts (N,E,S,W).
     * @remarks Non-reentrant: reused across telemetry calls.
     */
    static #SCRATCH_COUNTS = new Int32Array(4);
    /**
     * Open-address hash table for visited coordinate detection (pairs packed into 32-bit int).
     * Length is always a power of two; uses linear probing. A value of 0 represents EMPTY so we offset packed values by +1.
     */
    static #SCRATCH_VISITED_HASH = new Int32Array(0);
    /** Load factor threshold (~0.7) for resizing visited hash. */
    static #VISITED_HASH_LOAD = 0.7;
    /** Knuth multiplicative hashing constant (32-bit golden ratio). */
    static #HASH_KNUTH_32 = 2654435761 >>> 0;
    /** Scratch species id buffer (dynamic growth). */
    static #SCRATCH_SPECIES_IDS = new Int32Array(64);
    /** Scratch species count buffer parallel to ids. */
    static #SCRATCH_SPECIES_COUNTS = new Int32Array(64);
    /** Reusable candidate connection object buffer. */
    static #SCRATCH_CONN_CAND = [];
    /** Reusable hidden->output connection buffer. */
    static #SCRATCH_HIDDEN_OUT = [];
    /** Flags buffer for connection disabling (grown on demand). */
    static #SCRATCH_CONN_FLAGS = new Uint8Array(128);
    /** Scratch tail buffer reused by #getTail (grows geometrically). */
    static #SCRATCH_TAIL = new Array(64);
    /** Scratch sample result buffer reused by #sampleArray (ephemeral return). */
    static #SCRATCH_SAMPLE_RESULT = new Array(64);
    /** Scratch index buffer holding sorted indices by score (reused per generation). */
    static #SCRATCH_SORT_IDX = new Array(512);
    /** Optional typed-array scratch used internally to accelerate sorting without allocating each call. */
    static #SCRATCH_SORT_IDX_TA;
    /** Scratch stack (lo,hi pairs) for quicksort on indices. */
    static #SCRATCH_QS_STACK = new Int32Array(128);
    /** Scratch array reused when cloning an initial population. */
    static #SCRATCH_POP_CLONE = new Array(0);
    /** Scratch string array for activation function names (printNetworkStructure). */
    static #SCRATCH_ACT_NAMES = new Array(0);
    /** Reusable object buffer for snapshot top entries. */
    static #SCRATCH_SNAPSHOT_TOP = new Array(0);
    /** Reusable snapshot object (fields overwritten each persistence). */
    static #SCRATCH_SNAPSHOT_OBJ = {
      generation: 0,
      bestFitness: 0,
      simplifyMode: false,
      plateauCounter: 0,
      timestamp: 0,
      telemetryTail: void 0,
      top: void 0
    };
    /** Pooled buffer for mutation operator indices (shuffled prefix each use). */
    static #SCRATCH_MUTOP_IDX = new Uint16Array(0);
    /** Number of action outputs (N,E,S,W) */
    static #ACTION_DIM = 4;
    /** Precomputed 1/ln(4) for entropy normalization (micro-optimization). */
    static #INV_LOG4 = 1 / Math.log(4);
    /** LCG multiplier (1664525) used by the fast RNG (32-bit LCG). */
    static #LCG_MULT = 1664525;
    /** LCG additive constant (1013904223) used by the fast RNG. */
    static #LCG_ADD = 1013904223;
    /** Number of cached RNG outputs per refill (batched to amortize state writes). */
    static #RNG_CACHE_SIZE = 4;
    /** Bit shift applied when converting 32-bit state to fractional mantissa (>> 9). */
    static #RNG_SHIFT = 9;
    /** Scale factor to map shifted integer to [0,1): 1 / 0x800000. */
    static #RNG_SCALE = 1 / 8388608;
    /** Adaptive logits ring capacity (power-of-two). */
    static #LOGITS_RING_CAP = 512;
    /** Max allowed ring capacity (safety bound). */
    static #LOGITS_RING_CAP_MAX = 8192;
    /** Indicates SharedArrayBuffer-backed ring is active. */
    static #LOGITS_RING_SHARED = false;
    /** Logits ring (fallback non-shared row-of-vectors). */
    static #SCRATCH_LOGITS_RING = (() => {
      const cap = _EvolutionEngine.#LOGITS_RING_CAP;
      const rows = new Array(cap);
      for (let i = 0; i < cap; i++)
        rows[i] = new Float32Array(_EvolutionEngine.#ACTION_DIM);
      return rows;
    })();
    /** Shared flat logits storage when shared mode enabled (length = cap * ACTION_DIM). */
    static #SCRATCH_LOGITS_SHARED;
    /** Shared atomic write index (length=1 Int32). */
    static #SCRATCH_LOGITS_SHARED_W;
    /** Write cursor for non-shared ring. */
    static #SCRATCH_LOGITS_RING_W = 0;
    /** Internal helper: allocate a non-shared ring with specified capacity. */
    static #allocateLogitsRing(cap) {
      const rows = new Array(cap);
      for (let i = 0; i < cap; i++)
        rows[i] = new Float32Array(_EvolutionEngine.#ACTION_DIM);
      return rows;
    }
    /**
     * Behavior & environment constraints:
     * - No-op when `SharedArrayBuffer` is unavailable or when the global context is not
     *   `crossOriginIsolated` (the browser COOP+COEP requirement). In those cases the engine will
     *   continue using the fallback non-shared `#SCRATCH_LOGITS_RING`.
     * - Any exception during allocation or view creation is caught; on failure the method clears
     *   any partially-initialized shared references and leaves `#LOGITS_RING_SHARED` as false.
     *
     * Memory layout details:
     * - The SAB size is 4 + (cap * ACTION_DIM * 4) bytes.
     *   - Byte offset 0: Int32Array view of length 1 used as the atomic write index (4 bytes).
     *   - Byte offset 4: Float32Array view of length (cap * ACTION_DIM) storing the flattened logits.
     * - Consumers should treat the Float32Array as rows of length `ACTION_DIM` and use the
     *   atomic write index to coordinate producer/consumer access.
     *
     * Safety / assumptions:
     * - `cap` should be a sensible ring capacity (the rest of the ring logic prefers power-of-two
     *   capacities, though this method does not enforce it).
     * - Atomics.store is used to initialize the write index to 0.
     *
     * @param cap Number of rows (ring capacity). The Float32 storage length will be `cap * ACTION_DIM`.
     * @internal
     * @remarks This is a best-effort performance optimization for worker/agent setups; when the
     *          environment doesn't permit SAB usage the engine gracefully falls back to the
     *          per-row `#SCRATCH_LOGITS_RING` representation.
     * @example
     * // internal usage (may succeed only in cross-origin-isolated browsers or compatible worker hosts)
     * EvolutionEngine['#initSharedLogitsRing'](512);
     */
    static #initSharedLogitsRing(cap) {
      try {
        if (typeof SharedArrayBuffer === "undefined") return;
        if (globalThis?.crossOriginIsolated !== true) return;
        if (!Number.isInteger(cap) || cap <= 0) return;
        const actionDim = _EvolutionEngine.#ACTION_DIM;
        const totalFloats = cap * actionDim;
        const indexBytes = Int32Array.BYTES_PER_ELEMENT;
        const floatBytes = Float32Array.BYTES_PER_ELEMENT;
        const sab = new SharedArrayBuffer(indexBytes + totalFloats * floatBytes);
        _EvolutionEngine.#SCRATCH_LOGITS_SHARED_W = new Int32Array(sab, 0, 1);
        _EvolutionEngine.#SCRATCH_LOGITS_SHARED = new Float32Array(
          sab,
          indexBytes,
          totalFloats
        );
        Atomics.store(_EvolutionEngine.#SCRATCH_LOGITS_SHARED_W, 0, 0);
        _EvolutionEngine.#SCRATCH_LOGITS_SHARED.fill(0);
        _EvolutionEngine.#LOGITS_RING_SHARED = true;
      } catch {
        _EvolutionEngine.#LOGITS_RING_SHARED = false;
        _EvolutionEngine.#SCRATCH_LOGITS_SHARED = void 0;
        _EvolutionEngine.#SCRATCH_LOGITS_SHARED_W = void 0;
      }
    }
    /**
     * Ensure the logits ring has sufficient capacity for `desiredRecentSteps`.
     *
     * Heuristics:
     * - Grow when usage exceeds ~75% of capacity (and cap < max); growth chooses the next
     *   power-of-two >= desiredRecentSteps * 2 to leave headroom.
     * - Shrink when usage drops below 25% of capacity while maintaining a lower bound (128).
     * - All sizes are clamped to [128, #LOGITS_RING_CAP_MAX] and kept as powers of two.
     *
     * Behavior:
     * - On resize we reset the non-shared write cursor, reallocate the non-shared per-row ring,
     *   and attempt to reinitialize the SharedArrayBuffer-backed ring if shared mode is active.
     * - The method is best-effort and non-blocking; callers should avoid concurrent calls from
     *   multiple threads/workers because internal scratch state (non-shared ring) is replaced.
     *
     * @param desiredRecentSteps Estimated number of recent rows that need to be stored.
     * @internal
     */
    static #ensureLogitsRingCapacity(desiredRecentSteps) {
      if (!Number.isFinite(desiredRecentSteps) || desiredRecentSteps < 0) return;
      const MIN_CAP = 128;
      const maxCap = _EvolutionEngine.#LOGITS_RING_CAP_MAX;
      let cap = _EvolutionEngine.#LOGITS_RING_CAP;
      let target = cap;
      const nextPow2 = (n) => {
        if (n <= 1) return 1;
        return 1 << Math.ceil(Math.log2(n));
      };
      if (desiredRecentSteps > cap * 3 / 4 && cap < maxCap) {
        const desired = Math.min(desiredRecentSteps * 2, maxCap);
        target = Math.min(nextPow2(Math.ceil(desired)), maxCap);
      } else if (desiredRecentSteps < cap / 4 && cap > MIN_CAP) {
        let shrink = cap;
        while (shrink > MIN_CAP && desiredRecentSteps * 2 <= shrink / 2)
          shrink >>= 1;
        target = Math.max(shrink, MIN_CAP);
      }
      if (target !== cap) {
        _EvolutionEngine.#LOGITS_RING_CAP = target;
        _EvolutionEngine.#SCRATCH_LOGITS_RING_W = 0;
        _EvolutionEngine.#SCRATCH_LOGITS_RING = _EvolutionEngine.#allocateLogitsRing(
          target
        );
        if (_EvolutionEngine.#LOGITS_RING_SHARED)
          _EvolutionEngine.#initSharedLogitsRing(target);
      }
    }
    /**
     * Small node index scratch arrays reused when extracting nodes by type.
     * @remarks Non-reentrant: do not call concurrently.
     */
    static #SCRATCH_NODE_IDX = new Int32Array(64);
    /**
     * Object reference scratch array used as a short sample buffer (max 40 entries).
     * Avoids allocating small arrays inside hot telemetry paths.
     */
    static #SCRATCH_SAMPLE = new Array(40);
    /** Reusable string assembly character buffer for small joins (grown geometrically). */
    static #SCRATCH_STR = new Array(64);
    /** Internal 32-bit state for fast LCG RNG (mul 1664525 + 1013904223). */
    static #RNG_STATE = (Date.now() ^ 2654435769) >>> 0;
    /** Detailed profiling enable flag (set ASCII_MAZE_PROFILE_DETAILS=1). */
    static #PROFILE_ENABLED = (() => {
      try {
        return typeof process !== "undefined" && process?.env?.ASCII_MAZE_PROFILE_DETAILS === "1";
      } catch {
        return false;
      }
    })();
    /** Accumulators for detailed profiling (ms). */
    static #PROFILE_ACCUM = {
      telemetry: 0,
      simplify: 0,
      snapshot: 0,
      prune: 0
    };
    /** Small fixed-size visited table for tiny path exploration (<32) to avoid O(n^2) duplicate scan. */
    static #SMALL_EXPLORE_TABLE = new Int32Array(64);
    /** Bit mask for SMALL_EXPLORE_TABLE indices (table length - 1). */
    static #SMALL_EXPLORE_TABLE_MASK = 64 - 1;
    static #PROFILE_T0() {
      return _EvolutionEngine.#now();
    }
    static #PROFILE_ADD(key, delta) {
      if (!_EvolutionEngine.#PROFILE_ENABLED) return;
      _EvolutionEngine.#PROFILE_ACCUM[key] = (_EvolutionEngine.#PROFILE_ACCUM[key] || 0) + delta;
    }
    /**
     * RNG cache (batched draws) to amortize LCG state updates in tight loops.
     * Size is taken from `#RNG_CACHE_SIZE` so the batch parameter is centralized.
     */
    static #RNG_CACHE = new Float64Array(_EvolutionEngine.#RNG_CACHE_SIZE);
    // Force initial refill by setting index to cache size.
    static #RNG_CACHE_INDEX = _EvolutionEngine.#RNG_CACHE_SIZE;
    /**
     * Fast LCG producing a float in [0,1).
     *
     * Notes:
     * - Non-cryptographic: simple 32-bit LCG (mul/add) used for high-performance sampling.
     * - Batches `#RNG_CACHE_SIZE` outputs to reduce the number of state writes.
     * - Deterministic when `#DETERMINISTIC` is set and seeded via `setDeterministic`.
     * - Returns a double in [0,1). Consumers relying on high-quality randomness should
     *   replace this with a cryptographic RNG.
     *
     * @returns float in [0,1)
     * @internal
     */
    static #fastRandom() {
      if (_EvolutionEngine.#RNG_CACHE_INDEX >= _EvolutionEngine.#RNG_CACHE_SIZE) {
        let localRngState = _EvolutionEngine.#RNG_STATE >>> 0;
        for (let cacheFillIndex = 0; cacheFillIndex < _EvolutionEngine.#RNG_CACHE_SIZE; cacheFillIndex++) {
          localRngState = localRngState * _EvolutionEngine.#LCG_MULT + _EvolutionEngine.#LCG_ADD >>> 0;
          _EvolutionEngine.#RNG_CACHE[cacheFillIndex] = (localRngState >>> _EvolutionEngine.#RNG_SHIFT) * _EvolutionEngine.#RNG_SCALE;
        }
        _EvolutionEngine.#RNG_STATE = localRngState >>> 0;
        _EvolutionEngine.#RNG_CACHE_INDEX = 0;
      }
      const nextValue = _EvolutionEngine.#RNG_CACHE[_EvolutionEngine.#RNG_CACHE_INDEX++];
      return nextValue;
    }
    /** Deterministic mode flag (enables reproducible seeded RNG). */
    static #DETERMINISTIC = false;
    /** High-resolution time helper. */
    static #now() {
      return globalThis.performance?.now?.() ?? Date.now();
    }
    /**
     * Enable deterministic mode and optionally reseed the internal RNG.
     *
     * Behaviour (stepwise):
     * 1. Set the internal deterministic flag so other helpers can opt-in to deterministic behaviour.
     * 2. If `seed` is provided and finite, normalise it to an unsigned 32-bit integer. A seed value of
     *    `0` is remapped to the golden-ratio-derived constant `0x9e3779b9` to avoid the degenerate LCG state.
     * 3. Persist the chosen u32 seed into `#RNG_STATE` and force the RNG cache to refill so the next
     *    `#fastRandom()` call yields the deterministic sequence starting from the new seed.
     *
     * Notes:
     * - If `seed` is omitted the method only enables deterministic mode without reseeding the RNG state.
     * - The method is intentionally conservative about input coercion: only finite numeric seeds are accepted.
     *
     * @param seed Optional numeric seed. Fractional values are coerced via `>>> 0`. Passing `0` results in
     *             a non-zero canonical seed to avoid trivial cycles.
     * @example
     * // Enable deterministic mode with an explicit seed:
     * EvolutionEngine.setDeterministic(12345);
     *
     * @internal
     */
    static setDeterministic(seed) {
      _EvolutionEngine.#DETERMINISTIC = true;
      if (typeof seed === "number" && Number.isFinite(seed)) {
        const normalised = seed >>> 0 || 2654435769;
        _EvolutionEngine.#RNG_STATE = normalised >>> 0;
        _EvolutionEngine.#RNG_CACHE_INDEX = _EvolutionEngine.#RNG_CACHE_SIZE;
      }
    }
    /** Disable deterministic mode. */
    static clearDeterministic() {
      _EvolutionEngine.#DETERMINISTIC = false;
    }
    /** When true, telemetry skips higher-moment stats (kurtosis) for speed. */
    static #REDUCED_TELEMETRY = false;
    /** Skip most telemetry logging & higher moment stats when true (minimal mode). */
    static #TELEMETRY_MINIMAL = false;
    /** Disable Baldwinian refinement phase when true. */
    static #DISABLE_BALDWIN = false;
    /** Default tail history size used by telemetry */
    static #RECENT_WINDOW = 40;
    /** Default population size used when no popSize provided in cfg */
    static #DEFAULT_POPSIZE = 500;
    /** Default mutation rate (fraction of individuals mutated per generation) */
    static #DEFAULT_MUTATION_RATE = 0.2;
    /** Default mutation amount (fractional magnitude for mutation operators) */
    static #DEFAULT_MUTATION_AMOUNT = 0.3;
    /** Fraction of population reserved for elitism when computing elitism count */
    static #DEFAULT_ELITISM_FRACTION = 0.1;
    /** Fraction of population reserved for provenance when computing provenance count */
    static #DEFAULT_PROVENANCE_FRACTION = 0.2;
    /** Default minimum hidden nodes for new NEAT instances */
    /**
     * Default minimum hidden nodes enforced for each evolved network.
     * Raised from 6 -> 12 to increase representational capacity for maze scaling.
     * Adjust via code edit if future experiments need a different baseline.
     */
    static #DEFAULT_MIN_HIDDEN = 20;
    /** Default target species count for adaptive target species heuristics */
    static #DEFAULT_TARGET_SPECIES = 10;
    /** Default supervised training error threshold for local training */
    static #DEFAULT_TRAIN_ERROR = 0.01;
    /** Default supervised training learning rate for local training */
    static #DEFAULT_TRAIN_RATE = 1e-3;
    /** Default supervised training momentum */
    static #DEFAULT_TRAIN_MOMENTUM = 0.2;
    /** Default small batch size used during Lamarckian training */
    static #DEFAULT_TRAIN_BATCH_SMALL = 2;
    /** Default batch size used when training the fittest network for evaluation */
    static #DEFAULT_TRAIN_BATCH_LARGE = 20;
    /** Iterations used when training the fittest network for evaluation */
    static #FITTEST_TRAIN_ITERATIONS = 1e3;
    /** Saturation fraction threshold triggering hidden-output pruning */
    static #SATURATION_PRUNE_THRESHOLD = 0.5;
    /** Small threshold used in several numeric comparisons */
    static #NUMERIC_EPSILON_SMALL = 0.01;
    /** Small threshold used for std flat detection in logits */
    static #LOGSTD_FLAT_THRESHOLD = 5e-3;
    /** Default entropy range for adaptive target species */
    static #DEFAULT_ENTROPY_RANGE = [0.3, 0.8];
    /** Default smoothing factor for adaptive target species */
    static #DEFAULT_ADAPTIVE_SMOOTH = 0.5;
    /** Default probability used for small randomized jitter (25%) */
    static #DEFAULT_JITTER_PROB = 0.25;
    /** Default probability for 50/50 decisions */
    static #DEFAULT_HALF_PROB = 0.5;
    /** Fraction of sorted parents chosen as parent pool */
    static #DEFAULT_PARENT_FRACTION = 0.25;
    /** Small std threshold to consider 'small' std */
    static #DEFAULT_STD_SMALL = 0.25;
    /** Multiplier applied when std is small */
    static #DEFAULT_STD_ADJUST_MULT = 0.7;
    /** Initial weight range lower bound used by compass warm start */
    static #W_INIT_MIN = 0.55;
    /** Initial weight random range used by compass warm start */
    static #W_INIT_RANGE = 0.25;
    /** Base value for output bias initialization */
    static #OUTPUT_BIAS_BASE = 0.05;
    /** Step per output index when initializing output biases */
    static #OUTPUT_BIAS_STEP = 0.01;
    /** Absolute clamp applied after recentring output biases (prevents runaway values) */
    static #OUTPUT_BIAS_CLAMP = 5;
    /** Bias reset half-range (bias = rand * 2*R - R) */
    static #BIAS_RESET_HALF_RANGE = 0.1;
    /** Connection weight reset half-range (weight = rand * 2*R - R) */
    static #CONN_WEIGHT_RESET_HALF_RANGE = 0.2;
    /** Log tag for action entropy telemetry lines */
    static #LOG_TAG_ACTION_ENTROPY = "[ACTION_ENTROPY]";
    /** Log tag for output bias telemetry lines */
    static #LOG_TAG_OUTPUT_BIAS = "[OUTPUT_BIAS]";
    /** Log tag for logits telemetry lines */
    static #LOG_TAG_LOGITS = "[LOGITS]";
    /** High target probability for the chosen action during supervised warm start */
    static #TRAIN_OUT_PROB_HIGH = 0.92;
    /** Low target probability for non-chosen actions during supervised warm start */
    static #TRAIN_OUT_PROB_LOW = 0.02;
    /** Progress intensity: medium (single open path typical) */
    static #PROGRESS_MEDIUM = 0.7;
    /** Progress intensity: strong forward signal */
    static #PROGRESS_STRONG = 0.9;
    /** Progress intensity: typical junction neutrality */
    static #PROGRESS_JUNCTION = 0.6;
    /** Progress intensity: four-way moderate signal */
    static #PROGRESS_FOURWAY = 0.55;
    /** Progress intensity: regressing / weak progress */
    static #PROGRESS_REGRESS = 0.4;
    /** Progress intensity: mild regression / noise */
    static #PROGRESS_MILD_REGRESS = 0.45;
    /** Minimal progress positive blip used in a corner-case sample */
    static #PROGRESS_MIN_SIGNAL = 1e-3;
    /** Augmentation: base openness jitter value */
    static #AUGMENT_JITTER_BASE = 0.95;
    /** Augmentation: openness jitter range added to base */
    static #AUGMENT_JITTER_RANGE = 0.05;
    /** Augmentation: probability to jitter progress channel */
    static #AUGMENT_PROGRESS_JITTER_PROB = 0.35;
    /** Augmentation: progress delta full range */
    static #AUGMENT_PROGRESS_DELTA_RANGE = 0.1;
    /** Augmentation: progress delta half range (range/2) */
    static #AUGMENT_PROGRESS_DELTA_HALF = 0.05;
    /** Max iterations used during population pretrain */
    static #PRETRAIN_MAX_ITER = 60;
    /** Base iterations added in pretrain (8 + floor(setLen/2)) */
    static #PRETRAIN_BASE_ITER = 8;
    /** Default learning rate used during pretraining population warm-start */
    static #DEFAULT_PRETRAIN_RATE = 2e-3;
    /** Default momentum used during pretraining population warm-start */
    static #DEFAULT_PRETRAIN_MOMENTUM = 0.1;
    /** Default batch size used during population pretraining */
    static #DEFAULT_PRETRAIN_BATCH = 4;
    /** Entropy threshold used in collapse heuristics */
    static #ENTROPY_COLLAPSE_THRESHOLD = 0.35;
    /** Stability threshold used in collapse heuristics */
    static #STABILITY_COLLAPSE_THRESHOLD = 0.97;
    /** Window size (consecutive generations) used to detect species collapse */
    static #SPECIES_COLLAPSE_WINDOW = 20;
    /** Max length of species history buffer */
    static #SPECIES_HISTORY_MAX = 50;
    /** Collapse streak trigger (consecutive collapsed gens before recovery) */
    static #COLLAPSE_STREAK_TRIGGER = 6;
    /** Mutation rate escalation cap during collapse recovery */
    static #COLLAPSE_MUTRATE_CAP = 0.6;
    /** Mutation amount escalation cap during collapse recovery */
    static #COLLAPSE_MUTAMOUNT_CAP = 0.8;
    /** Novelty blend factor escalation cap during collapse recovery */
    static #COLLAPSE_NOVELTY_BLEND_CAP = 0.4;
    /** Mutation rate escalation multiplier */
    static #COLLAPSE_MUTRATE_MULT = 1.5;
    /** Mutation amount escalation multiplier */
    static #COLLAPSE_MUTAMOUNT_MULT = 1.3;
    /** Novelty blend factor escalation multiplier */
    static #COLLAPSE_NOVELTY_MULT = 1.2;
    /** Small-partition cutoff for quicksort; tuned empirically (was 16). */
    static #QS_SMALL_THRESHOLD = 24;
    /** Branchless (dx,dy)->direction index map ((dx+1)*3 + (dy+1)) => 0..3 or -1. */
    static #DIR_DELTA_TO_INDEX = (() => {
      const map = new Int8Array(9);
      map.fill(-1);
      map[(0 + 1) * 3 + (-1 + 1)] = 0;
      map[(1 + 1) * 3 + (0 + 1)] = 1;
      map[(0 + 1) * 3 + (1 + 1)] = 2;
      map[(-1 + 1) * 3 + (0 + 1)] = 3;
      return map;
    })();
    /**
     * Populate the engine's pooled node-index scratch buffer with indices of nodes matching `type`.
     *
     * Steps:
     * 1. Validate inputs and early-exit for empty or missing `nodes`.
     * 2. Iterate the node array once, selecting nodes whose `node.type === type`.
     * 3. Grow the pooled `#SCRATCH_NODE_IDX` Int32Array geometrically (power-of-two) when capacity
     *    is insufficient to avoid frequent allocations.
     * 4. Write matching indices into the scratch buffer and return the count of matches.
     *
     * Notes:
     * - The method mutates `EvolutionEngine.#SCRATCH_NODE_IDX` and is therefore not reentrant. Callers
     *   must copy the first `N` entries if they need persistence across subsequent engine calls.
     * - Returns the number of matched nodes; the first `N` entries of `#SCRATCH_NODE_IDX` contain the indices.
     *
     * @param nodes - Optional array of node objects (each expected to expose a `type` property).
     * @param type - Node type key to match (for example 'input', 'hidden', 'output').
     * @returns Number of matching nodes written into `#SCRATCH_NODE_IDX`.
     * @example
     * // Populate scratch with output node indices and get the count:
     * const outCount = EvolutionEngine['#getNodeIndicesByType'](nodes, 'output');
     * // Use the first outCount entries of EvolutionEngine['#SCRATCH_NODE_IDX'] as indices into nodes.
     *
     * @internal
     */
    static #getNodeIndicesByType(nodes, type) {
      if (!Array.isArray(nodes) || nodes.length === 0) return 0;
      const nodesRef = nodes;
      const desiredType = type;
      let writeCount = 0;
      let scratch = _EvolutionEngine.#SCRATCH_NODE_IDX;
      for (let nodeIndex = 0; nodeIndex < nodesRef.length; nodeIndex++) {
        const nodeRef = nodesRef[nodeIndex];
        if (!nodeRef || nodeRef.type !== desiredType) continue;
        if (writeCount >= scratch.length) {
          const nextCapacity = 1 << Math.ceil(Math.log2(writeCount + 1));
          const grown = new Int32Array(nextCapacity);
          grown.set(scratch);
          _EvolutionEngine.#SCRATCH_NODE_IDX = grown;
          scratch = grown;
        }
        scratch[writeCount++] = nodeIndex;
      }
      return writeCount;
    }
    /**
     * Compute exploration statistics for a path taken by an agent.
     *
     * Returned metrics:
     * - unique: number of distinct grid cells visited
     * - pathLen: total number of steps in path (array length)
     * - ratio: unique / pathLen (0 when pathLen == 0)
     *
     * Implementation details:
     * 1. Coordinates are packed into a single 32-bit integer: (x & 0xffff) << 16 | (y & 0xffff)
     * 2. Two code paths:
     *    a. Tiny path (< 32): use a fixed 64-slot Int32Array (#SMALL_EXPLORE_TABLE) cleared per call.
     *    b. Larger path: use a growable power-of-two scratch Int32Array (#SCRATCH_VISITED_HASH) sized
     *       for target load factor (#VISITED_HASH_LOAD). Table is zero-filled when reused.
     * 3. Open-addressing with linear probing; 0 denotes empty. We store packed+1 to disambiguate zero.
     * 4. Knuth multiplicative hashing constant extracted as a private static (#HASH_KNUTH_32) for clarity.
     * 5. All operations avoid heap allocation after initial buffer growth.
     *
     * Complexity: O(n) expected; worst-case O(n * alpha) with alpha ~ probe length (low under target load).
     * Determinism: Fully deterministic given identical path contents.
     * Reentrancy: Non-reentrant due to shared hash buffer.
     *
     * @param path - Array of [x,y] coordinates visited in order.
     * @returns { unique, pathLen, ratio }
     * @example
     * const stats = EvolutionEngine['#computeExplorationStats']([[0,0],[1,0],[1,0]]); // pseudo internal usage
     * @internal
     */
    static #computeExplorationStats(path) {
      const pathLength = path?.length || 0;
      if (pathLength === 0) return { unique: 0, pathLen: 0, ratio: 0 };
      if (pathLength < 32) {
        const distinctTiny = _EvolutionEngine.#countDistinctCoordinatesTiny(
          path,
          pathLength
        );
        return {
          unique: distinctTiny,
          pathLen: pathLength,
          ratio: distinctTiny / pathLength
        };
      }
      const distinct = _EvolutionEngine.#countDistinctCoordinatesHashed(
        path,
        pathLength
      );
      return {
        unique: distinct,
        pathLen: pathLength,
        ratio: distinct / pathLength
      };
    }
    /**
     * Count distinct packed coordinates for tiny paths (< 32) using a fixed-size table.
     * @param path - Coordinate path reference.
     * @param pathLength - Precomputed length (avoid repeated length lookups).
     * @returns number of unique coordinates.
     * @remarks Non-reentrant (shared tiny table). O(n) expected, tiny constant factors.
     */
    static #countDistinctCoordinatesTiny(path, pathLength) {
      if (pathLength === 0) return 0;
      const table = _EvolutionEngine.#SMALL_EXPLORE_TABLE;
      table.fill(0);
      let distinctCount = 0;
      const mask = _EvolutionEngine.#SMALL_EXPLORE_TABLE_MASK;
      for (let coordinateIndex = 0; coordinateIndex < pathLength; coordinateIndex++) {
        const coordinate = path[coordinateIndex];
        const packed = (coordinate[0] & 65535) << 16 | coordinate[1] & 65535;
        let hash = Math.imul(packed, _EvolutionEngine.#HASH_KNUTH_32) >>> 0;
        const storedValue = packed + 1 | 0;
        while (true) {
          const slot = hash & mask;
          const slotValue = table[slot];
          if (slotValue === 0) {
            table[slot] = storedValue;
            distinctCount++;
            break;
          }
          if (slotValue === storedValue) break;
          hash = hash + 1 | 0;
        }
      }
      return distinctCount;
    }
    /**
     * Count distinct coordinates for larger paths using a dynamically sized open-address hash table.
     * Ensures the table grows geometrically to keep probe chains short.
     *
     * Design rationale:
     * - Uses a single shared Int32Array (#SCRATCH_VISITED_HASH) grown geometrically (power-of-two) so
     *   subsequent calls amortize allocation costs. We target a load factor below `#VISITED_HASH_LOAD` (≈0.7).
     * - Multiplicative hashing (Knuth constant) provides a cheap, decent dispersion for packed 32-bit coordinates.
     * - Linear probing keeps memory contiguous (cache friendly) and avoids per-slot pointer overhead.
     * - We pack (x,y) into 32 bits allowing negative coordinates via masking (& 0xffff) with natural wrap —
     *   acceptable for maze sizes far below 65k.
     * - Instead of tombstones we only ever insert during this scan, so deletion complexity is avoided.
     *
     * Complexity: Expected O(n) with short probe sequences; worst-case O(n^2) only under adversarial clustering
     * (not expected with maze coordinate distributions and resizing policy).
     * Memory: One Int32Array reused; size grows but never shrinks (acceptable for long-running evolution sessions).
     * Determinism: Fully deterministic for the same input path.
     * Reentrancy: Non-reentrant due to shared buffer reuse.
     *
     * @param path - Coordinate path reference.
     * @param pathLength - Path length (number of coordinate entries).
     * @returns Number of unique coordinates encountered.
     * @remarks Non-reentrant (shared hash table). Expected O(n) with low probe lengths.
     */
    static #countDistinctCoordinatesHashed(path, pathLength) {
      const targetCapacity = pathLength << 1;
      let table = _EvolutionEngine.#SCRATCH_VISITED_HASH;
      if (table.length === 0 || targetCapacity > table.length * _EvolutionEngine.#VISITED_HASH_LOAD) {
        const needed = Math.ceil(
          targetCapacity / _EvolutionEngine.#VISITED_HASH_LOAD
        );
        const pow2 = 1 << Math.ceil(Math.log2(needed));
        table = _EvolutionEngine.#SCRATCH_VISITED_HASH = new Int32Array(pow2);
      } else {
        table.fill(0);
      }
      const mask = table.length - 1;
      let distinct = 0;
      for (let index = 0; index < pathLength; index++) {
        const coordinate = path[index];
        const packed = (coordinate[0] & 65535) << 16 | coordinate[1] & 65535;
        let hash = Math.imul(packed, _EvolutionEngine.#HASH_KNUTH_32) >>> 0;
        const storeVal = packed + 1 | 0;
        while (true) {
          const slot = hash & mask;
          const slotValue = table[slot];
          if (slotValue === 0) {
            table[slot] = storeVal;
            distinct++;
            break;
          }
          if (slotValue === storeVal) break;
          hash = hash + 1 | 0;
        }
      }
      return distinct;
    }
    /**
     * Compute core diversity metrics for the current NEAT population.
     *
     * Metrics returned:
     * - speciesUniqueCount: number of distinct species IDs present (genomes without a species get id -1)
     * - simpson: Simpson diversity index (1 - sum(p_i^2)) over species proportions
     * - wStd: standard deviation of enabled connection weights from a sampled subset of genomes
     *
     * Implementation notes / performance:
     * 1. Species counting uses two class‑static Int32Array scratch buffers (#SCRATCH_SPECIES_IDS / COUNTS)
     *    and linear search because typical species cardinality << population size, making a hash map slower.
     * 2. Weight distribution sampling uses a pooled object scratch buffer (#SCRATCH_SAMPLE) filled by
     *    #sampleIntoScratch (with replacement) to avoid per‑call allocations.
     * 3. Variance is computed with Welford's single‑pass algorithm for numerical stability and zero extra storage.
     * 4. All buffers grow geometrically (power of two) and never shrink to preserve amortized O(1) reallocation cost.
     *
     * Determinism: Sampling relies on the engine RNG; in deterministic mode (#DETERMINISTIC set) results are reproducible.
     * Reentrancy: Non‑reentrant due to shared scratch buffers.
     * Complexity: O(P + S + W) where P = population length, S = speciesUniqueCount (S <= P),
     *             and W = total enabled connections visited in the sampled genomes.
     * Memory: No per‑invocation heap allocations after initial buffer growth.
     *
     * @param neat - NEAT instance exposing a `population` array.
     * @param sampleSize - Upper bound on number of genomes to sample for weight variance (default 40).
     * @returns Object containing { speciesUniqueCount, simpson, wStd }.
     * @example
     * const diversity = EvolutionEngine['#computeDiversityMetrics'](neat, 32); // internal call example (pseudo)
     * @internal
     * @remarks Non-reentrant (shared scratch arrays).
     */
    static #computeDiversityMetrics(neat, sampleSize = 40) {
      const populationRef = neat.population ?? _EvolutionEngine.#EMPTY_VEC;
      const populationLength = populationRef.length | 0;
      if (populationLength === 0) {
        return { speciesUniqueCount: 0, simpson: 0, wStd: 0 };
      }
      let speciesIds = _EvolutionEngine.#SCRATCH_SPECIES_IDS;
      let speciesCounts = _EvolutionEngine.#SCRATCH_SPECIES_COUNTS;
      if (populationLength > speciesIds.length) {
        const nextSize = 1 << Math.ceil(Math.log2(populationLength));
        _EvolutionEngine.#SCRATCH_SPECIES_IDS = new Int32Array(nextSize);
        _EvolutionEngine.#SCRATCH_SPECIES_COUNTS = new Int32Array(nextSize);
        speciesIds = _EvolutionEngine.#SCRATCH_SPECIES_IDS;
        speciesCounts = _EvolutionEngine.#SCRATCH_SPECIES_COUNTS;
      }
      let speciesUniqueCount = 0;
      let totalPopulationCount = 0;
      for (let populationIndex = 0; populationIndex < populationLength; populationIndex++) {
        const genome = populationRef[populationIndex];
        const speciesId = (genome && genome.species != null ? genome.species : -1) | 0;
        let existingSpeciesIndex = -1;
        for (let speciesScanIndex = 0; speciesScanIndex < speciesUniqueCount; speciesScanIndex++) {
          if (speciesIds[speciesScanIndex] === speciesId) {
            existingSpeciesIndex = speciesScanIndex;
            break;
          }
        }
        if (existingSpeciesIndex === -1) {
          speciesIds[speciesUniqueCount] = speciesId;
          speciesCounts[speciesUniqueCount] = 1;
          speciesUniqueCount++;
        } else {
          speciesCounts[existingSpeciesIndex]++;
        }
        totalPopulationCount++;
      }
      if (totalPopulationCount === 0) totalPopulationCount = 1;
      let simpsonAccumulator = 0;
      for (let speciesIndex = 0; speciesIndex < speciesUniqueCount; speciesIndex++) {
        const proportion = speciesCounts[speciesIndex] / totalPopulationCount;
        simpsonAccumulator += proportion * proportion;
      }
      const simpson = 1 - simpsonAccumulator;
      const boundedSampleSize = sampleSize > 0 ? Math.min(populationLength, sampleSize | 0) : 0;
      const sampledLength = boundedSampleSize ? _EvolutionEngine.#sampleIntoScratch(populationRef, boundedSampleSize) : 0;
      let weightMean = 0;
      let weightM2 = 0;
      let enabledWeightCount = 0;
      for (let sampleIndex = 0; sampleIndex < sampledLength; sampleIndex++) {
        const sampledGenome = _EvolutionEngine.#SCRATCH_SAMPLE[sampleIndex];
        const connections = sampledGenome.connections ?? _EvolutionEngine.#EMPTY_VEC;
        for (let connectionIndex = 0; connectionIndex < connections.length; connectionIndex++) {
          const connection = connections[connectionIndex];
          if (connection && connection.enabled !== false) {
            enabledWeightCount++;
            const delta = connection.weight - weightMean;
            weightMean += delta / enabledWeightCount;
            weightM2 += delta * (connection.weight - weightMean);
          }
        }
      }
      const weightStdDev = enabledWeightCount ? Math.sqrt(weightM2 / enabledWeightCount) : 0;
      return { speciesUniqueCount, simpson, wStd: weightStdDev };
    }
    /**
     * Sample `k` items (with replacement) from a source array using the engine RNG.
     *
     * Characteristics:
     * - With replacement: the same element can appear multiple times.
     * - Uses a reusable pooled array (#SCRATCH_SAMPLE_RESULT) that grows geometrically (power-of-two) and is reused
     *   across calls to avoid allocations. Callers MUST copy (`slice()` / spread) if they need to retain the result
     *   beyond the next invocation.
     * - Deterministic under deterministic engine mode (shared RNG state); otherwise non-deterministic.
     * - Returns an empty array (length 0) for invalid inputs (`k <= 0`, non-array, or empty source). The returned
     *   empty array is a fresh literal to avoid accidental aliasing with the scratch buffer.
     *
     * Complexity: O(k). Memory: O(k) only during first growth; subsequent calls reuse storage.
     * Reentrancy: Non-reentrant (shared scratch buffer reused) — do not call concurrently.
     *
     * @param src - Source array to sample from.
     * @param k - Number of samples requested (fractional values truncated via floor). Negative treated as 0.
     * @returns Pooled ephemeral array of length `k` (or 0) containing sampled elements (with replacement).
     * @example
     * // Internal usage (pseudo):
     * const batch = EvolutionEngine['#sampleArray'](population, 16); // do not store long-term
     * const stableCopy = [...batch]; // copy if needed later
     * @internal
     * @remarks Non-reentrant; result must be treated as ephemeral.
     */
    static #sampleArray(src, k) {
      if (!Array.isArray(src) || k <= 0) return [];
      const sampleCount = Math.floor(k);
      const sourceLength = src.length | 0;
      if (sourceLength === 0 || sampleCount === 0) return [];
      if (sampleCount > _EvolutionEngine.#SCRATCH_SAMPLE_RESULT.length) {
        const nextSize = 1 << Math.ceil(Math.log2(sampleCount));
        _EvolutionEngine.#SCRATCH_SAMPLE_RESULT = new Array(nextSize);
      }
      const out = _EvolutionEngine.#SCRATCH_SAMPLE_RESULT;
      for (let sampleIndex = 0; sampleIndex < sampleCount; sampleIndex++) {
        out[sampleIndex] = src[_EvolutionEngine.#fastRandom() * sourceLength | 0];
      }
      out.length = sampleCount;
      return out;
    }
    /**
     * Apply simplify/prune pass to every genome in the provided NEAT population.
     *
     * Steps:
     * 1) Validate inputs and normalize prune fraction into [0,1]. If fraction is 0, exit early.
     * 2) Iterate the population, invoking the central per-genome pruning helper
     *    (#pruneWeakConnectionsForGenome) for each genome.
     * 3) Isolate failures: catch and ignore exceptions on a per-genome basis so a single
     *    faulty genome cannot abort the entire simplify phase (best-effort maintenance).
     *
     * Notes:
     * - This helper intentionally reuses existing per-genome helpers and class-level
     *   pooled buffers (via those helpers) to remain allocation-light. It itself does
     *   not allocate intermediate arrays.
     * - Non-reentrant: callers must not invoke concurrently due to shared scratch buffers
     *   used by downstream helpers.
     *
     * @param neat NEAT instance with a `population` array of genomes.
     * @param simplifyStrategy Strategy key forwarded to per-genome pruning logic.
     * @param simplifyPruneFraction Fraction in [0,1] controlling pruning aggressiveness.
     * @example
     * // Perform a single simplify generation across the population.
     * EvolutionEngine['#applySimplifyPruningToPopulation'](neatInstance, 'weakRecurrentPreferred', 0.12);
     */
    static #applySimplifyPruningToPopulation(neat, simplifyStrategy, simplifyPruneFraction) {
      if (!neat || !Array.isArray(neat.population) || neat.population.length === 0)
        return;
      const populationRef = neat.population;
      const pruneFraction = Number.isFinite(simplifyPruneFraction) ? Math.max(0, Math.min(1, simplifyPruneFraction)) : 0;
      if (pruneFraction === 0) return;
      for (let genomeIndex = 0; genomeIndex < populationRef.length; genomeIndex++) {
        const genome = populationRef[genomeIndex];
        try {
          if (!genome || !Array.isArray(genome.connections)) continue;
          _EvolutionEngine.#pruneWeakConnectionsForGenome(
            genome,
            simplifyStrategy ?? "",
            pruneFraction
          );
        } catch {
        }
      }
    }
    /**
     * Warm-start wiring for compass and directional openness inputs.
     *
     * Purpose:
     *  - Ensure the four directional input->output pathways and a compass fan-out exist with
     *    light initial weights so freshly-warmed networks have sensible starting connectivity.
     *  - This helper is allocation-light and reuses class-level scratch buffers (notably
     *    `#SCRATCH_NODE_IDX`) to avoid per-call allocations.
     *
     * Behaviour / steps:
     *  1) Fast-guard when `net` is missing or has no node list.
     *  2) For each of the 4 compass directions try to find an input node and the corresponding
     *     output node (indices are taken from `#SCRATCH_NODE_IDX` populated by callers).
     *  3) For each input->output pair ensure a connection exists; create it or set its weight
     *     to a small random initialization in [W_INIT_MIN, W_INIT_MIN+W_INIT_RANGE].
     *  4) Finally, connect the special 'compass' input (index 0 when present) to all outputs
     *     with a deterministic base weight computed from engine constants.
     *  5) Swallow unexpected errors to preserve best-effort semantics.
     *
     * Notes:
     *  - Non-reentrant: shared scratch arrays may be mutated elsewhere; callers must avoid
     *    concurrent use.
     *  - No temporary arrays are allocated; loops use local length aliases to minimize property reads.
     *
     * @param net - Network-like object with `nodes` and `connections` arrays and `connect(from,to,w)` method.
     * @example
     * // After constructing or pretraining `net`:
     * EvolutionEngine['#applyCompassWarmStart'](net);
     */
    static #applyCompassWarmStart(net) {
      try {
        if (!net) return;
        const nodesRef = net.nodes ?? _EvolutionEngine.#EMPTY_VEC;
        const connectionsRef = net.connections ?? _EvolutionEngine.#EMPTY_VEC;
        const outputCount = _EvolutionEngine.#getNodeIndicesByType(
          nodesRef,
          "output"
        );
        const inputCount = _EvolutionEngine.#getNodeIndicesByType(
          nodesRef,
          "input"
        );
        const wInitRange = _EvolutionEngine.#W_INIT_RANGE;
        const wInitMin = _EvolutionEngine.#W_INIT_MIN;
        for (let direction = 0; direction < 4; direction++) {
          const inputNodeIndex = direction + 1 < inputCount ? _EvolutionEngine.#SCRATCH_NODE_IDX[direction + 1] : -1;
          const outputNodeIndex = direction < outputCount ? _EvolutionEngine.#SCRATCH_NODE_IDX[direction] : -1;
          const inputNode = inputNodeIndex === -1 ? void 0 : nodesRef[inputNodeIndex];
          const outputNode = outputNodeIndex === -1 ? void 0 : nodesRef[outputNodeIndex];
          if (!inputNode || !outputNode) continue;
          let existingConn = void 0;
          for (let ci = 0, cLen = connectionsRef.length; ci < cLen; ci++) {
            const conn = connectionsRef[ci];
            if (conn.from === inputNode && conn.to === outputNode) {
              existingConn = conn;
              break;
            }
          }
          const initWeight = _EvolutionEngine.#fastRandom() * wInitRange + wInitMin;
          if (!existingConn) net.connect(inputNode, outputNode, initWeight);
          else existingConn.weight = initWeight;
        }
        const compassNodeIndex = inputCount > 0 ? _EvolutionEngine.#SCRATCH_NODE_IDX[0] : -1;
        const compassNode = compassNodeIndex === -1 ? void 0 : nodesRef[compassNodeIndex];
        if (!compassNode) return;
        for (let outIndex = 0; outIndex < outputCount; outIndex++) {
          const outNode = nodesRef[_EvolutionEngine.#SCRATCH_NODE_IDX[outIndex]];
          if (!outNode) continue;
          let existingConn = void 0;
          for (let ci = 0, cLen = connectionsRef.length; ci < cLen; ci++) {
            const conn = connectionsRef[ci];
            if (conn.from === compassNode && conn.to === outNode) {
              existingConn = conn;
              break;
            }
          }
          const baseWeight = _EvolutionEngine.#OUTPUT_BIAS_BASE + outIndex * _EvolutionEngine.#OUTPUT_BIAS_STEP;
          if (!existingConn) net.connect(compassNode, outNode, baseWeight);
          else existingConn.weight = baseWeight;
        }
      } catch {
      }
    }
    /**
     * Decide whether to start the simplify/pruning phase and return its duration in generations.
     *
     * Behaviour (stepwise):
     * 1. Normalise inputs defensively; non-finite or missing values are treated as 0.
     * 2. If the observed plateau counter meets or exceeds the configured plateau generations,
     *    the method will start a simplify phase only when running in a non-browser host (previous
     *    behaviour gated on `typeof window === 'undefined'`).
     * 3. Returns `simplifyDuration` when the simplify phase should start, or `0` to indicate no start.
     *
     * Rationale: Simplify/pruning is potentially expensive and historically skipped in browser contexts
     * to avoid blocking the UI; this helper preserves that heuristic while sanitising inputs.
     *
     * @param plateauCounter - Observed consecutive plateau generations (may be non-finite).
     * @param plateauGenerations - Configured threshold to trigger simplify phase (may be non-finite).
     * @param simplifyDuration - Requested simplify phase length in generations (returned when starting).
     * @returns Number of generations the simplify phase should run (0 means "do not start").
     * @example
     * const dur = EvolutionEngine['#maybeStartSimplify'](plateauCount, 10, 5);
     * if (dur > 0) { // begin simplify for dur generations
     *   // ...start simplify loop for `dur` generations
     * }
     * @internal
     */
    static #maybeStartSimplify(plateauCounter, plateauGenerations, simplifyDuration) {
      const observedPlateau = Number.isFinite(plateauCounter) ? Math.max(0, Math.floor(plateauCounter)) : 0;
      const requiredPlateau = Number.isFinite(plateauGenerations) ? Math.max(0, Math.floor(plateauGenerations)) : 0;
      const requestedDuration = Number.isFinite(simplifyDuration) ? Math.max(0, Math.floor(simplifyDuration)) : 0;
      if (observedPlateau < requiredPlateau) return 0;
      try {
        if (typeof window !== "undefined") return 0;
      } catch {
      }
      return requestedDuration;
    }
    /**
     * Run a single simplify/pruning generation if conditions permit.
     *
     * Steps:
     * 1. Normalize inputs and perform fast exits for zero remaining or invalid population.
     * 2. Environment gate: retain existing behaviour that skips heavy pruning in browser-like hosts.
     * 3. Optionally record profiling start time when profiling is enabled.
     * 4. Execute the centralized pruning pass across the population (best-effort per-genome).
     * 5. Record profiling delta and return the remaining simplify generations minus one.
     *
     * Notes:
     * - The method preserves historical behaviour where presence of a `window` global causes an early
     *   return to avoid blocking UI threads. A try/catch is used to safely probe the host environment.
     * - Inputs are defensively coerced to finite non-negative integers to avoid surprising arithmetic.
     *
     * @param neat - NEAT instance exposing a `population` array of genomes to be pruned.
     * @param simplifyRemaining - Number of simplify generations remaining before exiting (will be coerced to integer >= 0).
     * @param simplifyStrategy - Strategy identifier used by pruning routines (string, engine-specific).
     * @param simplifyPruneFraction - Fraction in [0,1] controlling pruning aggressiveness; non-finite values treated as 0.
     * @returns Remaining simplify generations after executing one cycle (0 means no further simplify).
     * @example
     * // Internal usage (pseudo): attempt one simplify generation and update remaining counter
     * const remaining = EvolutionEngine['#runSimplifyCycle'](neatInstance, simplifyRemaining, 'pruneWeak', 0.2);
     * // if remaining === 0 the simplify phase is complete or skipped
     * @internal
     */
    static #runSimplifyCycle(neat, simplifyRemaining, simplifyStrategy, simplifyPruneFraction) {
      const remainingGens = Number.isFinite(simplifyRemaining) ? Math.max(0, Math.floor(simplifyRemaining)) : 0;
      if (remainingGens === 0) return 0;
      if (!neat || !Array.isArray(neat.population) || neat.population.length === 0)
        return 0;
      try {
        if (typeof window !== "undefined") return remainingGens;
      } catch {
      }
      const profilingEnabled = _EvolutionEngine.#PROFILE_ENABLED;
      const profileStartMs = profilingEnabled ? _EvolutionEngine.#PROFILE_T0() : 0;
      _EvolutionEngine.#applySimplifyPruningToPopulation(
        neat,
        simplifyStrategy,
        simplifyPruneFraction
      );
      if (profilingEnabled) {
        const elapsedMs = _EvolutionEngine.#PROFILE_T0() - profileStartMs || 0;
        _EvolutionEngine.#PROFILE_ADD("simplify", elapsedMs);
      }
      return Math.max(0, remainingGens - 1);
    }
    /**
     * Apply Lamarckian (supervised) training to the current population.
     *
     * Description:
     * Runs a short, bounded supervised training pass on each network in the population. This
     * refinement is intentionally conservative (few iterations / small batch) to improve
     * local performance without collapsing evolutionary diversity.
     *
     * Steps:
     * 1. Validate inputs and early-exit for empty population or training set.
     * 2. Optionally down-sample the training set (with replacement) to bound per-generation cost.
     * 3. Iterate each network and run a small training pass. Adjust output biases heuristically.
     * 4. Collect optional training statistics (gradient norm) for telemetry when available.
     * 5. Emit telemetry and return elapsed time when profiling is enabled.
     *
     * @param neat - NEAT instance exposing a `population` array of networks.
     * @param trainingSet - Array of supervised examples (engine-specific format) used for local training.
     * @param iterations - Number of training iterations to run per-network (must be > 0).
     * @param sampleSize - Optional sample size to down-sample `trainingSet` (with replacement). Fractional/invalid treated as no sampling.
     * @param safeWrite - Logging helper used for telemetry lines (string writer).
     * @param profileEnabled - When true, function returns elapsed ms spent training; otherwise returns 0.
     * @param completedGenerations - Generation index used when emitting telemetry lines.
     * @returns Elapsed milliseconds spent in training when profiling is enabled; otherwise 0.
     * @example
     * // Internal usage (pseudo): run a short Lamarckian pass and get elapsed time when profiling
     * const elapsed = EvolutionEngine['#applyLamarckianTraining'](neat, trainExamples, 2, 8, console.log, true, gen);
     * @internal
     */
    static #applyLamarckianTraining(neat, trainingSet, iterations, sampleSize, safeWrite, profileEnabled, completedGenerations) {
      if (!neat || !Array.isArray(neat.population) || neat.population.length === 0)
        return 0;
      if (!Array.isArray(trainingSet) || trainingSet.length === 0) return 0;
      if (!Number.isFinite(iterations) || iterations <= 0) return 0;
      const profileStart = profileEnabled ? _EvolutionEngine.#now() : 0;
      const trainingSetRef = sampleSize && sampleSize > 0 && sampleSize < trainingSet.length ? _EvolutionEngine.#sampleArray(trainingSet, sampleSize) : trainingSet;
      let gradientNormSum = 0;
      let gradientNormSamples = 0;
      const populationRef = neat.population;
      for (const network of populationRef) {
        if (!network) continue;
        try {
          network.train(trainingSetRef, {
            iterations,
            error: _EvolutionEngine.#DEFAULT_TRAIN_ERROR,
            rate: _EvolutionEngine.#DEFAULT_TRAIN_RATE,
            momentum: _EvolutionEngine.#DEFAULT_TRAIN_MOMENTUM,
            batchSize: _EvolutionEngine.#DEFAULT_TRAIN_BATCH_SMALL,
            allowRecurrent: true,
            cost: methods_exports.Cost.softmaxCrossEntropy
          });
          _EvolutionEngine.#adjustOutputBiasesAfterTraining(network);
          try {
            const stats = network.getTrainingStats?.();
            const gradNorm = stats?.gradNorm;
            if (Number.isFinite(gradNorm)) {
              gradientNormSum += gradNorm;
              gradientNormSamples++;
            }
          } catch {
          }
        } catch {
        }
      }
      if (gradientNormSamples > 0) {
        const meanGrad = gradientNormSum / gradientNormSamples;
        safeWrite(
          `[GRAD] gen=${completedGenerations} meanGradNorm=${meanGrad.toFixed(
            4
          )} samples=${gradientNormSamples}
`
        );
      }
      return profileEnabled ? _EvolutionEngine.#now() - profileStart : 0;
    }
    /**
     * Aggregate and emit per-generation telemetry and run collapse/anti-collapse checks.
     *
     * This method centralises all higher-level telemetry duties for a single generation. It is
     * intentionally best-effort: all internal telemetry calls are wrapped in a try/catch so that
     * telemetry failures cannot interrupt the main evolution loop.
     *
     * Steps:
     * 0. Global guard: skip telemetry entirely when `#TELEMETRY_MINIMAL` is enabled.
     * 1. Emit action-entropy metrics (path-based uncertainty).
     * 2. Emit output-bias statistics for the fittest network when available.
     * 3. Compute logits-level statistics and run collapse detection / recovery heuristics.
     * 4. Emit exploration telemetry (unique coverage / progress).
     * 5. Emit diversity metrics (species richness, Simpson index, weight std).
     * 6. Optionally record profiling timings into `#PROFILE_ACCUM`.
     *
     * @param neat - NEAT instance exposing `population` and related internals used by some telemetry probes.
     * @param fittest - The current fittest genome/network (may be undefined during initialization).
     * @param genResult - Per-generation result object (expected to contain `path` and other telemetry fields).
     * @param generationIndex - Completed generation index used in telemetry labels.
     * @param writeLog - Logging helper used to emit telemetry lines (accepts a single string argument).
     * @returns void
     * @example
     * EvolutionEngine['#logGenerationTelemetry'](neat, neat.fittest, genResult, gen, msg => process.stdout.write(msg));
     * @internal
     */
    static #logGenerationTelemetry(neat, fittest, genResult, generationIndex, writeLog) {
      if (_EvolutionEngine.#TELEMETRY_MINIMAL) return;
      const profilingEnabled = _EvolutionEngine.#PROFILE_ENABLED;
      const profilingStart = profilingEnabled ? _EvolutionEngine.#PROFILE_T0() : 0;
      try {
        _EvolutionEngine.#logActionEntropy(genResult, generationIndex, writeLog);
        _EvolutionEngine.#logOutputBiasStats(fittest, generationIndex, writeLog);
        _EvolutionEngine.#logLogitsAndCollapse(
          neat,
          fittest,
          generationIndex,
          writeLog
        );
        _EvolutionEngine.#logExploration(genResult, generationIndex, writeLog);
        _EvolutionEngine.#logDiversity(neat, generationIndex, writeLog);
      } catch {
      }
      if (profilingEnabled) {
        _EvolutionEngine.#PROFILE_ADD(
          "telemetry",
          _EvolutionEngine.#PROFILE_T0() - profilingStart || 0
        );
      }
    }
    /**
     * Emit a compact action-entropy telemetry summary line.
     *
     * Steps:
     * 1. Defensive guards: validate `safeWrite` and read `generationResult.path` safely.
     * 2. Compute action-entropy metrics via `#computeActionEntropy` (pure function).
     * 3. Format a single-line telemetry record and emit it using `safeWrite`.
     *
     * @param generationResult - Per-generation result object (expected to expose `.path` array of visited coordinates).
     * @param gen - Completed generation index used in telemetry labels.
     * @param safeWrite - Writer function that accepts a single-string telemetry line (for example `msg => process.stdout.write(msg)`).
     * @internal
     * @example
     * // Internal usage: write to stdout
     * EvolutionEngine['#logActionEntropy'](genResult, 12, msg => process.stdout.write(msg));
     */
    static #logActionEntropy(generationResult, gen, safeWrite) {
      if (typeof safeWrite !== "function") return;
      const pathRef = generationResult?.path;
      try {
        const stats = _EvolutionEngine.#computeActionEntropy(pathRef);
        const logTag = _EvolutionEngine.#LOG_TAG_ACTION_ENTROPY;
        const entropyNormStr = Number.isFinite(stats?.entropyNorm) ? stats.entropyNorm.toFixed(3) : "0.000";
        const uniqueMovesStr = Number.isFinite(stats?.uniqueMoves) ? String(stats.uniqueMoves) : "0";
        const pathLenStr = Number.isFinite(stats?.pathLen) ? String(stats.pathLen) : "0";
        safeWrite(
          `${logTag} gen=${gen} entropyNorm=${entropyNormStr} uniqueMoves=${uniqueMovesStr} pathLen=${pathLenStr}
`
        );
      } catch {
      }
    }
    /**
     * Emit output-bias statistics for the provided fittest genome's output nodes.
     *
     * Steps:
     * 1. Defensive guards: ensure `safeWrite` is a function and obtain `nodes` from `fittest` safely.
     * 2. Query pooled node indices for outputs using `#getNodeIndicesByType` (non-reentrant scratch buffer).
     * 3. If outputs exist, compute bias statistics via `#computeOutputBiasStats` and format a single-line record.
     * 4. Emit the formatted line via `safeWrite`. All errors are swallowed to keep telemetry best-effort.
     *
     * @param fittest - Candidate genome/network expected to expose a `.nodes` array (may be undefined during init).
     * @param gen - Completed generation index used in telemetry labels.
     * @param safeWrite - Telemetry writer accepting a single string (for example `msg => process.stdout.write(msg)`).
     * @internal
     * @example
     * // Internal use: write bias stats to stdout
     * EvolutionEngine['#logOutputBiasStats'](neat.fittest, 5, msg => process.stdout.write(msg));
     */
    static #logOutputBiasStats(fittest, gen, safeWrite) {
      if (typeof safeWrite !== "function") return;
      const nodesRef = fittest?.nodes ?? [];
      try {
        const outputCount = _EvolutionEngine.#getNodeIndicesByType(
          nodesRef,
          "output"
        );
        if (outputCount <= 0) return;
        const biasStats = _EvolutionEngine.#computeOutputBiasStats(
          nodesRef,
          outputCount
        );
        const tag = _EvolutionEngine.#LOG_TAG_OUTPUT_BIAS;
        const meanStr = Number.isFinite(biasStats?.mean) ? biasStats.mean.toFixed(3) : "0.000";
        const stdStr = Number.isFinite(biasStats?.std) ? biasStats.std.toFixed(3) : "0.000";
        const biasesStr = String(biasStats?.biasesStr ?? "");
        safeWrite(
          `${tag} gen=${gen} mean=${meanStr} std=${stdStr} biases=${biasesStr}
`
        );
      } catch {
      }
    }
    /**
     * Compute and emit logits-level statistics, detect a collapse condition, and trigger
     * anti-collapse recovery when the collapse streak threshold is reached.
     *
     * Steps:
     * 1. Guard & extract the recent output history from the `fittest` candidate.
     * 2. Compute aggregated logit statistics for the recent tail via `#computeLogitStats`.
     * 3. Emit a single-line telemetry record containing means, stds, kurtosis, entropy mean and stability.
     * 4. Detect a collapse when all output stds are below `#LOGSTD_FLAT_THRESHOLD` AND
     *    (entropy mean is low OR decision stability is high). Maintain a collapse streak counter.
     * 5. When the streak reaches `#COLLAPSE_STREAK_TRIGGER`, invoke `#antiCollapseRecovery` to attempt recovery.
     *
     * @param neat - NEAT instance (passed to recovery helper when triggered).
     * @param fittest - Current fittest genome/network which may expose `_lastStepOutputs` (array of output vectors).
     * @param gen - Completed generation index used in telemetry labels and recovery actions.
     * @param safeWrite - Writer accepting a single-string telemetry line (for example `msg => process.stdout.write(msg)`).
     * @internal
     * @example
     * EvolutionEngine['#logLogitsAndCollapse'](neat, neat.fittest, gen, msg => process.stdout.write(msg));
     */
    static #logLogitsAndCollapse(neat, fittest, gen, safeWrite) {
      if (typeof safeWrite !== "function") return;
      try {
        const fullHistory = fittest?._lastStepOutputs ?? _EvolutionEngine.#EMPTY_VEC;
        if (!fullHistory.length) return;
        const recentTail = _EvolutionEngine.#getTail(
          fullHistory,
          _EvolutionEngine.#RECENT_WINDOW
        );
        const logitStats = _EvolutionEngine.#computeLogitStats(recentTail);
        safeWrite(
          `${_EvolutionEngine.#LOG_TAG_LOGITS} gen=${gen} means=${logitStats.meansStr} stds=${logitStats.stdsStr} kurt=${logitStats.kurtStr} entMean=${Number.isFinite(logitStats.entMean) ? logitStats.entMean.toFixed(3) : "0.000"} stability=${Number.isFinite(logitStats.stability) ? logitStats.stability.toFixed(3) : "0.000"} steps=${recentTail.length}
`
        );
        _EvolutionEngine._collapseStreak = _EvolutionEngine._collapseStreak || 0;
        const stdArray = logitStats.stds || [];
        let allStdsBelowThreshold = true;
        for (let stdIndex = 0; stdIndex < stdArray.length; stdIndex++) {
          const stdValue = stdArray[stdIndex];
          if (!(stdValue < _EvolutionEngine.#LOGSTD_FLAT_THRESHOLD)) {
            allStdsBelowThreshold = false;
            break;
          }
        }
        const isCollapsed = allStdsBelowThreshold && (logitStats.entMean < _EvolutionEngine.#ENTROPY_COLLAPSE_THRESHOLD || logitStats.stability > _EvolutionEngine.#STABILITY_COLLAPSE_THRESHOLD);
        if (isCollapsed) _EvolutionEngine._collapseStreak++;
        else _EvolutionEngine._collapseStreak = 0;
        if (_EvolutionEngine._collapseStreak === _EvolutionEngine.#COLLAPSE_STREAK_TRIGGER) {
          _EvolutionEngine.#antiCollapseRecovery(neat, gen, safeWrite);
        }
      } catch {
      }
    }
    /**
     * Emit exploration telemetry: unique coverage, path length, coverage ratio, progress and saturation fraction.
     *
     * Steps:
     * 1. Validate inputs (`safeWrite`) and safely extract `path` and numeric fields from `generationResult`.
     * 2. Compute exploration statistics via `#computeExplorationStats` (returns { unique, pathLen, ratio }).
     * 3. Format a single-line telemetry message with stable numeric formatting and emit via `safeWrite`.
     *
     * @param generationResult - Per-generation result object expected to expose `.path`, `.progress` and optional `.saturationFraction`.
     * @param gen - Completed generation index used in telemetry labels.
     * @param safeWrite - Writer function accepting a single telemetry string (for example `msg => process.stdout.write(msg)`).
     * @internal
     * @example
     * // Internal usage: emit exploration line to stdout
     * EvolutionEngine['#logExploration'](genResult, 7, msg => process.stdout.write(msg));
     */
    static #logExploration(generationResult, gen, safeWrite) {
      if (typeof safeWrite !== "function") return;
      const pathRef = generationResult?.path;
      const rawProgress = generationResult?.progress;
      const rawSatFrac = generationResult?.saturationFraction;
      try {
        const exploration = _EvolutionEngine.#computeExplorationStats(pathRef);
        const tag = "[EXPLORE]";
        const uniqueStr = Number.isFinite(exploration?.unique) ? String(exploration.unique) : "0";
        const pathLenStr = Number.isFinite(exploration?.pathLen) ? String(exploration.pathLen) : "0";
        const ratioStr = Number.isFinite(exploration?.ratio) ? exploration.ratio.toFixed(3) : "0.000";
        const progressStr = Number.isFinite(rawProgress) ? rawProgress.toFixed(1) : "0.0";
        const satFracStr = Number.isFinite(rawSatFrac) ? rawSatFrac.toFixed(3) : "0.000";
        safeWrite(
          `${tag} gen=${gen} unique=${uniqueStr} pathLen=${pathLenStr} ratio=${ratioStr} progress=${progressStr} satFrac=${satFracStr}
`
        );
      } catch {
      }
    }
    /**
     * Emit core diversity metrics for the current population.
     *
     * Steps:
     * 1. Defensive guards: validate `safeWrite` and that `neat` exposes a population.
     * 2. Compute diversity metrics via `#computeDiversityMetrics` (species count, Simpson index, weight std).
     * 3. Format a concise telemetry line with stable numeric formatting and emit via `safeWrite`.
     *
     * @param neat - NEAT instance exposing a `population` array used to compute diversity metrics.
     * @param gen - Completed generation index used in telemetry labels.
     * @param safeWrite - Telemetry writer accepting a single string (for example `msg => process.stdout.write(msg)`).
     * @internal
     * @example
     * // Internal usage: write diversity metrics to stdout
     * EvolutionEngine['#logDiversity'](neatInstance, 42, msg => process.stdout.write(msg));
     */
    static #logDiversity(neat, gen, safeWrite) {
      if (typeof safeWrite !== "function") return;
      if (!neat || !Array.isArray(neat.population)) return;
      try {
        const metrics = _EvolutionEngine.#computeDiversityMetrics(neat);
        const tag = "[DIVERSITY]";
        const speciesCountStr = Number.isFinite(metrics?.speciesUniqueCount) ? String(metrics.speciesUniqueCount) : "0";
        const simpsonStr = Number.isFinite(metrics?.simpson) ? metrics.simpson.toFixed(3) : "0.000";
        const weightStdStr = Number.isFinite(metrics?.wStd) ? metrics.wStd.toFixed(3) : "0.000";
        safeWrite(
          `${tag} gen=${gen} species=${speciesCountStr} simpson=${simpsonStr} weightStd=${weightStdStr}
`
        );
      } catch {
      }
    }
    /**
     * Persist a compact snapshot file when persistence is enabled and cadence matches.
     *
     * Steps:
     * 1. Defensive validation of IO primitives, scheduling cadence and NEAT shape.
     * 2. Start optional profiling window.
     * 3. Populate a pooled snapshot object with scalar metadata and a short telemetry tail.
     * 4. Reuse a pooled top-K buffer to write minimal per-genome metadata for the best genomes.
     * 5. Serialize the compact snapshot JSON and write it to disk using the provided `fs`.
     * 6. Record profiling delta (best-effort) and swallow any IO/errors to avoid destabilizing the loop.
     *
     * @param fs - File-system-like object with `writeFileSync(path, data)` (for example Node's `fs`).
     * @param pathModule - Path-like object exposing `join(...parts)` (for example Node's `path`).
     * @param persistDir - Directory where snapshots should be written; falsy disables persistence.
     * @param persistTopK - How many top genomes to include metadata for (0 disables top list).
     * @param completedGenerations - Current completed generation index (used for filename & metadata).
     * @param persistEvery - Cadence (in generations) at which to persist; <=0 disables persistence.
     * @param neat - NEAT instance exposing a `population` array.
     * @param bestFitness - Best fitness scalar to record in the snapshot metadata.
     * @param simplifyMode - Whether the engine is currently simplifying (recorded for diagnostics/UI).
     * @param plateauCounter - Plateau counter value recorded for diagnostics/UI.
     * @internal
     * @example
     * // Typical Node usage inside engine loop:
     * EvolutionEngine['#persistSnapshotIfNeeded'](require('fs'), require('path'), './snapshots', 5, gen, 10, neat, best, false, 0);
     */
    static #persistSnapshotIfNeeded(fs, pathModule, persistDir, persistTopK, completedGenerations, persistEvery, neat, bestFitness, simplifyMode, plateauCounter) {
      if (!fs || typeof fs.writeFileSync !== "function" || !pathModule || typeof pathModule.join !== "function" || !persistDir || !Number.isFinite(persistEvery) || persistEvery <= 0)
        return;
      if (!Number.isFinite(completedGenerations) || completedGenerations % persistEvery !== 0)
        return;
      if (!neat || !Array.isArray(neat.population) || neat.population.length === 0)
        return;
      try {
        const profileStart = _EvolutionEngine.#PROFILE_ENABLED ? _EvolutionEngine.#PROFILE_T0() : 0;
        const snapshot = _EvolutionEngine.#SCRATCH_SNAPSHOT_OBJ;
        snapshot.generation = completedGenerations;
        snapshot.bestFitness = bestFitness;
        snapshot.simplifyMode = Boolean(simplifyMode);
        snapshot.plateauCounter = Number.isFinite(plateauCounter) ? plateauCounter : 0;
        snapshot.timestamp = Date.now();
        snapshot.telemetryTail = _EvolutionEngine.#collectTelemetryTail(neat, 5);
        const populationRef = neat.population ?? _EvolutionEngine.#EMPTY_VEC;
        const sortedIndices = _EvolutionEngine.#getSortedIndicesByScore(populationRef) ?? _EvolutionEngine.#EMPTY_VEC;
        const normalizedTopK = Math.max(
          0,
          Math.floor(Number.isFinite(persistTopK) ? persistTopK : 0)
        );
        const topLimit = Math.min(normalizedTopK, sortedIndices.length);
        const topBuffer = _EvolutionEngine.#SCRATCH_SNAPSHOT_TOP;
        if (topBuffer.length < topLimit) topBuffer.length = topLimit;
        for (let rank = 0; rank < topLimit; rank++) {
          let entry = topBuffer[rank] ?? (topBuffer[rank] = {});
          const genome = populationRef[sortedIndices[rank]];
          entry.idx = sortedIndices[rank];
          entry.score = genome?.score;
          entry.nodes = genome?.nodes?.length ?? 0;
          entry.connections = genome?.connections?.length ?? 0;
          entry.json = typeof genome?.toJSON === "function" ? genome.toJSON() : void 0;
        }
        topBuffer.length = topLimit;
        snapshot.top = topBuffer;
        const snapshotFilePath = pathModule.join(
          persistDir,
          `snapshot_gen${completedGenerations}.json`
        );
        fs.writeFileSync(snapshotFilePath, JSON.stringify(snapshot));
        if (_EvolutionEngine.#PROFILE_ENABLED) {
          _EvolutionEngine.#PROFILE_ADD(
            "snapshot",
            _EvolutionEngine.#PROFILE_T0() - profileStart || 0
          );
        }
      } catch {
      }
    }
    /**
     * Collect a short telemetry tail (last N entries) from a NEAT instance if available.
     *
     * Steps:
     * 1. Validate that `neat` exists and exposes a callable `getTelemetry` method.
     * 2. Normalise `tailLength` to a non-negative integer (floor) with a sensible default.
     * 3. Call `neat.getTelemetry()` inside a try/catch to avoid propagation of telemetry errors.
     * 4. If telemetry is an array, return the last `tailLength` entries via `#getTail`; otherwise return the raw value.
     *
     * Behavioural notes:
     * - This helper is best-effort: any thrown error from `getTelemetry` will be swallowed and `undefined` returned.
     * - When the telemetry value is an array we reuse the pooled tail helper to avoid allocations.
     *
     * @param neat - NEAT instance that may implement `getTelemetry(): unknown`.
     * @param tailLength - Desired tail length (floored to integer >= 0). Defaults to 10 when invalid.
     * @returns An array containing the last `tailLength` telemetry entries when telemetry is an array,
     *          the raw telemetry value when non-array, or `undefined` on missing API / errors.
     * @example
     * // Internal usage: request last 5 telemetry entries when available
     * const tail = EvolutionEngine['#collectTelemetryTail'](neatInstance, 5);
     * @internal
     */
    static #collectTelemetryTail(neat, tailLength = 10) {
      if (!neat || typeof neat.getTelemetry !== "function") return void 0;
      const normalizedTailLength = Number.isFinite(tailLength) ? Math.max(0, Math.floor(tailLength)) : 10;
      try {
        const telemetryRaw = neat.getTelemetry?.();
        if (Array.isArray(telemetryRaw)) {
          return _EvolutionEngine.#getTail(
            telemetryRaw,
            normalizedTailLength
          );
        }
        return telemetryRaw;
      } catch (err) {
        return void 0;
      }
    }
    /**
     * Compute decision stability over a recent sequence of output vectors.
     *
     * Definition: stability = (# of consecutive pairs with identical argmax) / (total consecutive pairs).
     * For a sequence of N decisions there are (N-1) consecutive pairs; we skip the first vector when counting pairs.
     * Returns 0 when fewer than 2 vectors.
     *
     * Performance notes:
     * - Typical RECENT_WINDOW is small (<= 40) and ACTION_DIM is a fixed 4 for ASCII maze (N,E,S,W); cost is negligible so
     *   caching / memoization would add overhead with no throughput benefit. We therefore compute on demand.
     * - Specialized unrolled path for ACTION_DIM === 4 (the only case here) reduces loop overhead & branch mispredictions.
     * - No allocations; operates purely on provided arrays. If ACTION_DIM ever changes, the generic path still works.
     *
     * Complexity: O(R * D) where R = recent.length, D = ACTION_DIM (constant 4).
     * Determinism: Deterministic given identical input vectors.
     * Reentrancy: Pure function (no shared state touched).
     *
     * @param recent - Array of recent output activation vectors (each length = ACTION_DIM expected).
     * @returns Stability ratio in [0,1].
     * @internal
     */
    static #computeDecisionStability(recent) {
      const sequenceLength = recent?.length || 0;
      if (sequenceLength < 2) return 0;
      let stablePairCount = 0;
      let pairCount = 0;
      let previousArgmax = -1;
      const actionDim = _EvolutionEngine.#ACTION_DIM;
      const unroll = actionDim === 4;
      for (let rowIndex = 0; rowIndex < sequenceLength; rowIndex++) {
        const row = recent[rowIndex];
        if (!row || row.length === 0) continue;
        let argmax;
        if (unroll && row.length >= 4) {
          let bestVal = row[0];
          argmax = 0;
          const v1 = row[1];
          if (v1 > bestVal) {
            bestVal = v1;
            argmax = 1;
          }
          const v2 = row[2];
          if (v2 > bestVal) {
            bestVal = v2;
            argmax = 2;
          }
          const v3 = row[3];
          if (v3 > bestVal) {
            argmax = 3;
          }
        } else {
          argmax = 0;
          let bestVal = row[0];
          for (let outputIndex = 1; outputIndex < actionDim && outputIndex < row.length; outputIndex++) {
            const candidate = row[outputIndex];
            if (candidate > bestVal) {
              bestVal = candidate;
              argmax = outputIndex;
            }
          }
        }
        if (previousArgmax !== -1) {
          pairCount++;
          if (previousArgmax === argmax) stablePairCount++;
        }
        previousArgmax = argmax;
      }
      return pairCount ? stablePairCount / pairCount : 0;
    }
    /**
     * Compute the (base-e) softmax entropy of a single activation vector and normalize it to [0,1].
     *
     * Educational step-by-step outline (softmax + entropy):
     * 1. Defensive checks & determine effective length k: If vector empty or length < 2, entropy is 0 (no uncertainty).
     * 2. Numerical stabilisation: Subtract the maximum activation before exponentiating (log-sum-exp trick) to avoid overflow.
     * 3. Exponentiation: Convert centered logits to unnormalized positive scores e^{x_i - max}.
     * 4. Normalization: Sum the scores and divide each by the sum to obtain probabilities p_i.
     * 5. Shannon entropy: H = -Σ p_i log(p_i); ignore p_i == 0 (contributes 0 by continuity).
     * 6. Normalization to [0,1]: Divide by log(k); for k=4 we use a cached inverse (#INV_LOG4) to avoid division & log.
     *
     * Implementation details:
     * - Provides a specialized unrolled fast path for the very common ACTION_DIM=4 case.
     * - Uses the caller-provided scratch buffer `buf` to store exponentials (avoids per-call allocation).
     * - Previously a small bug omitted the p1 contribution in the 4-way path; fixed here.
     * - Pure & deterministic: no side effects on shared state.
     *
     * @param v Activation vector (logits) whose softmax entropy we want.
     * @param buf Scratch Float64Array with capacity >= v.length used to hold exponentials.
     * @returns Normalized entropy in [0,1]. 0 => fully certain (one probability ~1), 1 => uniform distribution.
     * @internal
     */
    static #softmaxEntropyFromVector(v, buf) {
      if (!v || !v.length) return 0;
      const k = Math.min(v.length, buf.length);
      if (k <= 1) return 0;
      if (k === 4) {
        const v0 = v[0] || 0;
        const v1 = v[1] || 0;
        const v2 = v[2] || 0;
        const v3 = v[3] || 0;
        let maxVal2 = v0;
        if (v1 > maxVal2) maxVal2 = v1;
        if (v2 > maxVal2) maxVal2 = v2;
        if (v3 > maxVal2) maxVal2 = v3;
        const e0 = Math.exp(v0 - maxVal2);
        const e1 = Math.exp(v1 - maxVal2);
        const e2 = Math.exp(v2 - maxVal2);
        const e3 = Math.exp(v3 - maxVal2);
        const sum2 = e0 + e1 + e2 + e3 || 1;
        const p0 = e0 / sum2;
        const p1 = e1 / sum2;
        const p2 = e2 / sum2;
        const p3 = e3 / sum2;
        let entropyAccumulator2 = 0;
        if (p0 > 0) entropyAccumulator2 += -p0 * Math.log(p0);
        if (p1 > 0) entropyAccumulator2 += -p1 * Math.log(p1);
        if (p2 > 0) entropyAccumulator2 += -p2 * Math.log(p2);
        if (p3 > 0) entropyAccumulator2 += -p3 * Math.log(p3);
        return entropyAccumulator2 * _EvolutionEngine.#INV_LOG4;
      }
      let maxVal = -Infinity;
      for (let actionIndex = 0; actionIndex < k; actionIndex++) {
        const value = v[actionIndex] || 0;
        if (value > maxVal) maxVal = value;
      }
      let sum = 0;
      for (let actionIndex = 0; actionIndex < k; actionIndex++) {
        const expValue = Math.exp((v[actionIndex] || 0) - maxVal);
        buf[actionIndex] = expValue;
        sum += expValue;
      }
      if (!sum) sum = 1;
      let entropyAccumulator = 0;
      for (let actionIndex = 0; actionIndex < k; actionIndex++) {
        const probability = buf[actionIndex] / sum;
        if (probability > 0)
          entropyAccumulator += -probability * Math.log(probability);
      }
      const denom = Math.log(k);
      return denom > 0 ? entropyAccumulator / denom : 0;
    }
    /**
     * Join the first `len` numeric entries of an array-like into a comma-separated string
     * with fixed decimal precision.
     *
     * Steps (educational):
     * 1. Normalize parameters: clamp `len` to the provided array-like length; clamp `digits` to [0, 20].
     * 2. Grow (geometric) the shared scratch string array if capacity is insufficient.
     * 3. Format each numeric value via `toFixed(digits)` directly into the scratch slots (no interim allocations).
     * 4. Temporarily set the scratch logical length to `len` and `Array.prototype.join(',')` to build the output.
     * 5. Restore the original scratch length (capacity preserved) and return the joined string.
     *
     * Complexity: O(n) time, O(1) additional space (amortized) beyond the shared scratch array.
     * Determinism: Deterministic for identical inputs (`toFixed` stable for finite numbers).
     * Reentrancy: Non-reentrant (shared `#SCRATCH_STR` buffer). Do not invoke concurrently from parallel contexts.
     *
     * @param arrLike Array-like source of numbers (only indices < len are read).
     * @param len Intended number of elements to serialize; clamped to available length.
     * @param digits Fixed decimal places (0–20). Values outside are clamped.
     * @returns Comma-separated string or empty string when `len <= 0` after normalization.
     */
    static #joinNumberArray(arrLike, len, digits = 3) {
      if (!arrLike) return "";
      const availableLength = arrLike.length >>> 0;
      if (!Number.isFinite(len) || len <= 0 || availableLength === 0) return "";
      const effectiveLength = len > availableLength ? availableLength : len;
      let fixedDigits = digits;
      if (!Number.isFinite(fixedDigits)) fixedDigits = 0;
      if (fixedDigits < 0) fixedDigits = 0;
      else if (fixedDigits > 20) fixedDigits = 20;
      if (effectiveLength > _EvolutionEngine.#SCRATCH_STR.length) {
        const nextSize = 1 << Math.ceil(Math.log2(effectiveLength));
        _EvolutionEngine.#SCRATCH_STR = new Array(nextSize);
      }
      const stringScratch = _EvolutionEngine.#SCRATCH_STR;
      for (let valueIndex = 0; valueIndex < effectiveLength; valueIndex++) {
        const rawValue = arrLike[valueIndex] ?? 0;
        stringScratch[valueIndex] = Number.isFinite(rawValue) ? rawValue.toFixed(fixedDigits) : "NaN";
      }
      const priorLength = stringScratch.length;
      stringScratch.length = effectiveLength;
      const joined = stringScratch.join(",");
      stringScratch.length = priorLength;
      return joined;
    }
    /**
     * Extract the last `count` items from an input array into a pooled scratch buffer (no new allocation).
     *
     * Educational steps:
     * 1. Validate & normalize parameters: non-array, empty, non-positive, or non-finite counts -> empty result. Clamp
     *    `count` to the source length and floor fractional values.
     * 2. Ensure pooled scratch buffer (#SCRATCH_TAIL) has sufficient capacity; grow geometrically (next power-of-two)
     *    so resizes are amortized and rare.
     * 3. Copy the tail slice elements into the scratch buffer with a tight loop (avoids `slice()` allocation).
     * 4. Set the logical length of the scratch buffer to the number of copied elements and return it.
     *
     * Complexity: O(k) where k = min(count, source length). Amortized O(1) extra space beyond the shared buffer.
     * Determinism: Deterministic given identical input array contents and `count`.
     * Reentrancy: Non-reentrant (returns a shared pooled buffer). Callers MUST copy (`slice()` / spread) if they need
     *             to retain contents across another engine call that may reuse the scratch.
     * Mutability: Returned array is mutable; mutations will affect the scratch buffer for subsequent calls.
     *
     * @param arr Source array reference.
     * @param n Desired tail length (floored; negative / non-finite treated as 0).
     * @returns Pooled ephemeral array containing the last `min(n, arr.length)` elements (or empty array literal when 0).
     * @internal
     */
    static #getTail(arr, n) {
      if (!Array.isArray(arr) || arr.length === 0 || !Number.isFinite(n) || n <= 0)
        return [];
      const desired = Math.floor(n);
      const takeCount = desired >= arr.length ? arr.length : desired;
      if (takeCount === 0) return [];
      if (takeCount > _EvolutionEngine.#SCRATCH_TAIL.length) {
        const nextSize = 1 << Math.ceil(Math.log2(takeCount));
        _EvolutionEngine.#SCRATCH_TAIL = new Array(nextSize);
      }
      const tailBuffer = _EvolutionEngine.#SCRATCH_TAIL;
      const startIndex = arr.length - takeCount;
      for (let elementIndex = 0; elementIndex < takeCount; elementIndex++) {
        tailBuffer[elementIndex] = arr[startIndex + elementIndex];
      }
      tailBuffer.length = takeCount;
      return tailBuffer;
    }
    /** Delegate to MazeUtils.pushHistory to keep bounded history semantics. @internal */
    static #pushHistory(buf, v, maxLen) {
      return MazeUtils.pushHistory(buf, v, maxLen);
    }
    /**
     * Re-center (demean) output node biases in-place and clamp them to a safe absolute range.
     *
     * Steps:
     * 1. Collect indices of output nodes into the shared scratch index buffer (#SCRATCH_NODE_IDX).
     * 2. Compute mean and (sample) standard deviation of their biases via Welford's online algorithm (single pass).
     * 3. Subtract the mean from each bias (re-centering) and clamp to ±#OUTPUT_BIAS_CLAMP to avoid extreme drift.
     * 4. Persist lightweight stats on the network object as `_outputBiasStats` for telemetry/logging.
     *
     * Rationale: Keeping output biases centered reduces systematic preference for any action direction emerging
     * from cumulative mutation drift, improving exploration signal quality without resetting useful relative offsets.
     *
     * Complexity: O(O) where O = number of output nodes. Memory: no new allocations (shared scratch indices reused).
     * Determinism: Deterministic given identical input network state. Reentrancy: Non-reentrant (shared scratch buffer).
     * Defensive Behavior: Silently no-ops if network shape unexpected; swallows errors to avoid destabilizing evolution loop.
     *
     * @param network Network whose output node biases will be recentred.
     * @internal
     */
    static #centerOutputBiases(network) {
      try {
        const nodeList = network?.nodes ?? _EvolutionEngine.#EMPTY_VEC;
        const totalNodeCount = nodeList.length | 0;
        if (totalNodeCount === 0) return;
        let outputNodeCount = 0;
        for (let nodeIndex = 0; nodeIndex < totalNodeCount; nodeIndex++) {
          const candidateNode = nodeList[nodeIndex];
          if (candidateNode && candidateNode.type === "output") {
            _EvolutionEngine.#SCRATCH_NODE_IDX[outputNodeCount++] = nodeIndex;
          }
        }
        if (outputNodeCount === 0) return;
        let meanBias = 0;
        let sumSquaredDiffs = 0;
        for (let outputIndex = 0; outputIndex < outputNodeCount; outputIndex++) {
          const nodeIdx = _EvolutionEngine.#SCRATCH_NODE_IDX[outputIndex];
          const biasValue = Number(nodeList[nodeIdx].bias) || 0;
          const sampleCount = outputIndex + 1;
          const delta = biasValue - meanBias;
          meanBias += delta / sampleCount;
          sumSquaredDiffs += delta * (biasValue - meanBias);
        }
        const stdBias = outputNodeCount ? Math.sqrt(sumSquaredDiffs / outputNodeCount) : 0;
        const clampAbs = _EvolutionEngine.#OUTPUT_BIAS_CLAMP;
        for (let outputIndex = 0; outputIndex < outputNodeCount; outputIndex++) {
          const nodeIdx = _EvolutionEngine.#SCRATCH_NODE_IDX[outputIndex];
          const original = Number(nodeList[nodeIdx].bias) || 0;
          let adjusted = original - meanBias;
          if (adjusted > clampAbs) adjusted = clampAbs;
          else if (adjusted < -clampAbs) adjusted = -clampAbs;
          nodeList[nodeIdx].bias = adjusted;
        }
        network._outputBiasStats = { mean: meanBias, std: stdBias };
      } catch {
      }
    }
    /**
     * Prune (disable) a fraction of the weakest enabled connections in a genome according to a strategy.
     *
     * High‑level flow:
     * 1. Validate inputs & normalize prune fraction (clamp into [0,1]); exit early for degenerate cases.
     * 2. Collect enabled connections into a pooled candidate buffer (no fresh allocations, reused scratch array).
     * 3. Compute how many to prune: floor(enabled * fraction) but ensure at least 1 when fraction > 0.
     * 4. Order candidates per strategy (e.g. prefer recurrent links first) using small‑array insertion sorts / partitions.
     * 5. Disable (set enabled = false) the selected weakest connections in place (no structural array mutation).
     *
     * Rationale:
     * - Periodic pruning combats structural bloat / drift, helping convergence and interpretability.
     * - In‑place flagging preserves indices referenced elsewhere (e.g. mutation bookkeeping) and avoids churn.
     * - Strategy indirection lets us bias removal (recurrent first, etc.) without duplicating the core pruning loop.
     *
     * Strategies supported (case‑sensitive):
     * - "weakRecurrentPreferred" : Two‑phase ordering. Recurrent OR gater connections are partitioned to the front, each partition then sorted by |weight| ascending so recurrent/gater weakest go first.
     * - (any other string / default) : All enabled connections globally ordered by |weight| ascending.
     *
     * Determinism: Deterministic for a fixed genome state and strategy (sorting by stable numeric key, insertion sort chosen for small E ensures predictable behavior). If two connections share identical |weight| their relative order may depend on initial array order (stable enough for internal use).
     * Reentrancy: Uses class‑pooled scratch buffers (#SCRATCH_CONN_CAND, #SCRATCH_CONN_FLAGS); not safe for concurrent calls.
     * Complexity: O(E log E) worst via native sort fallback for larger batches; predominantly O(E^2) small‑E insertion sorts (E = enabled connections) with tiny constants typical for NEAT genomes.
     * Memory: O(1) additional heap (scratch arrays reused, geometric growth elsewhere handled centrally).
     * Failure Handling: Silently swallows per‑genome errors (best‑effort maintenance; evolution loop stability prioritized).
     *
     * @param genome Genome object whose `connections` array will be examined. Each connection is expected to expose:
     *  - weight: number (signed; magnitude used for weakness ordering)
     *  - enabled: boolean flag (connections with enabled === false are ignored; flag is flipped to disable)
     *  - recurrent / gater (optional): truthy flags used by the recurrent‑preferential strategy
     *  Additional properties (from, to, etc.) are ignored here.
     * @param simplifyStrategy Strategy key controlling candidate ordering. Recognized: "weakRecurrentPreferred" (recurrent first); any other value falls back to pure weakest‑by‑|weight| ordering.
     * @param simplifyPruneFraction Fraction of enabled connections to prune (0..1). Values outside range are clamped. A positive fraction that produces a 0 count still forces pruning of 1 connection (progress guarantee). 0 or non‑finite => no‑op.
     *
     * @example
     * // Internally during simplify phase:
     * EvolutionEngine['#pruneWeakConnectionsForGenome'](genome, 'weakRecurrentPreferred', 0.15);
     *
     * @internal
     */
    static #pruneWeakConnectionsForGenome(genome, simplifyStrategy, simplifyPruneFraction) {
      try {
        if (!genome || !Array.isArray(genome.connections)) return;
        const rawFraction = Number.isFinite(simplifyPruneFraction) ? simplifyPruneFraction : 0;
        if (rawFraction <= 0) return;
        const allConnections = genome.connections;
        let candidateConnections = _EvolutionEngine.#collectEnabledConnections(
          allConnections
        );
        const enabledConnectionCount = candidateConnections.length;
        if (enabledConnectionCount === 0) return;
        const clampedFraction = rawFraction >= 1 ? 1 : rawFraction < 0 ? 0 : rawFraction;
        let pruneTarget = Math.floor(enabledConnectionCount * clampedFraction);
        if (clampedFraction > 0 && pruneTarget === 0) pruneTarget = 1;
        if (pruneTarget <= 0) return;
        candidateConnections = _EvolutionEngine.#sortCandidatesByStrategy(
          candidateConnections,
          simplifyStrategy
        );
        _EvolutionEngine.#disableSmallestEnabledConnections(
          candidateConnections,
          Math.min(pruneTarget, candidateConnections.length)
        );
      } catch {
      }
    }
    /**
     * Collect all currently enabled connections from a genome connection array into a pooled scratch buffer.
     *
     * Steps:
     * 1. Validate & early exit: non-array or empty -> return new empty literal (avoids exposing scratch).
     * 2. Reset pooled scratch buffer (#SCRATCH_CONN_CAND) logical length to 0 (capacity retained for reuse).
     * 3. Linear scan: push each connection whose `enabled !== false` (treats missing / undefined as enabled for legacy compatibility).
     * 4. Return the pooled scratch array (EPHEMERAL) containing references to the enabled connection objects.
     *
     * Rationale:
     * - Centralizes enabled filtering logic so pruning / analytics share identical semantics.
     * - Reuses a single array instance to avoid transient garbage during frequent simplify phases.
     * - Keeps semantics liberal (`enabled !== false`) to treat absent flags as enabled (historical behavior preserved).
     *
     * Determinism: Deterministic for a fixed input ordering (stable one-pass filter, no reordering).
     * Reentrancy: Not reentrant — returns a shared pooled buffer; callers must copy if they need persistence across nested engine calls.
     * Complexity: O(E) where E = total connections scanned.
     * Memory: O(1) additional heap; capacity grows geometrically elsewhere and is retained.
     *
     * @param connectionsSource Array of connection objects; each may expose `enabled` boolean (false => filtered out).
     * @returns Pooled ephemeral array of enabled connections (DO NOT mutate length; copy if storing long-term).
     * @example
     * const enabled = EvolutionEngine['#collectEnabledConnections'](genome.connections);
     * const stableCopy = enabled.slice(); // only if retention needed
     * @internal
     */
    static #collectEnabledConnections(connectionsSource) {
      if (!Array.isArray(connectionsSource) || connectionsSource.length === 0)
        return [];
      const candidateBuffer = _EvolutionEngine.#SCRATCH_CONN_CAND;
      candidateBuffer.length = 0;
      for (let connectionIndex = 0; connectionIndex < connectionsSource.length; connectionIndex++) {
        const candidateConnection = connectionsSource[connectionIndex];
        if (candidateConnection && candidateConnection.enabled !== false)
          candidateBuffer.push(candidateConnection);
      }
      return candidateBuffer;
    }
    /**
     * Collect enabled outgoing connections from a hidden node that terminate at any output node.
     *
     * Educational steps:
     * 1. Validate inputs & early-exit: invalid node / connections / zero outputs => fresh empty array literal
     *    (avoid exposing pooled scratch for erroneous calls).
     * 2. Clamp effective output count to available scratch index capacity and `nodesRef` length (defensive bounds).
     * 3. Reset pooled result buffer (#SCRATCH_HIDDEN_OUT) by setting length=0 (capacity retained for reuse).
     * 4. Iterate enabled outgoing connections; for each, linearly scan output indices (tiny constant factor) to
     *    detect whether its `to` endpoint references one of the output nodes; push on first match and break.
     * 5. Return pooled buffer (EPHEMERAL). Callers MUST copy if they need persistence beyond next engine helper.
     *
     * Rationale:
     * - Output node count is small (typically 4), so an inner linear scan is faster and allocation-free compared
     *   to constructing a Set/Map each time.
     * - Pooled buffer eliminates per-call garbage during simplify/pruning phases where this helper can be hot.
     * - Defensive clamping prevents out-of-bounds reads if caller overstates `outputCount`.
     *
     * Determinism: Deterministic given stable ordering of hiddenNode.connections.out and scratch index ordering.
     * Reentrancy: Not reentrant (shared scratch buffer). Do not call concurrently.
     * Complexity: O(E * O) where E = enabled outgoing connections, O = outputCount (tiny constant).
     * Memory: O(1) additional heap (buffer reused). No new allocations after initial growth elsewhere.
     * Failure Handling: Returns [] on invalid inputs instead of exposing scratch to minimize accidental mutation.
     *
     * @param hiddenNode Hidden node object with structure `{ connections: { out: Connection[] } }`.
     * @param nodesRef Full node array; indices stored in `#SCRATCH_NODE_IDX` resolve into this array.
     * @param outputCount Declared number of output nodes (will be clamped to safe range).
     * @returns Pooled ephemeral array of connections from `hiddenNode` to any output node.
     * @example
     * const outs = EvolutionEngine['#collectHiddenToOutputConns'](hNode, nodes, outputCount);
     * const stable = outs.slice(); // copy if retention required
     * @internal
     */
    static #collectHiddenToOutputConns(hiddenNode, nodesRef, outputCount) {
      if (!hiddenNode || !hiddenNode.connections || !Array.isArray(nodesRef) || nodesRef.length === 0 || !Number.isFinite(outputCount) || outputCount <= 0) {
        return [];
      }
      const maxScratch = _EvolutionEngine.#SCRATCH_NODE_IDX.length;
      const effectiveOutputCount = Math.min(
        outputCount | 0,
        maxScratch,
        nodesRef.length
      );
      if (effectiveOutputCount <= 0) return [];
      const hiddenOutBuffer = _EvolutionEngine.#SCRATCH_HIDDEN_OUT;
      hiddenOutBuffer.length = 0;
      const outgoing = hiddenNode.connections.out ?? _EvolutionEngine.#EMPTY_VEC;
      for (let outIndex = 0; outIndex < outgoing.length; outIndex++) {
        const candidate = outgoing[outIndex];
        if (!candidate || candidate.enabled === false) continue;
        for (let outputIndex = 0; outputIndex < effectiveOutputCount; outputIndex++) {
          const nodeIdx = _EvolutionEngine.#SCRATCH_NODE_IDX[outputIndex];
          const targetNode = nodesRef[nodeIdx];
          if (candidate.to === targetNode) {
            hiddenOutBuffer.push(candidate);
            break;
          }
        }
      }
      return hiddenOutBuffer;
    }
    /**
     * Order (in-place) a buffer of enabled candidate connections according to a pruning strategy.
     *
     * Strategies:
     *  - "weakRecurrentPreferred": Two-phase ordering. First, a linear partition brings recurrent OR gater
     *    connections ( (from === to) || gater ) to the front preserving relative order within each group (stable-ish
     *    via single forward pass + conditional swaps). Then each partition (recurrent/gater segment and the remainder)
     *    is insertion-sorted independently by ascending absolute weight (|weight| smallest first).
     *  - (default / anything else): Entire array insertion-sorted by ascending absolute weight.
     *
     * Returned array is the same reference mutated in place (allows fluent internal usage). This helper never allocates
     * a new array: it relies on small-N characteristics of genomes during simplify phases, making insertion sort's
     * O(n^2) worst-case acceptable with very low constants (n typically << 128 for enabled connection subsets).
     *
     * Steps (generic):
     * 1. Validate input; return as-is for non-arrays / empty arrays.
     * 2. If strategy is recurrent-preferential: partition then insertion-sort both segments.
     * 3. Else: insertion-sort the entire buffer.
     * 4. Return mutated buffer reference.
     *
     * Rationale:
     * - Partition + localized sorts avoid a full compare function invocation for every cross-group pair when we wish
     *   to bias pruning away from recurrent loops (or explicitly target them first).
     * - Insertion sort avoids engine-level allocations and outperforms generic sort for the very small candidate sets
     *   typically encountered during pruning sessions.
     *
     * Determinism: Deterministic given a stable initial ordering and identical connection properties. Ties (equal |weight|)
     * retain relative order within each partition thanks to forward-scanning partition & stable insertion strategy for
     * equal magnitudes (we only shift while strictly greater).
     * Complexity: O(n^2) worst-case (n = candidates length) but n is small; partition pass is O(n).
     * Memory: O(1) additional (in-place swaps only). No allocations.
     * Reentrancy: Pure w.r.t. global engine state; mutates only the provided array reference.
     *
     * @param candidateConnections Array of connection objects (mutated in-place) to order for pruning selection.
     * @param strategyKey Strategy discriminator string ("weakRecurrentPreferred" or fallback ordering).
     * @returns Same reference to `candidateConnections`, ordered per strategy.
     * @example
     * EvolutionEngine['#sortCandidatesByStrategy'](buf, 'weakRecurrentPreferred');
     * @internal
     */
    static #sortCandidatesByStrategy(candidateConnections, strategyKey) {
      if (!Array.isArray(candidateConnections) || candidateConnections.length === 0)
        return candidateConnections;
      if (strategyKey === "weakRecurrentPreferred") {
        let partitionWriteIndex = 0;
        for (let scanIndex = 0; scanIndex < candidateConnections.length; scanIndex++) {
          const connectionCandidate = candidateConnections[scanIndex];
          if (connectionCandidate && (connectionCandidate.from === connectionCandidate.to || connectionCandidate.gater)) {
            if (scanIndex !== partitionWriteIndex) {
              const tmpConnection = candidateConnections[partitionWriteIndex];
              candidateConnections[partitionWriteIndex] = candidateConnections[scanIndex];
              candidateConnections[scanIndex] = tmpConnection;
            }
            partitionWriteIndex++;
          }
        }
        _EvolutionEngine.#insertionSortByAbsWeight(
          candidateConnections,
          0,
          partitionWriteIndex
        );
        _EvolutionEngine.#insertionSortByAbsWeight(
          candidateConnections,
          partitionWriteIndex,
          candidateConnections.length
        );
        return candidateConnections;
      }
      _EvolutionEngine.#insertionSortByAbsWeight(
        candidateConnections,
        0,
        candidateConnections.length
      );
      return candidateConnections;
    }
    /**
     * In‑place insertion sort of a slice of a candidate connection buffer by ascending absolute weight.
     *
     * Design / behavior:
     * - Stable for ties: when two connections have identical |weight| their original relative order is preserved
     *   because we only shift elements whose |weight| is strictly greater than the candidate being inserted.
     * - Bounds are treated as a half‑open interval [startIndex, endExclusive). Out‑of‑range / degenerate ranges
     *   (null buffer, start >= endExclusive, slice length < 2) return immediately.
     * - Missing / non‑finite weights are coerced to 0 via `Math.abs(candidate?.weight || 0)` keeping semantics
     *   consistent with liberal pruning logic elsewhere.
     * - Chosen because candidate sets during simplify phases are typically small (tens, rarely > 128); insertion
     *   sort outperforms generic `Array.prototype.sort` for small N while avoiding allocation and comparator indirection.
     *
     * Complexity: O(k^2) worst‑case (k = endExclusive - startIndex) with tiny constants for typical k.
     * Memory: O(1) extra (element temp + indices). No allocations.
     * Determinism: Fully deterministic for a fixed input slice content.
     * Reentrancy: Pure (mutates only provided buffer slice; no shared global scratch accessed).
     *
     * @param connectionsBuffer Buffer containing connection objects with a numeric `weight` property.
     * @param startIndex Inclusive start index of the slice to sort (negative values coerced to 0).
     * @param endExclusive Exclusive end index (values > buffer length clamped). If <= startIndex the call is a no‑op.
     * @internal
     */
    static #insertionSortByAbsWeight(connectionsBuffer, startIndex, endExclusive) {
      if (!Array.isArray(connectionsBuffer)) return;
      const length = connectionsBuffer.length;
      if (length === 0) return;
      let from = Number.isFinite(startIndex) ? startIndex | 0 : 0;
      let to = Number.isFinite(endExclusive) ? endExclusive | 0 : 0;
      if (from < 0) from = 0;
      if (to > length) to = length;
      if (to - from < 2) return;
      for (let scanIndex = from + 1; scanIndex < to; scanIndex++) {
        const candidateConnection = connectionsBuffer[scanIndex];
        const candidateAbsWeight = Math.abs(
          candidateConnection && Number.isFinite(candidateConnection.weight) ? candidateConnection.weight : 0
        );
        let shiftIndex = scanIndex - 1;
        while (shiftIndex >= from) {
          const probe = connectionsBuffer[shiftIndex];
          const probeAbsWeight = Math.abs(
            probe && Number.isFinite(probe.weight) ? probe.weight : 0
          );
          if (probeAbsWeight <= candidateAbsWeight) break;
          connectionsBuffer[shiftIndex + 1] = probe;
          shiftIndex--;
        }
        connectionsBuffer[shiftIndex + 1] = candidateConnection;
      }
    }
    /**
     * Maximum candidate length (inclusive) at which bulk pruning still prefers insertion sort
     * over native Array.prototype.sort for determinism and lower overhead on very small arrays.
     * @internal
     */
    static #PRUNE_BULK_INSERTION_MAX = 64;
    /**
     * Disable (set enabled = false) the weakest enabled connections up to a target count.
     *
     * Two operating modes chosen adaptively by `pruneCount` vs active candidate size:
     * 1. Bulk mode (pruneCount >= activeEnabled/2): Fully order candidates by |weight| then disable
     *    the first pruneCount entries. Uses insertion sort for small N (<= #PRUNE_BULK_INSERTION_MAX)
     *    else a single native sort call.
     * 2. Sparse mode (pruneCount < activeEnabled/2): Repeated selection of current minimum |weight|
     *    without fully sorting (multi-pass partial selection). After each disable we swap the last
     *    active element into the removed slot (shrinking window) to avoid O(n) splices.
     *
     * Rationale:
     * - Avoids the O(n log n) cost of a full sort when disabling only a small fraction (selection
     *   becomes O(k * n) but k << n). When pruning many, a single ordering is cheaper.
     * - In-place modification preserves object identity and external references.
     * - Liberal enabled check (enabled !== false) matches collection semantics.
     * - Uses a reusable `Uint8Array` (#SCRATCH_CONN_FLAGS) resized geometrically (currently only
     *   cleared here—reserved for potential future marking/telemetry without reallocation).
     *
     * Complexity:
     * - Bulk: O(n^2) for insertion path small n, else O(n log n) via native sort.
     * - Sparse: O(k * n) worst (k = pruneCount) with shrinking n after each removal (average slightly better).
     * Memory: O(1) additional (reuses shared scratch flags; no new arrays created).
     * Determinism: Deterministic for identical candidate ordering and weights (native sort comparator is pure).
     * Reentrancy: Not safe for concurrent calls (shared scratch flags buffer reused & zeroed).
     * Failure Handling: Silently no-ops on invalid inputs.
     *
     * @param candidateConnections Array containing candidate connection objects (each with `weight` & `enabled`).
     * @param pruneCount Number of weakest enabled connections to disable (clamped to [0, candidateConnections.length]).
     * @internal
     */
    static #disableSmallestEnabledConnections(candidateConnections, pruneCount) {
      if (!Array.isArray(candidateConnections) || !candidateConnections.length)
        return;
      if (!Number.isFinite(pruneCount) || pruneCount <= 0) return;
      const totalCandidates = candidateConnections.length;
      if (pruneCount >= totalCandidates) pruneCount = totalCandidates;
      let connectionFlags = _EvolutionEngine.#SCRATCH_CONN_FLAGS;
      if (totalCandidates > connectionFlags.length) {
        _EvolutionEngine.#SCRATCH_CONN_FLAGS = new Uint8Array(totalCandidates);
        connectionFlags = _EvolutionEngine.#SCRATCH_CONN_FLAGS;
      } else {
        connectionFlags.fill(0, 0, totalCandidates);
      }
      let activeEnabledCount = 0;
      for (let scanIndex = 0; scanIndex < totalCandidates; scanIndex++) {
        const connectionRef = candidateConnections[scanIndex];
        if (connectionRef && connectionRef.enabled !== false) {
          if (scanIndex !== activeEnabledCount)
            candidateConnections[activeEnabledCount] = connectionRef;
          activeEnabledCount++;
        }
      }
      if (activeEnabledCount === 0) return;
      if (pruneCount >= activeEnabledCount) pruneCount = activeEnabledCount;
      if (pruneCount >= activeEnabledCount >>> 1) {
        if (activeEnabledCount <= _EvolutionEngine.#PRUNE_BULK_INSERTION_MAX) {
          _EvolutionEngine.#insertionSortByAbsWeight(
            candidateConnections,
            0,
            activeEnabledCount
          );
        } else {
          candidateConnections.slice(0, activeEnabledCount).sort(
            (firstConnection, secondConnection) => Math.abs(firstConnection?.weight || 0) - Math.abs(secondConnection?.weight || 0)
          ).forEach((sortedConnection, sortedIndex) => {
            candidateConnections[sortedIndex] = sortedConnection;
          });
        }
        const disableLimit = pruneCount;
        for (let disableIndex = 0; disableIndex < disableLimit; disableIndex++) {
          const connectionRef = candidateConnections[disableIndex];
          if (connectionRef && connectionRef.enabled !== false)
            connectionRef.enabled = false;
        }
        return;
      }
      let remainingToDisable = pruneCount;
      let activeSliceLength = activeEnabledCount;
      while (remainingToDisable > 0 && activeSliceLength > 0) {
        let minIndex = 0;
        let minAbsWeight = Math.abs(
          candidateConnections[0] && Number.isFinite(candidateConnections[0].weight) ? candidateConnections[0].weight : 0
        );
        for (let probeIndex = 1; probeIndex < activeSliceLength; probeIndex++) {
          const probe = candidateConnections[probeIndex];
          const probeAbs = Math.abs(
            probe && Number.isFinite(probe.weight) ? probe.weight : 0
          );
          if (probeAbs < minAbsWeight) {
            minAbsWeight = probeAbs;
            minIndex = probeIndex;
          }
        }
        const targetConnection = candidateConnections[minIndex];
        if (targetConnection && targetConnection.enabled !== false)
          targetConnection.enabled = false;
        const lastActiveIndex = --activeSliceLength;
        candidateConnections[minIndex] = candidateConnections[lastActiveIndex];
        remainingToDisable--;
      }
    }
    /**
     * Compute directional action entropy (normalized to [0,1]) and number of distinct move directions
     * observed along a path of integer coordinates.
     *
     * Behaviour & notes:
     * - Uses the pooled `#SCRATCH_COUNTS` Int32Array (length 4) to avoid per-call allocations. Callers
     *   MUST NOT rely on preserved contents across engine helpers.
     * - Treats a direction as the delta between consecutive coordinates. Only unit deltas in the 8-neighbour
     *   Moore neighbourhood with a mapped index are considered; others are ignored.
     * - Returns entropy normalized by log(4) using `#INV_LOG4` so results are in [0,1]. For empty/degenerate
     *   inputs the entropy is 0 and uniqueMoves is 0.
     *
     * Complexity: O(L) where L = pathArr.length. Memory: O(1) (no allocations). Determinism: deterministic for
     * identical inputs. Reentrancy: Non-reentrant due to shared scratch buffer use.
     *
     * @param pathArr Array-like sequence of [x,y] coordinates visited (expected integers).
     * @returns Object with { entropyNorm, uniqueMoves, pathLen }.
     * @internal
     */
    static #computeActionEntropy(pathArr) {
      if (!Array.isArray(pathArr) || pathArr.length < 2)
        return { entropyNorm: 0, uniqueMoves: 0, pathLen: pathArr?.length | 0 };
      const counts = _EvolutionEngine.#SCRATCH_COUNTS;
      counts[0] = 0;
      counts[1] = 0;
      counts[2] = 0;
      counts[3] = 0;
      let totalMoves = 0;
      const dirMap = _EvolutionEngine.#DIR_DELTA_TO_INDEX;
      for (let i = 1; i < pathArr.length; i++) {
        const cur = pathArr[i];
        const prev = pathArr[i - 1];
        if (!cur || !prev) continue;
        const dx = cur[0] - prev[0];
        const dy = cur[1] - prev[1];
        if (dx < -1 || dx > 1 || dy < -1 || dy > 1) continue;
        const key = (dx + 1) * 3 + (dy + 1);
        const dirIdx = dirMap[key];
        if (dirIdx >= 0) {
          counts[dirIdx]++;
          totalMoves++;
        }
      }
      if (totalMoves === 0)
        return { entropyNorm: 0, uniqueMoves: 0, pathLen: pathArr.length };
      let entropy = 0;
      let uniqueMoves = 0;
      for (let k = 0; k < 4; k++) {
        const c = counts[k];
        if (c > 0) {
          const p = c / totalMoves;
          entropy += -p * Math.log(p);
          uniqueMoves++;
        }
      }
      const entropyNorm = entropy * _EvolutionEngine.#INV_LOG4;
      return { entropyNorm, uniqueMoves, pathLen: pathArr.length };
    }
    /**
     * Compute summary statistics over a sliding window of recent logit vectors.
     * Uses class-level scratch buffers to avoid allocations and supports a
     * reduced telemetry mode which skips higher moments (kurtosis).
     *
     * Contract:
     * - Input: `recent` is an array of numeric vectors (each vector length >= actionDim
     *   is not required; missing entries are treated as 0).
     * - Output: an object containing formatted strings, aggregated arrays and
     *   scalar summaries.
     *
     * @param recent - Array of recent logit vectors, newest last.
     * @returns An object { meansStr, stdsStr, kurtStr, entMean, stability, steps, means, stds }
     * @internal
     */
    static #computeLogitStats(recent) {
      if (!Array.isArray(recent) || recent.length === 0)
        return {
          meansStr: "",
          stdsStr: "",
          kurtStr: "",
          entMean: 0,
          stability: 0,
          steps: 0,
          means: _EvolutionEngine.#SCRATCH_MEANS,
          stds: _EvolutionEngine.#SCRATCH_STDS
        };
      const reducedTelemetry = _EvolutionEngine.#REDUCED_TELEMETRY;
      const actionDim = Math.max(0, _EvolutionEngine.#ACTION_DIM);
      const sampleCount = recent.length;
      _EvolutionEngine.#resetLogitScratch(actionDim, reducedTelemetry);
      let entropyAggregate = 0;
      if (reducedTelemetry) {
        entropyAggregate = _EvolutionEngine.#accumulateLogitStatsReduced(
          recent,
          actionDim
        );
        _EvolutionEngine.#finalizeLogitStatsReduced(actionDim, sampleCount);
      } else if (actionDim === 4) {
        entropyAggregate = _EvolutionEngine.#accumulateLogitStatsUnrolled4(
          recent,
          sampleCount
        );
        _EvolutionEngine.#finalizeLogitStatsFull(actionDim, sampleCount);
      } else {
        entropyAggregate = _EvolutionEngine.#accumulateLogitStatsGeneric(
          recent,
          actionDim
        );
        _EvolutionEngine.#finalizeLogitStatsFull(actionDim, sampleCount);
      }
      const entropyMean = entropyAggregate / sampleCount;
      const stability = _EvolutionEngine.#computeDecisionStability(recent);
      const meansStr = _EvolutionEngine.#joinNumberArray(
        _EvolutionEngine.#SCRATCH_MEANS,
        actionDim,
        3
      );
      const stdsStr = _EvolutionEngine.#joinNumberArray(
        _EvolutionEngine.#SCRATCH_STDS,
        actionDim,
        3
      );
      const kurtStr = reducedTelemetry ? "" : _EvolutionEngine.#joinNumberArray(
        _EvolutionEngine.#SCRATCH_KURT,
        actionDim,
        2
      );
      return {
        meansStr,
        stdsStr,
        kurtStr,
        entMean: entropyMean,
        stability,
        steps: sampleCount,
        means: _EvolutionEngine.#SCRATCH_MEANS,
        stds: _EvolutionEngine.#SCRATCH_STDS
      };
    }
    /**
     * Prepare and zero the class-level scratch buffers used by logit statistics.
     *
     * Steps:
     * 1. Normalize `actionDim` to a non-negative integer and fast-exit on zero.
     * 2. Grow (only when needed) the pooled Float64Array buffers to at least `actionDim` length.
     * 3. Zero the active prefix [0, actionDim) of means, second-moment (M2) and std buffers.
     * 4. When full telemetry is enabled also ensure/zero M3/M4/kurtosis buffers.
     *
     * Notes:
     * - This helper intentionally avoids preserving previous contents when resizing — callers always
     *   expect zeroed buffers after invocation.
     * - Allocations are kept minimal: a new backing array is created only when the existing capacity
     *   is insufficient; new capacity is chosen to be at least `actionDim` (no aggressive over-sizing).
     *
     * @param actionDim - Number of active action dimensions (will be floored & clamped to >= 0).
     * @param reducedTelemetry - When true skip higher-moment buffers (M3/M4/kurtosis) to save memory/CPU.
     * @example
     * // Internal usage: prepare scratch for 4 actions with full telemetry enabled
     * EvolutionEngine['#resetLogitScratch'](4, false);
     * @internal
     */
    static #resetLogitScratch(actionDim, reducedTelemetry) {
      const dim = Number.isFinite(actionDim) ? Math.max(0, Math.floor(actionDim)) : 0;
      if (dim === 0) return;
      if (!_EvolutionEngine.#SCRATCH_MEANS || _EvolutionEngine.#SCRATCH_MEANS.length < dim) {
        _EvolutionEngine.#SCRATCH_MEANS = new Float64Array(dim);
      }
      if (!_EvolutionEngine.#SCRATCH_M2_RAW || _EvolutionEngine.#SCRATCH_M2_RAW.length < dim) {
        _EvolutionEngine.#SCRATCH_M2_RAW = new Float64Array(dim);
      }
      if (!_EvolutionEngine.#SCRATCH_STDS || _EvolutionEngine.#SCRATCH_STDS.length < dim) {
        _EvolutionEngine.#SCRATCH_STDS = new Float64Array(dim);
      }
      const meansBuffer = _EvolutionEngine.#SCRATCH_MEANS;
      const secondMomentBuffer = _EvolutionEngine.#SCRATCH_M2_RAW;
      const stdBuffer = _EvolutionEngine.#SCRATCH_STDS;
      meansBuffer.fill(0, 0, dim);
      secondMomentBuffer.fill(0, 0, dim);
      stdBuffer.fill(0, 0, dim);
      if (!reducedTelemetry) {
        if (!_EvolutionEngine.#SCRATCH_M3_RAW || _EvolutionEngine.#SCRATCH_M3_RAW.length < dim) {
          _EvolutionEngine.#SCRATCH_M3_RAW = new Float64Array(dim);
        }
        if (!_EvolutionEngine.#SCRATCH_M4_RAW || _EvolutionEngine.#SCRATCH_M4_RAW.length < dim) {
          _EvolutionEngine.#SCRATCH_M4_RAW = new Float64Array(dim);
        }
        if (!_EvolutionEngine.#SCRATCH_KURT || _EvolutionEngine.#SCRATCH_KURT.length < dim) {
          _EvolutionEngine.#SCRATCH_KURT = new Float64Array(dim);
        }
        _EvolutionEngine.#SCRATCH_M3_RAW.fill(0, 0, dim);
        _EvolutionEngine.#SCRATCH_M4_RAW.fill(0, 0, dim);
        _EvolutionEngine.#SCRATCH_KURT.fill(0, 0, dim);
      }
    }
    /**
     * Accumulate running means and second raw moments (M2) using a reduced-telemetry
     * Welford pass (no higher moments) and also accumulate per-sample softmax entropy.
     *
     * Contract / side-effects:
     * - Fills the class-level scratch buffers: `#SCRATCH_MEANS`, `#SCRATCH_M2_RAW`, and `#SCRATCH_STDS`.
     * - Returns the aggregated entropy sum (caller will divide by sample count to get mean entropy).
     *
     * Example:
     * const entropySum = EvolutionEngine['#accumulateLogitStatsReduced'](recentLogits, 4);
     *
     * @param recent Array of recent logit vectors (newest last). Missing entries treated as 0.
     * @param actionDim Number of action dimensions to process (floored & clamped by caller).
     * @returns Sum of softmax entropies for each vector in `recent`.
     */
    static #accumulateLogitStatsReduced(recent, actionDim) {
      const sampleCount = Array.isArray(recent) ? recent.length : 0;
      if (sampleCount === 0 || actionDim <= 0) return 0;
      const meansBuffer = _EvolutionEngine.#SCRATCH_MEANS;
      const secondMomentBuffer = _EvolutionEngine.#SCRATCH_M2_RAW;
      const stdsBuffer = _EvolutionEngine.#SCRATCH_STDS;
      let entropyAccumulator = 0;
      for (const [sampleIndex, rawVector] of recent.entries()) {
        const vector = rawVector ?? _EvolutionEngine.#EMPTY_VEC;
        const sampleNumber = sampleIndex + 1;
        for (let dimIndex = 0; dimIndex < actionDim; dimIndex++) {
          const observedValue = vector[dimIndex] ?? 0;
          const previousMean = meansBuffer[dimIndex];
          const delta = observedValue - previousMean;
          const deltaNormalized = delta / sampleNumber;
          const updatedMean = previousMean + deltaNormalized;
          meansBuffer[dimIndex] = updatedMean;
          const correction = observedValue - updatedMean;
          secondMomentBuffer[dimIndex] += delta * correction;
        }
        entropyAccumulator += _EvolutionEngine.#softmaxEntropyFromVector(
          vector,
          _EvolutionEngine.#SCRATCH_EXPS
        );
      }
      const invSampleCount = 1 / sampleCount;
      for (let dimIndex = 0; dimIndex < actionDim; dimIndex++) {
        const variance = secondMomentBuffer[dimIndex] * invSampleCount;
        stdsBuffer[dimIndex] = variance > 0 ? Math.sqrt(variance) : 0;
      }
      return entropyAccumulator;
    }
    /**
     * Compute unrolled Welford moments for the common ACTION_DIM === 4 case.
     *
     * Steps (high level):
     * 1. Stream over samples and update running means and raw central moments (M2/M3/M4)
     *    for each of the four action dimensions using numerically-stable recurrence.
     * 2. Accumulate per-sample softmax entropy into `entropyAccumulator` for later averaging.
     * 3. After the streaming pass write final means/stds into the shared scratch buffers and
     *    compute kurtosis when full telemetry is enabled.
     *
     * Notes:
     * - Uses descriptive local names for the four directions (North/East/South/West) to clarify intent.
     * - Preserves the original numeric formulas and ordering to remain bit-for-bit compatible.
     *
     * @param recent Array of sample vectors (may contain undefined entries; missing values treated as 0).
     * @param sampleCount Number of samples to process (should equal recent.length)
     * @returns Sum of softmax entropies across samples (caller computes mean if desired)
     * @example
     * const entropySum = EvolutionEngine['#accumulateLogitStatsUnrolled4'](recentLogits, recentLogits.length);
     */
    static #accumulateLogitStatsUnrolled4(recent, sampleCount) {
      if (!Array.isArray(recent) || sampleCount === 0) return 0;
      let meanNorth = 0, meanEast = 0, meanSouth = 0, meanWest = 0;
      let M2North = 0, M2East = 0, M2South = 0, M2West = 0;
      let M3North = 0, M3East = 0, M3South = 0, M3West = 0;
      let M4North = 0, M4East = 0, M4South = 0, M4West = 0;
      let entropyAccumulator = 0;
      const expsBuf = _EvolutionEngine.#SCRATCH_EXPS;
      for (let sampleIndex = 0; sampleIndex < sampleCount; sampleIndex++) {
        const vec = recent[sampleIndex] ?? _EvolutionEngine.#EMPTY_VEC;
        const xNorth = vec[0] ?? 0;
        const xEast = vec[1] ?? 0;
        const xSouth = vec[2] ?? 0;
        const xWest = vec[3] ?? 0;
        const n = sampleIndex + 1;
        {
          const delta = xNorth - meanNorth;
          const deltaN = delta / n;
          const deltaN2 = deltaN * deltaN;
          const term1 = delta * deltaN * (n - 1);
          M4North += term1 * deltaN2 * (n * n - 3 * n + 3) + 6 * deltaN2 * M2North - 4 * deltaN * M3North;
          M3North += term1 * deltaN * (n - 2) - 3 * deltaN * M2North;
          M2North += term1;
          meanNorth += deltaN;
        }
        {
          const delta = xEast - meanEast;
          const deltaN = delta / n;
          const deltaN2 = deltaN * deltaN;
          const term1 = delta * deltaN * (n - 1);
          M4East += term1 * deltaN2 * (n * n - 3 * n + 3) + 6 * deltaN2 * M2East - 4 * deltaN * M3East;
          M3East += term1 * deltaN * (n - 2) - 3 * deltaN * M2East;
          M2East += term1;
          meanEast += deltaN;
        }
        {
          const delta = xSouth - meanSouth;
          const deltaN = delta / n;
          const deltaN2 = deltaN * deltaN;
          const term1 = delta * deltaN * (n - 1);
          M4South += term1 * deltaN2 * (n * n - 3 * n + 3) + 6 * deltaN2 * M2South - 4 * deltaN * M3South;
          M3South += term1 * deltaN * (n - 2) - 3 * deltaN * M2South;
          M2South += term1;
          meanSouth += deltaN;
        }
        {
          const delta = xWest - meanWest;
          const deltaN = delta / n;
          const deltaN2 = deltaN * deltaN;
          const term1 = delta * deltaN * (n - 1);
          M4West += term1 * deltaN2 * (n * n - 3 * n + 3) + 6 * deltaN2 * M2West - 4 * deltaN * M3West;
          M3West += term1 * deltaN * (n - 2) - 3 * deltaN * M2West;
          M2West += term1;
          meanWest += deltaN;
        }
        entropyAccumulator += _EvolutionEngine.#softmaxEntropyFromVector(
          vec,
          expsBuf
        );
      }
      const meansBuf = _EvolutionEngine.#SCRATCH_MEANS;
      meansBuf[0] = meanNorth;
      meansBuf[1] = meanEast;
      meansBuf[2] = meanSouth;
      meansBuf[3] = meanWest;
      const invSample = 1 / sampleCount;
      const varNorth = M2North * invSample;
      const varEast = M2East * invSample;
      const varSouth = M2South * invSample;
      const varWest = M2West * invSample;
      const stdsBuf = _EvolutionEngine.#SCRATCH_STDS;
      stdsBuf[0] = varNorth > 0 ? Math.sqrt(varNorth) : 0;
      stdsBuf[1] = varEast > 0 ? Math.sqrt(varEast) : 0;
      stdsBuf[2] = varSouth > 0 ? Math.sqrt(varSouth) : 0;
      stdsBuf[3] = varWest > 0 ? Math.sqrt(varWest) : 0;
      if (!_EvolutionEngine.#REDUCED_TELEMETRY) {
        const kurtBuf = _EvolutionEngine.#SCRATCH_KURT;
        kurtBuf[0] = varNorth > 1e-18 ? sampleCount * M4North / (M2North * M2North) - 3 : 0;
        kurtBuf[1] = varEast > 1e-18 ? sampleCount * M4East / (M2East * M2East) - 3 : 0;
        kurtBuf[2] = varSouth > 1e-18 ? sampleCount * M4South / (M2South * M2South) - 3 : 0;
        kurtBuf[3] = varWest > 1e-18 ? sampleCount * M4West / (M2West * M2West) - 3 : 0;
      }
      return entropyAccumulator;
    }
    /**
     * Generic accumulation for arbitrary action dimension including higher moments when enabled.
     * @internal
     */
    static #accumulateLogitStatsGeneric(recent, actionDim) {
      const meansBuf = _EvolutionEngine.#SCRATCH_MEANS;
      const m2Buf = _EvolutionEngine.#SCRATCH_M2_RAW;
      const m3Buf = _EvolutionEngine.#SCRATCH_M3_RAW;
      const m4Buf = _EvolutionEngine.#SCRATCH_M4_RAW;
      const sampleCount = recent.length;
      let entropyAccumulator = 0;
      for (let sampleIndex = 0; sampleIndex < sampleCount; sampleIndex++) {
        const vector = recent[sampleIndex] ?? _EvolutionEngine.#EMPTY_VEC;
        const seqNumber = sampleIndex + 1;
        for (let dimIndex = 0; dimIndex < actionDim; dimIndex++) {
          const x = vector[dimIndex] ?? 0;
          const delta = x - meansBuf[dimIndex];
          const deltaN = delta / seqNumber;
          const deltaN2 = deltaN * deltaN;
          const term1 = delta * deltaN * (seqNumber - 1);
          if (!_EvolutionEngine.#REDUCED_TELEMETRY)
            m4Buf[dimIndex] += term1 * deltaN2 * (seqNumber * seqNumber - 3 * seqNumber + 3) + 6 * deltaN2 * m2Buf[dimIndex] - 4 * deltaN * (m3Buf ? m3Buf[dimIndex] : 0);
          if (!_EvolutionEngine.#REDUCED_TELEMETRY)
            m3Buf[dimIndex] += term1 * deltaN * (seqNumber - 2) - 3 * deltaN * m2Buf[dimIndex];
          m2Buf[dimIndex] += term1;
          meansBuf[dimIndex] += deltaN;
        }
        entropyAccumulator += _EvolutionEngine.#softmaxEntropyFromVector(
          vector,
          _EvolutionEngine.#SCRATCH_EXPS
        );
      }
      return entropyAccumulator;
    }
    /**
     * Finalize full-statistics values (stds and kurtosis) after accumulation.
     * @internal
     */
    static #finalizeLogitStatsFull(actionDim, sampleCount) {
      const m2Buf = _EvolutionEngine.#SCRATCH_M2_RAW;
      const m4Buf = _EvolutionEngine.#SCRATCH_M4_RAW;
      const stdsBuf = _EvolutionEngine.#SCRATCH_STDS;
      const kurtBuf = _EvolutionEngine.#SCRATCH_KURT;
      for (let dimIndex = 0; dimIndex < actionDim; dimIndex++) {
        const variance = m2Buf[dimIndex] / sampleCount;
        stdsBuf[dimIndex] = variance > 0 ? Math.sqrt(variance) : 0;
        if (!_EvolutionEngine.#REDUCED_TELEMETRY) {
          const m4v = m4Buf[dimIndex];
          kurtBuf[dimIndex] = variance > 1e-18 ? sampleCount * m4v / (m2Buf[dimIndex] * m2Buf[dimIndex]) - 3 : 0;
        }
      }
    }
    /**
     * Finalize reduced-statistics values (only stds) after accumulation.
     * @internal
     */
    static #finalizeLogitStatsReduced(actionDim, sampleCount) {
      const m2Buf = _EvolutionEngine.#SCRATCH_M2_RAW;
      const stdsBuf = _EvolutionEngine.#SCRATCH_STDS;
      for (let dimIndex = 0; dimIndex < actionDim; dimIndex++) {
        const variance = m2Buf[dimIndex] / sampleCount;
        stdsBuf[dimIndex] = variance > 0 ? Math.sqrt(variance) : 0;
      }
    }
    /**
     * Compute summary statistics for output node biases.
     * Uses class-level scratch buffers and avoids intermediate allocations.
     * @param nodes - full node list from a network
     * @param outputCount - number of output nodes (must be <= nodes.length)
     * @returns an object with mean, std and a comma-separated biases string
     * @internal
     */
    static #computeOutputBiasStats(nodes, outputCount) {
      if (!nodes || outputCount <= 0) return { mean: 0, std: 0, biasesStr: "" };
      let mean = 0;
      let M2 = 0;
      for (let outIndex = 0; outIndex < outputCount; outIndex++) {
        const nodeIndex = _EvolutionEngine.#SCRATCH_NODE_IDX[outIndex];
        const biasValue = nodes[nodeIndex]?.bias ?? 0;
        const count = outIndex + 1;
        const delta = biasValue - mean;
        mean += delta / count;
        M2 += delta * (biasValue - mean);
      }
      const std = outputCount ? Math.sqrt(M2 / outputCount) : 0;
      if (outputCount > _EvolutionEngine.#SCRATCH_STR.length) {
        const nextSize = 1 << Math.ceil(Math.log2(outputCount));
        _EvolutionEngine.#SCRATCH_STR = new Array(nextSize);
      }
      const sBuf = _EvolutionEngine.#SCRATCH_STR;
      for (let bi = 0; bi < outputCount; bi++) {
        const idx = _EvolutionEngine.#SCRATCH_NODE_IDX[bi];
        sBuf[bi] = (nodes[idx]?.bias ?? 0).toFixed(2);
      }
      const prevLenBias = sBuf.length;
      sBuf.length = outputCount;
      const biasesStr = sBuf.join(",");
      sBuf.length = prevLenBias;
      return { mean, std, biasesStr };
    }
    /**
     * Expand population by creating up to `targetAdd` children from top parents.
     * Uses neat-managed spawn when available, otherwise falls back to clone/mutate/add.
     * Avoids short-lived allocations by reusing class-level scratch buffers.
     * Contract / behaviour:
     * - Inputs: `neat` driver (may provide `spawnFromParent`, `addGenome`, or `_invalidateGenomeCaches`),
     *   `targetAdd` (desired number of new genomes), `safeWrite` logger and generation counter.
     * - Output: side-effects on `neat.population` and `neat.options.popsize`; emits a single status line.
     * - Error model: per-child exceptions are swallowed (best-effort growth). The method is non-throwing.
     * Edge cases:
     * - If `neat.population` is missing or empty nothing is done.
     * - `targetAdd` is clamped to non-negative integer; fractional values are floored.
     * @internal
     */
    static #expandPopulation(neat, targetAdd, safeWrite, completedGenerations) {
      const wanted = Number.isFinite(targetAdd) ? Math.max(0, Math.floor(targetAdd)) : 0;
      if (wanted <= 0) return;
      const {
        populationRef,
        sortedIdx,
        parentPoolSize
      } = _EvolutionEngine.#prepareExpansion(neat, wanted);
      if (!populationRef?.length || parentPoolSize === 0) return;
      for (let addIndex = 0; addIndex < wanted; addIndex++) {
        const pickIndex = _EvolutionEngine.#fastRandom() * parentPoolSize | 0;
        const parent = populationRef[sortedIdx[pickIndex]];
        try {
          _EvolutionEngine.#createChildFromParent(neat, parent);
        } catch {
        }
      }
      neat.options.popsize = neat.population.length;
      safeWrite(
        `[DYNAMIC_POP] Expanded population to ${neat.population.length} at gen ${completedGenerations}
`
      );
    }
    /**
     * Prepare and validate working sets used when expanding the population.
     *
     * @param neat - NEAT driver object which may expose a `population` array.
     * @param _targetAdd - Requested number of additions (unused here; kept for API symmetry).
     * @returns An object with:
     *  - `populationRef`: reference to the population array (or [] when missing),
     *  - `sortedIdx`: indices of `populationRef` sorted by descending score (empty if no population),
     *  - `parentPoolSize`: number of parents to sample from (0 when none available).
     *
     * Example:
     * const { populationRef, sortedIdx, parentPoolSize } =
     *   EvolutionEngine['#prepareExpansion'](neat, 4);
     * // if populationRef.length === 0 then parentPoolSize === 0 and expansion is skipped.
     *
     * @internal
     */
    static #prepareExpansion(neat, _targetAdd) {
      const populationRef = Array.isArray(neat?.population) ? neat.population : [];
      if (populationRef.length === 0) {
        return { populationRef, sortedIdx: [], parentPoolSize: 0 };
      }
      const sortedIdx = _EvolutionEngine.#getSortedIndicesByScore(populationRef);
      const desiredParentCount = Math.ceil(
        sortedIdx.length * _EvolutionEngine.#DEFAULT_PARENT_FRACTION
      );
      const parentCount = Math.max(2, desiredParentCount);
      const parentPoolSize = Math.min(parentCount, sortedIdx.length);
      return { populationRef, sortedIdx, parentPoolSize };
    }
    /**
     * Determine how many mutation operations to attempt for a new child (1 or 2).
     * @internal
     */
    static #determineMutateCount() {
      return 1 + (_EvolutionEngine.#fastRandom() < _EvolutionEngine.#DEFAULT_HALF_PROB ? 1 : 0);
    }
    /**
     * Apply up to `mutateCount` distinct mutation operations to `clone`.
     *
     * Behavioural contract:
     * 1. Uses the engine's cached mutation operation array (via `#getMutationOps`) as the operation pool.
     * 2. Selects up to `mutateCount` unique operations without allocating a fresh permutation array by
     *    reusing the pooled `#SCRATCH_MUTOP_IDX` Uint16Array and performing a partial Fisher–Yates shuffle.
     * 3. For very small `mutateCount` values the method takes an unrolled fast path to avoid shuffle overhead.
     * 4. Mutation is applied by calling `clone.mutate(op)` for each chosen op when `clone.mutate` exists.
     *
     * Implementation notes:
     * - Defensive: clamps and validates inputs; no-ops when there are zero available mutation ops or when
     *   `mutateCount` <= 0.
     * - Uses descriptive local names and avoids temporary allocations other than those grown on the pooled buffer.
     * - Side-effects: mutates the pooled `#SCRATCH_MUTOP_IDX` contents but restores no state (caller must treat
     *   the scratch buffer as ephemeral).
     *
     * Complexity:
     * - O(opCount) to initialise the pooled index buffer. Partial Fisher–Yates costs O(k) where k = applied count.
     * - Memory: O(1) extra (reuses class scratch buffer).
     *
     * @param clone - Genome-like object expected to expose `mutate(op)`; if missing, mutation calls are skipped.
     * @param neat - NEAT driver used to resolve the available mutation operations via `#getMutationOps`.
     * @param mutateCount - Desired number of distinct mutation ops to apply (floored to integer and clamped).
     * @example
     * // Apply up to two random distinct mutations from the configured mutation set:
     * EvolutionEngine['#applyMutationsToClone'](someClone, neat, 2);
     *
     * @internal
     */
    static #applyMutationsToClone(clone, neat, mutateCount) {
      const mutationOps = _EvolutionEngine.#getMutationOps(neat);
      const operationCount = mutationOps.length | 0;
      if (operationCount === 0) return;
      if (_EvolutionEngine.#SCRATCH_MUTOP_IDX.length < operationCount) {
        const nextSize = 1 << Math.ceil(Math.log2(operationCount));
        _EvolutionEngine.#SCRATCH_MUTOP_IDX = new Uint16Array(nextSize);
      }
      const indexBuffer = _EvolutionEngine.#SCRATCH_MUTOP_IDX;
      for (let writeIndex = 0; writeIndex < operationCount; writeIndex++) {
        indexBuffer[writeIndex] = writeIndex;
      }
      const wanted = Math.max(0, Math.floor(mutateCount || 0));
      const toApply = Math.min(wanted, operationCount);
      if (toApply === 0) return;
      if (toApply === 1) {
        const opIndex = indexBuffer[0];
        const op = mutationOps[opIndex];
        if (typeof clone?.mutate === "function") clone.mutate(op);
        return;
      }
      if (toApply === 2) {
        const firstIndex = indexBuffer[0];
        const secondIndex = indexBuffer[1];
        if (typeof clone?.mutate === "function") {
          clone.mutate(mutationOps[firstIndex]);
          clone.mutate(mutationOps[secondIndex]);
        }
        return;
      }
      for (let selectionCursor = 0; selectionCursor < toApply; selectionCursor++) {
        const remaining = operationCount - selectionCursor;
        const offset = _EvolutionEngine.#fastRandom() * remaining | 0;
        const swapPosition = selectionCursor + offset;
        const temp = indexBuffer[selectionCursor];
        indexBuffer[selectionCursor] = indexBuffer[swapPosition];
        indexBuffer[swapPosition] = temp;
        const chosenOpIndex = indexBuffer[selectionCursor];
        const chosenOp = mutationOps[chosenOpIndex];
        if (typeof clone?.mutate === "function") clone.mutate(chosenOp);
      }
    }
    /**
     * Register a newly-created clone with the NEAT driver if supported, falling back to a simple push.
     * Preserves the original best-effort semantics and cache invalidation hook.
     *
     * Contract & behaviour:
     * 1. Prefer calling `neat.addGenome(clone, [parentId])` when the driver exposes it. This allows
     *    driver-specific bookkeeping (species, id assignment, telemetry).
     * 2. When `addGenome` is absent, attempt a lightweight fallback: call `_invalidateGenomeCaches` if
     *    present, then push the clone into `neat.population` (creating the array if missing).
     * 3. Best-effort error model: per-registration exceptions are swallowed; the method tries to ensure the
     *    clone is present in `neat.population` before returning.
     *
     * Notes:
     * - The helper mutates the provided `neat` object to guarantee a `population` array exists when falling back.
     * - This is intentionally forgiving to avoid breaking the evolution loop on driver edge cases.
     *
     * @param neat - NEAT driver / manager object (may be undefined in tests; guarded defensively).
     * @param clone - Genome object to register (expected to be a valid genome instance).
     * @param parentId - Optional identifier or array of parent ids used by driver-level registration.
     * @example
     * // Preferred (driver-aware) registration when using a full NEAT manager:
     * EvolutionEngine['#registerClone'](neat, genomeClone, parentId);
     *
     * @internal
     */
    static #registerClone(neat, clone, parentId) {
      if (!neat || !clone) return;
      try {
        if (typeof neat.addGenome === "function") {
          neat.addGenome(clone, [parentId]);
          return;
        }
        if (!Array.isArray(neat.population)) neat.population = [];
        if (typeof neat._invalidateGenomeCaches === "function") {
          try {
            neat._invalidateGenomeCaches(clone);
          } catch {
          }
        }
        neat.population.push(clone);
        return;
      } catch (err) {
        try {
          if (neat && !Array.isArray(neat.population)) neat.population = [];
          neat?.population?.push(clone);
        } catch {
        }
      }
    }
    /**
     * Create and register a single child derived from `parent`.
     *
     * Behavioural contract (best-effort):
     * 1. Prefer the driver-level `neat.spawnFromParent(parent, mutateCount)` when available. If it returns a
     *    child-like object we register it via `#registerClone` so driver bookkeeping remains consistent.
     * 2. If the driver doesn't provide spawn or spawn fails, fall back to cloning the parent, applying
     *    `mutateCount` mutation operations, sanitising the clone (clear score) and registering it.
     * 3. All steps are non-throwing from the caller's perspective; internal exceptions are swallowed
     *    so expansion remains best-effort and doesn't abort the evolution loop.
     *
     * Steps (inline):
     * 1. Defensive guard: exit when `neat` or `parent` are missing.
     * 2. Compute `mutateCount` once and reuse for both driver-spawn and fallback paths.
     * 3. Try driver spawn inside a protective try/catch; if a child is produced, register and return.
     * 4. Fallback: produce a clone (use `parent.clone()` when available), apply mutations, clear score,
     *    and register the clone.
     * 5. Swallow any errors and return silently (best-effort).
     *
     * @param neat - NEAT driver / manager object.
     * @param parent - Parent genome object used as the basis for spawning/cloning.
     * @example
     * EvolutionEngine['#createChildFromParent'](neat, someParentGenome);
     *
     * @internal
     */
    static #createChildFromParent(neat, parent) {
      if (!neat || !parent) return;
      const mutateCount = _EvolutionEngine.#determineMutateCount();
      if (typeof neat.spawnFromParent === "function") {
        try {
          const spawnedChild = neat.spawnFromParent(parent, mutateCount);
          if (spawnedChild) {
            _EvolutionEngine.#registerClone(
              neat,
              spawnedChild,
              parent?._id
            );
            return;
          }
        } catch {
        }
      }
      try {
        const clone = typeof parent.clone === "function" ? parent.clone() : parent;
        try {
          _EvolutionEngine.#applyMutationsToClone(clone, neat, mutateCount);
        } catch {
        }
        try {
          clone.score = void 0;
        } catch {
        }
        _EvolutionEngine.#registerClone(neat, clone, parent?._id);
      } catch {
      }
    }
    /**
     * Return indices of population sorted descending by score using pooled index buffer.
     * Uses iterative quicksort on the indices to avoid allocating a copy of the population.
     * @internal
     */
    /**
     * Return indices of `population` sorted by descending `score` using a pooled, allocation-free sorter.
     *
     * Steps:
     * 1. Validate inputs and fast-exit for empty populations.
     * 2. Prepare a pooled index buffer (number[] or typed Int32Array) sized to `len`.
     * 3. Initialize the index buffer with the identity permutation [0,1,2,...].
     * 4. Sort indices by descending `population[idx].score` using an iterative quicksort with median-of-three pivot
     *    and an insertion-sort fallback for small partitions. All work uses pooled scratch (no per-call allocations
     *    aside from a minimal typed-array growth when required).
     * 5. Return a number[] view trimmed to `len` (public API remains number[] for compatibility).
     *
     * @param population - Array-like population where each entry may expose a numeric `.score` property.
     * @returns number[] Sorted indices (highest score first). Empty array when input empty.
     * @example
     * const indices = EvolutionEngine['#getSortedIndicesByScore'](population);
     */
    static #getSortedIndicesByScore(population) {
      const populationLength = population.length | 0;
      if (populationLength === 0) return [];
      let useTypedScratch = false;
      const typedScratchBuf = _EvolutionEngine.#SCRATCH_SORT_IDX_TA;
      if (typedScratchBuf && typedScratchBuf.length >= populationLength) {
        useTypedScratch = true;
      } else if (!typedScratchBuf && populationLength > 512) {
        const allocSize = 1 << Math.ceil(Math.log2(populationLength));
        _EvolutionEngine.#SCRATCH_SORT_IDX_TA = new Int32Array(allocSize);
        useTypedScratch = true;
      }
      if (_EvolutionEngine.#SCRATCH_SORT_IDX.length < populationLength) {
        const nextSize = 1 << Math.ceil(Math.log2(populationLength));
        _EvolutionEngine.#SCRATCH_SORT_IDX = new Array(nextSize);
      }
      const indexScratch = useTypedScratch ? _EvolutionEngine.#SCRATCH_SORT_IDX_TA : _EvolutionEngine.#SCRATCH_SORT_IDX;
      for (let initIdx = 0; initIdx < populationLength; initIdx++)
        indexScratch[initIdx] = initIdx;
      if (!useTypedScratch)
        _EvolutionEngine.#SCRATCH_SORT_IDX.length = populationLength;
      let qsStack = _EvolutionEngine.#SCRATCH_QS_STACK;
      if (qsStack.length < 2)
        qsStack = _EvolutionEngine.#SCRATCH_QS_STACK = new Int32Array(128);
      let stackPtr = 0;
      qsStack[stackPtr++] = 0;
      qsStack[stackPtr++] = populationLength - 1;
      while (stackPtr > 0) {
        const hi = qsStack[--stackPtr];
        const lo = qsStack[--stackPtr];
        if (lo >= hi) continue;
        if (hi - lo <= _EvolutionEngine.#QS_SMALL_THRESHOLD) {
          _EvolutionEngine.#insertionSortIndices(indexScratch, lo, hi, population);
          continue;
        }
        let leftPtr = lo;
        let rightPtr = hi;
        const pivotScore = _EvolutionEngine.#medianOfThreePivot(
          indexScratch,
          lo,
          hi,
          population
        );
        while (leftPtr <= rightPtr) {
          while (true) {
            const li = indexScratch[leftPtr];
            if ((population[li]?.score ?? -Infinity) <= pivotScore) break;
            leftPtr++;
          }
          while (true) {
            const rj = indexScratch[rightPtr];
            if ((population[rj]?.score ?? -Infinity) >= pivotScore) break;
            rightPtr--;
          }
          if (leftPtr <= rightPtr) {
            const t = indexScratch[leftPtr];
            indexScratch[leftPtr] = indexScratch[rightPtr];
            indexScratch[rightPtr] = t;
            leftPtr++;
            rightPtr--;
          }
        }
        const leftPartitionSize = rightPtr - lo;
        const rightPartitionSize = hi - leftPtr;
        if (leftPartitionSize > rightPartitionSize) {
          if (lo < rightPtr) {
            stackPtr = _EvolutionEngine.#qsPushRange(stackPtr, lo, rightPtr);
            qsStack = _EvolutionEngine.#SCRATCH_QS_STACK;
          }
          if (leftPtr < hi) {
            stackPtr = _EvolutionEngine.#qsPushRange(stackPtr, leftPtr, hi);
            qsStack = _EvolutionEngine.#SCRATCH_QS_STACK;
          }
        } else {
          if (leftPtr < hi) {
            stackPtr = _EvolutionEngine.#qsPushRange(stackPtr, leftPtr, hi);
            qsStack = _EvolutionEngine.#SCRATCH_QS_STACK;
          }
          if (lo < rightPtr) {
            stackPtr = _EvolutionEngine.#qsPushRange(stackPtr, lo, rightPtr);
            qsStack = _EvolutionEngine.#SCRATCH_QS_STACK;
          }
        }
      }
      if (useTypedScratch) {
        if (_EvolutionEngine.#SCRATCH_SORT_IDX.length < populationLength)
          _EvolutionEngine.#SCRATCH_SORT_IDX = new Array(
            1 << Math.ceil(Math.log2(populationLength))
          );
        const out = _EvolutionEngine.#SCRATCH_SORT_IDX;
        const ta = _EvolutionEngine.#SCRATCH_SORT_IDX_TA;
        for (let k = 0; k < populationLength; k++) out[k] = ta[k];
        out.length = populationLength;
        return out;
      }
      _EvolutionEngine.#SCRATCH_SORT_IDX.length = populationLength;
      return _EvolutionEngine.#SCRATCH_SORT_IDX;
    }
    /**
     * In-place insertion sort of an index buffer slice by descending `population[idx].score`.
     *
     * Behaviour / contract:
     *  - Sorts the half-open slice [lo, hi] inclusive of both bounds (legacy behaviour preserved).
     *  - Operates in-place on `indexBuf` (no new arrays are allocated). `indexBuf` may be a
     *    `number[]` or an `Int32Array` typed buffer. Callers relying on a `number[]` view should
     *    ensure the appropriate buffer type is supplied (the pooled sorter orchestrator handles
     *    typed->number[] copy when necessary).
     *  - Comparison uses `population[index]?.score` with missing scores treated as -Infinity
     *    so entries without numeric scores sink to the end (lowest priority).
     *  - Stable for equal scores: ties preserve original relative ordering because we only shift
     *    when strictly less-than the current key.
     *
     * Steps (high level):
     *  1. Validate inputs and fast-exit for degenerate ranges.
     *  2. For each element in the slice, extract its index and score (the "key").
     *  3. Shift larger elements rightwards until the insertion point is found.
     *  4. Write the key into its final slot.
     *
     * Notes:
     *  - This method is intentionally allocation-free and non-reentrant (it mutates the
     *    provided buffer). Do not call concurrently with other helpers that reuse the same
     *    pooled scratch buffers.
     *
     * @param indexBuf - Mutable index buffer (either `number[]` or `Int32Array`) containing
     *                   integer indices into `population` to be partially-sorted.
     * @param lo - Inclusive lower bound of the slice to sort (will be clamped by caller).
     * @param hi - Inclusive upper bound of the slice to sort (if hi <= lo the call is a no-op).
     * @param population - Array-like population where `.score` is read for each index.
     * @example
     * // Sort the indices 0..(n-1) stored in `idxBuf` by descending score
     * EvolutionEngine['#insertionSortIndices'](idxBuf, 0, n - 1, population);
     *
     * @internal
     */
    static #insertionSortIndices(indexBuf, lo, hi, population) {
      if (!indexBuf || lo >= hi) return;
      const populationRef = population ?? _EvolutionEngine.#EMPTY_VEC;
      const scoreOf = (idx) => populationRef[idx]?.score ?? Number.NEGATIVE_INFINITY;
      for (let writePos = lo + 1; writePos <= hi; writePos++) {
        const keyIndex = indexBuf[writePos];
        const keyScore = scoreOf(keyIndex);
        let scanPos = writePos - 1;
        while (scanPos >= lo && scoreOf(indexBuf[scanPos]) < keyScore) {
          indexBuf[scanPos + 1] = indexBuf[scanPos];
          scanPos--;
        }
        indexBuf[scanPos + 1] = keyIndex;
      }
    }
    /**
     * Compute the median-of-three pivot score taken from indices at `lo`, `mid`, `hi`.
     *
     * Behaviour / contract:
     *  - Reads three candidate indices from `indexBuf` at positions `lo`, `mid`, `hi` and returns
     *    the median of their `population[idx].score` values.
     *  - `indexBuf` may be a `number[]` or an `Int32Array` (the sorter uses pooled typed buffers);
     *    this helper performs reads only and does not allocate new arrays.
     *  - Missing or non-numeric `.score` values are treated as `Number.NEGATIVE_INFINITY`, so
     *    entries without a score sort to the end.
     *
     * Steps (high level):
     *  1. Compute the middle position and load the three candidate indices.
     *  2. Fetch their scores with a safe fallback.
     *  3. Use a small sequence of comparisons and swaps (no allocations) to determine the median
     *     score value and return it.
     *
     * Notes:
     *  - This method is intentionally small and allocation-free so it can be used in hot sorting
     *    paths. It's non-reentrant when used with shared pooled buffers but it performs only local reads.
     *
     * @param indexBuf - Index buffer (either `number[]` or `Int32Array`) containing population indices.
     * @param lo - Inclusive low index in `indexBuf`.
     * @param hi - Inclusive high index in `indexBuf`.
     * @param population - Array-like population where `.score` is read for each index.
     * @returns The median score (a number) among the three candidate positions.
     * @example
     * const pivot = EvolutionEngine['#medianOfThreePivot'](idxBuf, 0, n-1, population);
     *
     * @internal
     */
    static #medianOfThreePivot(indexBuf, lo, hi, population) {
      const mid = lo + hi >> 1;
      const leftIndex = indexBuf[lo];
      const middleIndex = indexBuf[mid];
      const rightIndex = indexBuf[hi];
      const popRef = population ?? _EvolutionEngine.#EMPTY_VEC;
      let leftScore = popRef[leftIndex]?.score ?? Number.NEGATIVE_INFINITY;
      let middleScore = popRef[middleIndex]?.score ?? Number.NEGATIVE_INFINITY;
      let rightScore = popRef[rightIndex]?.score ?? Number.NEGATIVE_INFINITY;
      if (leftScore > middleScore) {
        const tmp = leftScore;
        leftScore = middleScore;
        middleScore = tmp;
      }
      if (middleScore > rightScore) {
        const tmp = middleScore;
        middleScore = rightScore;
        rightScore = tmp;
        if (leftScore > middleScore) {
          const tmp2 = leftScore;
          leftScore = middleScore;
          middleScore = tmp2;
        }
      }
      return middleScore;
    }
    /**
     * Push a [lo, hi] pair onto the pooled quicksort stack.
     *
     * Behaviour / contract:
     *  - Uses the class-level `#SCRATCH_QS_STACK` Int32Array as a reusable stack to avoid
     *    per-call allocations in the hot sorting path. The backing buffer may be grown when
     *    capacity is insufficient; growth size follows power-of-two doubling to bound
     *    amortized allocations.
     *  - Mutates the pooled stack and returns the updated `stackPtr` (the index of the next
     *    free slot). Callers should use the returned value; the method does not update any
     *    external stack pointer state beyond returning it.
     *  - Non-reentrant: the pooled stack is shared and must not be used concurrently.
     *
     * Steps:
     *  1. Ensure the pooled `Int32Array` exists and has capacity for two more elements.
     *  2. If capacity is insufficient, allocate a new `Int32Array` with at least double the
     *     previous length (or large enough to accommodate the required size), copy contents,
     *   and swap it into the pooled field.
     *  3. Push `rangeLo` then `rangeHi` into the stack and return the incremented pointer.
     *
     * @param stackPtr - Current stack pointer (next free slot index) into `#SCRATCH_QS_STACK`.
     * @param rangeLo - Inclusive lower bound of the range to push.
     * @param rangeHi - Inclusive upper bound of the range to push.
     * @returns Updated stack pointer (after the push).
     * @example
     * // push initial full range onto pooled stack
     * let ptr = 0;
     * ptr = EvolutionEngine['#qsPushRange'](ptr, 0, population.length - 1);
     *
     * @internal
     */
    static #qsPushRange(stackPtr, rangeLo, rangeHi) {
      let stackBuf = _EvolutionEngine.#SCRATCH_QS_STACK;
      const required = stackPtr + 2;
      if (required > stackBuf.length) {
        let newCapacity = Math.max(stackBuf.length << 1, 4);
        while (newCapacity < required) newCapacity <<= 1;
        const grown = new Int32Array(newCapacity);
        grown.set(stackBuf);
        _EvolutionEngine.#SCRATCH_QS_STACK = stackBuf = grown;
      }
      stackBuf[stackPtr++] = rangeLo | 0;
      stackBuf[stackPtr++] = rangeHi | 0;
      return stackPtr;
    }
    /** Cached reference to mutation ops array (invalidated if the driver replaces the reference). */
    static #CACHED_MUTATION_OPS = null;
    /**
     * Pooled scratch buffer for temporary bias storage when computing output-bias statistics.
     * - Lazily grown with power-of-two sizing to avoid per-call allocations.
     * - Shared across engine helpers; non-reentrant (callers must not use concurrently).
     */
    static #SCRATCH_BIAS_TA = new Float64Array(0);
    /**
     * Resolve and cache the configured mutation operations from the NEAT driver options.
     *
     * Behaviour / contract:
     *  - Reads `neat?.options?.mutation` and returns a stable array reference when available.
     *  - Caches the resolved reference in `#CACHED_MUTATION_OPS` to avoid repeated property
     *    lookups on hot paths. If the driver later replaces its `mutation` reference, the cache
     *    is updated on the next call.
     *  - Minimises allocations: when the driver provides an actual `Array` we use it directly.
     *    When a non-array object is provided, we attempt a cheap, one-time normalization and
     *    cache the result (this may allocate once).
     *  - The returned array should be treated as read-only by callers. Mutating it may break
     *    the driver's expectations and the engine's caching semantics.
     *
     * Steps:
     *  1. Fast-guard for a missing `neat` or options object -> return shared empty vector.
     *  2. Read the candidate `mutation` value and compare by reference with the cached value.
     *  3. If the reference changed, resolve to an array (use directly if already an Array,
     *     attempt to reuse array-like shapes, or perform a one-time Object->Array conversion).
     *  4. Return the cached array or the shared empty vector.
     *
     * @param neat - NEAT driver object (may be undefined in tests).
     * @returns Read-only array of mutation operation descriptors (may be `#EMPTY_VEC`).
     * @example
     * const ops = EvolutionEngine['#getMutationOps'](neat);
     * // if (ops.length) { apply mutations }
     * @internal
     */
    static #getMutationOps(neat) {
      try {
        if (!neat) return _EvolutionEngine.#EMPTY_VEC;
        const candidate = neat?.options?.mutation;
        if (candidate && _EvolutionEngine.#CACHED_MUTATION_OPS !== candidate) {
          if (Array.isArray(candidate)) {
            _EvolutionEngine.#CACHED_MUTATION_OPS = candidate;
          } else if (candidate && typeof candidate === "object") {
            const maybeLen = candidate.length;
            if (Number.isFinite(maybeLen) && maybeLen >= 0) {
              _EvolutionEngine.#CACHED_MUTATION_OPS = candidate;
            } else {
              _EvolutionEngine.#CACHED_MUTATION_OPS = Object.values(
                candidate
              );
            }
          } else {
            _EvolutionEngine.#CACHED_MUTATION_OPS = _EvolutionEngine.#EMPTY_VEC;
          }
        }
        return _EvolutionEngine.#CACHED_MUTATION_OPS ?? _EvolutionEngine.#EMPTY_VEC;
      } catch {
        return _EvolutionEngine.#EMPTY_VEC;
      }
    }
    /**
     * Ensure every output node in the provided NEAT population uses the identity activation.
     *
     * Rationale:
     * - Some evaluation paths expect raw network outputs (logits) so callers may apply softmax
     *   externally. This helper enforces `Activation.identity` on all nodes typed as `output`.
     * - Uses pooled references and performs no allocations.
     *
     * Steps:
     * 1. Defensive: verify `neat` and `neat.population` exist; fast-exit when missing.
     * 2. Iterate genomes and their `nodes` arrays (fall back to shared empty vector when absent).
     * 3. For each node object that declares `type === 'output'` set `node.squash = methods.Activation.identity`.
     * 4. Swallow errors to preserve best-effort, non-throwing behaviour in the evolution loop.
     *
     * Notes:
     * - The helper mutates node objects in-place. Callers should not rely on this being reentrant
     *   or safe to call concurrently with other helpers that mutate the same population.
     *
     * @param neat - NEAT driver object which may contain a `population` array (optional).
     * @example
     * EvolutionEngine['#ensureOutputIdentity'](neat);
     * @internal
     */
    static #ensureOutputIdentity(neat) {
      try {
        if (!neat) return;
        const populationRef = Array.isArray(neat.population) ? neat.population : _EvolutionEngine.#EMPTY_VEC;
        for (let genomeIndex = 0; genomeIndex < populationRef.length; genomeIndex++) {
          const genome = populationRef[genomeIndex];
          if (!genome) continue;
          const nodesRef = Array.isArray(genome.nodes) ? genome.nodes : _EvolutionEngine.#EMPTY_VEC;
          for (let nodeIndex = 0; nodeIndex < nodesRef.length; nodeIndex++) {
            const node = nodesRef[nodeIndex];
            if (node && node.type === "output") {
              node.squash = methods_exports.Activation.identity;
            }
          }
        }
      } catch {
      }
    }
    /**
     * Update the engine-wide species history and adapt mutation/novelty parameters when a
     * species collapse is detected.
     *
     * Behaviour / contract:
     *  - Counts unique species ids present in `neat.population` using pooled Int32Array scratch
     *    buffers to avoid per-call allocations.
     *  - Pushes the computed species count into a global history buffer and inspects the
     *    most-recent window to detect collapse (consecutive single-species entries).
     *  - When a collapse is detected the function applies conservative escalations to
     *    `mutationRate`, `mutationAmount` and `config.novelty.blendFactor` (when present).
     *  - Returns `true` when a collapse was observed, `false` otherwise. Silently returns
     *    `false` on unexpected errors to preserve the evolution loop.
     *
     * Steps:
     *  1. Normalize and fast-exit when `neat` or `neat.population` is missing.
     *  2. Ensure pooled species scratch buffers (`#SCRATCH_SPECIES_IDS`, `#SCRATCH_SPECIES_COUNTS`)
     *     have capacity for the population size (grow using power-of-two sizing when needed).
     3. Count unique species using a small in-place table in the scratch arrays.
     4. Push the species count into `_speciesHistory` and inspect the rolling window for collapse.
     5. When collapsed, escalate mutation/novelty parameters using configured caps/multipliers.
     6. Return the collapse detection boolean.
     *
     * @param neat - NEAT driver instance which may expose a `population` array.
     * @returns boolean `true` when species collapse observed; `false` otherwise.
     * @example
     * const collapsed = EvolutionEngine['#handleSpeciesHistory'](neat);
     * if (collapsed) console.log('Species collapse: escalated mutation params');
     * @internal
     */
    static #handleSpeciesHistory(neat) {
      try {
        _EvolutionEngine._speciesHistory = _EvolutionEngine._speciesHistory ?? _EvolutionEngine.#EMPTY_VEC;
        const populationRef = Array.isArray(neat?.population) ? neat.population : _EvolutionEngine.#EMPTY_VEC;
        let speciesIdsBuf = _EvolutionEngine.#SCRATCH_SPECIES_IDS;
        let speciesCountsBuf = _EvolutionEngine.#SCRATCH_SPECIES_COUNTS;
        if (populationRef.length > speciesIdsBuf.length) {
          const nextSize = 1 << Math.ceil(Math.log2(populationRef.length || 1));
          _EvolutionEngine.#SCRATCH_SPECIES_IDS = new Int32Array(nextSize);
          _EvolutionEngine.#SCRATCH_SPECIES_COUNTS = new Int32Array(nextSize);
          speciesIdsBuf = _EvolutionEngine.#SCRATCH_SPECIES_IDS;
          speciesCountsBuf = _EvolutionEngine.#SCRATCH_SPECIES_COUNTS;
        }
        let uniqueCount = 0;
        for (let genomeIndex = 0; genomeIndex < populationRef.length; genomeIndex++) {
          const genome = populationRef[genomeIndex];
          if (!genome || genome.species == null) continue;
          const speciesId = genome.species | 0;
          let foundIndex = -1;
          for (let scan = 0; scan < uniqueCount; scan++) {
            if (speciesIdsBuf[scan] === speciesId) {
              foundIndex = scan;
              break;
            }
          }
          if (foundIndex === -1) {
            speciesIdsBuf[uniqueCount] = speciesId;
            speciesCountsBuf[uniqueCount] = 1;
            uniqueCount++;
          } else {
            speciesCountsBuf[foundIndex]++;
          }
        }
        const speciesCount = uniqueCount || 1;
        _EvolutionEngine._speciesHistory = _EvolutionEngine.#pushHistory(
          _EvolutionEngine._speciesHistory,
          speciesCount,
          _EvolutionEngine.#SPECIES_HISTORY_MAX
        );
        const _speciesHistory = _EvolutionEngine._speciesHistory ?? _EvolutionEngine.#EMPTY_VEC;
        const recentWindow = _EvolutionEngine.#getTail(
          _speciesHistory,
          _EvolutionEngine.#SPECIES_COLLAPSE_WINDOW
        );
        const collapsed = recentWindow.length === _EvolutionEngine.#SPECIES_COLLAPSE_WINDOW && recentWindow.every((v) => v === 1);
        if (collapsed) {
          const neatAny = neat;
          if (typeof neatAny.mutationRate === "number") {
            neatAny.mutationRate = Math.min(
              _EvolutionEngine.#COLLAPSE_MUTRATE_CAP,
              neatAny.mutationRate * _EvolutionEngine.#COLLAPSE_MUTRATE_MULT
            );
          }
          if (typeof neatAny.mutationAmount === "number") {
            neatAny.mutationAmount = Math.min(
              _EvolutionEngine.#COLLAPSE_MUTAMOUNT_CAP,
              neatAny.mutationAmount * _EvolutionEngine.#COLLAPSE_MUTAMOUNT_MULT
            );
          }
          if (neatAny.config && neatAny.config.novelty) {
            neatAny.config.novelty.blendFactor = Math.min(
              _EvolutionEngine.#COLLAPSE_NOVELTY_BLEND_CAP,
              neatAny.config.novelty.blendFactor * _EvolutionEngine.#COLLAPSE_NOVELTY_MULT
            );
          }
        }
        return collapsed;
      } catch {
        return false;
      }
    }
    /**
     * Possibly expand the population when configured and plateau conditions are met.
     * This helper decides whether to grow the NEAT population and delegates the
     * actual creation of children to `#expandPopulation` when required.
     *
     * Behaviour & guarantees:
     * - Best-effort: non-throwing and swallows internal errors to avoid breaking the
     *   evolution loop. Any growth side-effects are performed by `#expandPopulation`.
     * - Allocation-light: performs numeric checks and uses pooled references; it does
     *   not allocate per-call data structures.
     *
     * @param neat - NEAT driver instance; expected to expose a `population` array and `options`.
     * @param dynamicPopEnabled - When falsy no expansion will be attempted.
     * @param completedGenerations - Current generation counter (integer, newest generation).
     * @param dynamicPopMax - Maximum allowed population size (upper bound, integer).
     * @param plateauGenerations - Window length used to compute plateau ratio (integer > 0).
     * @param plateauCounter - Number of plateaued generations observed within the window.
     * @param dynamicPopExpandInterval - Generation interval to attempt expansion (e.g. every N gens).
     * @param dynamicPopExpandFactor - Fractional growth factor used to compute additions (e.g. 0.1 -> 10%).
     * @param dynamicPopPlateauSlack - Minimum plateau ratio (0..1) required to trigger expansion.
     * @param safeWrite - Logger function used by `#expandPopulation` to emit status lines.
     *
     * @example
     * // Attempt an expansion every 5 generations when at least 75% of the plateau
     * // window is 'stalled'. The call is best-effort and will not throw.
     * EvolutionEngine['#maybeExpandPopulation'](
     *   neat,
     *   true,        // dynamicPopEnabled
     *   100,         // completedGenerations
     *   500,         // dynamicPopMax
     *   10,          // plateauGenerations
     *   8,           // plateauCounter
     *   5,           // dynamicPopExpandInterval
     *   0.1,         // dynamicPopExpandFactor
     *   0.75,        // dynamicPopPlateauSlack
     *   console.log  // safeWrite
     * );
     *
     * @internal
     */
    static #maybeExpandPopulation(neat, dynamicPopEnabled, completedGenerations, dynamicPopMax, plateauGenerations, plateauCounter, dynamicPopExpandInterval, dynamicPopExpandFactor, dynamicPopPlateauSlack, safeWrite) {
      try {
        if (!dynamicPopEnabled || completedGenerations <= 0) return;
        const populationRef = Array.isArray(neat?.population) ? neat.population : _EvolutionEngine.#EMPTY_VEC;
        const maxAllowed = Number.isFinite(dynamicPopMax) ? Math.max(0, dynamicPopMax | 0) : 0;
        if (populationRef.length >= maxAllowed) return;
        const plateauWindow = Number.isFinite(plateauGenerations) && plateauGenerations > 0 ? plateauGenerations | 0 : 0;
        const plateauRatio = plateauWindow > 0 ? Math.min(1, (plateauCounter | 0) / plateauWindow) : 0;
        const expandInterval = Number.isFinite(dynamicPopExpandInterval) && dynamicPopExpandInterval > 0 ? Math.max(1, dynamicPopExpandInterval | 0) : 0;
        if (expandInterval === 0) return;
        const isGenerationTrigger = (completedGenerations | 0) % expandInterval === 0;
        if (!isGenerationTrigger) return;
        const slackThreshold = Number.isFinite(dynamicPopPlateauSlack) ? dynamicPopPlateauSlack : 0;
        if (plateauRatio < slackThreshold) return;
        const currentSize = populationRef.length | 0;
        const factor = Number.isFinite(dynamicPopExpandFactor) ? Math.max(0, dynamicPopExpandFactor) : 0;
        const computedAdd = Math.floor(Math.max(1, currentSize * factor));
        const allowed = Math.max(0, maxAllowed - currentSize);
        const targetAdd = Math.min(computedAdd, allowed);
        if (targetAdd > 0) {
          _EvolutionEngine.#expandPopulation(
            neat,
            targetAdd,
            safeWrite,
            completedGenerations | 0
          );
        }
      } catch {
      }
    }
    /**
     * Safely update a UI dashboard with the latest run state and optionally yield to the
     * host/frame via an awaited flush function.
     *
     * Behaviour (best-effort):
     *  1) If `dashboardManager.update` exists and is callable, call it with the stable
     *     argument order (maze, result, network, completedGenerations, neat). Any exception
     *     raised by the dashboard is swallowed to avoid interrupting the evolution loop.
     *  2) If `flushToFrame` is supplied as an async function, await it to yield control to
     *     the event loop or renderer (for example `() => new Promise(r => requestAnimationFrame(r))`).
     *  3) The helper avoids heap allocations and relies on existing pooled scratch buffers in
     *     the engine for heavy telemetry elsewhere; this method intentionally performs only
     *     short-lived control flow and minimal work.
     *
     * @param maze - Maze instance or descriptor used by dashboard rendering.
     * @param result - Per-run result object (path, progress, telemetry, etc.).
     * @param network - Network or genome object that should be visualised.
     * @param completedGenerations - Integer index of the completed generation.
     * @param neat - NEAT manager instance (context passed to the dashboard update).
     * @param dashboardManager - Optional manager exposing `update(maze, result, network, gen, neat)`.
     * @param flushToFrame - Optional async function used to yield to the host/frame scheduler; may be omitted.
     *
     * @example
     * // Yield to the browser's next repaint after dashboard update:
     * await EvolutionEngine['#updateDashboardAndMaybeFlush'](
     *   maze, genResult, fittestNetwork, gen, neatInstance, dashboard, () => new Promise(r => requestAnimationFrame(r))
     * );
     *
     * @internal
     */
    static async #updateDashboardAndMaybeFlush(maze, result, network, completedGenerations, neat, dashboardManager, flushToFrame) {
      const manager = dashboardManager;
      const yieldFrame = flushToFrame;
      if (manager?.update && typeof manager.update === "function") {
        try {
          manager.update(maze, result, network, completedGenerations, neat);
        } catch (_updateError) {
        }
      }
      if (typeof yieldFrame === "function") {
        try {
          await yieldFrame();
        } catch (_flushError) {
        }
      }
    }
    /**
     * Periodic dashboard update used when the engine wants to refresh a non-primary
     * dashboard view (for example background or periodic reporting). This helper is
     * intentionally small, allocation-light and best-effort: dashboard errors are
     * swallowed so the evolution loop cannot be interrupted by UI issues.
     *
     * Behavioural contract:
     *  1) If `dashboardManager.update` is present and callable the method invokes it with
     *     the stable argument order: (maze, bestResult, bestNetwork, completedGenerations, neat).
     *  2) If `flushToFrame` is supplied the helper awaits it after the update to yield to
     *     the host renderer (eg. requestAnimationFrame). Any exceptions raised by the
     *     flush are swallowed.
     *  3) The helper avoids creating ephemeral arrays/objects and therefore does not use
     *     typed-array scratch buffers here — there is no hot numerical work to pool. Other
     *     engine helpers already reuse class-level scratch buffers where appropriate.
     *
     * Steps / inline intent:
     *  1. Fast-guard when an update cannot be performed (missing manager, update method,
     *     or missing content to visualise).
     *  2. Call the dashboard update in a try/catch to preserve best-effort semantics.
     *  3. Optionally await the provided `flushToFrame` function to yield to the host.
     *
     * @param maze - Maze descriptor passed to the dashboard renderer.
     * @param bestResult - Best-run result object used for display (may be falsy when not present).
     * @param bestNetwork - Network or genome object to visualise (may be falsy when not present).
     * @param completedGenerations - Completed generation index (number).
     * @param neat - NEAT manager instance (passed through to dashboard update).
     * @param dashboardManager - Optional manager exposing `update(maze, result, network, gen, neat)`.
     * @param flushToFrame - Optional async function used to yield to the host/frame scheduler
     *                      (for example: `() => new Promise(r => requestAnimationFrame(r))`).
     * @example
     * // Safe periodic update and yield to next frame
     * await EvolutionEngine['#updateDashboardPeriodic'](
     *   maze, result, network, gen, neatInstance, dashboard, () => new Promise(r => requestAnimationFrame(r))
     * );
     *
     * @internal
     */
    static async #updateDashboardPeriodic(maze, bestResult, bestNetwork, completedGenerations, neat, dashboardManager, flushToFrame) {
      const dashboard = dashboardManager;
      const updateFunction = dashboard?.update;
      const frameFlush = flushToFrame;
      if (typeof updateFunction !== "function" || !bestNetwork || !bestResult)
        return;
      try {
        updateFunction.call(
          dashboard,
          maze,
          bestResult,
          bestNetwork,
          completedGenerations,
          neat
        );
      } catch (updateError) {
      }
      if (typeof frameFlush === "function") {
        try {
          await frameFlush();
        } catch (flushError) {
        }
      }
    }
    /**
     * Re-centers and clamps output node biases after local training.
     *
     * Behaviour & contract:
     *  - Computes the mean and (population) standard deviation of the output node biases
     *    using a numerically-stable single-pass Welford accumulator.
     *  - Subtracts the mean from each output bias and applies a small-scale multiplier when
     *    the measured std is below a configured small-std threshold to avoid collapsing to zero.
     *  - Clamps final biases into the safe range [-5, 5] and writes them back in-place.
     *  - Uses a pooled Float64Array (`#SCRATCH_BIAS_TA`) to avoid per-call allocations when
     *    collecting bias values; the buffer grows lazily and uses power-of-two sizing.
     *  - Best-effort: swallows internal errors to preserve the evolution loop.
     *
     * Steps:
     *  1. Fast-guard when `network` is missing or contains no output nodes.
     *  2. Ensure pooled bias scratch buffer has capacity for `outCount` elements.
     *  3. One-pass Welford accumulation over biases to compute mean and M2.
     *  4. Compute population std = sqrt(M2 / outCount) and optionally apply small-std multiplier.
     *  5. Subtract mean from each bias, scale if needed, clamp to [-5,5], and write back.
     *
     * @param network - Network object containing a `nodes` array. Missing nodes are treated as empty.
     * @internal
     * @example
     * // After performing local training on `net` run:
     * EvolutionEngine['#adjustOutputBiasesAfterTraining'](net);
     */
    static #adjustOutputBiasesAfterTraining(network) {
      try {
        if (!network) return;
        const nodesRef = network.nodes ?? _EvolutionEngine.#EMPTY_VEC;
        const outputNodeCount = _EvolutionEngine.#getNodeIndicesByType(
          nodesRef,
          "output"
        );
        if (outputNodeCount <= 0) return;
        let biasScratch = _EvolutionEngine.#SCRATCH_BIAS_TA;
        if (biasScratch.length < outputNodeCount) {
          let newCap = biasScratch.length || 1;
          while (newCap < outputNodeCount) newCap <<= 1;
          biasScratch = _EvolutionEngine.#SCRATCH_BIAS_TA = new Float64Array(
            newCap
          );
        }
        let mean = 0;
        let M2 = 0;
        for (let oi = 0; oi < outputNodeCount; oi++) {
          const nodeIndex = _EvolutionEngine.#SCRATCH_NODE_IDX[oi];
          const currentBias = nodesRef[nodeIndex]?.bias ?? 0;
          biasScratch[oi] = currentBias;
          const sampleIndex = oi + 1;
          const delta = currentBias - mean;
          mean += delta / sampleIndex;
          M2 += delta * (currentBias - mean);
        }
        const populationStd = outputNodeCount > 0 ? Math.sqrt(M2 / outputNodeCount) : 0;
        const smallStdThreshold = _EvolutionEngine.#DEFAULT_STD_SMALL;
        const smallStdMultiplier = _EvolutionEngine.#DEFAULT_STD_ADJUST_MULT;
        for (let oi = 0; oi < outputNodeCount; oi++) {
          const nodeIndex = _EvolutionEngine.#SCRATCH_NODE_IDX[oi];
          let adjusted = biasScratch[oi] - mean;
          if (populationStd < smallStdThreshold) adjusted *= smallStdMultiplier;
          nodesRef[nodeIndex].bias = Math.max(-5, Math.min(5, adjusted));
        }
      } catch {
      }
    }
    /**
     * Build the supervised training set used for Lamarckian warm-start training.
     * @returns Array of training cases. Each case has:
     *  - `input`: [compassScalar, openN, openE, openS, openW, progressDelta]
     *  - `output`: one-hot desired move [N,E,S,W] with soft probabilities (TRAIN_OUT_PROB_HIGH/LOW)
     * @example
     * // Typical usage (warm-start pretraining):
     * const ds = EvolutionEngine['#buildLamarckianTrainingSet']();
     * EvolutionEngine['#pretrainPopulationWarmStart'](neat, ds);
     * @internal
     */
    static #buildLamarckianTrainingSet() {
      const trainingSet = [];
      const high = _EvolutionEngine.#TRAIN_OUT_PROB_HIGH;
      const low = _EvolutionEngine.#TRAIN_OUT_PROB_LOW;
      const OUTPUTS = [
        [high, low, low, low],
        [low, high, low, low],
        [low, low, high, low],
        [low, low, low, high]
      ];
      const makeInput = (compassScalar, openN, openE, openS, openW, progressDelta) => [compassScalar, openN, openE, openS, openW, progressDelta];
      const pushCase = (inp, direction) => trainingSet.push({ input: inp, output: OUTPUTS[direction] });
      pushCase(makeInput(0, 1, 0, 0, 0, _EvolutionEngine.#PROGRESS_MEDIUM), 0);
      pushCase(makeInput(0.25, 0, 1, 0, 0, _EvolutionEngine.#PROGRESS_MEDIUM), 1);
      pushCase(makeInput(0.5, 0, 0, 1, 0, _EvolutionEngine.#PROGRESS_MEDIUM), 2);
      pushCase(makeInput(0.75, 0, 0, 0, 1, _EvolutionEngine.#PROGRESS_MEDIUM), 3);
      pushCase(makeInput(0, 1, 0, 0, 0, _EvolutionEngine.#PROGRESS_STRONG), 0);
      pushCase(makeInput(0.25, 0, 1, 0, 0, _EvolutionEngine.#PROGRESS_STRONG), 1);
      pushCase(makeInput(0, 1, 0.6, 0, 0, _EvolutionEngine.#PROGRESS_JUNCTION), 0);
      pushCase(makeInput(0, 1, 0, 0.6, 0, _EvolutionEngine.#PROGRESS_JUNCTION), 0);
      pushCase(
        makeInput(0.25, 0.6, 1, 0, 0, _EvolutionEngine.#PROGRESS_JUNCTION),
        1
      );
      pushCase(
        makeInput(0.25, 0, 1, 0.6, 0, _EvolutionEngine.#PROGRESS_JUNCTION),
        1
      );
      pushCase(
        makeInput(0.5, 0, 0.6, 1, 0, _EvolutionEngine.#PROGRESS_JUNCTION),
        2
      );
      pushCase(
        makeInput(0.5, 0, 0, 1, 0.6, _EvolutionEngine.#PROGRESS_JUNCTION),
        2
      );
      pushCase(
        makeInput(0.75, 0, 0, 0.6, 1, _EvolutionEngine.#PROGRESS_JUNCTION),
        3
      );
      pushCase(
        makeInput(0.75, 0.6, 0, 0, 1, _EvolutionEngine.#PROGRESS_JUNCTION),
        3
      );
      pushCase(
        makeInput(0, 1, 0.8, 0.5, 0.4, _EvolutionEngine.#PROGRESS_FOURWAY),
        0
      );
      pushCase(
        makeInput(0.25, 0.7, 1, 0.6, 0.5, _EvolutionEngine.#PROGRESS_FOURWAY),
        1
      );
      pushCase(
        makeInput(0.5, 0.6, 0.55, 1, 0.65, _EvolutionEngine.#PROGRESS_FOURWAY),
        2
      );
      pushCase(
        makeInput(0.75, 0.5, 0.45, 0.7, 1, _EvolutionEngine.#PROGRESS_FOURWAY),
        3
      );
      pushCase(makeInput(0, 1, 0.3, 0, 0, _EvolutionEngine.#PROGRESS_REGRESS), 0);
      pushCase(
        makeInput(0.25, 0.5, 1, 0.4, 0, _EvolutionEngine.#PROGRESS_REGRESS),
        1
      );
      pushCase(
        makeInput(0.5, 0, 0.3, 1, 0.2, _EvolutionEngine.#PROGRESS_REGRESS),
        2
      );
      pushCase(
        makeInput(0.75, 0, 0.5, 0.4, 1, _EvolutionEngine.#PROGRESS_REGRESS),
        3
      );
      pushCase(
        makeInput(
          0,
          0,
          0,
          _EvolutionEngine.#PROGRESS_MIN_SIGNAL,
          0,
          _EvolutionEngine.#PROGRESS_MILD_REGRESS
        ),
        2
      );
      for (let dsi = 0; dsi < trainingSet.length; dsi++) {
        const caseEntry = trainingSet[dsi];
        for (let dirIndex = 1; dirIndex <= 4; dirIndex++) {
          if (caseEntry.input[dirIndex] === 1 && _EvolutionEngine.#fastRandom() < _EvolutionEngine.#DEFAULT_JITTER_PROB)
            caseEntry.input[dirIndex] = _EvolutionEngine.#AUGMENT_JITTER_BASE + _EvolutionEngine.#fastRandom() * _EvolutionEngine.#AUGMENT_JITTER_RANGE;
        }
        if (_EvolutionEngine.#fastRandom() < _EvolutionEngine.#AUGMENT_PROGRESS_JITTER_PROB)
          caseEntry.input[5] = Math.min(
            1,
            Math.max(
              0,
              caseEntry.input[5] + (_EvolutionEngine.#fastRandom() * _EvolutionEngine.#AUGMENT_PROGRESS_DELTA_RANGE - _EvolutionEngine.#AUGMENT_PROGRESS_DELTA_HALF)
            )
          );
      }
      return trainingSet;
    }
    /**
     * Pretrain the population using a small supervised dataset and apply a warm-start.
     *
     * Behaviour & contract:
     *  - Runs a short supervised training pass (backprop) on each network in `neat.population`.
     *  - Applies lightweight warm-start heuristics after training: compass wiring and output bias centering.
     *  - Errors are isolated per-network: a failing network does not abort the overall pretrain step.
     *  - This helper is allocation-light and does not create sizable temporary buffers; it delegates heavy
     *    work to `net.train` and the `#applyCompassWarmStart` / `#centerOutputBiases` helpers which reuse
     *    class-level scratch buffers where appropriate.
     *
     * Steps:
     *  1) Validate inputs and obtain `population` (fast-exit on empty populations).
     *  2) For each network: guard missing `train` method, compute conservative iteration budget, then call `train`.
     *  3) Apply warm-start heuristics (compass wiring + bias centering). Swallow any per-network exceptions.
     *
     * @param neat NEAT instance exposing a `population` array of networks. Missing/empty populations are a no-op.
     * @param lamarckianTrainingSet Array of `{input:number[], output:number[]}` training cases used for warm-start.
     * @internal
     */
    static #pretrainPopulationWarmStart(neat, lamarckianTrainingSet) {
      if (!neat) return;
      const population = neat.population ?? _EvolutionEngine.#EMPTY_VEC;
      if (!Array.isArray(population) || population.length === 0) return;
      for (let networkIndex = 0; networkIndex < population.length; networkIndex++) {
        const network = population[networkIndex];
        try {
          if (!network || typeof network.train !== "function") continue;
          const iterations = Math.min(
            _EvolutionEngine.#PRETRAIN_MAX_ITER,
            _EvolutionEngine.#PRETRAIN_BASE_ITER + Math.floor((lamarckianTrainingSet?.length || 0) / 2)
          );
          network.train(lamarckianTrainingSet, {
            iterations,
            error: _EvolutionEngine.#DEFAULT_TRAIN_ERROR,
            rate: _EvolutionEngine.#DEFAULT_PRETRAIN_RATE,
            momentum: _EvolutionEngine.#DEFAULT_PRETRAIN_MOMENTUM,
            batchSize: _EvolutionEngine.#DEFAULT_PRETRAIN_BATCH,
            allowRecurrent: true,
            cost: methods_exports.Cost.softmaxCrossEntropy
          });
          try {
            _EvolutionEngine.#applyCompassWarmStart(network);
          } catch {
          }
          try {
            _EvolutionEngine.#centerOutputBiases(network);
          } catch {
          }
        } catch {
        }
      }
    }
    /**
     * Create a cooperative frame-yielding function used by the evolution loop.
     * @internal
     * @returns A function that yields cooperatively to the next animation frame / tick.
     *
     * Behaviour:
     *  - Prefers `requestAnimationFrame` when available (browser hosts).
     *  - Falls back to `setImmediate` when available (Node) or `setTimeout(...,0)` otherwise.
     *  - Respects a cooperative pause flag (`globalThis.asciiMazePaused`) by polling between ticks
     *    without busy-waiting. The returned function resolves once a single new frame/tick is available
     *    and the pause flag is not set.
     *
     * Steps:
     *  1) Choose the preferred tick function based on the host runtime.
     *  2) When called, await the preferred tick; if `asciiMazePaused` is true poll again after the tick.
     *  3) Resolve once a tick passed while not paused.
     */
    static #makeFlushToFrame() {
      const rafTick = () => new Promise(
        (resolve) => globalThis.requestAnimationFrame ? globalThis.requestAnimationFrame(() => resolve()) : setTimeout(() => resolve(), 0)
      );
      const immediateTick = () => new Promise(
        (resolve) => typeof setImmediate === "function" ? setImmediate(resolve) : setTimeout(resolve, 0)
      );
      const timeoutTick = () => new Promise((resolve) => setTimeout(resolve, 0));
      const preferredTick = typeof globalThis.requestAnimationFrame === "function" ? rafTick : typeof setImmediate === "function" ? immediateTick : timeoutTick;
      return async () => {
        while (true) {
          await preferredTick();
          if (!globalThis.asciiMazePaused) return;
        }
      };
    }
    /**
     * Initialize persistence helpers (Node `fs` & `path`) when available and ensure the target
     * directory exists. This helper intentionally does nothing in browser-like hosts.
     *
     * Steps:
     * 1) Detect whether a Node-like `require` is available and attempt to load `fs` and `path`.
     * 2) If both modules are available and `persistDir` is provided, ensure the directory exists
     *    by creating it recursively when necessary.
     * 3) Return an object containing the (possibly null) `{ fs, path }` references for callers to use.
     *
     * Notes:
     * - This helper deliberately performs defensive checks and swallows synchronous errors because
     *   persistence is optional in many host environments (tests, browser demos).
     * - No large allocations are performed here; the function returns lightweight references.
     *
     * @param persistDir Optional directory to ensure exists. If falsy, no filesystem mutations are attempted.
     * @returns Object with `{ fs, path }` where each value may be `null` when unavailable.
     * @internal
     */
    static #initPersistence(persistDir) {
      let fs = null;
      let path = null;
      try {
        const maybeRequire = globalThis.require ?? (typeof __require === "function" ? __require : null);
        if (maybeRequire) {
          try {
            fs = maybeRequire("fs");
            path = maybeRequire("path");
          } catch {
          }
        }
      } catch {
      }
      if (fs && typeof fs.existsSync === "function" && persistDir) {
        try {
          if (!fs.existsSync(persistDir)) {
            if (typeof fs.mkdirSync === "function")
              fs.mkdirSync(persistDir, { recursive: true });
          }
        } catch {
        }
      }
      return { fs, path };
    }
    /**
     * Build a resilient writer that attempts to write to Node stdout, then a provided
     * dashboard logger, and finally `console.log` as a last resort.
     *
     * Steps:
     * 1) If Node `process.stdout.write` is available, use it (no trailing newline forced).
     * 2) Else if `dashboardManager.logFunction` exists, call it.
     * 3) Else fall back to `console.log` and trim the message.
     *
     * Notes:
     * - Errors are swallowed; logging must never throw and disrupt the evolution loop.
     * - This factory is allocation-light; the returned function only creates a trimmed string
     *   when falling back to `console.log`.
     *
     * @param dashboardManager Optional manager exposing `logFunction(msg:string)` used in some UIs.
     * @returns A function accepting a single string message to write.
     * @internal
     */
    static #makeSafeWriter(dashboardManager) {
      const hasProcessStdout = (() => {
        try {
          return typeof process !== "undefined" && process && process.stdout && typeof process.stdout.write === "function";
        } catch {
          return false;
        }
      })();
      const dashboardLogFn = (() => {
        try {
          return dashboardManager && dashboardManager.logFunction ? dashboardManager.logFunction.bind(dashboardManager) : null;
        } catch {
          return null;
        }
      })();
      return (msg) => {
        if (!msg && msg !== "") return;
        if (hasProcessStdout) {
          try {
            process.stdout.write(msg);
            return;
          } catch {
          }
        }
        if (dashboardLogFn) {
          try {
            dashboardLogFn(msg);
            return;
          } catch {
          }
        }
        try {
          if (typeof console !== "undefined" && typeof console.log === "function")
            console.log(msg.trim());
        } catch {
        }
      };
    }
    /**
     * Construct a configured Neat instance using the project's recommended defaults.
     *
     * Steps:
     * 1) Normalize `cfg` into a local `conf` bag so we can use nullish coalescing for defaults.
     * 2) Derive commonly-used numeric settings (popsize, elitism, provenance) into descriptive locals.
     * 3) Assemble the final options object and instantiate the `Neat` driver.
     *
     * Notes:
     * - This helper centralizes engine opinionated defaults so other parts of the engine remain concise.
     * - No typed-array scratch buffers are required here; the configuration objects are small and infrequently created.
     *
     * @param inputCount Number of inputs for the networks.
     * @param outputCount Number of outputs for the networks.
     * @param fitnessCallback Function receiving a network and returning its fitness score.
     * @param cfg Optional configuration overrides (popSize, mutation, telemetry, etc.).
     * @returns A new configured `Neat` instance.
     * @example
     * // Create a neat instance with a custom population size and disabled lineage tracking
     * const neat = EvolutionEngine['#createNeat'](10, 4, fitnessFn, { popSize: 200, lineageTracking: false });
     * @internal
     */
    static #createNeat(inputCount, outputCount, fitnessCallback, cfg) {
      const conf = cfg ?? {};
      const popSize = Number.isFinite(conf.popSize) ? conf.popSize : _EvolutionEngine.#DEFAULT_POPSIZE;
      const mutationOps = Array.isArray(conf.mutation) ? conf.mutation : [
        methods_exports.mutation.ADD_NODE,
        methods_exports.mutation.SUB_NODE,
        methods_exports.mutation.ADD_CONN,
        methods_exports.mutation.SUB_CONN,
        methods_exports.mutation.MOD_BIAS,
        methods_exports.mutation.MOD_ACTIVATION,
        methods_exports.mutation.MOD_CONNECTION,
        methods_exports.mutation.ADD_LSTM_NODE
      ];
      const elitism = Math.max(
        1,
        Math.floor(popSize * _EvolutionEngine.#DEFAULT_ELITISM_FRACTION)
      );
      const provenance = Math.max(
        1,
        Math.floor(popSize * _EvolutionEngine.#DEFAULT_PROVENANCE_FRACTION)
      );
      const allowRecurrent = conf.allowRecurrent !== false;
      const adaptiveMutation = conf.adaptiveMutation ?? {
        enabled: true,
        strategy: "twoTier"
      };
      const multiObjective = conf.multiObjective ?? {
        enabled: true,
        complexityMetric: "nodes",
        autoEntropy: true
      };
      const telemetry = conf.telemetry ?? {
        enabled: true,
        performance: true,
        complexity: true,
        hypervolume: true
      };
      const lineageTracking = conf.lineageTracking === true;
      const novelty = conf.novelty ?? { enabled: true, blendFactor: 0.15 };
      const targetSpecies = conf.targetSpecies ?? _EvolutionEngine.#DEFAULT_TARGET_SPECIES;
      const adaptiveTargetSpecies = conf.adaptiveTargetSpecies ?? {
        enabled: true,
        entropyRange: _EvolutionEngine.#DEFAULT_ENTROPY_RANGE,
        speciesRange: [6, 14],
        smooth: _EvolutionEngine.#DEFAULT_ADAPTIVE_SMOOTH
      };
      const neatInstance = new Neat(inputCount, outputCount, fitnessCallback, {
        popsize: popSize,
        mutation: mutationOps,
        mutationRate: _EvolutionEngine.#DEFAULT_MUTATION_RATE,
        mutationAmount: _EvolutionEngine.#DEFAULT_MUTATION_AMOUNT,
        elitism,
        provenance,
        allowRecurrent,
        minHidden: _EvolutionEngine.#DEFAULT_MIN_HIDDEN,
        adaptiveMutation,
        multiObjective,
        telemetry,
        lineageTracking,
        novelty,
        targetSpecies,
        adaptiveTargetSpecies
      });
      return neatInstance;
    }
    /**
     * Seed the NEAT population from an optional initial population and/or an optional
     * initial best network.
     *
     * This method is intentionally best-effort and non-throwing: any cloning or
     * driver mutating errors are swallowed so the evolution loop can continue.
     *
     * Parameters:
     * @param neat - NEAT driver/manager object which may receive the initial population.
     * @param initialPopulation - Optional array of networks to use as the starting population.
     * @param initialBestNetwork - Optional single network to place at index 0 (best seed).
     * @param targetPopSize - Fallback population size used when `neat.population` is missing.
     *
     * Example:
     * // Use a provided population and ensure `neat.options.popsize` is kept in sync
     * EvolutionEngine['#seedInitialPopulation'](neat, providedPopulation, providedBest, 150);
     *
     * Implementation notes / steps:
     * 1) Fast-guard when `neat` is falsy (nothing to seed).
     * 2) When `initialPopulation` is provided, clone entries into the pooled
     *    `#SCRATCH_POP_CLONE` buffer (grow the pool only when needed). This avoids
     *    per-call allocations while still returning a fresh logical array length.
     * 3) If `initialBestNetwork` is supplied, ensure `neat.population` exists and
     *    overwrite index 0 with a clone of the supplied best network.
     * 4) Keep `neat.options.popsize` consistent with the actual population length
     *    (best-effort, swallowed errors).
     *
     * The method prefers calling `.clone()` on network objects when available and
     * falls back to referencing the original object on clone failure.
     *
     * @internal
     */
    static #seedInitialPopulation(neat, initialPopulation, initialBestNetwork, targetPopSize) {
      if (!neat) return;
      try {
        if (Array.isArray(initialPopulation) && initialPopulation.length > 0) {
          const sourceLength = initialPopulation.length;
          let pooledCloneBuffer = _EvolutionEngine.#SCRATCH_POP_CLONE;
          if (!Array.isArray(pooledCloneBuffer) || pooledCloneBuffer.length < sourceLength) {
            pooledCloneBuffer = new Array(sourceLength);
            _EvolutionEngine.#SCRATCH_POP_CLONE = pooledCloneBuffer;
          }
          for (let sourceIndex = 0; sourceIndex < sourceLength; sourceIndex++) {
            const candidateNetwork = initialPopulation[sourceIndex];
            try {
              pooledCloneBuffer[sourceIndex] = candidateNetwork && typeof candidateNetwork.clone === "function" ? candidateNetwork.clone() : candidateNetwork;
            } catch (cloneError) {
              pooledCloneBuffer[sourceIndex] = candidateNetwork;
            }
          }
          pooledCloneBuffer.length = sourceLength;
          neat.population = pooledCloneBuffer;
        }
        if (initialBestNetwork) {
          if (!Array.isArray(neat.population)) neat.population = [];
          try {
            neat.population[0] = typeof initialBestNetwork.clone === "function" ? initialBestNetwork.clone() : initialBestNetwork;
          } catch {
          }
        }
        try {
          neat.options = neat.options || {};
          neat.options.popsize = Array.isArray(neat.population) ? neat.population.length : targetPopSize;
        } catch {
        }
      } catch (outerError) {
        try {
          neat.options = neat.options || {};
          neat.options.popsize = Array.isArray(neat.population) ? neat.population.length : targetPopSize;
        } catch {
        }
      }
    }
    /**
     * Inspect cooperative cancellation sources and annotate the provided result when cancelled.
     *
     * Behaviour & contract:
     *  - Prefer non-allocating, cheap checks. This helper is allocation-free and uses only
     *    short-lived local references (no typed-array scratch buffers are necessary here).
     *  - Checks two cancellation sources in priority order:
     *      1) `options.cancellation.isCancelled()` (legacy cancellation object)
     *      2) `options.signal.aborted` (standard AbortSignal)
     *  - When a cancellation is observed the helper sets `bestResult.exitReason` to the
     *    canonical string ('cancelled' or 'aborted') and returns that string.
     *  - All checks are best-effort: exceptions are swallowed to avoid disrupting the
     *    evolution control loop.
     *
     * Parameters:
     * @param options - Optional run configuration which may contain `cancellation` and/or `signal`.
     * @param bestResult - Optional mutable result object that will be annotated with `exitReason`.
     * @returns A reason string ('cancelled' | 'aborted') when cancellation is detected, otherwise `undefined`.
     *
     * Example:
     * const cancelReason = EvolutionEngine['#checkCancellation'](opts, runResult);
     * if (cancelReason) return cancelReason;
     *
     * Notes:
     *  - No pooling or typed-array scratch buffers are required for this small helper.
     *  - Keep this method allocation-free and safe to call on hot paths.
     *
     * @internal
     */
    static #checkCancellation(options, bestResult) {
      try {
        const legacyCancellation = options?.cancellation;
        if (legacyCancellation && typeof legacyCancellation.isCancelled === "function" && legacyCancellation.isCancelled()) {
          if (bestResult) bestResult.exitReason = "cancelled";
          return "cancelled";
        }
        const abortSignal = options?.signal;
        if (abortSignal?.aborted) {
          if (bestResult) bestResult.exitReason = "aborted";
          return "aborted";
        }
      } catch (err) {
      }
      return void 0;
    }
    /**
     * Sample `k` items from `src` into the pooled SCRATCH_SAMPLE buffer (with replacement).
     * Returns the number of items written into the scratch buffer.
     * @internal
     * @remarks Non-reentrant: uses shared `#SCRATCH_SAMPLE` buffer.
     */
    static #sampleIntoScratch(src, k) {
      if (!Array.isArray(src) || k <= 0) return 0;
      const requestedSampleCount = Math.floor(k);
      const sourceLength = src.length | 0;
      if (sourceLength === 0) return 0;
      let pooledBuffer = _EvolutionEngine.#SCRATCH_SAMPLE;
      if (!Array.isArray(pooledBuffer))
        pooledBuffer = _EvolutionEngine.#SCRATCH_SAMPLE = [];
      if (pooledBuffer.length < requestedSampleCount) {
        let newCapacity = pooledBuffer.length > 0 ? pooledBuffer.length : 1;
        while (newCapacity < requestedSampleCount) newCapacity <<= 1;
        const newBuf = new Array(newCapacity);
        for (let i = 0; i < pooledBuffer.length; i++) newBuf[i] = pooledBuffer[i];
        _EvolutionEngine.#SCRATCH_SAMPLE = newBuf;
        pooledBuffer = newBuf;
      }
      const writeCount = Math.min(requestedSampleCount, pooledBuffer.length);
      let writeIndex = 0;
      const fastRand = _EvolutionEngine.#fastRandom;
      const blockBound = writeCount & ~3;
      while (writeIndex < blockBound) {
        pooledBuffer[writeIndex++] = src[fastRand() * sourceLength | 0];
        pooledBuffer[writeIndex++] = src[fastRand() * sourceLength | 0];
        pooledBuffer[writeIndex++] = src[fastRand() * sourceLength | 0];
        pooledBuffer[writeIndex++] = src[fastRand() * sourceLength | 0];
      }
      while (writeIndex < writeCount) {
        pooledBuffer[writeIndex++] = src[fastRand() * sourceLength | 0];
      }
      return writeCount;
    }
    /**
     * Sample up to k items (with replacement) from src segment [segmentStart, end) into scratch buffer.
     * Avoids temporary slice allocation for segment sampling.
     * @internal
     * @remarks Non-reentrant: uses shared `#SCRATCH_SAMPLE` buffer.
     *
     * Example:
     * // Sample 10 items from src starting at index 20 into the engine scratch buffer
     * const written = EvolutionEngine['#sampleSegmentIntoScratch'](srcArray, 20, 10);
     */
    static #sampleSegmentIntoScratch(src, segmentStart, k) {
      if (!Array.isArray(src) || k <= 0) return 0;
      const sourceLength = src.length | 0;
      if (segmentStart >= sourceLength) return 0;
      const segmentLength = sourceLength - (segmentStart | 0);
      if (segmentLength <= 0) return 0;
      const requestedSampleCount = Math.floor(k);
      let pooledBuffer = _EvolutionEngine.#SCRATCH_SAMPLE;
      if (!Array.isArray(pooledBuffer))
        pooledBuffer = _EvolutionEngine.#SCRATCH_SAMPLE = [];
      if (pooledBuffer.length < requestedSampleCount) {
        let newCapacity = pooledBuffer.length > 0 ? pooledBuffer.length : 1;
        while (newCapacity < requestedSampleCount) newCapacity <<= 1;
        const newBuf = new Array(newCapacity);
        for (let i = 0; i < pooledBuffer.length; i++) newBuf[i] = pooledBuffer[i];
        _EvolutionEngine.#SCRATCH_SAMPLE = newBuf;
        pooledBuffer = newBuf;
      }
      const writeCount = Math.min(requestedSampleCount, pooledBuffer.length);
      let writeIndex = 0;
      const fastRand = _EvolutionEngine.#fastRandom;
      const baseIndex = segmentStart | 0;
      const blockBound = writeCount & ~3;
      while (writeIndex < blockBound) {
        pooledBuffer[writeIndex++] = src[baseIndex + (fastRand() * segmentLength | 0)];
        pooledBuffer[writeIndex++] = src[baseIndex + (fastRand() * segmentLength | 0)];
        pooledBuffer[writeIndex++] = src[baseIndex + (fastRand() * segmentLength | 0)];
        pooledBuffer[writeIndex++] = src[baseIndex + (fastRand() * segmentLength | 0)];
      }
      while (writeIndex < writeCount) {
        pooledBuffer[writeIndex++] = src[baseIndex + (fastRand() * segmentLength | 0)];
      }
      return writeCount;
    }
    /**
     * Run one generation: evolve, ensure output identity, update species history, maybe expand population,
     * and run Lamarckian training if configured.
     *
     * Behaviour & contract:
     *  - Performs a single NEAT generation step in a best-effort, non-throwing manner.
     *  - Measures profiling durations when `doProfile` is truthy. Profiling is optional and
     *    kept allocation-free (uses local numeric temporaries only).
     *  - Invokes the following steps in order (each step is wrapped in a try/catch so
     *    the evolution loop remains resilient to per-stage failures):
     *      1) `neat.evolve()` to produce the fittest network for this generation.
     *      2) `#ensureOutputIdentity` to normalise output activations for consumers.
     *      3) `#handleSpeciesHistory` to update species statistics and history.
     *      4) `#maybeExpandPopulation` to grow the population when configured and warranted.
     *      5) Optional Lamarckian warm-start training via `#applyLamarckianTraining`.
     *  - The method is allocation-light and reuses engine helpers / pooled buffers where
     *    appropriate. It never throws; internal errors are swallowed and optionally logged
     *    via the provided `safeWrite` function.
     *
     * Parameters (props):
     * @param neat - NEAT driver instance used for evolving the generation.
     * @param doProfile - When truthy measure timing for the evolve step (ms) using engine clock.
     * @param lamarckianIterations - Number of supervised training iterations to run per genome (0 to skip).
     * @param lamarckianTrainingSet - Array of supervised training cases used for warm-start (may be empty).
     * @param lamarckianSampleSize - Optional per-network sample size used by the warm-start routine.
     * @param safeWrite - Safe logging function; used only for best-effort diagnostic messages.
     * @param completedGenerations - Current generation index (used by expansion heuristics).
     * @param dynamicPopEnabled - Whether dynamic population expansion is enabled.
     * @param dynamicPopMax - Upper bound on population size for expansion.
     * @param plateauGenerations - Window size used by plateau detection.
     * @param plateauCounter - Current plateau counter used by expansion heuristics.
     * @param dynamicPopExpandInterval - Generation interval to attempt expansion.
     * @param dynamicPopExpandFactor - Fractional growth factor used to compute new members.
     * @param dynamicPopPlateauSlack - Minimum plateau ratio required to trigger expansion.
     *
     * @returns An object shaped { fittest, tEvolve, tLamarck } where:
     *  - `fittest` is the network returned by `neat.evolve()` (may be null on error),
     *  - `tEvolve` is the measured evolve duration in milliseconds when `doProfile` is true (0 otherwise),
     *  - `tLamarck` is the total time spent in Lamarckian training (0 when skipped).
     *
     * @example
     * // Run a single generation with profiling and optional Lamarckian warm-start
     * const { fittest, tEvolve, tLamarck } = await EvolutionEngine['#runGeneration'](
     *   neatInstance,
     *   true,   // doProfile
     *   5,      // lamarckianIterations
     *   trainingSet,
     *   16,     // lamarckianSampleSize
     *   console.log,
     *   genIndex,
     *   true,
     *   500,
     *   10,
     *   plateauCounter,
     *   5,
     *   0.1,
     *   0.75
     * );
     *
     * @internal
     */
    static async #runGeneration(neat, doProfile, lamarckianIterations, lamarckianTrainingSet, lamarckianSampleSize, safeWrite, completedGenerations, dynamicPopEnabled, dynamicPopMax, plateauGenerations, plateauCounter, dynamicPopExpandInterval, dynamicPopExpandFactor, dynamicPopPlateauSlack) {
      const profileEnabled = Boolean(doProfile);
      const clockNow = () => _EvolutionEngine.#now();
      const startTime = profileEnabled ? clockNow() : 0;
      let fittestNetwork = null;
      let evolveDuration = 0;
      let lamarckDuration = 0;
      try {
        fittestNetwork = await neat?.evolve();
        if (profileEnabled) evolveDuration = clockNow() - startTime;
      } catch (evolveError) {
        try {
          safeWrite?.(`#runGeneration: evolve() threw: ${String(evolveError)}`);
        } catch {
        }
      }
      try {
        _EvolutionEngine.#ensureOutputIdentity(neat);
      } catch (identityError) {
        try {
          safeWrite?.(
            `#runGeneration: ensureOutputIdentity failed: ${String(
              identityError
            )}`
          );
        } catch {
        }
      }
      try {
        _EvolutionEngine.#handleSpeciesHistory(neat);
      } catch (speciesError) {
        try {
          safeWrite?.(
            `#runGeneration: handleSpeciesHistory failed: ${String(speciesError)}`
          );
        } catch {
        }
      }
      try {
        _EvolutionEngine.#maybeExpandPopulation(
          neat,
          Boolean(dynamicPopEnabled),
          completedGenerations,
          dynamicPopMax,
          plateauGenerations,
          plateauCounter,
          dynamicPopExpandInterval,
          dynamicPopExpandFactor,
          dynamicPopPlateauSlack,
          safeWrite
        );
      } catch (expandError) {
        try {
          safeWrite?.(
            `#runGeneration: maybeExpandPopulation failed: ${String(expandError)}`
          );
        } catch {
        }
      }
      try {
        const shouldRunLamarckian = Number.isFinite(lamarckianIterations) && lamarckianIterations > 0 && Array.isArray(lamarckianTrainingSet) && lamarckianTrainingSet.length > 0;
        if (shouldRunLamarckian) {
          lamarckDuration = _EvolutionEngine.#applyLamarckianTraining(
            neat,
            lamarckianTrainingSet,
            lamarckianIterations,
            lamarckianSampleSize,
            safeWrite,
            doProfile,
            completedGenerations
          );
        }
      } catch (lamarckError) {
        try {
          safeWrite?.(
            `#runGeneration: applyLamarckianTraining failed: ${String(
              lamarckError
            )}`
          );
        } catch {
        }
      }
      return {
        fittest: fittestNetwork,
        tEvolve: evolveDuration,
        tLamarck: lamarckDuration
      };
    }
    /**
     * Update plateau detection state based on the latest fitness.
     *
     * Behaviour & contract:
     *  - Compare the provided `fitness` with the last recorded best-for-plateau plus a
     *    configurable improvement threshold. If the new fitness exceeds that value the
     *    plateau counter is reset and the last-best-for-plateau is updated.
     *  - Otherwise the plateau counter is incremented (capped to avoid overflow).
     *  - The helper is allocation-free and intentionally simple; no pooled scratch
     *    buffers are required for this numeric operation.
     *
     * Steps (high level):
     *  1) Validate numeric inputs and normalise the improvement threshold to a non-negative number.
     *  2) If `fitness` represents a meaningful improvement then reset the counter and update the last-best.
     *  3) Otherwise increment the counter (with a safe cap) and return the updated state.
     *
     * Parameters:
     * @param fitness - Latest measured fitness (finite number expected).
     * @param lastBestFitnessForPlateau - Previous best fitness used as the plateau baseline.
     * @param plateauCounter - Current plateau counter (integer >= 0).
     * @param plateauImprovementThreshold - Minimum improvement required to reset plateau (>= 0).
     * @returns Updated `{ plateauCounter, lastBestFitnessForPlateau }`.
     *
     * @example
     * const state = EvolutionEngine['#updatePlateauState'](1.23, 1.1, 3, 0.05);
     * // state => { plateauCounter: 0, lastBestFitnessForPlateau: 1.23 }
     *
     * @internal
     */
    static #updatePlateauState(fitness, lastBestFitnessForPlateau, plateauCounter, plateauImprovementThreshold) {
      if (!Number.isFinite(fitness)) {
        return { plateauCounter, lastBestFitnessForPlateau };
      }
      const baseline = Number.isFinite(lastBestFitnessForPlateau) ? lastBestFitnessForPlateau : -Infinity;
      const improvementThreshold = Number.isFinite(plateauImprovementThreshold) && plateauImprovementThreshold > 0 ? plateauImprovementThreshold : 0;
      let counter = Number.isFinite(plateauCounter) && plateauCounter >= 0 ? Math.floor(plateauCounter) : 0;
      if (fitness > baseline + improvementThreshold) {
        lastBestFitnessForPlateau = fitness;
        counter = 0;
        return { plateauCounter: counter, lastBestFitnessForPlateau };
      }
      const SAFE_CAP = 536870911;
      counter = Math.min(SAFE_CAP, counter + 1);
      return { plateauCounter: counter, lastBestFitnessForPlateau: baseline };
    }
    /**
     * Handle simplify entry and per-generation advance.
     *
     * Behaviour & contract:
     *  - Decides when to enter a simplification phase and runs one simplify cycle per
     *    generation while active. The helper is intentionally small and allocation-free.
     *  - It delegates the decision to start simplifying to `#maybeStartSimplify` and the
     *    per-generation work to `#runSimplifyCycle`. Both calls are best-effort and any
     *    internal errors are swallowed so the evolution loop remains resilient.
     *
     * Steps:
     *  1) Fast-guard and normalise numeric inputs.
     *  2) If not currently simplifying, ask `#maybeStartSimplify` whether to begin and
     *     initialise `simplifyRemaining` accordingly (reset plateau counter when started).
     *  3) If simplifying, run one simplify cycle and update remaining duration; turn off
     *     simplify mode when the remaining budget is exhausted.
     *
     * Notes:
     *  - This helper does not allocate scratch buffers; no typed-array pooling is necessary.
     *  - Returns the minimal state the caller needs to persist between generations.
     *
     * @param neat - NEAT driver instance used for simplification operations.
     * @param plateauCounter - Current plateau counter (integer >= 0).
     * @param plateauGenerations - Window size used to decide when to attempt simplification.
     * @param simplifyDuration - Requested simplify duration (generations) when starting.
     * @param simplifyMode - Current boolean indicating whether a simplify cycle is active.
     * @param simplifyRemaining - Remaining simplify generations (integer >= 0).
     * @param simplifyStrategy - Strategy identifier passed to the simplify cycle.
     * @param simplifyPruneFraction - Fraction of connections to prune when simplifying.
     * @returns Object with updated { simplifyMode, simplifyRemaining, plateauCounter }.
     *
     * @example
     * const state = EvolutionEngine['#handleSimplifyState'](neat, 3, 10, 5, false, 0, 'aggressive', 0.2);
     * // use returned state in the next generation loop
     *
     * @internal
     */
    static #handleSimplifyState(neat, plateauCounter, plateauGenerations, simplifyDuration, simplifyMode, simplifyRemaining, simplifyStrategy, simplifyPruneFraction) {
      let counter = Number.isFinite(plateauCounter) && plateauCounter >= 0 ? Math.floor(plateauCounter) : 0;
      const windowSize = Number.isFinite(plateauGenerations) && plateauGenerations > 0 ? Math.floor(plateauGenerations) : 0;
      const requestedDuration = Number.isFinite(simplifyDuration) && simplifyDuration > 0 ? Math.floor(simplifyDuration) : 0;
      let remaining = Number.isFinite(simplifyRemaining) && simplifyRemaining > 0 ? Math.floor(simplifyRemaining) : 0;
      let active = Boolean(simplifyMode);
      if (!active) {
        try {
          const startBudget = _EvolutionEngine.#maybeStartSimplify(
            counter,
            windowSize,
            requestedDuration
          );
          if (Number.isFinite(startBudget) && startBudget > 0) {
            active = true;
            remaining = Math.floor(startBudget);
            counter = 0;
          }
        } catch (startError) {
        }
      }
      if (active) {
        try {
          remaining = _EvolutionEngine.#runSimplifyCycle(
            neat,
            remaining,
            simplifyStrategy,
            simplifyPruneFraction
          );
          if (!Number.isFinite(remaining) || remaining <= 0) {
            active = false;
            remaining = 0;
          }
        } catch (cycleError) {
          active = false;
          remaining = 0;
        }
      }
      return {
        simplifyMode: active,
        simplifyRemaining: remaining,
        plateauCounter: counter
      };
    }
    /**
     * Simulate the supplied `fittest` genome/network and perform allocation-light postprocessing.
     *
     * Behaviour & contract:
     *  - Runs the simulation via `MazeMovement.simulateAgent` and attaches compact telemetry
     *    (saturation fraction, action entropy) directly onto the `fittest` object (in-place).
     *  - When per-step logits are returned the helper attempts to copy them into the engine's pooled
     *    ring buffers to avoid per-run allocations. Two copy modes are supported:
     *      1) Shared SAB-backed flat Float32Array with an atomic Int32 write index (cross-worker safe).
     *      2) Local in-process per-row Float32Array ring (`#SCRATCH_LOGITS_RING`).
     *  - Best-effort: all mutation and buffer-copy steps are guarded; failures are swallowed so the
     *    evolution loop is not interrupted. Use `safeWrite` for optional diagnostic messages.
     *
     * Steps (high level):
     *  1) Run the simulator and capture wall-time when `doProfile` is truthy.
     *  2) Attach compact telemetry fields to `fittest` and ensure legacy `_lastStepOutputs` exists.
     *  3) If per-step logits are available, ensure ring capacity and copy them into the selected ring.
     *  4) Optionally prune saturated hidden->output connections and emit telemetry via `#logGenerationTelemetry`.
     *  5) Return the raw simulation result and elapsed simulation time (ms when profiling enabled).
     *
     * Notes on pooling / reentrancy:
     *  - The local ring `#SCRATCH_LOGITS_RING` is not re-entrant; callers must avoid concurrent writes.
     *  - When `#LOGITS_RING_SHARED` is true we prefer the SAB-backed path which uses Atomics and is safe
     *    for cross-thread producers.
     *
     * @param fittest Genome/network considered the generation's best; may be mutated with metadata.
     * @param encodedMaze Maze descriptor used by the simulator.
     * @param startPosition Start co-ordinates passed as-is to the simulator.
     * @param exitPosition Exit co-ordinates passed as-is to the simulator.
     * @param distanceMap Optional precomputed distance map consumed by the simulator.
     * @param maxSteps Optional maximum simulation steps; may be undefined to allow default.
     * @param doProfile When truthy measure and return the simulation time in milliseconds.
     * @param safeWrite Optional logger used for non-fatal diagnostic messages.
     * @param logEvery Emit telemetry every `logEvery` generations (0 disables periodic telemetry).
     * @param completedGenerations Current generation index used for conditional telemetry.
     * @param neat NEAT driver instance passed to telemetry hooks.
     * @returns An object { generationResult, simTime } where simTime is ms when profiling is enabled.
     * @example
     * const { generationResult, simTime } = EvolutionEngine['#simulateAndPostprocess'](
     *   bestGenome, maze, start, exit, distMap, 1000, true, console.log, 10, genIdx, neat
     * );
     * @internal
     */
    static #simulateAndPostprocess(fittest, encodedMaze, startPosition, exitPosition, distanceMap, maxSteps, doProfile, safeWrite, logEvery, completedGenerations, neat) {
      const startTime = doProfile ? _EvolutionEngine.#now() : 0;
      const simResult = MazeMovement.simulateAgent(
        fittest,
        encodedMaze,
        startPosition,
        exitPosition,
        distanceMap,
        maxSteps
      );
      try {
        if (!fittest._lastStepOutputs) {
          fittest._lastStepOutputs = _EvolutionEngine.#SCRATCH_LOGITS_RING;
        }
      } catch {
      }
      try {
        fittest._saturationFraction = simResult?.saturationFraction ?? 0;
        fittest._actionEntropy = simResult?.actionEntropy ?? 0;
      } catch {
      }
      try {
        const perStepLogits = simResult?.stepOutputs;
        if (Array.isArray(perStepLogits) && perStepLogits.length > 0) {
          _EvolutionEngine.#ensureLogitsRingCapacity(perStepLogits.length);
          const useSharedSAB = _EvolutionEngine.#LOGITS_RING_SHARED && _EvolutionEngine.#SCRATCH_LOGITS_SHARED && _EvolutionEngine.#SCRATCH_LOGITS_SHARED_W;
          const actionDim = _EvolutionEngine.#ACTION_DIM;
          if (useSharedSAB) {
            const sharedBuffer = _EvolutionEngine.#SCRATCH_LOGITS_SHARED;
            const atomicIndexView = _EvolutionEngine.#SCRATCH_LOGITS_SHARED_W;
            const capacityMask = _EvolutionEngine.#LOGITS_RING_CAP - 1;
            for (let stepIndex = 0; stepIndex < perStepLogits.length; stepIndex++) {
              const logitsVector = perStepLogits[stepIndex];
              if (!Array.isArray(logitsVector)) continue;
              const currentWriteIndex = Atomics.load(atomicIndexView, 0) & capacityMask;
              const baseOffset = currentWriteIndex * actionDim;
              const copyLength = Math.min(actionDim, logitsVector.length);
              for (let dimIndex = 0; dimIndex < copyLength; dimIndex++) {
                sharedBuffer[baseOffset + dimIndex] = logitsVector[dimIndex] ?? 0;
              }
              Atomics.store(
                atomicIndexView,
                0,
                Atomics.load(atomicIndexView, 0) + 1 & 2147483647
              );
            }
          } else {
            const ringCapacityMask = _EvolutionEngine.#LOGITS_RING_CAP - 1;
            for (let stepIndex = 0; stepIndex < perStepLogits.length; stepIndex++) {
              const logitsVector = perStepLogits[stepIndex];
              if (!Array.isArray(logitsVector)) continue;
              const writePos = _EvolutionEngine.#SCRATCH_LOGITS_RING_W & ringCapacityMask;
              const targetRow = _EvolutionEngine.#SCRATCH_LOGITS_RING[writePos];
              const copyLength = Math.min(actionDim, logitsVector.length);
              for (let dimIndex = 0; dimIndex < copyLength; dimIndex++) {
                targetRow[dimIndex] = logitsVector[dimIndex] ?? 0;
              }
              _EvolutionEngine.#SCRATCH_LOGITS_RING_W = _EvolutionEngine.#SCRATCH_LOGITS_RING_W + 1 & 2147483647;
            }
          }
        }
      } catch {
      }
      try {
        if (simResult?.saturationFraction && simResult.saturationFraction > _EvolutionEngine.#SATURATION_PRUNE_THRESHOLD) {
          _EvolutionEngine.#pruneSaturatedHiddenOutputs(fittest);
        }
      } catch {
      }
      try {
        if (!_EvolutionEngine.#TELEMETRY_MINIMAL && logEvery > 0 && completedGenerations % logEvery === 0) {
          _EvolutionEngine.#logGenerationTelemetry(
            neat,
            fittest,
            simResult,
            completedGenerations,
            safeWrite
          );
        }
      } catch {
      }
      const elapsed = doProfile ? _EvolutionEngine.#now() - startTime : 0;
      return { generationResult: simResult, simTime: elapsed };
    }
    /**
     * Inspect common termination conditions and perform minimal, best-effort side-effects.
     *
     * Behaviour & contract:
     *  - Checks three canonical stop reasons in priority order: `solved`, `stagnation`, then `maxGenerations`.
     *  - When a stop condition is met the helper will:
     *      a) Annotate `bestResult.exitReason` with the canonical reason string.
     *      b) Attempt to update the `dashboardManager` (if present) and await `flushToFrame` to yield to the host.
     *      c) On solve, optionally toggle a cooperative pause flag and emit a small `asciiMazeSolved` event.
     *  - All side-effects are best-effort: exceptions are caught and swallowed so the evolution loop cannot be aborted.
     *  - The helper is allocation-light and uses only local references; it is safe to call frequently.
     *
     * Steps (high-level):
     *  1) Fast-check `solved` using `bestResult.success` and `minProgressToPass`.
     *  2) If solved: update dashboard, await flush, emit optional pause/event, set exit reason and return 'solved'.
     *  3) Check stagnation (bounded by `maxStagnantGenerations`) and, if triggered, update dashboard/flush and return 'stagnation'.
     *  4) Check max generations and return 'maxGenerations' when reached.
     *  5) Return `undefined` when no stop condition applies.
     *
     * @param bestResult Mutable run summary object (may be mutated with `exitReason`).
     * @param bestNetwork Network object associated with the best result (used for dashboard rendering).
     * @param maze Maze descriptor passed to dashboard updates/events.
     * @param completedGenerations Current generation index (integer).
     * @param neat NEAT driver instance (passed to dashboard update).
     * @param dashboardManager Optional manager exposing `update(maze, result, network, gen, neat)`.
     * @param flushToFrame Async function used to yield to the host renderer (e.g. requestAnimationFrame); may be a no-op.
     * @param minProgressToPass Numeric threshold used to consider a run 'solved'.
     * @param autoPauseOnSolve When truthy set cooperative pause flag and emit an event on solve.
     * @param stopOnlyOnSolve When true ignore stagnation/maxGenerations as stop reasons.
     * @param stagnantGenerations Current count of stagnant generations observed.
     * @param maxStagnantGenerations Max allowed stagnant generations before stopping.
     * @param maxGenerations Absolute generation cap after which the run stops.
     * @returns A canonical reason string ('solved'|'stagnation'|'maxGenerations') when stopping, otherwise `undefined`.
     * @example
     * const reason = await EvolutionEngine['#checkStopConditions'](bestResult, bestNet, maze, gen, neat, dashboard, flush, 95, true, false, stagnant, 500, 10000);
     * if (reason) console.log('Stopping due to', reason);
     * @internal
     */
    static async #checkStopConditions(bestResult, bestNetwork, maze, completedGenerations, neat, dashboardManager, flushToFrame, minProgressToPass, autoPauseOnSolve, stopOnlyOnSolve, stagnantGenerations, maxStagnantGenerations, maxGenerations) {
      const hasBest = Boolean(bestResult);
      const shouldConsiderStops = !stopOnlyOnSolve;
      if (bestResult?.success && bestResult.progress >= (minProgressToPass ?? 0)) {
        try {
          dashboardManager?.update?.(
            maze,
            bestResult,
            bestNetwork,
            completedGenerations,
            neat
          );
        } catch {
        }
        try {
          await flushToFrame?.();
        } catch {
        }
        if (autoPauseOnSolve) {
          try {
            if (typeof window !== "undefined") {
              window.asciiMazePaused = true;
              try {
                window.dispatchEvent(
                  new CustomEvent("asciiMazeSolved", {
                    detail: {
                      maze,
                      generations: completedGenerations,
                      progress: bestResult?.progress
                    }
                  })
                );
              } catch {
              }
            }
          } catch {
          }
        }
        if (hasBest) bestResult.exitReason = "solved";
        return "solved";
      }
      if (shouldConsiderStops && isFinite(maxStagnantGenerations) && stagnantGenerations >= maxStagnantGenerations) {
        try {
          dashboardManager?.update?.(
            maze,
            bestResult,
            bestNetwork,
            completedGenerations,
            neat
          );
        } catch {
        }
        try {
          await flushToFrame?.();
        } catch {
        }
        if (hasBest) bestResult.exitReason = "stagnation";
        return "stagnation";
      }
      if (shouldConsiderStops && isFinite(maxGenerations) && completedGenerations >= maxGenerations) {
        if (hasBest) bestResult.exitReason = "maxGenerations";
        return "maxGenerations";
      }
      return void 0;
    }
    /**
     * Prune weak outgoing connections from hidden->output when a hidden node appears
     * saturated (low mean absolute outgoing weight and near-zero variance).
     *
     * Behaviour & contract:
     *  - Performs a single-pass Welford accumulation over absolute outgoing weights to
     *    decide whether a hidden node's outputs are collapsed.
     *  - Uses engine-level typed-array scratch buffers (Float32Array) to avoid per-call
     *    allocations when collecting absolute weights. The scratch buffer will grow lazily
     *    using power-of-two sizing when necessary.
     *  - When saturation is detected we deterministically disable roughly half of the
     *    outgoing connections with smallest absolute weight. Mutation is done in-place.
     *  - All work is best-effort: internal exceptions are swallowed to keep the evolution
     *    loop resilient.
     *
     * Steps (inline):
     *  1) Fast-guard & profiling snapshot.
     *  2) Iterate hidden nodes, collect their outgoing-to-output connections.
     *  3) Copy absolute weights into the pooled Float32Array and run Welford to compute mean/M2.
     *  4) If mean and variance indicate collapse, disable the smallest half of active connections.
     *  5) Record profiling delta when enabled.
     *
     * @param genome Mutable genome object containing a `nodes` array.
     * @internal
     * @example
     * // Soft-prune a single genome after a high-saturation simulation:
     * EvolutionEngine['#pruneSaturatedHiddenOutputs'](genome);
     */
    static #pruneSaturatedHiddenOutputs(genome) {
      try {
        const startProfile = _EvolutionEngine.#PROFILE_ENABLED ? _EvolutionEngine.#PROFILE_T0() : 0;
        const nodesRef = genome?.nodes ?? _EvolutionEngine.#EMPTY_VEC;
        const outputCount = _EvolutionEngine.#getNodeIndicesByType(
          nodesRef,
          "output"
        );
        const hiddenCount = _EvolutionEngine.#getNodeIndicesByType(
          nodesRef,
          "hidden"
        );
        let absWeightsTA = _EvolutionEngine.#SCRATCH_EXPS;
        const indexFlags = _EvolutionEngine.#SCRATCH_NODE_IDX;
        for (let hiddenIndex = 0; hiddenIndex < hiddenCount; hiddenIndex++) {
          const hiddenNode = nodesRef[Number(_EvolutionEngine.#SCRATCH_NODE_IDX[outputCount + hiddenIndex])];
          if (!hiddenNode) continue;
          const outConns = _EvolutionEngine.#collectHiddenToOutputConns(
            hiddenNode,
            nodesRef,
            outputCount
          ) || [];
          const outConnsLen = outConns.length;
          if (outConnsLen < 2) continue;
          const needed = outConnsLen;
          if (!absWeightsTA || absWeightsTA.length < needed) {
            let newCap = 1;
            while (newCap < needed) newCap <<= 1;
            absWeightsTA = new Float64Array(newCap);
            _EvolutionEngine.#SCRATCH_EXPS = absWeightsTA;
          }
          const fillLimit = Math.min(outConnsLen, absWeightsTA.length);
          for (let wi = 0; wi < fillLimit; wi++) {
            const conn = outConns[wi];
            absWeightsTA[wi] = Math.abs(conn?.weight) || 0;
          }
          let mean = 0;
          let M2 = 0;
          for (let wi = 0; wi < fillLimit; wi++) {
            const value = absWeightsTA[wi];
            const n = wi + 1;
            const delta = value - mean;
            mean += delta / n;
            M2 += delta * (value - mean);
          }
          const variance = fillLimit ? M2 / fillLimit : 0;
          if (mean < 0.5 && variance < _EvolutionEngine.#NUMERIC_EPSILON_SMALL) {
            const disableTarget = Math.max(1, Math.floor(outConnsLen / 2));
            for (let fi = 0; fi < outConnsLen; fi++) indexFlags[fi] = 0;
            for (let di = 0; di < disableTarget; di++) {
              let minPos = -1;
              let minAbs = Infinity;
              for (let j = 0; j < outConnsLen; j++) {
                if (indexFlags[j]) continue;
                const candidate = outConns[j];
                if (!candidate || candidate.enabled === false) {
                  indexFlags[j] = 1;
                  continue;
                }
                const weightAbs = Math.abs(candidate.weight) || 0;
                if (weightAbs < minAbs) {
                  minAbs = weightAbs;
                  minPos = j;
                }
              }
              if (minPos >= 0) {
                outConns[minPos].enabled = false;
                indexFlags[minPos] = 1;
              } else {
                break;
              }
            }
            for (let fi = 0; fi < outConnsLen; fi++) indexFlags[fi] = 0;
          }
        }
        if (_EvolutionEngine.#PROFILE_ENABLED) {
          _EvolutionEngine.#PROFILE_ADD(
            "prune",
            _EvolutionEngine.#PROFILE_T0() - startProfile || 0
          );
        }
      } catch {
      }
    }
    /**
     * Anti-collapse recovery: reinitialise a fraction of the non-elite population's
     * output biases and their outgoing weights.
     *
     * Behaviour & contract:
     *  - Selects a deterministic fraction (up to 30%) of non-elite genomes and reinitialises
     *    their output-node biases and any outgoing connections targeting outputs.
     *  - Uses the engine's pooled sample buffer (`#SCRATCH_SAMPLE`) to avoid per-call
     *    allocations. Sampling is done via `#sampleSegmentIntoScratch` into that pool.
     *  - Returns nothing; diagnostic summaries are emitted via the provided `safeWrite`.
     *  - Best-effort and non-throwing: internal errors are swallowed to keep the
     *    evolution loop resilient.
     *
     * Props / Parameters:
     * @param neat - NEAT driver instance which must expose `population` and `options.elitism`.
     * @param completedGenerations - Current generation index used for diagnostic logging.
     * @param safeWrite - Lightweight writer function used for best-effort diagnostics.
     *
     * Example:
     * // Periodically call from the generation loop to recover from weight/bias collapse
     * EvolutionEngine['#antiCollapseRecovery'](neatInstance, generationIndex, console.log);
     *
     * @internal
     */
    static #antiCollapseRecovery(neat, completedGenerations, safeWrite) {
      try {
        const neatInstance = neat ?? null;
        if (!neatInstance) return;
        const elitismCount = Number.isFinite(neatInstance?.options?.elitism) ? Math.max(0, Math.floor(neatInstance.options.elitism)) : 0;
        const population = Array.isArray(neatInstance.population) ? neatInstance.population : _EvolutionEngine.#EMPTY_VEC;
        const nonEliteStartIndex = elitismCount;
        const nonEliteCount = Math.max(0, population.length - nonEliteStartIndex);
        if (nonEliteCount === 0) return;
        const fractionToReinit = 0.3;
        const maxCandidates = Math.floor(nonEliteCount * fractionToReinit) || 1;
        let pooledSampleBuffer = _EvolutionEngine.#SCRATCH_SAMPLE;
        if (!Array.isArray(pooledSampleBuffer)) {
          pooledSampleBuffer = _EvolutionEngine.#SCRATCH_SAMPLE = [];
        }
        const sampledCount = _EvolutionEngine.#sampleSegmentIntoScratch(
          population,
          nonEliteStartIndex,
          maxCandidates
        );
        if (sampledCount <= 0) return;
        let totalConnectionResets = 0;
        let totalBiasResets = 0;
        for (let sampleIndex = 0; sampleIndex < sampledCount; sampleIndex++) {
          const genome = pooledSampleBuffer[sampleIndex];
          if (!genome) continue;
          try {
            const {
              connReset,
              biasReset
            } = _EvolutionEngine.#reinitializeGenomeOutputsAndWeights(genome) || {
              connReset: 0,
              biasReset: 0
            };
            totalConnectionResets += Number(connReset) || 0;
            totalBiasResets += Number(biasReset) || 0;
          } catch (genomeErr) {
          }
        }
        try {
          safeWrite(
            `[ANTICOLLAPSE] gen=${completedGenerations} reinitGenomes=${sampledCount} connReset=${totalConnectionResets} biasReset=${totalBiasResets}
`
          );
        } catch {
        }
      } catch {
      }
    }
    /**
     * Reinitialize output-node biases and outgoing weights that target those outputs
     * for a single genome. This helper is used by the anti-collapse recovery routine
     * to inject fresh variability into non-elite individuals.
     *
     * Behaviour & contract:
     *  - Reuses the engine's pooled sample buffer `#SCRATCH_SAMPLE` to collect output
     *    nodes without allocating a temporary array per-call.
     *  - Randomises each output node's `bias` within [-BIAS_RESET_HALF_RANGE, +BIAS_RESET_HALF_RANGE].
     *  - Resets connection `weight` values for any connection where `conn.to` points to an
     *    output node to a value sampled from the symmetric range defined by
     *    `#CONN_WEIGHT_RESET_HALF_RANGE`.
     *  - Best-effort: the function swallows internal errors and returns zeroed counts on failure.
     *
     * Steps / inline intent:
     *  1) Fast-guard and obtain the genome's node list.
     *  2) Ensure the pooled sample buffer exists and has capacity (grow by power-of-two).
     *  3) Collect references to output nodes into the pooled buffer.
     *  4) Reinitialise each collected output's bias.
     *  5) Reset connection weights that target any collected output (use a Set for O(1) lookup).
     *
     * @param genome - Mutable genome object containing `nodes` and `connections` arrays.
     * @returns Object with counts: `{ connReset: number, biasReset: number }`.
     * @example
     * // Reinitialise outputs for a single genome and inspect the number of changes
     * const deltas = EvolutionEngine['#reinitializeGenomeOutputsAndWeights'](genome);
     * console.log(`connReset=${deltas.connReset} biasReset=${deltas.biasReset}`);
     * @internal
     */
    static #reinitializeGenomeOutputsAndWeights(genome) {
      try {
        const nodesList = Array.isArray(genome?.nodes) ? genome.nodes : [];
        let sampleBuf = _EvolutionEngine.#SCRATCH_SAMPLE;
        if (!Array.isArray(sampleBuf))
          sampleBuf = _EvolutionEngine.#SCRATCH_SAMPLE = [];
        const requiredCapacity = nodesList.length;
        if (sampleBuf.length < requiredCapacity) {
          let newCapacity = Math.max(1, sampleBuf.length);
          while (newCapacity < requiredCapacity) newCapacity <<= 1;
          sampleBuf.length = newCapacity;
        }
        let outputCount = 0;
        for (const node of nodesList) {
          if (node && node.type === "output") {
            sampleBuf[outputCount++] = node;
          }
        }
        let biasReset = 0;
        const biasHalfRange = Number(_EvolutionEngine.#BIAS_RESET_HALF_RANGE) || 0;
        for (let idx = 0; idx < outputCount; idx++) {
          const outNode = sampleBuf[idx];
          if (!outNode) continue;
          outNode.bias = _EvolutionEngine.#fastRandom() * (2 * biasHalfRange) - biasHalfRange;
          biasReset++;
        }
        let connReset = 0;
        const connections = Array.isArray(genome?.connections) ? genome.connections : [];
        if (connections.length > 0 && outputCount > 0) {
          const outputsSet = /* @__PURE__ */ new Set();
          for (let idx = 0; idx < outputCount; idx++) {
            const outNode = sampleBuf[idx];
            if (outNode) outputsSet.add(outNode);
          }
          const weightHalfRange = Number(_EvolutionEngine.#CONN_WEIGHT_RESET_HALF_RANGE) || 0;
          for (const conn of connections) {
            try {
              if (outputsSet.has(conn?.to)) {
                conn.weight = _EvolutionEngine.#fastRandom() * (2 * weightHalfRange) - weightHalfRange;
                connReset++;
              }
            } catch {
            }
          }
        }
        return { connReset, biasReset };
      } catch {
        return { connReset: 0, biasReset: 0 };
      }
    }
    /**
     * Compact a single genome's connection list in-place by removing disabled connections.
     *
     * Behaviour & contract:
     *  - Performs an in-place stable compaction of `genome.connections`, preserving the
     *    relative order of enabled connections while removing entries where `conn.enabled === false`.
     *  - The operation is allocation-light and avoids creating temporary arrays for most
     *    workloads. It follows a two-pointer write/read technique that is optimiser-friendly.
     *  - Best-effort and non-throwing: any internal error is swallowed and the method returns 0.
     *
     * Steps (inline):
     *  1) Fast-guard and obtain the connections list reference.
     *  2) Walk the array with a read pointer and copy enabled connections forward to the write pointer.
     *  3) Truncate the array if disabled connections were removed and return the number removed.
     *
     * @param genome - Mutable genome object that may contain a `connections` array.
     * @returns Number of removed (disabled) connections. Returns 0 on error or when nothing was removed.
     * @example
     * // Compact the connections for a genome and inspect how many disabled connections were removed
     * const removed = EvolutionEngine['#compactGenomeConnections'](genome);
     * console.log(`removed disabled connections: ${removed}`);
     * @internal
     */
    static #compactGenomeConnections(genome) {
      try {
        const connectionsList = Array.isArray(genome?.connections) ? genome.connections : [];
        const totalConnections = connectionsList.length;
        if (totalConnections === 0) return 0;
        let writeIndex = 0;
        for (let readIndex = 0; readIndex < totalConnections; readIndex++) {
          const connection = connectionsList[readIndex];
          if (connection && connection.enabled !== false) {
            if (readIndex !== writeIndex)
              connectionsList[writeIndex] = connection;
            writeIndex++;
          }
        }
        const removedCount = totalConnections - writeIndex;
        if (removedCount > 0) connectionsList.length = writeIndex;
        return removedCount;
      } catch {
        return 0;
      }
    }
    /**
     * Compact the entire population by removing disabled connections from each genome.
     *
     * Behaviour & contract:
     *  - Iterates the `neat.population` array and compacts each genome's connection list
     *    in-place using `#compactGenomeConnections`.
     *  - Uses the engine's pooled sample buffer (`#SCRATCH_SAMPLE`) as a temporary
     *    per-genome removed-counts scratch area to avoid per-call allocations.
     *  - Grows the pooled scratch buffer lazily using power-of-two sizing when necessary.
     *  - Returns the total number of removed (disabled) connections across the population.
     *  - Best-effort and non-throwing: internal errors are swallowed and zero is returned
     *    when compaction cannot be completed.
     *
     * Steps (inline):
     *  1) Fast-guard and obtain the population reference.
     *  2) Ensure the pooled scratch buffer exists and has capacity for the population length.
     *  3) For each genome, run `#compactGenomeConnections` in isolation and store the removed
     *     count into the pooled buffer.
     *  4) Sum the removed counts and return the total.
     *
     * @param neat - NEAT driver exposing a `population` array.
     * @returns Total removed disabled connections across the population (integer >= 0).
     * @example
     * // Compact all genomes and obtain the total number of connections removed
     * const totalRemoved = EvolutionEngine['#compactPopulation'](neatInstance);
     * console.log(`removed connections: ${totalRemoved}`);
     * @internal
     */
    static #compactPopulation(neat) {
      try {
        const populationList = Array.isArray(neat?.population) ? neat.population : [];
        const populationSize = populationList.length;
        if (populationSize === 0) return 0;
        let scratchCounts = _EvolutionEngine.#SCRATCH_SAMPLE;
        if (!Array.isArray(scratchCounts))
          scratchCounts = _EvolutionEngine.#SCRATCH_SAMPLE = [];
        if (scratchCounts.length < populationSize) {
          let newCapacity = Math.max(1, scratchCounts.length);
          while (newCapacity < populationSize) newCapacity <<= 1;
          scratchCounts.length = newCapacity;
        }
        let totalRemoved = 0;
        for (let idx = 0; idx < populationSize; idx++) {
          try {
            const genome = populationList[idx];
            const removedForGenome = _EvolutionEngine.#compactGenomeConnections(genome) | 0;
            scratchCounts[idx] = removedForGenome;
            totalRemoved += removedForGenome;
          } catch {
            scratchCounts[idx] = 0;
          }
        }
        return totalRemoved;
      } catch {
        return 0;
      }
    }
    /**
     * Shrink oversize pooled scratch buffers when they grow much larger than the population.
     *
     * Behaviour & contract:
     *  - Heuristically shrink pooled buffers (plain arrays and typed arrays) when their
     *    capacity exceeds a configurable multiple of the current population size. This
     *    reduces memory pressure after large compaction or temporary peaks.
     *  - Uses power-of-two sizing for the target capacity to keep growth/shrinkage cache-friendly.
     *  - When shrinking typed arrays the helper creates a new typed array and copies the
     *    preserved prefix (min(oldLen, newLen)) to avoid losing useful scratch state.
     *  - Best-effort: all errors are swallowed so this maintenance helper cannot throw.
     *
     * Steps (inline):
     *  1) Fast-guard and compute the population size.
     *  2) Compute a target capacity (power-of-two) for pools using a small minimum.
     *  3) For each known pool: if current capacity >> target threshold, allocate a smaller
     *     pool and copy preserved items where appropriate.
     *
     * @param neat - NEAT instance used to derive population size for heuristics.
     * @internal
     */
    static #maybeShrinkScratch(neat) {
      try {
        const populationSize = Array.isArray(neat?.population) ? neat.population.length : 0;
        if (!populationSize) return;
        const SHRINK_THRESHOLD_FACTOR = 8;
        const MIN_POOL_SIZE = 8;
        const nextPowerOfTwo = (n) => 1 << Math.ceil(Math.log2(Math.max(1, n)));
        const desiredCapacity = nextPowerOfTwo(
          Math.max(MIN_POOL_SIZE, populationSize)
        );
        try {
          const sortIdx = _EvolutionEngine.#SCRATCH_SORT_IDX;
          if (Array.isArray(sortIdx) && sortIdx.length > populationSize * SHRINK_THRESHOLD_FACTOR) {
            _EvolutionEngine.#SCRATCH_SORT_IDX = new Array(desiredCapacity);
          }
        } catch {
        }
        try {
          let samplePool = _EvolutionEngine.#SCRATCH_SAMPLE;
          if (!Array.isArray(samplePool))
            samplePool = _EvolutionEngine.#SCRATCH_SAMPLE = [];
          if (samplePool.length > populationSize * SHRINK_THRESHOLD_FACTOR) {
            samplePool.length = desiredCapacity;
            _EvolutionEngine.#SCRATCH_SAMPLE = samplePool;
          }
        } catch {
        }
        try {
          const exps = _EvolutionEngine.#SCRATCH_EXPS;
          if (exps instanceof Float64Array && exps.length > populationSize * SHRINK_THRESHOLD_FACTOR) {
            const newLen = desiredCapacity;
            const smaller = new Float64Array(newLen);
            smaller.set(exps.subarray(0, Math.min(exps.length, newLen)));
            _EvolutionEngine.#SCRATCH_EXPS = smaller;
          }
        } catch {
        }
        try {
          const biasTa = _EvolutionEngine.#SCRATCH_BIAS_TA;
          if (biasTa instanceof Float64Array && biasTa.length > populationSize * SHRINK_THRESHOLD_FACTOR) {
            const newLen = desiredCapacity;
            const smaller = new Float64Array(newLen);
            smaller.set(biasTa.subarray(0, Math.min(biasTa.length, newLen)));
            _EvolutionEngine.#SCRATCH_BIAS_TA = smaller;
          }
        } catch {
        }
        try {
          const nodeIdx = _EvolutionEngine.#SCRATCH_NODE_IDX;
          if (nodeIdx instanceof Int32Array && nodeIdx.length > populationSize * SHRINK_THRESHOLD_FACTOR) {
            const newLen = desiredCapacity;
            const smaller = new Int32Array(newLen);
            smaller.set(nodeIdx.subarray(0, Math.min(nodeIdx.length, newLen)));
            _EvolutionEngine.#SCRATCH_NODE_IDX = smaller;
          }
        } catch {
        }
      } catch {
      }
    }
    /**
     * Runs the NEAT neuro-evolution process for an agent to solve a given ASCII maze.
     *
     * This is the core function of the `EvolutionEngine`. It sets up and runs the evolutionary
     * algorithm to train a population of neural networks. Each network acts as the "brain" for an
     * agent, controlling its movement through the maze from a start point 'S' to an exit 'E'.
     *
     * The process involves several key steps:
     * 1.  **Initialization**: Sets up the maze, NEAT parameters, and the initial population of networks.
     * 2.  **Generational Loop**: Iterates through generations, performing the following for each:
     *     a. **Evaluation**: Each network's performance (fitness) is measured by how well its agent navigates the maze.
     *        Fitness is typically based on progress towards the exit, speed, and efficiency.
     *     b. **Lamarckian Refinement**: Each individual in the population undergoes a brief period of supervised training
     *        (backpropagation) on a set of ideal sensory-action pairs. This helps to fine-tune promising behaviors.
     *     c. **Selection & Reproduction**: The NEAT algorithm selects the fittest individuals to become parents for the
     *        next generation. It uses genetic operators (crossover and mutation) to create offspring.
     * 3.  **Termination**: The loop continues until a solution is found (an agent successfully reaches the exit) or other
     *     stopping criteria are met (e.g., maximum generations, stagnation).
     *
     * This hybrid approach, combining the global search of evolution with the local search of backpropagation,
     * can significantly accelerate learning and lead to more robust solutions.
     *
     * @param options - A comprehensive configuration object for the maze evolution process.
     * @returns A Promise that resolves with an object containing the best network found, its simulation result, and the final NEAT instance.
     */
    static async runMazeEvolution(options) {
      const {
        mazeConfig,
        agentSimConfig,
        evolutionAlgorithmConfig,
        reportingConfig,
        fitnessEvaluator
      } = options;
      const { maze } = mazeConfig;
      const {
        logEvery = 10,
        dashboardManager,
        paceEveryGeneration
      } = reportingConfig;
      const {
        allowRecurrent = true,
        // Allow networks to have connections that loop back, enabling memory.
        popSize = 500,
        // The number of neural networks in each generation.
        maxStagnantGenerations = 500,
        // Stop evolution if the best fitness doesn't improve for this many generations.
        minProgressToPass = 95,
        // The percentage of progress required to consider the maze "solved".
        maxGenerations = Infinity,
        // A safety cap on the total number of generations to prevent infinite loops.
        randomSeed,
        // An optional seed for the random number generator to ensure reproducible results.
        initialPopulation,
        // An optional population of networks to start with.
        initialBestNetwork,
        // An optional pre-trained network to seed the population.
        lamarckianIterations = 10,
        // The number of backpropagation steps for each individual per generation.
        lamarckianSampleSize,
        // If set, use a random subset of the training data for Lamarckian learning.
        plateauGenerations = 40,
        // Number of generations to wait for improvement before considering the population to be on a plateau.
        plateauImprovementThreshold = 1e-6,
        // The minimum fitness improvement required to reset the plateau counter.
        simplifyDuration = 30,
        // The number of generations to run the network simplification process.
        simplifyPruneFraction = 0.05,
        // The fraction of weak connections to prune during simplification.
        simplifyStrategy = "weakWeight",
        // The strategy for choosing which connections to prune.
        persistEvery = 25,
        // Save a snapshot of the best networks every N generations.
        persistDir = "./ascii_maze_snapshots",
        // The directory to save snapshots in.
        persistTopK = 3,
        // The number of top-performing networks to save in each snapshot.
        dynamicPopEnabled = true,
        // Enable dynamic adjustment of the population size.
        dynamicPopMax: dynamicPopMaxCfg,
        // The maximum population size for dynamic adjustments.
        dynamicPopExpandInterval = 25,
        // The number of generations between population size expansions.
        dynamicPopExpandFactor = 0.15,
        // The factor by which to expand the population size.
        dynamicPopPlateauSlack = 0.6,
        // A slack factor for plateau detection when dynamic population is enabled.
        stopOnlyOnSolve = false,
        // If true, ignore stagnation/maxGenerations and run until solved.
        autoPauseOnSolve = true,
        // Browser demo will override to false to keep running continuously
        deterministic = false,
        memoryCompactionInterval = 50,
        telemetryReduceStats = false,
        telemetryMinimal = false,
        disableBaldwinianRefinement = false
      } = evolutionAlgorithmConfig;
      if (deterministic || typeof randomSeed === "number") {
        _EvolutionEngine.setDeterministic(
          typeof randomSeed === "number" ? randomSeed : 305419896
        );
      }
      _EvolutionEngine.#REDUCED_TELEMETRY = !!telemetryReduceStats;
      _EvolutionEngine.#TELEMETRY_MINIMAL = !!telemetryMinimal;
      _EvolutionEngine.#DISABLE_BALDWIN = !!disableBaldwinianRefinement;
      const dynamicPopMax = typeof dynamicPopMaxCfg === "number" ? dynamicPopMaxCfg : Math.max(popSize, 120);
      const encodedMaze = MazeUtils.encodeMaze(maze);
      const startPosition = MazeUtils.findPosition(maze, "S");
      const exitPosition = MazeUtils.findPosition(maze, "E");
      const distanceMap = MazeUtils.buildDistanceMap(encodedMaze, exitPosition);
      const inputSize = 6;
      const outputSize = 4;
      const currentFitnessEvaluator = fitnessEvaluator || FitnessEvaluator.defaultFitnessEvaluator;
      const fitnessContext = {
        encodedMaze,
        startPosition,
        exitPosition,
        agentSimConfig,
        distanceMap
      };
      const neatFitnessCallback = (network) => {
        return currentFitnessEvaluator(network, fitnessContext);
      };
      const neat = _EvolutionEngine.#createNeat(
        inputSize,
        outputSize,
        neatFitnessCallback,
        {
          popSize,
          allowRecurrent,
          adaptiveMutation: { enabled: true, strategy: "twoTier" },
          multiObjective: {
            enabled: true,
            complexityMetric: "nodes",
            autoEntropy: true
          },
          telemetry: {
            enabled: true,
            performance: true,
            complexity: true,
            hypervolume: true
          },
          lineageTracking: true,
          novelty: { enabled: true, blendFactor: 0.15 },
          targetSpecies: 10,
          adaptiveTargetSpecies: {
            enabled: true,
            entropyRange: [0.3, 0.8],
            speciesRange: [6, 14],
            smooth: 0.5
          }
        }
      );
      _EvolutionEngine.#seedInitialPopulation(
        neat,
        initialPopulation,
        initialBestNetwork,
        popSize
      );
      let bestNetwork = evolutionAlgorithmConfig.initialBestNetwork;
      let bestFitness = -Infinity;
      let bestResult;
      let stagnantGenerations = 0;
      let completedGenerations = 0;
      let plateauCounter = 0;
      let simplifyMode = false;
      let simplifyRemaining = 0;
      let lastBestFitnessForPlateau = -Infinity;
      const { fs, path } = _EvolutionEngine.#initPersistence(persistDir);
      const flushToFrame = _EvolutionEngine.#makeFlushToFrame();
      const lamarckianTrainingSet = _EvolutionEngine.#buildLamarckianTrainingSet();
      if (lamarckianTrainingSet.length) {
        _EvolutionEngine.#pretrainPopulationWarmStart(neat, lamarckianTrainingSet);
      }
      const doProfile = typeof process !== "undefined" && typeof process.env !== "undefined" && process.env.ASCII_MAZE_PROFILE === "1";
      let tEvolveTotal = 0;
      let tLamarckTotal = 0;
      let tSimTotal = 0;
      let lastCompactionGen = 0;
      const safeWrite = _EvolutionEngine.#makeSafeWriter(dashboardManager);
      while (true) {
        const cancelReason = _EvolutionEngine.#checkCancellation(
          options,
          bestResult
        );
        if (cancelReason) break;
        const genRes = await _EvolutionEngine.#runGeneration(
          neat,
          doProfile,
          lamarckianIterations,
          lamarckianTrainingSet,
          lamarckianSampleSize,
          safeWrite,
          completedGenerations,
          dynamicPopEnabled,
          dynamicPopMax,
          plateauGenerations,
          plateauCounter,
          dynamicPopExpandInterval,
          dynamicPopExpandFactor,
          dynamicPopPlateauSlack
        );
        const fittest = genRes.fittest;
        if (doProfile) {
          tEvolveTotal += genRes.tEvolve || 0;
          tLamarckTotal += genRes.tLamarck || 0;
        }
        if (!_EvolutionEngine.#DISABLE_BALDWIN) {
          try {
            fittest.train(lamarckianTrainingSet, {
              iterations: _EvolutionEngine.#FITTEST_TRAIN_ITERATIONS,
              error: _EvolutionEngine.#DEFAULT_TRAIN_ERROR,
              rate: _EvolutionEngine.#DEFAULT_TRAIN_RATE,
              momentum: _EvolutionEngine.#DEFAULT_TRAIN_MOMENTUM,
              batchSize: _EvolutionEngine.#DEFAULT_TRAIN_BATCH_LARGE,
              allowRecurrent: true
            });
          } catch {
          }
        }
        const fitness = fittest.score ?? 0;
        completedGenerations++;
        ({
          plateauCounter,
          lastBestFitnessForPlateau
        } = _EvolutionEngine.#updatePlateauState(
          fitness,
          lastBestFitnessForPlateau,
          plateauCounter,
          plateauImprovementThreshold
        ));
        ({
          simplifyMode,
          simplifyRemaining
        } = _EvolutionEngine.#handleSimplifyState(
          neat,
          plateauCounter,
          plateauGenerations,
          simplifyDuration,
          simplifyMode,
          simplifyRemaining,
          simplifyStrategy,
          simplifyPruneFraction
        ));
        const simRes = _EvolutionEngine.#simulateAndPostprocess(
          fittest,
          encodedMaze,
          startPosition,
          exitPosition,
          distanceMap,
          agentSimConfig.maxSteps,
          doProfile,
          safeWrite,
          logEvery,
          completedGenerations,
          neat
        );
        const generationResult = simRes.generationResult;
        if (doProfile) tSimTotal += simRes.simTime;
        if (fitness > bestFitness) {
          bestFitness = fitness;
          bestNetwork = fittest;
          bestResult = generationResult;
          stagnantGenerations = 0;
          await _EvolutionEngine.#updateDashboardAndMaybeFlush(
            maze,
            generationResult,
            fittest,
            completedGenerations,
            neat,
            dashboardManager,
            flushToFrame
          );
        } else {
          stagnantGenerations++;
          if (completedGenerations % logEvery === 0) {
            await _EvolutionEngine.#updateDashboardPeriodic(
              maze,
              bestResult,
              bestNetwork,
              completedGenerations,
              neat,
              dashboardManager,
              flushToFrame
            );
          }
        }
        _EvolutionEngine.#persistSnapshotIfNeeded(
          fs,
          path,
          persistDir,
          persistTopK,
          completedGenerations,
          persistEvery,
          neat,
          bestFitness,
          simplifyMode,
          plateauCounter
        );
        const stopReason = await _EvolutionEngine.#checkStopConditions(
          bestResult,
          bestNetwork,
          maze,
          completedGenerations,
          neat,
          dashboardManager,
          flushToFrame,
          minProgressToPass,
          autoPauseOnSolve,
          stopOnlyOnSolve,
          stagnantGenerations,
          maxStagnantGenerations,
          maxGenerations
        );
        if (stopReason) break;
        if (memoryCompactionInterval > 0 && completedGenerations - lastCompactionGen >= memoryCompactionInterval) {
          const removedDisabled = _EvolutionEngine.#compactPopulation(neat);
          if (removedDisabled > 0) {
            _EvolutionEngine.#maybeShrinkScratch(neat);
            safeWrite(
              `[COMPACT] gen=${completedGenerations} removedDisabledConns=${removedDisabled}
`
            );
          }
          lastCompactionGen = completedGenerations;
        }
        if (paceEveryGeneration) {
          try {
            await flushToFrame();
          } catch {
          }
        }
      }
      if (doProfile && completedGenerations > 0) {
        const gen = completedGenerations;
        const avgEvolve = (tEvolveTotal / gen).toFixed(2);
        const avgLamarck = (tLamarckTotal / gen).toFixed(2);
        const avgSim = (tSimTotal / gen).toFixed(2);
        safeWrite(
          `
[PROFILE] Generations=${gen} avg(ms): evolve=${avgEvolve} lamarck=${avgLamarck} sim=${avgSim} totalPerGen=${(+avgEvolve + +avgLamarck + +avgSim).toFixed(2)}
`
        );
        if (_EvolutionEngine.#PROFILE_ENABLED) {
          const det = _EvolutionEngine.#PROFILE_ACCUM;
          const denom = gen || 1;
          safeWrite(
            `[PROFILE_DETAIL] avgTelemetry=${(det.telemetry / denom).toFixed(
              2
            )} avgSimplify=${(det.simplify / denom).toFixed(2)} avgSnapshot=${(det.snapshot / denom).toFixed(2)} avgPrune=${(det.prune / denom).toFixed(2)}
`
          );
        }
      }
      return {
        bestNetwork,
        bestResult,
        neat,
        exitReason: bestResult?.exitReason ?? "incomplete"
      };
    }
    /**
     * Print a concise, human-readable summary of a network's topology and runtime metadata.
     *
     * This method is intentionally a thin orchestrator: heavy lifting is delegated to
     * small private helper methods so callers can quickly understand the high-level
     * structure without digging through implementation details.
     *
     * Props / Parameters:
     * @param network - The network (genome) to inspect. Expected shape: { nodes: any[], connections: any[] }.
     *
     * Returns: void (logs to the console). The function never throws and will tolerate
     * partially-formed network objects.
     *
     * Example:
     * // Print a neat summary of the best evolved network for debugging
     * EvolutionEngine.printNetworkStructure(bestNetwork);
     */
    static printNetworkStructure(network) {
      try {
        console.log("Network Structure:");
        const {
          nodeList,
          inputNodes,
          hiddenNodes,
          outputNodes
        } = _EvolutionEngine.#classifyNodes(network);
        console.log("Nodes:", nodeList.length);
        console.log("  Input nodes:", inputNodes.length);
        console.log("  Hidden nodes:", hiddenNodes.length);
        console.log("  Output nodes:", outputNodes.length);
        const activationNames = _EvolutionEngine.#gatherActivationNames(network);
        console.log("Activation functions:", activationNames);
        const connectionsList = Array.isArray(network?.connections) ? network.connections : [];
        console.log("Connections:", connectionsList.length);
        const hasRecurrentOrGated = _EvolutionEngine.#detectRecurrentOrGated(
          connectionsList
        );
        console.log("Has recurrent/gated connections:", hasRecurrentOrGated);
      } catch (e) {
        console.log(
          "printNetworkStructure: failed to inspect network (partial data)"
        );
      }
    }
    /**
     * Classify nodes into input / hidden / output buckets.
     *
     * Behavior & contract:
     *  - Allocation-light: returns references into the original node array (no cloning).
     *  - Tolerates missing network or sparse node arrays (holes preserved by skipping).
     *  - Reuses a small pooled buckets structure across calls to reduce per-call allocations.
     *
     * Props:
     * @param network - Network-like object with an optional `nodes` array.
     * @returns An object { nodeList, inputNodes, hiddenNodes, outputNodes } where each
     *          bucket is a (pooled) array referencing nodes from the original `nodes`.
     *
     * Example:
     * const { nodeList, inputNodes, hiddenNodes, outputNodes } = EvolutionEngine['#classifyNodes'](someNet);
     * console.log(`inputs=${inputNodes.length} hidden=${hiddenNodes.length} outputs=${outputNodes.length}`);
     */
    static #classifyNodes(network) {
      const normalizedNodeList = _EvolutionEngine.#normalizeNodesArray(network);
      return _EvolutionEngine.#classifyNodesFromArray(normalizedNodeList);
    }
    /**
     * Normalize the incoming network into a safe node list reference.
     * Small helper to keep the main method focused on orchestration.
     */
    static #normalizeNodesArray(network) {
      return Array.isArray(network?.nodes) ? network.nodes : [];
    }
    /**
     * Core classifier that performs a single pass over `nodesArray` and fills three pooled buckets.
     * Implementation notes / steps:
     *  1) Lazily ensure a pooled buckets structure exists on the class to avoid allocating new arrays.
     *  2) Clear the pooled buckets by setting .length = 0 (non-allocating when capacity is sufficient).
     *  3) Iterate the node list once and push references into the appropriate bucket using descriptive names.
     *  4) Return the buckets alongside the original node list.
     *
     * This method intentionally keeps the hot loop tiny and readable.
     */
    static #classifyNodesFromArray(nodesArray) {
      if (!_EvolutionEngine._SCRATCH_NODE_BUCKETS) {
        _EvolutionEngine._SCRATCH_NODE_BUCKETS = [[], [], []];
      }
      const pooledBuckets = _EvolutionEngine._SCRATCH_NODE_BUCKETS;
      const inputBucket = pooledBuckets[0];
      const hiddenBucket = pooledBuckets[1];
      const outputBucket = pooledBuckets[2];
      inputBucket.length = 0;
      hiddenBucket.length = 0;
      outputBucket.length = 0;
      for (let nodeIndex = 0; nodeIndex < nodesArray.length; nodeIndex++) {
        const node = nodesArray[nodeIndex];
        if (!node) continue;
        const nodeType = String(node.type ?? "hidden");
        if (nodeType === "input") {
          inputBucket.push(node);
        } else if (nodeType === "output") {
          outputBucket.push(node);
        } else {
          hiddenBucket.push(node);
        }
      }
      return {
        nodeList: nodesArray,
        inputNodes: inputBucket,
        hiddenNodes: hiddenBucket,
        outputNodes: outputBucket
      };
    }
    /**
     * Populate and return a pooled array of activation function names for the network's nodes.
     * Uses the engine-level SCRATCH_ACT_NAMES pool to avoid per-call allocation.
     */
    static #gatherActivationNames(network) {
      const nodesArray = Array.isArray(network?.nodes) ? network.nodes : [];
      if (!Array.isArray(_EvolutionEngine.#SCRATCH_ACT_NAMES)) {
        _EvolutionEngine.#SCRATCH_ACT_NAMES = [];
      }
      const pooledNames = _EvolutionEngine.#SCRATCH_ACT_NAMES;
      if (pooledNames.length < nodesArray.length)
        pooledNames.length = nodesArray.length;
      for (let i = 0; i < nodesArray.length; i++) {
        const n = nodesArray[i];
        pooledNames[i] = n?.squash?.name ?? String(n?.squash ?? "unknown");
      }
      pooledNames.length = nodesArray.length;
      return pooledNames;
    }
    /**
     * Detect whether any connection is recurrent (from === to) or gated (has a gater).
     * Accepts the connections list as input to avoid re-indexing network object.
     * Uses a small pooled Int8Array as a temporary flag buffer when the connection list is large.
     */
    static #detectRecurrentOrGated(connectionsList) {
      if (!Array.isArray(connectionsList) || connectionsList.length === 0)
        return false;
      const listLen = connectionsList.length;
      const SMALL_LIST_THRESHOLD = 128;
      if (listLen < SMALL_LIST_THRESHOLD) {
        for (let index = 0; index < listLen; index++) {
          const connection = connectionsList[index];
          if (!connection) continue;
          if (connection.gater) return true;
          if (connection.from === connection.to) return true;
        }
        return false;
      }
      try {
        const pooledFlags = _EvolutionEngine.#ensureConnFlagsCapacity(listLen);
        if (!pooledFlags) {
          for (let index = 0; index < listLen; index++) {
            const connection = connectionsList[index];
            if (!connection) continue;
            if (connection.gater || connection.from === connection.to)
              return true;
          }
          return false;
        }
        for (let index = 0; index < listLen; index++) {
          const connection = connectionsList[index];
          if (!connection) continue;
          if (connection.gater) return true;
          if (connection.from === connection.to) return true;
          pooledFlags[index] = 1;
        }
        return false;
      } catch {
        for (let index = 0; index < listLen; index++) {
          const connection = connectionsList[index];
          if (!connection) continue;
          if (connection.gater || connection.from === connection.to) return true;
        }
        return false;
      }
    }
    /**
     * Ensure the pooled connection-flag Int8Array has at least `minCapacity` entries.
     * Returns the pooled buffer or `null` when allocation fails.
     */
    static #ensureConnFlagsCapacity(minCapacity) {
      try {
        const clsAny = _EvolutionEngine;
        const existing = clsAny._SCRATCH_CONN_FLAGS;
        if (existing instanceof Int8Array && existing.length >= minCapacity)
          return existing;
        let cap = 1;
        while (cap < minCapacity) cap <<= 1;
        const newBuf = new Int8Array(cap);
        clsAny._SCRATCH_CONN_FLAGS = newBuf;
        return newBuf;
      } catch {
        return null;
      }
    }
  };

  // test/examples/asciiMaze/mazes.ts
  var MazeGenerator = class _MazeGenerator {
    #width;
    #height;
    #grid = [];
    #startX = 0;
    #startY = 0;
    #farthest = { x: 0, y: 0, depth: 0 };
    // Cell markers
    static WALL = 1;
    static PATH = 0;
    static START = 2;
    static EXIT = 3;
    constructor(rawWidth, rawHeight) {
      this.#width = rawWidth;
      this.#height = rawHeight;
      this.#normalizeDimensions();
      this.#initializeGrid();
      this.#carvePerfectMaze();
      this.#markStartAndExit();
    }
    /**
     * STEP 1: Normalize requested dimensions.
     * - Floors values.
     * - Enforces minimum size 5.
     * - Forces odd numbers so corridors are one cell thick with surrounding walls.
     */
    #normalizeDimensions() {
      this.#width = Math.max(5, Math.floor(this.#width));
      this.#height = Math.max(5, Math.floor(this.#height));
      if (this.#width % 2 === 0) this.#width -= 1;
      if (this.#height % 2 === 0) this.#height -= 1;
    }
    /**
     * STEP 2: Initialize full wall grid and compute central starting cell (odd coordinates).
     */
    #initializeGrid() {
      this.#grid = Array.from(
        { length: this.#height },
        () => Array.from({ length: this.#width }, () => _MazeGenerator.WALL)
      );
      const toOdd = (value) => value % 2 === 0 ? value - 1 : value;
      this.#startX = toOdd(Math.floor(this.#width / 2));
      this.#startY = toOdd(Math.floor(this.#height / 2));
      this.#grid[this.#startY][this.#startX] = _MazeGenerator.PATH;
      this.#farthest = { x: this.#startX, y: this.#startY, depth: 0 };
    }
    /**
     * Helper: bounds check for safe coordinate access.
     */
    #inBounds(column, row) {
      return column >= 0 && row >= 0 && column < this.#width && row < this.#height;
    }
    /**
     * STEP 3: Carve a perfect maze using an iterative depth-first search (recursive backtracker).
     * Maintains a stack of frontier cells; at each step chooses a random unvisited neighbor
     * two cells away, carving both the intermediary wall cell and the target cell. Tracks
     * the farthest cell (by depth) from the start for later exit placement.
     */
    #carvePerfectMaze() {
      const stack = [
        { x: this.#startX, y: this.#startY, depth: 0 }
      ];
      while (stack.length) {
        const current = stack[stack.length - 1];
        const neighborDirections = [
          { deltaX: 0, deltaY: -2 },
          { deltaX: 2, deltaY: 0 },
          { deltaX: 0, deltaY: 2 },
          { deltaX: -2, deltaY: 0 }
        ];
        for (let remaining = neighborDirections.length - 1; remaining > 0; remaining--) {
          const randomFloat = Math.random();
          const swapIndex = randomFloat * (remaining + 1) | 0;
          if (swapIndex !== remaining) {
            const tmp = neighborDirections[remaining];
            neighborDirections[remaining] = neighborDirections[swapIndex];
            neighborDirections[swapIndex] = tmp;
          }
        }
        const unvisited = [];
        for (const direction of neighborDirections) {
          const nextX = current.x + direction.deltaX;
          const nextY = current.y + direction.deltaY;
          if (!this.#inBounds(nextX, nextY)) continue;
          if (nextX <= 0 || nextY <= 0 || nextX >= this.#width - 1 || nextY >= this.#height - 1)
            continue;
          if (this.#grid[nextY][nextX] !== _MazeGenerator.WALL) continue;
          unvisited.push({
            nextX,
            nextY,
            wallX: current.x + direction.deltaX / 2,
            wallY: current.y + direction.deltaY / 2
          });
        }
        if (unvisited.length === 0) {
          stack.pop();
          continue;
        }
        const chosen = unvisited[0];
        this.#grid[chosen.wallY][chosen.wallX] = _MazeGenerator.PATH;
        this.#grid[chosen.nextY][chosen.nextX] = _MazeGenerator.PATH;
        const depth = current.depth + 1;
        stack.push({ x: chosen.nextX, y: chosen.nextY, depth });
        if (depth > this.#farthest.depth)
          this.#farthest = { x: chosen.nextX, y: chosen.nextY, depth };
      }
    }
    /**
     * STEP 4: Mark start and farthest cell (exit) on the grid.
     */
    #markStartAndExit() {
      this.#grid[this.#startY][this.#startX] = _MazeGenerator.START;
      this.#placeEdgeExit();
    }
    /**
     * Compute shortest-path distances (BFS) from the start across carved PATH cells.
     * @returns 2D array of distances (or -1 if unreachable).
     */
    #computeDistances() {
      const distances = Array.from(
        { length: this.#height },
        () => Array.from({ length: this.#width }, () => -1)
      );
      const queue = [];
      queue.push({ x: this.#startX, y: this.#startY });
      distances[this.#startY][this.#startX] = 0;
      let readIndex = 0;
      while (readIndex < queue.length) {
        const current = queue[readIndex++];
        const baseDistance = distances[current.y][current.x];
        const neighbors = [
          { x: current.x, y: current.y - 1 },
          { x: current.x + 1, y: current.y },
          { x: current.x, y: current.y + 1 },
          { x: current.x - 1, y: current.y }
        ];
        for (const neighbor of neighbors) {
          if (!this.#inBounds(neighbor.x, neighbor.y)) continue;
          const cell = this.#grid[neighbor.y][neighbor.x];
          if (![_MazeGenerator.PATH, _MazeGenerator.START].includes(cell) || distances[neighbor.y][neighbor.x] !== -1)
            continue;
          distances[neighbor.y][neighbor.x] = baseDistance + 1;
          queue.push(neighbor);
        }
      }
      return distances;
    }
    /**
     * Select a border-adjacent interior path cell maximizing distance from the start
     * and open an actual edge (outer frame) cell, marking that outer cell as EXIT.
     * If no interior candidate is found (degenerate tiny maze), fallback to previous
     * farthest internal cell marking.
     */
    #placeEdgeExit() {
      const distances = this.#computeDistances();
      const candidates = [];
      for (let y = 1; y < this.#height - 1; y++) {
        for (let x = 1; x < this.#width - 1; x++) {
          if (distances[y][x] < 0) continue;
          if (this.#grid[y][x] === _MazeGenerator.START) continue;
          if (y === 1) {
            candidates.push({
              interiorX: x,
              interiorY: y,
              borderX: x,
              borderY: 0,
              distance: distances[y][x]
            });
          }
          if (y === this.#height - 2) {
            candidates.push({
              interiorX: x,
              interiorY: y,
              borderX: x,
              borderY: this.#height - 1,
              distance: distances[y][x]
            });
          }
          if (x === 1) {
            candidates.push({
              interiorX: x,
              interiorY: y,
              borderX: 0,
              borderY: y,
              distance: distances[y][x]
            });
          }
          if (x === this.#width - 2) {
            candidates.push({
              interiorX: x,
              interiorY: y,
              borderX: this.#width - 1,
              borderY: y,
              distance: distances[y][x]
            });
          }
        }
      }
      if (candidates.length === 0) {
        this.#grid[this.#farthest.y][this.#farthest.x] = _MazeGenerator.EXIT;
        return;
      }
      candidates.sort((a, b) => b.distance - a.distance);
      const chosen = candidates[0];
      if (this.#grid[chosen.interiorY][chosen.interiorX] === _MazeGenerator.EXIT)
        this.#grid[chosen.interiorY][chosen.interiorX] = _MazeGenerator.PATH;
      this.#grid[chosen.borderY][chosen.borderX] = _MazeGenerator.EXIT;
    }
    /**
     * STEP 5: Derive box drawing wall character from neighboring wall continuity.
     * Considers the four cardinal neighbors as wall/not-wall and maps bitmask to glyph.
     * Falls back to a solid block if an unexpected isolated pattern appears.
     */
    #wallGlyph(column, row) {
      const isWall = (c, r) => this.#inBounds(c, r) && ![_MazeGenerator.PATH, _MazeGenerator.START, _MazeGenerator.EXIT].includes(
        this.#grid[r][c]
      );
      const north = isWall(column, row - 1);
      const east = isWall(column + 1, row);
      const south = isWall(column, row + 1);
      const west = isWall(column - 1, row);
      const mask = (north ? 1 : 0) | (east ? 2 : 0) | (south ? 4 : 0) | (west ? 8 : 0);
      switch (mask) {
        case 5:
        case 1:
        case 4:
          return "\u2551";
        case 10:
        case 2:
        case 8:
          return "\u2550";
        case 3:
          return "\u255A";
        case 9:
          return "\u255D";
        case 6:
          return "\u2554";
        case 12:
          return "\u2557";
        case 14:
          return "\u2566";
        case 11:
          return "\u2569";
        case 7:
          return "\u2560";
        case 13:
          return "\u2563";
        case 15:
          return "\u256C";
        default:
          return "\u2588";
      }
    }
    /**
     * STEP 6: Render final ASCII maze lines.
     * Preserves a continuous rectangular outer frame using the standard corner/edge glyphs.
     */
    #render() {
      const lines = [];
      for (let rowIndex = 0; rowIndex < this.#height; rowIndex++) {
        let rendered = "";
        for (let columnIndex = 0; columnIndex < this.#width; columnIndex++) {
          const cellValue = this.#grid[rowIndex][columnIndex];
          if (cellValue === _MazeGenerator.PATH) rendered += ".";
          else if (cellValue === _MazeGenerator.START) rendered += "S";
          else if (cellValue === _MazeGenerator.EXIT) rendered += "E";
          else if (rowIndex === 0 && columnIndex === 0) rendered += "\u2554";
          else if (rowIndex === 0 && columnIndex === this.#width - 1)
            rendered += "\u2557";
          else if (rowIndex === this.#height - 1 && columnIndex === 0)
            rendered += "\u255A";
          else if (rowIndex === this.#height - 1 && columnIndex === this.#width - 1)
            rendered += "\u255D";
          else if (rowIndex === 0 || rowIndex === this.#height - 1)
            rendered += "\u2550";
          else if (columnIndex === 0 || columnIndex === this.#width - 1)
            rendered += "\u2551";
          else rendered += this.#wallGlyph(columnIndex, rowIndex);
        }
        lines.push(rendered);
      }
      return lines;
    }
    /**
     * Public entry: returns the rendered maze as string lines.
     */
    generate() {
      return this.#render();
    }
  };

  // test/examples/asciiMaze/refineWinner.ts
  init_network();
  function refineWinnerWithBackprop(winner) {
    if (!winner) return void 0;
    try {
      winner.nodes.forEach((node) => {
        if (typeof node.squash !== "function") {
          node.squash = methods_exports.Activation.logistic;
        }
      });
    } catch {
    }
    const trainingSet = [];
    const OUT = (dirIndex) => [0, 1, 2, 3].map((i) => i === dirIndex ? 0.92 : 0.02);
    const add = (inp, d) => trainingSet.push({ input: inp, output: OUT(d) });
    const compassDirs = [0, 0.25, 0.5, 0.75];
    for (let dir = 0; dir < 4; dir++) {
      const compass = compassDirs[dir];
      const open = [0, 0, 0, 0];
      open[dir] = 1;
      add([compass, ...open, 0.85], dir);
      add([compass, ...open, 0.65], dir);
      add([compass, ...open, 0.55], dir);
      add([compass, ...open, 0.5], dir);
    }
    try {
      winner.train(trainingSet, {
        iterations: 220,
        error: 5e-3,
        rate: 1e-3,
        momentum: 0.1,
        batchSize: 8,
        cost: methods_exports.Cost.softmaxCrossEntropy
      });
    } catch {
    }
    try {
      return winner.clone();
    } catch {
      return winner;
    }
  }

  // test/examples/asciiMaze/browser-entry.ts
  var DEFAULT_CONTAINER_ID = "ascii-maze-output";
  var RESIZE_WIDTH_THRESHOLD = 8;
  var RESIZE_DEBOUNCE_MS = 120;
  var AUTO_START_DELAY_MS = 20;
  var MIN_PROGRESS_TO_PASS = 90;
  var DEFAULT_MAX_STAGNANT_GENERATIONS = 50;
  var DEFAULT_MAX_GENERATIONS = 100;
  var PER_GENERATION_LOG_FREQUENCY = 1;
  var INITIAL_MAZE_DIMENSION = 8;
  var MAX_MAZE_DIMENSION = 40;
  var MAZE_DIMENSION_INCREMENT = 4;
  var AGENT_MAX_STEPS = 600;
  var POPULATION_SIZE = 20;
  function createEvolutionSettings(dimension) {
    return {
      agentMaxSteps: AGENT_MAX_STEPS,
      popSize: POPULATION_SIZE,
      maxStagnantGenerations: DEFAULT_MAX_STAGNANT_GENERATIONS,
      maxGenerations: DEFAULT_MAX_GENERATIONS,
      lamarckianIterations: 4,
      lamarckianSampleSize: 12,
      mazeFactory: () => new MazeGenerator(dimension, dimension).generate()
    };
  }
  var TelemetryHub = class {
    /** Registered listener callbacks (unique). */
    #listeners = /* @__PURE__ */ new Set();
    /** Add a listener and return an unsubscribe function. */
    add(listener) {
      this.#listeners.add(listener);
      return () => this.#listeners.delete(listener);
    }
    /** Dispatch to a snapshot of listeners so mutations during iteration are safe. */
    dispatch(payload) {
      const snapshot = Array.from(this.#listeners);
      for (const listener of snapshot) {
        try {
          listener(payload);
        } catch {
        }
      }
    }
  };
  async function start(container = DEFAULT_CONTAINER_ID, opts = {}) {
    const hostElement = typeof container === "string" ? document.getElementById(container) : container;
    const archiveElement = hostElement ? hostElement.querySelector("#ascii-maze-archive") : null;
    const liveElement = hostElement ? hostElement.querySelector("#ascii-maze-live") : null;
    const clearer = BrowserTerminalUtility.createTerminalClearer(
      liveElement ?? void 0
    );
    const liveLogger = createBrowserLogger(liveElement ?? void 0);
    const archiveLogger = createBrowserLogger(archiveElement ?? void 0);
    const dashboard = new DashboardManager(
      clearer,
      liveLogger,
      archiveLogger
    );
    const telemetryHub = new TelemetryHub();
    dashboard._telemetryHook = (telemetry) => telemetryHub.dispatch(telemetry);
    try {
      const observeTarget = hostElement ?? document.getElementById("ascii-maze-output");
      if (observeTarget && typeof ResizeObserver !== "undefined") {
        let lastObservedWidth = observeTarget.clientWidth;
        const resizeObserver = new ResizeObserver((entries) => {
          for (const entry of entries) {
            const width = entry.contentRect.width;
            if (Math.abs(width - lastObservedWidth) > RESIZE_WIDTH_THRESHOLD) {
              lastObservedWidth = width;
              try {
                dashboard.redraw?.([], void 0);
              } catch {
              }
            }
          }
        });
        resizeObserver.observe(observeTarget);
      } else if (observeTarget) {
        let debounceTimer = void 0;
        const handler = () => {
          if (typeof debounceTimer === "number") clearTimeout(debounceTimer);
          debounceTimer = window.setTimeout(() => {
            try {
              dashboard.redraw?.([], void 0);
            } catch {
            }
          }, RESIZE_DEBOUNCE_MS);
        };
        window.addEventListener("resize", handler);
      }
    } catch {
    }
    let cancelled = false;
    const internalController = new AbortController();
    const externalSignal = opts.signal;
    const composeAbortSignal = (maybeExternal) => {
      if (maybeExternal) {
        if (maybeExternal.aborted) return maybeExternal;
        if (typeof AbortSignal.any === "function") {
          try {
            return AbortSignal.any([
              maybeExternal,
              internalController.signal
            ]);
          } catch {
          }
        }
        try {
          maybeExternal.addEventListener(
            "abort",
            () => {
              try {
                internalController.abort();
              } catch {
              }
            },
            { once: true }
          );
        } catch {
        }
      }
      return internalController.signal;
    };
    const combinedSignal = composeAbortSignal(externalSignal);
    let running = true;
    try {
      combinedSignal.addEventListener(
        "abort",
        () => {
          cancelled = true;
          running = false;
          try {
            resolveDone?.();
          } catch {
          }
        },
        { once: true }
      );
    } catch {
    }
    let currentDimension = INITIAL_MAZE_DIMENSION;
    let resolveDone;
    const donePromise = new Promise((resolve) => resolveDone = resolve);
    let previousBestNetwork;
    const scheduleNextMaze = (cb) => {
      try {
        if (typeof requestAnimationFrame === "function")
          requestAnimationFrame(cb);
        else setTimeout(cb, 0);
      } catch {
        setTimeout(cb, 0);
      }
    };
    const runEvolution = async () => {
      if (cancelled) {
        running = false;
        resolveDone?.();
        return;
      }
      const settings = createEvolutionSettings(currentDimension);
      const mazeLayout = settings.mazeFactory();
      let solved = false;
      try {
        const result = await EvolutionEngine.runMazeEvolution({
          mazeConfig: { maze: mazeLayout },
          agentSimConfig: { maxSteps: settings.agentMaxSteps },
          evolutionAlgorithmConfig: {
            allowRecurrent: true,
            popSize: settings.popSize,
            maxStagnantGenerations: settings.maxStagnantGenerations,
            minProgressToPass: MIN_PROGRESS_TO_PASS,
            maxGenerations: settings.maxGenerations,
            autoPauseOnSolve: false,
            stopOnlyOnSolve: false,
            lamarckianIterations: settings.lamarckianIterations,
            lamarckianSampleSize: settings.lamarckianSampleSize,
            initialBestNetwork: previousBestNetwork
          },
          reportingConfig: {
            dashboardManager: dashboard,
            logEvery: PER_GENERATION_LOG_FREQUENCY,
            label: `browser-procedural-${currentDimension}x${currentDimension}`,
            paceEveryGeneration: true
            // custom flag (consumed if supported) to yield between generations
          },
          cancellation: { isCancelled: () => cancelled },
          signal: combinedSignal
        });
        const progress = result?.bestResult?.progress;
        try {
          const bestNet = result?.bestNetwork;
          if (bestNet) {
            const refined = refineWinnerWithBackprop(bestNet);
            previousBestNetwork = refined || bestNet;
          }
        } catch {
        }
        solved = typeof progress === "number" && progress >= MIN_PROGRESS_TO_PASS;
        try {
          console.log(
            "[asciiMaze] maze complete",
            currentDimension,
            "solved?",
            solved,
            "progress",
            progress
          );
        } catch {
        }
      } catch (error) {
        console.error(
          "Error while running procedural maze",
          currentDimension,
          error
        );
      }
      if (!cancelled && solved && currentDimension < MAX_MAZE_DIMENSION) {
        currentDimension = Math.min(
          currentDimension + MAZE_DIMENSION_INCREMENT,
          MAX_MAZE_DIMENSION
        );
        scheduleNextMaze(() => runEvolution());
      } else {
        running = false;
        resolveDone?.();
      }
    };
    runEvolution();
    const handle = {
      stop: () => {
        cancelled = true;
        try {
          internalController.abort();
        } catch {
        }
        running = false;
      },
      // Include AbortSignal aborted state so external aborts flip isRunning() without relying solely on listener side-effects.
      isRunning: () => running && !cancelled && !combinedSignal.aborted,
      done: Promise.resolve(donePromise).catch(() => {
      }),
      onTelemetry: (telemetryCallback) => telemetryHub.add(telemetryCallback),
      getTelemetry: () => dashboard.getLastTelemetry?.()
    };
    return handle;
  }
  if (typeof window !== "undefined" && window.document) {
    const globalWindow = window;
    globalWindow.asciiMaze = globalWindow.asciiMaze || {};
    globalWindow.asciiMaze.start = start;
    if (!globalWindow.asciiMazeStart) {
      globalWindow.asciiMazeStart = (containerElement) => {
        console.warn(
          "[asciiMaze] window.asciiMazeStart is deprecated; use import { start } ... or window.asciiMaze.start"
        );
        return start(containerElement);
      };
    }
    if (!globalWindow.asciiMaze._autoStarted) {
      globalWindow.asciiMaze._autoStarted = true;
      setTimeout(() => {
        try {
          if (document.getElementById(DEFAULT_CONTAINER_ID)) start();
        } catch {
        }
      }, AUTO_START_DELAY_MS);
    }
  }
})();
//# sourceMappingURL=ascii-maze.bundle.js.map
